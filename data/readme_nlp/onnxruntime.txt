onnxruntime onnxruntime provides inofficial julia bindings onnxruntime exposes low level interface mirrors official api level interface contributions welcome usage level api follows julia import onnxruntime ox julia path ox testdatapath incrementxonnx path toy model julia model ox loadinference path julia input dict input randn float dictstring matrixfloat entry input julia model input dictstring matrixfloat entry output gpu usage simply pkg add cuda julia import cuda julia ox loadinference path executionprovider cuda low level api mirrors offical api example looks using onnxruntime capi using onnxruntime testdatapath api getapi env createenv api name myenv createsessionoptions api path testdatapath incrementxonnx session createsession api env path mem createcpumemoryinfo api inputarray randn float inputtensor createtensorwithdataasortvalue api mem vec inputarray size inputarray runoptions createrunoptions api inputnames input outputnames output inputs inputtensor outputs run api session runoptions inputnames inputs outputnames outputtensor outputs outputarray gettensormutabledata api outputtensor alternatives onnxruntime python bindings via pycalljl onnxjl onnxnaivenasfluxjl