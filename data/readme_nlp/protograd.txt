protogradjl protograd experimental julia package gradientbased model optimization including course deep learning aims simple composable flexible progress playground ideas expect feature completeness stability package builds top mature popular libraries zygote automatic differentiation nnlib providing common operators deep learning check examples folder protograd construct train models following readme feeling package philosophy begins naturally using protograd models models callable objects type extends protogradmodel abstract type following overly simple example defines type linear model version protogradlinear struct linearmodel protogradmodel linearmodel attributes model interpreted parameters optimized gradients respect assumed attributes numerical arrays type abstractarrayabstractfloat functions model objects tuple objects types note means example hyperparamenters stored attributes hyperparameters implicit model structure layers units otherwise stored type parameters value types models defined structure vector space free linearmodel randn randn mscaled type linearmodel msum mscaled mainlinearmodel dotsyntax assignment loop fusion mscaled msum mscaled mainlinearmodel dot products using linearalgebra dot msum objective functions training model usually amounts optimizing objective function principle custom function model example mean squared error meansquarederror yhat sum yhat size meansquarederror generic function method data artificially generated according random noisy linear model aoriginal randn boriginal randn randn aoriginal boriginal randn define objective objective model meansquarederror model objective returns loss value stochastic approximations data objective implemented iterating data batches coupling loss follows using statsbase batchsize batches protograd forever idx sample size batchsize replace false return idx idx stochasticobjective protograd supervisedobjective meansquarederror batches protogradsupervisedobjectivetypeofmainmeansquarederror basegeneratorbaseiteratorsrepeated protogradvarmainvar tuplematrixfloat matrixfloat meansquarederror basegeneratorbaseiteratorsrepeated protogradvarmainvarprotogradvarmainvarmainvar baseiteratorsrepeated evaluating objective yield stochasticobjective println stochasticobjective println value stochasticobjective println stochasticobjective println time gradient computation computing gradient objective respect model easy grad val protograd gradient objective mainlinearmodel val value objective evaluated grad contains gradient respect attributes importantly grad linearmodel object grad added subtracted dot products fitting models objective fitting models using gradientbased algorithms relatively simple following loop plain gradient descent constant stepsize mfit copy grad protograd gradient objective mfit mfit mfit grad warning assignment grad soft scope ambiguous global variable name exists grad treated local disambiguate using local grad suppress warning global grad assign existing global variable string verify check objective value mfit objective mfit returns loss value compared protograd implements gradient descent optimization algorithms form iterators following yield iterations optimizer protograd gradientdescent stepsize e iterations iterators optimizer objective baseiteratorsprotogradgradientdescentiterablemainlinearmodel mainvar floatprotogradgradientdescentiterablemainlinearmodel mainvar floatmainlinearmodel mainvar iterations object iterator looped elements inspected example decide stop training sake compactness output iteration solution mfit protograd iterations solution mainlinearmodel page generated using literatejl