continuoustimepolicygradients continuoustimepolicygradientsjl package development implementation continuoustime policy gradient ctpg methods notes package wip include verbose tutorials julia differentialequationsjl etc thanks namhoon cho shared materials initial efforts investigate ctpg methods similar packages written julia focusing control policy optimisation based continuoustime adjoint sensitivity method include ctpg developed samuel ainsworth controlneuralode developed ilya orson citation continuoustimepolicygradientsjl developed considering control tasks main application ctpg method cost gradient computation utilised perform policy optimisation setup background planning offline control law learning decisiontime planning online control profile optimisation following paper addresses optimisation structured neural controller using ctpg flight vehicle normal acceleration tracking controller illustrating example please consider citing paper package useful namhoon cho hyosang shin optimisation structured neural controller based continuoustime policy gradient arxiv january level training interface ctpgtrain ctpgtrain dynamicsplant function dynamicscontroller function costrunning function costterminal function costregularisor function policynn scenario solvealg tsit sensealg interpolatingadjoint autojacvec zygotevjp ensemblealg ensemblethreads opt adam opt lbfgs maxiters maxiters progressplot true solvekwargs ctpgtrain provides level interface optimisation neural networks inside oderepresented dynamics based continuoustime policy gradient ctpg methods belong adjoint sensitivity analysis techniques code implemented default values keyword arguments specified considering training neural controller main application context herein neural controller refers dynamic controller incorporates neuralnetworkrepresented components mathematical description code utilises functionalities provided diffeqfluxjl diffeqsensitivityjl packages automatic differentiation ad capabilities provided zygotejl package integrated diffeqfluxjl ctpgtrain presumes consistency functions provided input arguments ad tool hence dynamics cost functions maintain transparence ad tools optimisation training minimises cost function defined deterministic samples initial plant x reference performing ensemble simulation based parallelised computation signals defined described time plant plant output sensor output xc controller plant input controller output exogenous reference xaug augmented forward dynamics xc costrunning pnn neural network parameter arguments provided explained dynamicsplant describes dynamics plant controlled input arguments vector type dynamicscontroller describes dynamics controller includes neural networks components input arguments xc pnn vector type dynamicssensor describes dynamics sensor measures output variables fed controller input arguments vector type costrunning describes running cost defined integrand lagrangeform continuous functional input arguments vector type costterminal describes terminal cost defined mayerform cost function defines bolzaform costrunning input arguments xf vector type costregularisor describes regularisation term appended cost loss function input argument pnn vector type policynn neural networks entering controller dynamics diffeqfluxbased fastchain recommended construction scenario contains parameters related ensemblebased training scenarios ensemble vector initial plant x reference constituting trajectory realisations tspan time span forwardpass integration tsave array time saved solving ode typically defined tsave tspantsavetspan dimx length dimxc lengthxc keyword arguments provided explained solvealg algorithm solving odes default value tsit sensealg algorithm adjoint sensitivity analysis default value interpolatingadjointautojacvec zygotevjp control usually render backsolveadjoint unstable vjp choice autojacvec reversediffvjptrue usually faster zygotevjp ode function branching inside please refer diffeqflux documentation details ensemblealg algorithm handling ensemble odes default value ensemblethreads multithreaded computation cpu opt algorithm phase optimisation rapidly delivers parameter favourable region local minimum default value adam opt algorithm phase opitmisaiton defalut value lbfgs refines result phase precise minimum please refer diffeqflux documentation details phase composition optimisers maxiters maximum iterations allowed phase optimisation opt defalut value maxiters maximum iterations allowed phase optimisation opt defalut value progressplot indicator plot history nominal condition ensemble learning process default value true inominal index select plot using progressplot optimisation process ensemble defined scenario defalut value pnn initial value nn parameters supplied user bypass random initialisation pnn continue optimisation previous result defalut value solvekwargs additional keyword arguments passed onto ode solver ctpgtrain returns following outputs result final result parameter optimisation fwdensemblesol ensemble solution forward simulation using final neural network parameters losshistory history loss function evaluated iter