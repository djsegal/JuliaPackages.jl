arrayallezjl add arrayallez log exp conveniently choose yeppp appleaccelerate intelvectormath requiring installed fallback version loop threads arrays rand exp precisely exp log loop using appleaccelerate using intelvectormath using yeppp exp mutates log copies besides log exp scale understands rowscolumns iscale divides inv elementwise inverse mutating versions instead simple broadcasted versions ones rand rand scale simply scale using rmul iscale mutating commands attempt define gradients tracker ans zygote caveat emptor exp mutates forward input backward gradient terrible idea using tracker param randn exp tracker sum exp data true grad package defines gradients prod overwriting incorrect cumprod pr array experiment lrucache space rand size copy copy similar sim array float btime ns bytes inv inv functions opt dropdims macro wraps reductions sum dims dropdims understands dropdims sum randn dims trunc int removed package provide functions generalising matrix multiplication handled packages tensorcoreboxdot contracts neighbours rand rand size nnlibbatchedmul batch dimension rand rand size vectorizejl comprehensive wrapper stridedjl adds threads broadcasting loopvectorizationjl adds avx black mag