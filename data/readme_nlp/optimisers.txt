optimisersjl optimisersjl defines standard gradientbased optimisation rules tools applying deeply nested models future training fluxjl neural networks luxjl separately array else understood functorsjl installation add optimisers usage core idea optimiser momentum explicitly handled initialised setup step update returns model trainable parameters adjusted optimisers setup optimisers adam model grad zygote gradient loss model model optimisers update model grad step models deeply nested layers containing parameters fluxjl models similarly nested tree gradient using zygote explicit style shown implicit params function destructure collects trainable parameters vector returns function rebuild similar model vector re optimisers destructure model model re vector documentation explains usage detail describes optimization rules define on