jldistributedfluxml package fluxml train evaluate inference analyze models distributed cluster moment slurm cluster manager tested getting started comming soon training examples assumes partitioned data multiple dataframe serialized using serialization package shardfilelist using distributed addproc using distributedfluxml batchsize epochs deserfut spawnat global rawdata deserialize zip shardfilelist fut deserfut waitfut labels irisversicolor irisvirginica irissetosa xarray arrayrawdata sepall sepalw petall petalw yarray fluxonehotbatchrawdataclass labels datachan channel ch nchunk ceilintsizexarraybatchsize xdat fluxchunktransposexarray nchunk ydat fluxchunkyarray nchunk epoch epochs zipxdat ydat ch ch datremchan remotechannel datachan myid trainworkersshift circshift shift workers reuse workers remote data hosts datremchansdict dict fetchfrom datremchan zip trainworkersshift lossf fluxlosseslogitcrossentropy opt fluxoptimiseadam model chaindensedense dense emptystatusarray distributedfluxmltrainlossf model datremchansdict opt statuschan custom gradiant calc argument gradcalc train meant novel nomalization schemes example datachannel returns touple desired grad calc coule function nodenormgradcalcxsy lossf model devicegpu xsy lossfmodel aggsum opt reduce using distributed addproc using distributedfluxml distributedfluxmloptoutallreduceinit mockvals allrfut spawnat distributedfluxmloptoutallreduceallreduce zipmockvals fetchfut fut allrfut mockvals skip allrfut spawnat distributedfluxmloptoutallreduceallreduce zipmockvals fetchfut fut allrfut