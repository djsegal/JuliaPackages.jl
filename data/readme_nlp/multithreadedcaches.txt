multithreadedcaches multithreadedcache fastish threadsafe cache cache stores pairs cache deterministic computation api cache look key available produce value added cache accesses cache look thread cache fall shared threadsafe cache concurrent misses key shared cache coordinate task perform compuatation value task block thread caches low contention usually locked single task multithreadedcache scales naive baseline dictreentrantlock instead alternatives considered approaches concurrent caches include concurrent hash table theory package advantage append aspect cache contention benefits conventional multithreaded dictionary practice actually true adjustments account task migration benefits current design multithread caches designed low contention sharding key space keeping separate lock subcache example array separate caches sharded prefix key hash lock package differs design sharding hash thread id key space tradeoff accepts data duplication exchange hopefully contention example julia cache multithreadedcache int int dict multithreadedcache int int dict julia initcache cache multithreadedcache int int dict julia cache julia cache accesses safe arbitrary threads julia cache performance current benchmark results measuring scaling recorded baseline dict reentrantlock info benchmark results threadsnthreads timeserial timeparallel timebaseline info benchmark results threadsnthreads timeserial timeparallel timebaseline info benchmark results threadsnthreads timeserial timeparallel timebaselin