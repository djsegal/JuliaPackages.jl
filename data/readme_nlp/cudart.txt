cudart note package actively developed please cudadrv instead build status code coverage package wraps cuda runtime api wrapper driver api cudadrv cudadrvjl preferred program gpu julia cudartjl require runtime api platform support tested linux osx windows windows visual studio supported installation nvidia gpu device computer available computation graphics card cuda library installed perform steps manually choose bit bit versions match julia installation install julia package using pkg add cudart installation compile couple files deps directory files provide utility functions functionality package build step fails try fixing running pkgbuildcudart manually installation probably idea run testruntestsjl script system pkgtestcudart errors check cuda installation example examine ptx files deps test look files appropriate computer bit compiled bit usage start saying using cudart import cudart prefer qualify module name install import cudadrv package provides functionality launch kernels gpu initialization gpus initialized computations freed complexities process due interaction julia garbage collection cuda array object allocated session usable close device session fortunately cudart process transparent user easiest ensure functionality proper cleanup resources using block syntax result devices dev true devlist code gpu computations argument devices function accepts integer input integer representing cuda device starting returns true false indicating device respectively devtrue means device devlist variable defined inside block vectorint available devices devices sufficient capabilities construct result devices dev capability dev devlist code gpu computations select devices major capability query properties device deviceproperties attribute functions list fields restrict computations device leaving devices users nmax keyword result devices func nmax devlist code gpu computations finally request devices busy tasks using result devices func status free devlist code gpu computations wait specific devices available waitfreedevlist block syntax initializes devices loads utility functions defined deps onto gpu ensures proper freeing memory unloading code block finishes initialize utilities manually calling cudartinitdevlist cudartclosedevlist devlist integer device list handy trouble unfortunately syntax usually result ideal backtraces require utility functions manually manage device device dev code gpu computations devicereset dev dev integer device choosingquerying active device code command devicedev makes dev active device example commands allocate device memory executed whichever device currently active calling dev device return currentlyactive device arrays device arrays cudart supports main types device arrays cudaarray cudapitchedarray correspond contiguous memory blocks pitched pointers respectively declare uninitialized array device da cudaarray float db cudapitchedarray int d conventional reminding array allocated device copy host array device da cudaarray dap cudapitchedarray copy da copy dap copy device array host tohost da copy da typical julia functions size ndims reinterpret eltype fill etc cuda array types noteworthy omission directly index cuda array da fail supported hostdevice memory transfers relatively slow write code host makes individual elements device array inspect values device array tohost copy host memory device storing array using dev device da host arrays array type hostarray allocated cuda library using pinned memory ha hostarray float circumstances using hostarray improve speed memory transfers allow asynchronous operations using stream warning using hostarray conjunction memorymapped file observed cause segfaults time workaround modules custom kernels teach cuda programming please refer cuda documentation online sources example file deps compiling modules write custom kernels writing cu file compiling ptx module linux compilation look nvcc ptx specify code compiled compute capability devices using nvcc ptx gencodearchcomputecodesm write code support multiple datatypes float float recommended write code using templates extern instantiate bindings datatype example template typename device void kernelfunction data code goes template typename t typename t device void kernelfunctiont data t data code goes extern void global kernelfunctionfloatfloat data kernelfunctiondata void global kernelfunctiondoubledouble data kernelfunctiondata void global kernelfunctionintfloatint data float data kernelfunctiondatadata initializing freeing ptx modules easily kernels available recommended approach define analogous following ptx module example kernels described previous section module mycudamodule import cudadrv cumodule cumodulefile cufunction cudacall using cudart export function const ptxdict dict const mdlist array cumodule function mdinit devlist global ptxdict global mdlist isempty mdlist error mdlist empty dev devlist device dev md cumodulefile mycudamoduleptx ptxdictdev function float cufunction md kernelfunctionfloat ptxdictdev function float cufunction md kernelfunctiondouble ptxdictdev function int float cufunction md kernelfunctionintfloat push mdlist md mdclose empty mdlist empty ptxdict function init function devlist local ret mdinit devlist try ret devlist finally mdclose ret function function data cudaarray dev device data cufunction ptxdictdev function set grid block cudacall cufunction grid block ptr data mycudamodule usage look following using cudart mycudamodule rand result devices dev capability dev devlist mycudamodule init devlist dev device dev function cudaarray grid block dimensions written streams streams manage synchronize computations cpu gpu using multiple cuda devices using julia sync async macros short demonstration activates processing multiple devices measuredsleeptime cudart devices dev true nmax devlist sleeptime results array float length devlist streams device dev stream dev devlist force run precompile cudasleep sleeptime dev devlist stream streams wait streams nextidx idx idx sync begin idev length devlist async begin true idx nextidx idx length results break tstart time dev devlistidev stream streamsidev cudasleep sleeptime dev dev stream stream wait stream tstop time resultsidx tstop tstart results realistic version demonstration feed collect results cuda devices using single julia process organize efforts random notes notes memory julia convention matrices stored columnmajor whereas cuda rowmajor efficiency wrapper avoids reordering memory linear sequence addresses main memory gpu usages probably purposes linear algebra effectively means storing transpose matrices gpu todo create cudamatrix cudapitchedmatrix types automatically transpose copying main gpu memory useful cublas note size cudaarraycudapitchedarray represented size corresponding mainmemory object array dimensions reported julia change copy main gpu memori