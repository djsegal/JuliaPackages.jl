bertwordpiecetokenizer load bert wordpiece tokenizer installation julia using pkg pkg add bertwordpiecetokenizer usage initialize import bertwordpiecetokenizer bwp initialize tokenizer local file bwp init pathvocabtxt bwp init pathvocabtxt dolowercase true bwp init pathvocabtxt dolowercase false initialize tokenizer http url bwp init dolowercase true initialize tokenizer http url cache vocabulary local file bwp init cachepath pathvocabtxt dolowercase true tokenize initializing tokenize text using bwptokenize encode text using bwpencode tokenize text tokens bwp tokenize apples encode text tokenids segmentids bwp encode apples truncation specify max length truncation strategy using bwpenabletruncation bwp enabletruncation truncation post bwp enabletruncation truncation pre benchmark julia julia using timeit julia import bertwordpiecetokenizer bwp julia bwp init cachepath bertuncasedvocabtxt dolowercase true julia bwp encode apples julia timeit bwp encode apples loops s loop pure python bertkeras tokenizers import tokenizer tokenizer tokenizer bertuncasedvocabtxt dolowercase true tokenizer encode apples timeit tokenizer encode apples s s loop mean std dev runs loops rust binding python tokenizers import bertwordpiecetokenizer tokenizer bertwordpiecetokenizer bertuncasedvocabtxt lowercase true tokenizer encode apples encoding numtokens attributes ids typeids tokens offsets attentionmask specialtokensmask overflowing timeit tokenizer encode apples s ns loop mean std dev runs loop