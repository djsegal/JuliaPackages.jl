tldr causalelm enables estimation causal effects settings randomized control trial impossible infeasible estimation averatge treatment effect ate intent treat effect itt average treatment effect treated att estimated via computation doubly robust estimation dre abnormal returns estimated event study design causalelm supports estimation individual treatment effects conditional average treatment effects cate vis learning learning learning underlying machine learning model estimators extreme learning machine l regularized extreme learning machine extreme learning machines causal inference causal effect intervention counterfactual conventional methods statistical analysis infeasible unbiased estimate causal effect ate ate itt predicting counterfactual comparing observed outcomes approach causalelm takes estimate event study designs interrupted time series analysis computation dre meatlearning via learners learners learners event study designs estimate effect intervention outcome single unit observe multiple time periods example announcement merger affected price stock price stock merger announced predict machine learning methods compare predicted counterfactual observed price data estimate effect merger announcement effect medicine disease administration random administered mulitiple time periods produce biased estimates overcome computation models observed data model predict outcomes patients recieved treatment compares predictions outcomes none patients recieved treatment doubly robust estimation dre takes similar approach models treatment mechanism adjust initial estimates advantage dre model outcome model treatment mechanism correctly specified yield unbiased estimates furthermore individual benefit treatment opposed average treatment effect depending characteristics data metalearning methods learning learning learning scenarios estimate treatment effect depends predict counterfactual common approaches getting accurate predictions counterfactual super learner combines multiple machine learning methods requires extensive tuning treebased methods hyperparameter spaces hyperparameter tuning computationally expensive requires researchers arbitrary decisions models regularization apply depth trees interaction effects etc hands elms able achieve accuracy variety regression classification tasks generalize moreover hyperparameter space tune fast train becasue backpropagation update weights conventional neural networks causalelm features simple interface enables estimating causal effects lines code analytically derived l penalty reduces cross validation time multicollinearity fast automatic cross validation longitudinal panel time series data includes activation functions allows userdefined activation functions single interface continous binary categorical outcome variables estimation values standard errors via asymptotic randomization inference dependencies outside julia standard library steps plan version causalelm implement robustness checks estimators users estimate summarize test robustness causal models lines code contributing contributions welcome submitting pull request please read contribution guidlin