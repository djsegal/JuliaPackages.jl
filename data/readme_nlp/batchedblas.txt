nvidia provides batched versions blas gemv gemm trsm functions support floating alpha beta scalars batchedblasjl extends support batched arrays currently providing batched versions dot gemv symv spmv ger syr spr arrays abstractfloats integers scaling coefficients scalars vectors addition type flexibility performance benefit symmetric packed symmetric matrices execution times syr spr faster equivalent batched gemm benchmarks a follow dashed lines transposed version gemv uppertriangle versions functions lower example usage julia using cuda symmetricformats batchedblas julia matrix size julia batch dimension julia reshape reshapeunitrangeint eltype int julia sp cuarrayfloatundef packedsize julia sp symmetricpackedview tri julia sp cuarrayfloat cudamemdevicebuffer julia cuarrayfloatreshape cuarrayfloat cudamemdevicebuffer julia batchedspr sp julia sp cuarrayfloat cudamemdevicebuffer julia symmetricpackedsp symmetricpackedfloat cuarrayfloat cudamemdevicebuffer julia symmetricpacked arraytranspose symmetricpackedfloat matrixfloat