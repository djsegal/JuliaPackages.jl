praytoolsjl praytoolsjl former traintools rename created internal package name developing split personality praytoolsjl collection routines simplify boring stuff messing training nns mainly various versions distributed training parallel training ptrain loss ps preparesamples opt iterations cb cby bs threads nthreads ttrain loss ps preparesamples opt iterations cb cby performs parallel training assuming loss function additive differing preparesamples called ptrain single thread calls preparesamples prepare minibatch dividebatchbsint xs divides bs subbatches dispatched separated thread calculate gradient ttrain thread calls preparesamples calculate gradient immediately means ptrain preparesamples return minibatch ttrain return subbatch thread functions treereduction algorithm complexity reducing gradients logbs iterations iterations loop stops cb callback function similar fluxtrain cby callback taking output loss function argument convenient floating averages loading data background backgrounddataloaderloadfun executes function loadfun times background loaded items retrieved blocking minibatch loaded wait till available minibatch retrieved call loadfun issued moment stop structure destroyed add loading samples background preparesamples randn rand bdl backgrounddataloader preparesamples train loss ps bdl opt iterations forget run julia single threads praytoolsinitevalcby initializes simple callback function cby history praytoolsinitevalcbyaccuracy accuracymodel