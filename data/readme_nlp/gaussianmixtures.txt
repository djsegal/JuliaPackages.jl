gaussianmixtures julia package gaussian mixture models gmms package contains support gaussian mixture models basic training likelihood calculation model adaptation implemented julia type specific dahua lin mixturemodels deals normal multivariate distributions gaussians efficiently hopefully support switching gmm mixturemodels types moment implemented diagonal covariance covariance gmms covariance variational bayes gmms training parameters gmm using expectation maximization em algorithm inner loop computing baumwelch statistics executed efficiently using julia standard parallelization infrastructure using sge support data larger fit combined memory computing cluster bigdata incorporated package install pkg add gaussianmixtures vector dimensions remarks dimension main indexing variables gaussian index data feature dimension covariance adds dimensions data stored d slices computations efficiently matrix multiplications nice data standard rowcolumn consistently indexes approach data index row index feature dimension index column index gaussian index mixed depending combined dimension consequence data run matrix records dataframe hence statistics feature dimension occur consecutive memory advantageous caching efficiency hand features belonging data separated memory probably according generated extend streamlined implementation choice direction data run philosophical final conclusion please note choice data run opposite convention distributionsjl convert gmm mixturemodel benefit methods provided distributions transpose data type simplified version type definition gaussian mixture model type gmm int gaussians int dimension gaussian vector weights array means unionarray vectorarray diagonal covariances vector covariances hist arrayhistory history gmm currently variable heterogeneous form interpretation depending represents covariance diagonal covariance matrices covariance represented vector cholinv diagonal covariance formed vertically stacking rowvectors diag constructors gmm weights vector array array hist vector basic outer constructor gmm weights vector length weights mixtures matrix means gaussians matrix variances diagonal gaussians vector triangular matrices representing cholesky decomposition covariance hist vector history objects describing gmm obtained type history simply contains time comment string gmm matrix diag gmm vector create gmm mixture multivariate gaussian initialize mean variance data data nx matrix nx data vector length nx gmm int matrix method kmeans diag ninit niter nfinal niter create gmm mixtures training data using expectation maximization algorithm arriving gaussians methodkmeans means clustering clustering package initialize centers ninit iterations means algorithm niter iterations em method split initializing single gaussian data subsequently splitting gaussians followed retraining using em algorithm gaussians obtained power methodsplit niter iterations em algorithm nfinal iterations final step gmm int int diag initialize gmm multivariate gaussians dimension means set origin variances silly specified covariances diagonal replace values weights means covariances afterwards training functions em gmm gmm matrix niter int varfloor e update parameters gmm using expectation maximization em algorithm niter times optimizing loglikelihood data function em returns vector average log likelihoods intermediate iterations gmm training data llpg gmm gmm matrix returns llij log xi gaussj log likelihood gaussian data xi avll gmm gmm matrix computes average log likelihood gmm data normalized feature dimension size mixture gmm avll log log data distributed multivariate diagonal covariance gaussian i avll gmmposterior gmm gmm matrix returns tuple containing pij gmm xi posterior probability data xi belongs gaussian log likelihood gaussian data xi llpg history gmm gmm history gmm initialized split parameters trained etc history item contains time completion event string examine minimal example using gmm clustering functions splitgmm minweighte covfactor doubles gaussians splitting gaussian gaussians minweight pruning gaussians little weight replaced extra split gaussian weight covfactor controls apart means split gaussian positioned gmm returns diag depending type covariance matrix eltypegmm returns datatype gmm weightsgmm returns weights vector meansgmm returns means matrix covarsgmm returns covariances copygmm returns deep copy gmm gmm returns covariance gmm based gmm diaggmm returns diagonal gmm ignoring diagonal elementsin gmm converting gmms element type gmm changed expect import export functions mixturemodel currently float element type converttypegmmdatatype gmm convert data type gmm floatgmm floatgmm floatgmm convenience functions convert mixturemodelgmm construct instance type mixturemodel gmm please note functions pdfmixturemodel matrix data run sideways package gmmmixturemodelmultivariatecontinuousmvnormal construct gmm mixturemodel paralellization training gmm huge quantities data significant amount time built support parallelization infrastructure julia method stats heart em algorithm detect multiple processors available nprocs processor available data split chunks chunk mapped separate processor afterwards statistics subprocesses aggregated sge environment obtain cores example issuing using clustermanagers clustermanagers addprocssge using gaussianmixtures size gmm data determine advantageous memory stats method efficient algorithms inner loop calculation highly optimized blas friendly parallizable implementation requires fair bit memory input data processed blocks limited amount memory default set gb specified gobal setting setmem gig set memory approximately stats gigabytes baumwelch statistics heart em training operations gmms lies computation baumwelch statistics data aligning gmm optimized implementations basic calculation statistics statsgmmgmm matrix paralleltrue computes baumwelch statistics alignment data universal background gmm gmm st nd statistics retuned matrix obtaining statistics supervector format flattening carried direction theses statistics uncentered random gmms sometimes insteresting generate random gmms genrate random rand gmm sep generates gmm normally distributed means according sep covariance matrices chosen random rand gmm generate datapoints sampled gmm resulting times array speaker recognition methods following methods speaker language recognition eventually move module csstats gmm gmm matrix computes centered scaled statistics similar centered ubm mean scaled covariance csstats gmm matrix constructor return csstats object centered stats type currently defined type csstats vector zero stats ng matrix stats ng csstats type map adaptation simple elegant dotscoring speaker recognition system dotscore csstats csstats float computes dotscoring approximation gmmubm log likelihood ratio gmm map adapted ubm means using data relevance factor test data maxapost gmm gmm matrix means bool true weights bool false covars bool false perform maximum posterior map adaptation ubm gmm data using relevance means weights covars indicate ubm updated saving loading gmm using package jld methods allow saving gmm array gmms disk using jld save filename string name string gmm gmm save filename string name string gmms arraygmm saves gmm array gmms name name file filename data loaded julia session using plain jld gmm load filename name using covariance matrices loaded linearalgebra module current session jld unable reconstruct linearalgebrauppertriangular type gmm object created using jld using gaussianmixtures using linearalgebra gmm load filename name support amounts training data functions defined data type accepted data matrix indicated object type data basically list matrices filenames bigdata datafile matrix represented vertically stacking matrices obtained loading files listed disc functions gaussianmixtures try run computations parallel processing files simultaneously multiple coresmachines try limit times data loaded form disc parallel execution computer cluster attempt ensure data processed worker local file caching advantage variational bayes training started support variational bayes gmms parameters gmm estimates represented distribution training parameters govern distributions carried em algorithm implementation follow approach section christopher bishop book current version gaussianmixtures attempted optimize code efficiency variational bayes training types prior variational gmm type gmmprior effective prior observations m vector prior scale precision w matrix prior precision type vgmm int gaussians int dimension gaussian gmmprior prior vgmm vector dirichlet vector scale precision matrix means means vector degrees freedom vectormatrix scale matrix precision hist vectorhistory history please note currently covariance vgmms training using observed data initial gmm prior gmm niter means initialization gmm gmmprior set values default vgmm initialize variational gmm training proceed em em training checks occupancy gaussians nonzero step gaussian removed effect total gaussians reduce procedure distributionsjl gmm model build mixturemodel distributionsjl package example using gaussianmixtures using distributions rand gmm mixturemodel conveniently sampling gmm sample rand furthermore gaussian mixture model constructed using mixturemodel converted gmm via constructor call gg gmm