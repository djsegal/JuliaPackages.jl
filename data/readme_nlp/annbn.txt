fast stable artificial neural networks scope julia code implementation annbn numerical scheme regards computation artificial neural networks weights iterative training algorithm dividing dataset neighborhoods features algorithm training vastly fast exhibits remarkably low errors adheres underlying theory formulation regression classification accuracy computer vision tasks exploitation spatial information approximating highly nonlinear functions multiple dimensions low errors approximating partial derivatives numerically solving partial differential equations hyperparameters optimization overfitting inherently eliminated testset errors similar train errors results exactly reproducible complexity proposed algorithm class mn computing time download files run examples comprised test folder examples root test folder contains examples manuscript regression solution pdes subfolder testmnist contains annbn implementation classification mnist databse computer vision file create variables xxtrain manuscript yytrain itrain vars xxtest yytest itest coresponding sample data testing prediction model weights hidden layer stored variable aall vectorvectorfloat output layer alayer length nerons change neurons correspondngly calculation neurons wights performed using functions annbntrainlayerrbfneuronsvarsitrainnperpartindsallxxtrainyytraincc annbntrainlayersigmoidfastneuronsvarsitrainnperpartindsallxxtrainyytrain depending radial basis section manuscript sigmoid approach utilized correspondingly input variables neurons neurons vars input variables itrain observations nperpart cumulative observations neuron indsall indices variables clustering xxtrain input database yytrain input responce cc shape parameter radial basis annbn trainlayerrbf variables nperpart indsall automatically created indsallnperpartannbnclusteringneuronsxxtrain iterations clustering datasets slow sorted indices utilizing neurons indsallitrainitemsperneuronintflooritrainneuronsonesintneuronsnperpartcumsumitemsperneuronnperpartitrain accuracy increase neurons ram demands increase afterwards weights aall alayer utilized predict observations using annbnpredictnewrbf annbnpredictnew functions regression start example testnvariablesjl change generating function directly input xxtrain yytrain observations etc compare methods classification computer vision start example testmnistmnistjl exactly reproduce results table manuscript structure appropriate classif