<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-haleqojl" class="anchor" aria-hidden="true" href="#haleqojl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>HALeqO.jl</h1>
<p dir="auto">Homotopy Augmented Lagrangian method for EQuality-constrained Optimization</p>
<p dir="auto">HALeqO.jl is a pure Julia implementation of a solver for continuous nonlinear equality-constrained optimization problems of the form</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="min f(x)  over x in R^n  subject to c(x) = 0"><pre class="notranslate"><code>min f(x)  over x in R^n  subject to c(x) = 0
</code></pre></div>
<p dir="auto">based on a homotopy augmented Lagrangian method and globalised Newton's steps with Armijo's linesearch. To invoke the <code>haleqo</code> solver, you have to pass it an <a href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl">NLPModel</a>; it returns a <a href="https://github.com/JuliaSmoothOptimizers/SolverCore.jl">GenericExecutionStats</a>.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using NLPModels, HALeqO
out = haleqo(nlp)"><pre class="notranslate"><code>using NLPModels, HALeqO
out = haleqo(nlp)
</code></pre></div>
<p dir="auto">You can solve an JuMP model <code>m</code> by using NLPModels to convert it.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using NLPModelsJuMP, HALeqO
nlp = MathOptNLPModel(m)
out = haleqo(nlp)"><pre class="notranslate"><code>using NLPModelsJuMP, HALeqO
nlp = MathOptNLPModel(m)
out = haleqo(nlp)
</code></pre></div>
<h3 dir="auto"><a id="user-content-linear-solver" class="anchor" aria-hidden="true" href="#linear-solver"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Linear solver</h3>
<p dir="auto">HALeqO.jl uses the free <a href="https://github.com/osqp/QDLDL.jl">QDLDL.jl</a> routines as main linear solver and <a href="https://github.com/timholy/PositiveFactorizations.jl">PositiveFactorizations.jl</a> for regularizing the Hessian matrix. These could be replaced by, or complemented with, <a href="https://github.com/JuliaSmoothOptimizers/LDLFactorizations.jl">LDLFactorizations.jl</a> and <a href="https://github.com/JuliaSmoothOptimizers/HSL.jl">HSL.jl</a>'s <code>MA57</code> based on <a href="https://www.hsl.rl.ac.uk/" rel="nofollow">HSL</a>.</p>
<h3 dir="auto"><a id="user-content-citing" class="anchor" aria-hidden="true" href="#citing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Citing</h3>
<p dir="auto">If you are using HALeqO for your work, we encourage you to</p>
<ul dir="auto">
<li><a href="CITATION.bib">Cite</a> the related <a href="https://doi.org/10.1109/CDC45484.2021.9683199" rel="nofollow">paper</a>,</li>
<li>Put a star on this repository.</li>
</ul>
<h3 dir="auto"><a id="user-content-bug-reports-and-support" class="anchor" aria-hidden="true" href="#bug-reports-and-support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Bug reports and support</h3>
<p dir="auto">Please report any issues via the <a href="https://github.com/aldma/HALeqO.jl/issues">issue tracker</a>. All types of issues are welcome including bug reports, typos, feature requests and so on.</p>
<h3 dir="auto"><a id="user-content-benchmarks" class="anchor" aria-hidden="true" href="#benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Benchmarks</h3>
<p dir="auto">We compared HALeqO against <a href="https://coin-or.github.io/Ipopt/" rel="nofollow">IPOPT</a>, via the wrapper provided by <a href="https://github.com/JuliaSmoothOptimizers/NLPModelsIpopt.jl">NLPModelsIpopt</a>, and <a href="https://github.com/JuliaSmoothOptimizers/NCL.jl">NCL.jl</a> invoking IPOPT. See <code>run_benchmarks.jl</code> in the <code>tests</code> folder.</p>
</article></div>