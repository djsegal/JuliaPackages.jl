<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-posdefmanifoldmljl" class="anchor" aria-hidden="true" href="#posdefmanifoldmljl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>PosDefManifoldML.jl</h1>
<table>
<thead>
<tr>
<th align="center"><strong>Documentation</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://Marco-Congedo.github.io/PosDefManifoldML.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/3e353c26ddfe819150acbc732248f4f2a37f5175/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a></td>
</tr>
</tbody>
</table>
<p><strong>PosDefManifoldML</strong> is a <a href="https://julialang.org/" rel="nofollow"><strong>Julia</strong></a> package for classifying data in the <a href="https://en.wikipedia.org/wiki/Riemannian_manifold" rel="nofollow"><strong>Riemannian manifolds</strong></a> <strong>P</strong> of real or complex <a href="https://en.wikipedia.org/wiki/Definiteness_of_a_matrix" rel="nofollow"><strong>positive definite matrices</strong></a>. It is based on the <a href="https://github.com/Marco-Congedo/PosDefManifold.jl">PosDefManifold.jl</a> and <a href="https://github.com/JuliaStats/GLMNet.jl">GLMNet.jl</a> packages.</p>
<p><a href="https://en.wikipedia.org/wiki/Machine_learning" rel="nofollow">Machine learning</a> (ML) in <strong>P</strong> can either operate directly on the manifold, which requires dedicated Riemannian methods, or the data can be projected onto the <strong>tangent space</strong>, where standard (Euclidean) machine learning methods apply (e.g., linear discriminant analysis, support-vector machine, logistic regression, random forest, deep neuronal networks, etc).</p>
<p><a target="_blank" rel="noopener noreferrer" href="/docs/src/assets/Fig1.jpg"><img src="/docs/src/assets/Fig1.jpg" alt="" style="max-width:100%;"></a></p>
<p>For the moment being, <strong>PosDefManifoldML</strong> implements the Riemannian <strong>Minimum Distance to Mean (MDM)</strong>
classifier, which operates directly in <strong>P</strong>, the <strong>elastic net logistic regression</strong>
(including the pure <strong>Ridge</strong> and pure <strong>Lasso</strong> logistic regression model) and several
<strong>support-vector machine</strong> classifiers in the tangent space.
The models operating in the tangent space can be used also for traditional (Euclidean) feature vectors,
making of this package also a nice interface to the binomial family of generalized linear models implemented
in <em>GLMNet.jl</em> and all SVM models implemented in <em>LIBSVM.jl</em></p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<p>Run this line in Julia's REPL:</p>
<pre><code>]add PosDefManifold PosDefManifoldML
</code></pre>
<h2><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Examples</h2>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> PosDefManifold, PosDefManifoldML

<span class="pl-c"><span class="pl-c">#</span> simulate symmetric positive definite (SDP) matrices data for a 2-class problem.</span>
<span class="pl-c"><span class="pl-c">#</span> P is a vector of SPD matrices, y a vector of labels. Tr=training, Te=testing.</span>
<span class="pl-c"><span class="pl-c">#</span> SDP matrices will be all of size 10x10.</span>
<span class="pl-c"><span class="pl-c">#</span> The training set will have 30 matrices for class 1 and 40 for class 2.</span>
<span class="pl-c"><span class="pl-c">#</span> The testing set will have 60 matrices for class 1 and 80 for class 2.</span>
PTr, PTe, yTr, yTe<span class="pl-k">=</span><span class="pl-c1">gen2ClassData</span>(<span class="pl-c1">10</span>, <span class="pl-c1">30</span>, <span class="pl-c1">40</span>, <span class="pl-c1">60</span>, <span class="pl-c1">80</span>)

<span class="pl-c"><span class="pl-c">#</span> # # MACHINE LEARNING IN THE PD MANIFOLD # # #</span>

<span class="pl-c"><span class="pl-c">#</span> (1)</span>
<span class="pl-c"><span class="pl-c">#</span> create and fit (train) a Riemannian Minimum Distance to Mean (MDM) model:</span>
model<span class="pl-k">=</span><span class="pl-c1">fit</span>(<span class="pl-c1">MDM</span>(), PTr, yTr)
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> predict labels (classify the testing set):</span>
yPred<span class="pl-k">=</span><span class="pl-c1">predict</span>(model, PTe, <span class="pl-c1">:l</span>)
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> prediction error (in proportion)</span>
<span class="pl-c1">predictErr</span>(yTe, yPred)
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> predict probabilities for the matrices in `PTe` of belonging to each class:</span>
<span class="pl-c1">predict</span>(model, PTe, <span class="pl-c1">:p</span>)

<span class="pl-c"><span class="pl-c">#</span> (2)</span>
<span class="pl-c"><span class="pl-c">#</span> average accuracy obtained by 10-fold cross-validation:</span>
cv <span class="pl-k">=</span> <span class="pl-c1">cvAcc</span>(<span class="pl-c1">MDM</span>(), PTr, yTr)

<span class="pl-c"><span class="pl-c">#</span> # # MACHINE LEARNING IN THE TANGENT SPACE # # #</span>

<span class="pl-c"><span class="pl-c">#</span> (1)</span>
<span class="pl-c"><span class="pl-c">#</span> create and fit (train) LASSO Logistic Regression models</span>
<span class="pl-c"><span class="pl-c">#</span> finding the best model by cross-validation:</span>
model<span class="pl-k">=</span><span class="pl-c1">fit</span>(<span class="pl-c1">ENLR</span>(), PTr, yTr)
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> predict labels (classify the testing set) using the 'best' model:</span>
yPred<span class="pl-k">=</span><span class="pl-c1">predict</span>(model, PTe, <span class="pl-c1">:l</span>)
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> prediction error (in proportion)</span>
<span class="pl-c1">predictErr</span>(yTe, yPred)
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> ...</span>
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> create and fit a RIDGE logistic regression model</span>
model<span class="pl-k">=</span><span class="pl-c1">fit</span>(<span class="pl-c1">ENLR</span>(), PTr, yTr; alpha<span class="pl-k">=</span><span class="pl-c1">0</span>)
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span>...</span>
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> create and fit an ELASTIC NET logistic regression model with alpha = 0.5</span>
model<span class="pl-k">=</span><span class="pl-c1">fit</span>(<span class="pl-c1">ENLR</span>(), PTr, yTr; alpha<span class="pl-k">=</span><span class="pl-c1">0.5</span>)

<span class="pl-c"><span class="pl-c">#</span> (2)</span>
<span class="pl-c"><span class="pl-c">#</span> average accuracy obtained by 10-fold cross-validation:</span>
cv <span class="pl-k">=</span> <span class="pl-c1">cvAcc</span>(<span class="pl-c1">ENLR</span>(), PTr, yTr; alpha<span class="pl-k">=</span><span class="pl-c1">0.5</span>)

<span class="pl-c"><span class="pl-c">#</span> (1)</span>
<span class="pl-c"><span class="pl-c">#</span> create and fit (train) an SVM with Radial Basis kernel</span>

<span class="pl-c"><span class="pl-c">#</span> finding the best model by cross-validation:</span>
model<span class="pl-k">=</span><span class="pl-c1">fit</span>(<span class="pl-c1">SVM</span>(), PTr, yTr)
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> predict labels (classify the testing set) using the 'best' model:</span>
yPred<span class="pl-k">=</span><span class="pl-c1">predict</span>(model, PTe, <span class="pl-c1">:l</span>)
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> prediction error (in proportion)</span>
<span class="pl-c1">predictErr</span>(yTe, yPred)
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> ...</span>

<span class="pl-c"><span class="pl-c">#</span> (2)</span>
<span class="pl-c"><span class="pl-c">#</span> average accuracy obtained by 10-fold cross-validation:</span>
cv <span class="pl-k">=</span> <span class="pl-c1">cvAcc</span>(<span class="pl-c1">SVM</span>(), PTr, yTr)

</pre></div>
<h2><a id="user-content-about-the-authors" class="anchor" aria-hidden="true" href="#about-the-authors"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>About the Authors</h2>
<p><a href="https://sites.google.com/site/marcocongedo" rel="nofollow">Marco Congedo</a>, corresponding
author, is a research scientist of <a href="http://www.cnrs.fr/en" rel="nofollow">CNRS</a> (Centre National de la Recherche Scientifique), working in <a href="https://www.univ-grenoble-alpes.fr/english/" rel="nofollow">UGA</a> (University of Grenoble Alpes). <strong>contact</strong>: marco <em>dot</em> congedo <em>at</em> gmail <em>dot</em> com</p>
<p>Saloni Jain is a student at the
<a href="http://www.iitkgp.ac.in/" rel="nofollow">Indian Institute of Technology, Kharagpur</a>, India.</p>
<table>
<thead>
<tr>
<th align="center"><strong>Documentation</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://Marco-Congedo.github.io/PosDefManifoldML.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/3e353c26ddfe819150acbc732248f4f2a37f5175/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a></td>
</tr>
</tbody>
</table>
</article></div>