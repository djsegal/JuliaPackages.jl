<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p>This package was originally authored by <a href="https://github.com/Allardvm">Allardvm</a> and <a href="https://github.com/wakakusa/">wakakusa</a></p>
<h1><a id="user-content-lightgbmjl" class="anchor" aria-hidden="true" href="#lightgbmjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LightGBM.jl
<a target="_blank" rel="noopener noreferrer" href="https://github.com/IQVIA-ML/LightGBM.jl/workflows/CI/badge.svg"><img src="https://github.com/IQVIA-ML/LightGBM.jl/workflows/CI/badge.svg" alt="CI" style="max-width:100%;"></a>
<a href="LICENSE.md"><img src="https://camo.githubusercontent.com/bbf49a2eb96e6f718803f2493bd7aa3baae61abb09b7f8fc185a94e08c504dc6/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c6174" alt="License" data-canonical-src="http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" style="max-width:100%;"></a>
<a href="https://IQVIA-ML.github.io/LightGBM.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a>
<a href="https://IQVIA-ML.github.io/LightGBM.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a></h1>
<p><strong>LightGBM.jl</strong> provides a high-performance Julia interface for Microsoft's
<a href="https://lightgbm.readthedocs.io/en/latest/" rel="nofollow">LightGBM</a>.</p>
<p>The package adds a couple of convenience features:</p>
<ul>
<li>Automated cross-validation</li>
<li>Exhaustive grid search search procedure</li>
<li>Integration with <a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> (which also provides the above via different interfaces)</li>
</ul>
<p>Additionally, the package automatically converts all LightGBM parameters that refer to indices
(e.g. <code>categorical_feature</code>) from Julia's one-based indices to C's zero-based indices.</p>
<p>A majority of the C-interfaces are implemented. A few are known to be missing and are
<a href="https://github.com/IQVIA-ML/LightGBM.jl/issues">tracked.</a></p>
<p>All major operating systems (Windows, Linux, and Mac OS X) are supported. Julia versions 1.0+ are supported.</p>
<h1><a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Table of Contents</h1>
<ol>
<li><a href="#installation">Installation</a></li>
<li><a href="#a-simple-example-using-lightgbm-example-files">Example</a></li>
<li><a href="#mlj-support">MLJ</a></li>
</ol>
<h1><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h1>
<p>Please ensure your system meets the pre-requisites for LightGBM. This generally means ensuring
that <code>libomp</code> is installed and linkable on your system. See here for <a href="https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html" rel="nofollow">Microsoft's installation guide.</a></p>
<p>Please note that the package actually downloads a <a href="https://github.com/microsoft/LightGBM/releases">precompiled binary</a>
so you do not need to install LightGBM first. This is done as a user convenience, and support
will be added for supplying ones own LightGBM binary (for GPU acceleration, etc).</p>
<p>To add the package to Julia:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="Pkg.add(&quot;LightGBM&quot;)
"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>LightGBM<span class="pl-pds">"</span></span>)</pre></div>
<p>Running tests for the package requires the use of the LightGBM example files,
download and extract the <a href="https://github.com/microsoft/LightGBM/archive/v2.3.1.zip">LightGBM source</a>
and set the enviroment variable <code>LIGHTGBM_EXAMPLES_PATH</code> to the root of the source installation.
Then you can run the tests by simply doing</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="Pkg.test(&quot;LightGBM&quot;)
"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">test</span>(<span class="pl-s"><span class="pl-pds">"</span>LightGBM<span class="pl-pds">"</span></span>)</pre></div>
<h1><a id="user-content-a-simple-example-using-lightgbm-example-files" class="anchor" aria-hidden="true" href="#a-simple-example-using-lightgbm-example-files"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>A simple example using LightGBM example files</h1>
<p>First, download <a href="https://github.com/microsoft/LightGBM/archive/v3.2.0.zip">LightGBM source</a>
and untar it somewhere.</p>
<div class="highlight highlight-source-shell position-relative" data-snippet-clipboard-copy-content="cd ~
wget https://github.com/microsoft/LightGBM/archive/v3.2.0.tar.gz
tar -xf v3.2.0.tar.gz
"><pre><span class="pl-c1">cd</span> <span class="pl-k">~</span>
wget https://github.com/microsoft/LightGBM/archive/v3.2.0.tar.gz
tar -xf v3.2.0.tar.gz</pre></div>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using LightGBM
using DelimitedFiles

LIGHTGBM_SOURCE = abspath(&quot;~/LightGBM-3.2.0&quot;)

# Load LightGBM's binary classification example.
binary_test = readdlm(joinpath(LIGHTGBM_SOURCE, &quot;examples&quot;, &quot;binary_classification&quot;, &quot;binary.test&quot;), '\t')
binary_train = readdlm(joinpath(LIGHTGBM_SOURCE, &quot;examples&quot;, &quot;binary_classification&quot;, &quot;binary.train&quot;), '\t')
X_train = binary_train[:, 2:end]
y_train = binary_train[:, 1]
X_test = binary_test[:, 2:end]
y_test = binary_test[:, 1]

# Create an estimator with the desired parameters—leave other parameters at the default values.
estimator = LGBMClassification(
    objective = &quot;binary&quot;,
    num_iterations = 100,
    learning_rate = .1,
    early_stopping_round = 5,
    feature_fraction = .8,
    bagging_fraction = .9,
    bagging_freq = 1,
    num_leaves = 1000,
    num_class = 1,
    metric = [&quot;auc&quot;, &quot;binary_logloss&quot;]
)

# Fit the estimator on the training data and return its scores for the test data.
fit!(estimator, X_train, y_train, (X_test, y_test))

# Predict arbitrary data with the estimator.
predict(estimator, X_train)

# Cross-validate using a two-fold cross-validation iterable providing training indices.
splits = (collect(1:3500), collect(3501:7000))
cv(estimator, X_train, y_train, splits)

# Exhaustive search on an iterable containing all combinations of learning_rate ∈ {.1, .2} and
# bagging_fraction ∈ {.8, .9}
params = [Dict(:learning_rate =&gt; learning_rate,
               :bagging_fraction =&gt; bagging_fraction) for
          learning_rate in (.1, .2),
          bagging_fraction in (.8, .9)]
search_cv(estimator, X_train, y_train, splits, params)

# Save and load the fitted model.
filename = pwd() * &quot;/finished.model&quot;
savemodel(estimator, filename)
loadmodel!(estimator, filename)
"><pre><span class="pl-k">using</span> LightGBM
<span class="pl-k">using</span> DelimitedFiles

LIGHTGBM_SOURCE <span class="pl-k">=</span> <span class="pl-c1">abspath</span>(<span class="pl-s"><span class="pl-pds">"</span>~/LightGBM-3.2.0<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">#</span> Load LightGBM's binary classification example.</span>
binary_test <span class="pl-k">=</span> <span class="pl-c1">readdlm</span>(<span class="pl-c1">joinpath</span>(LIGHTGBM_SOURCE, <span class="pl-s"><span class="pl-pds">"</span>examples<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>binary_classification<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>binary.test<span class="pl-pds">"</span></span>), <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\t</span><span class="pl-pds">'</span></span>)
binary_train <span class="pl-k">=</span> <span class="pl-c1">readdlm</span>(<span class="pl-c1">joinpath</span>(LIGHTGBM_SOURCE, <span class="pl-s"><span class="pl-pds">"</span>examples<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>binary_classification<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>binary.train<span class="pl-pds">"</span></span>), <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\t</span><span class="pl-pds">'</span></span>)
X_train <span class="pl-k">=</span> binary_train[:, <span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]
y_train <span class="pl-k">=</span> binary_train[:, <span class="pl-c1">1</span>]
X_test <span class="pl-k">=</span> binary_test[:, <span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]
y_test <span class="pl-k">=</span> binary_test[:, <span class="pl-c1">1</span>]

<span class="pl-c"><span class="pl-c">#</span> Create an estimator with the desired parameters—leave other parameters at the default values.</span>
estimator <span class="pl-k">=</span> <span class="pl-c1">LGBMClassification</span>(
    objective <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>binary<span class="pl-pds">"</span></span>,
    num_iterations <span class="pl-k">=</span> <span class="pl-c1">100</span>,
    learning_rate <span class="pl-k">=</span> <span class="pl-c1">.1</span>,
    early_stopping_round <span class="pl-k">=</span> <span class="pl-c1">5</span>,
    feature_fraction <span class="pl-k">=</span> <span class="pl-c1">.8</span>,
    bagging_fraction <span class="pl-k">=</span> <span class="pl-c1">.9</span>,
    bagging_freq <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    num_leaves <span class="pl-k">=</span> <span class="pl-c1">1000</span>,
    num_class <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    metric <span class="pl-k">=</span> [<span class="pl-s"><span class="pl-pds">"</span>auc<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>binary_logloss<span class="pl-pds">"</span></span>]
)

<span class="pl-c"><span class="pl-c">#</span> Fit the estimator on the training data and return its scores for the test data.</span>
<span class="pl-c1">fit!</span>(estimator, X_train, y_train, (X_test, y_test))

<span class="pl-c"><span class="pl-c">#</span> Predict arbitrary data with the estimator.</span>
<span class="pl-c1">predict</span>(estimator, X_train)

<span class="pl-c"><span class="pl-c">#</span> Cross-validate using a two-fold cross-validation iterable providing training indices.</span>
splits <span class="pl-k">=</span> (<span class="pl-c1">collect</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">3500</span>), <span class="pl-c1">collect</span>(<span class="pl-c1">3501</span><span class="pl-k">:</span><span class="pl-c1">7000</span>))
<span class="pl-c1">cv</span>(estimator, X_train, y_train, splits)

<span class="pl-c"><span class="pl-c">#</span> Exhaustive search on an iterable containing all combinations of learning_rate ∈ {.1, .2} and</span>
<span class="pl-c"><span class="pl-c">#</span> bagging_fraction ∈ {.8, .9}</span>
params <span class="pl-k">=</span> [<span class="pl-c1">Dict</span>(<span class="pl-c1">:learning_rate</span> <span class="pl-k">=&gt;</span> learning_rate,
               <span class="pl-c1">:bagging_fraction</span> <span class="pl-k">=&gt;</span> bagging_fraction) <span class="pl-k">for</span>
          learning_rate <span class="pl-k">in</span> (<span class="pl-c1">.1</span>, <span class="pl-c1">.2</span>),
          bagging_fraction <span class="pl-k">in</span> (<span class="pl-c1">.8</span>, <span class="pl-c1">.9</span>)]
<span class="pl-c1">search_cv</span>(estimator, X_train, y_train, splits, params)

<span class="pl-c"><span class="pl-c">#</span> Save and load the fitted model.</span>
filename <span class="pl-k">=</span> <span class="pl-c1">pwd</span>() <span class="pl-k">*</span> <span class="pl-s"><span class="pl-pds">"</span>/finished.model<span class="pl-pds">"</span></span>
<span class="pl-c1">savemodel</span>(estimator, filename)
<span class="pl-c1">loadmodel!</span>(estimator, filename)</pre></div>
<h1><a id="user-content-mlj-support" class="anchor" aria-hidden="true" href="#mlj-support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>MLJ Support</h1>
<p>This package has an interface to <a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a>.
Exhaustive MLJ documentation is out of scope for here, however the main things are:</p>
<p>The MLJ interface models are</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="LightGBM.MLJInterface.LGBMClassifier
LightGBM.MLJInterface.LGBMRegressor
"><pre>LightGBM<span class="pl-k">.</span>MLJInterface<span class="pl-k">.</span>LGBMClassifier
LightGBM<span class="pl-k">.</span>MLJInterface<span class="pl-k">.</span>LGBMRegressor</pre></div>
<p>And these have the same interface parameters as the <a href="#estimators">estimators</a></p>
<p>The interface models are generally passed to <code>MLJBase.fit</code> or <code>MLJBase.machine</code>
and integrated as part of a larger MLJ pipeline. <a href="https://alan-turing-institute.github.io/DataScienceTutorials.jl/end-to-end/boston-lgbm/" rel="nofollow">An example is provided</a></p>
<h1><a id="user-content-custom-lightgbm-binaries" class="anchor" aria-hidden="true" href="#custom-lightgbm-binaries"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Custom LightGBM binaries</h1>
<p>Though this package comes with a precompiled binary (<code>lib_lightgbm.so</code> for linux, <code>lib_lightgbm.dylib</code> for macos, <code>lib_lightgbm.dll</code> for windows, refer to <a href="https://github.com/microsoft/LightGBM/releases">Microsoft's LightGBM release page</a>), a custom binary can be used with this package (we use <code>Libdl.dlopen</code> to do this). In order to do so, either:</p>
<ul>
<li>Add the directory of your custom binary to the <code>Libdl.DL_LOAD_PATH</code> before calling <code>import LightGBM</code>, e.g.
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="import Libdl
push!(Libdl.DL_LOAD_PATH, &quot;/path/to/your/lib_lightgbm/directory&quot;)

import LightGBM
...
"><pre><code>import Libdl
push!(Libdl.DL_LOAD_PATH, "/path/to/your/lib_lightgbm/directory")

import LightGBM
...
</code></pre></div>
</li>
<li>Specify the directory of your custom binary in the environment variables <code>LD_LIBRARY_PATH</code> (for linux), <code>DYLD_LIBRARY_PATH</code> (macos), <code>PATH</code> (windows), or place the custom binary file in the system search path</li>
</ul>
<p>Note: <code>Libdl.DL_LOAD_PATH</code> will be first searched and used, then the system library paths. If no binaries are found, the program will fallback to using the precompiled binary</p>
<h2><a id="user-content-contributors-" class="anchor" aria-hidden="true" href="#contributors-"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contributors <g-emoji class="g-emoji" alias="sparkles" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png">✨</g-emoji></h2>
<p>The list of our Contributors can be found <a href="CONTRIBUTORS.md">here</a>.
Please don't hesitate to add yourself when you contribute.</p>
</article></div>