<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><p>This package was originally authored by <a href="https://github.com/Allardvm">Allardvm</a> and <a href="https://github.com/wakakusa/">wakakusa</a></p>
<h1><a id="user-content-lightgbmjl" class="anchor" aria-hidden="true" href="#lightgbmjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>LightGBM.jl
<a target="_blank" rel="noopener noreferrer" href="https://github.com/IQVIA-ML/LightGBM.jl/workflows/CI/badge.svg"><img src="https://github.com/IQVIA-ML/LightGBM.jl/workflows/CI/badge.svg" alt="CI" style="max-width:100%;"></a>
<a href="LICENSE.md"><img src="https://camo.githubusercontent.com/4440d5deb3a53c4f8661ee765378e6071e7878e8/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c6174" alt="License" data-canonical-src="http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" style="max-width:100%;"></a></h1>
<p><strong>LightGBM.jl</strong> provides a high-performance Julia interface for Microsoft's
<a href="https://lightgbm.readthedocs.io/en/latest/" rel="nofollow">LightGBM</a>.</p>
<p>The package adds a couple of convenience features:</p>
<ul>
<li>Automated cross-validation</li>
<li>Exhaustive grid search search procedure</li>
<li>Integration with <a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> (which also provides the above via different interfaces)</li>
</ul>
<p>Additionally, the package automatically converts all LightGBM parameters that refer to indices
(e.g. <code>categorical_feature</code>) from Julia's one-based indices to C's zero-based indices.</p>
<p>A majority of the C-interfaces are implemented. A few are known to be missing and are
<a href="https://github.com/IQVIA-ML/LightGBM.jl/issues">tracked.</a></p>
<p>All major operating systems (Windows, Linux, and Mac OS X) are supported. Julia versions 1.0+ are supported.</p>
<h1><a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Table of Contents</h1>
<ol>
<li><a href="#installation">Installation</a></li>
<li><a href="#a-simple-example-using-lightgbm-example-files">Example</a></li>
<li><a href="#exports">Exports</a></li>
<li><a href="#mlj-support">MLJ</a></li>
</ol>
<h1><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h1>
<p>Please ensure your system meets the pre-requisites for LightGBM. This generally means ensuring
that <code>libomp</code> is installed and linkable on your system. See here for <a href="https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html" rel="nofollow">Microsoft's installation guide.</a></p>
<p>Please note that the package actually downloads a <a href="https://github.com/microsoft/LightGBM/releases">precompiled binary</a>
so you do not need to install LightGBM first. This is done as a user convenience, and support
will be added for supplying ones own LightGBM binary (for GPU acceleration, etc).</p>
<p>To add the package to Julia:</p>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>LightGBM<span class="pl-pds">"</span></span>)</pre></div>
<p>Running tests for the package requires the use of the LightGBM example files,
download and extract the <a href="https://github.com/microsoft/LightGBM/archive/v2.3.1.zip">LightGBM source</a>
and set the enviroment variable <code>LIGHTGBM_EXAMPLES_PATH</code> to the root of the source installation.
Then you can run the tests by simply doing</p>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">test</span>(<span class="pl-s"><span class="pl-pds">"</span>LightGBM<span class="pl-pds">"</span></span>)</pre></div>
<h1><a id="user-content-a-simple-example-using-lightgbm-example-files" class="anchor" aria-hidden="true" href="#a-simple-example-using-lightgbm-example-files"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>A simple example using LightGBM example files</h1>
<p>First, download <a href="https://github.com/microsoft/LightGBM/archive/v2.3.1.zip">LightGBM source</a>
and untar it somewhere.</p>
<div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span> <span class="pl-k">~</span>
wget https://github.com/microsoft/LightGBM/archive/v2.3.1.tar.gz
tar -xf v2.3.1.tar.gz</pre></div>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> LightGBM
<span class="pl-k">using</span> DelimitedFiles

LIGHTGBM_SOURCE <span class="pl-k">=</span> <span class="pl-c1">abspath</span>(<span class="pl-s"><span class="pl-pds">"</span>~/LightGBM-2.3.1<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">#</span> Load LightGBM's binary classification example.</span>
binary_test <span class="pl-k">=</span> <span class="pl-c1">readdlm</span>(<span class="pl-c1">joinpath</span>(LIGHTGBM_SOURCE, <span class="pl-s"><span class="pl-pds">"</span>examples<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>binary_classification<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>binary.test<span class="pl-pds">"</span></span>), <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\t</span><span class="pl-pds">'</span></span>)
binary_train <span class="pl-k">=</span> <span class="pl-c1">readdlm</span>(<span class="pl-c1">joinpath</span>(LIGHTGBM_SOURCE, <span class="pl-s"><span class="pl-pds">"</span>examples<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>binary_classification<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>binary.train<span class="pl-pds">"</span></span>), <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\t</span><span class="pl-pds">'</span></span>)
X_train <span class="pl-k">=</span> binary_train[:, <span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]
y_train <span class="pl-k">=</span> binary_train[:, <span class="pl-c1">1</span>]
X_test <span class="pl-k">=</span> binary_test[:, <span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]
y_test <span class="pl-k">=</span> binary_test[:, <span class="pl-c1">1</span>]

<span class="pl-c"><span class="pl-c">#</span> Create an estimator with the desired parameters—leave other parameters at the default values.</span>
estimator <span class="pl-k">=</span> <span class="pl-c1">LGBMClassification</span>(
    objective <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>binary<span class="pl-pds">"</span></span>,
    num_iterations <span class="pl-k">=</span> <span class="pl-c1">100</span>,
    learning_rate <span class="pl-k">=</span> <span class="pl-c1">.1</span>,
    early_stopping_round <span class="pl-k">=</span> <span class="pl-c1">5</span>,
    feature_fraction <span class="pl-k">=</span> <span class="pl-c1">.8</span>,
    bagging_fraction <span class="pl-k">=</span> <span class="pl-c1">.9</span>,
    bagging_freq <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    num_leaves <span class="pl-k">=</span> <span class="pl-c1">1000</span>,
    num_class <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    metric <span class="pl-k">=</span> [<span class="pl-s"><span class="pl-pds">"</span>auc<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>binary_logloss<span class="pl-pds">"</span></span>]
)

<span class="pl-c"><span class="pl-c">#</span> Fit the estimator on the training data and return its scores for the test data.</span>
<span class="pl-c1">fit!</span>(estimator, X_train, y_train, (X_test, y_test))

<span class="pl-c"><span class="pl-c">#</span> Predict arbitrary data with the estimator.</span>
<span class="pl-c1">predict</span>(estimator, X_train)

<span class="pl-c"><span class="pl-c">#</span> Cross-validate using a two-fold cross-validation iterable providing training indices.</span>
splits <span class="pl-k">=</span> (<span class="pl-c1">collect</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">3500</span>), <span class="pl-c1">collect</span>(<span class="pl-c1">3501</span><span class="pl-k">:</span><span class="pl-c1">7000</span>))
<span class="pl-c1">cv</span>(estimator, X_train, y_train, splits)

<span class="pl-c"><span class="pl-c">#</span> Exhaustive search on an iterable containing all combinations of learning_rate ∈ {.1, .2} and</span>
<span class="pl-c"><span class="pl-c">#</span> bagging_fraction ∈ {.8, .9}</span>
params <span class="pl-k">=</span> [<span class="pl-c1">Dict</span>(<span class="pl-c1">:learning_rate</span> <span class="pl-k">=&gt;</span> learning_rate,
               <span class="pl-c1">:bagging_fraction</span> <span class="pl-k">=&gt;</span> bagging_fraction) <span class="pl-k">for</span>
          learning_rate <span class="pl-k">in</span> (<span class="pl-c1">.1</span>, <span class="pl-c1">.2</span>),
          bagging_fraction <span class="pl-k">in</span> (<span class="pl-c1">.8</span>, <span class="pl-c1">.9</span>)]
<span class="pl-c1">search_cv</span>(estimator, X_train, y_train, splits, params)

<span class="pl-c"><span class="pl-c">#</span> Save and load the fitted model.</span>
filename <span class="pl-k">=</span> <span class="pl-c1">pwd</span>() <span class="pl-k">*</span> <span class="pl-s"><span class="pl-pds">"</span>/finished.model<span class="pl-pds">"</span></span>
<span class="pl-c1">savemodel</span>(estimator, filename)
<span class="pl-c1">loadmodel</span>(estimator, filename)</pre></div>
<h1><a id="user-content-exports" class="anchor" aria-hidden="true" href="#exports"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Exports</h1>
<p>Note that a lot of parameters used within this module and in the code and examples are
exact matches with those from <a href="https://lightgbm.readthedocs.io/en/latest/Parameters.html" rel="nofollow">LightGBM.</a>
Not all of these are necessarily supported but see the guide for detailed explanations of what these
parameters do and their valid values.</p>
<h2><a id="user-content-functions" class="anchor" aria-hidden="true" href="#functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Functions</h2>
<h3><a id="user-content-fitestimator-x-y-test-verbosity--1-is_row_major--false" class="anchor" aria-hidden="true" href="#fitestimator-x-y-test-verbosity--1-is_row_major--false"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>fit!(estimator, X, y[, test...]; [verbosity = 1, is_row_major = false])</code></h3>
<p>Fit the <code>estimator</code> with features data <code>X</code> and label <code>y</code> using the X-y pairs in <code>test</code> as
validation sets.</p>
<p>Return a dictionary with an entry for each validation set. Each entry of the dictionary is another
dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these entries is an
array that holds the validation metric's value at each evaluation of the metric.</p>
<h4><a id="user-content-arguments" class="anchor" aria-hidden="true" href="#arguments"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Arguments</h4>
<ul>
<li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li>
<li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li>
<li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li>
<li><code>test::Tuple{Matrix{TX},Vector{Ty}}...</code>: optionally contains one or more tuples of X-y pairs of
the same types as <code>X</code> and <code>y</code> that should be used as validation sets.</li>
<li><code>verbosity::Integer</code>: keyword argument that controls LightGBM's verbosity. <code>&lt; 0</code> for fatal logs
only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li>
<li><code>is_row_major::Bool</code>: keyword argument that indicates whether or not <code>X</code> is row-major. <code>true</code>
indicates that it is row-major, <code>false</code> indicates that it is column-major (Julia's default).</li>
<li><code>weights::Vector{Tw&lt;:Real}</code>: the training weights.</li>
<li><code>init_score::Vector{Ti&lt;:Real}</code>: the init scores.</li>
</ul>
<h3><a id="user-content-predictestimator-x-predict_type--0-num_iterations---1-verbosity--1-is_row_major--false" class="anchor" aria-hidden="true" href="#predictestimator-x-predict_type--0-num_iterations---1-verbosity--1-is_row_major--false"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>predict(estimator, X; [predict_type = 0, num_iterations = -1, verbosity = 1, is_row_major = false])</code></h3>
<p>Return an array with outputs</p>
<ul>
<li>Probabilities for binary or multiclass (with output being 2-d if multiclass)</li>
<li>Regression predictions</li>
</ul>
<h3><a id="user-content-predict_classesmulticlass_estimator-x-predict_type--0-num_iterations---1-verbosity--1-is_row_major--false-binary_threshold--05" class="anchor" aria-hidden="true" href="#predict_classesmulticlass_estimator-x-predict_type--0-num_iterations---1-verbosity--1-is_row_major--false-binary_threshold--05"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>predict_classes(multiclass_estimator, X; [predict_type = 0, num_iterations = -1, verbosity = 1, is_row_major = false, binary_threshold = 0.5])</code></h3>
<p>A convenience method for obtaining predicted classes from the <code>LGBMClassification</code> estimator.</p>
<h4><a id="user-content-arguments-1" class="anchor" aria-hidden="true" href="#arguments-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Arguments</h4>
<ul>
<li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li>
<li><code>X::Matrix{T&lt;:Real}</code>: the features data.</li>
<li><code>predict_type::Integer</code>: keyword argument that controls the prediction type. <code>0</code> for normal
scores with transform (if needed), <code>1</code> for raw scores, <code>2</code> for leaf indices.</li>
<li><code>num_iterations::Integer</code>: keyword argument that sets the number of iterations of the model to
use in the prediction. <code>&lt; 0</code> for all iterations.</li>
<li><code>verbosity::Integer</code>: keyword argument that controls LightGBM's verbosity. <code>&lt; 0</code> for fatal logs
only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li>
<li><code>is_row_major::Bool</code>: keyword argument that indicates whether or not <code>X</code> is row-major. <code>true</code>
indicates that it is row-major, <code>false</code> indicates that it is column-major (Julia's default).</li>
<li><code>binary_threshold::Real</code>: The decision threshold to use for a binary classification
(when using <code>binary</code> objective only, otherwise argmax decision)</li>
</ul>
<h3><a id="user-content-cvestimator-x-y-splits-verbosity--1-experimentalinterface-may-change" class="anchor" aria-hidden="true" href="#cvestimator-x-y-splits-verbosity--1-experimentalinterface-may-change"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>cv(estimator, X, y, splits; [verbosity = 1])</code> (Experimental—interface may change)</h3>
<p>Cross-validate the <code>estimator</code> with features data <code>X</code> and label <code>y</code>. The iterable <code>splits</code> provides
vectors of indices for the training dataset. The remaining indices are used to create the
validation dataset.</p>
<p>Return a dictionary with an entry for the validation dataset and, if the parameter
<code>is_training_metric</code> is set in the <code>estimator</code>, an entry for the training dataset. Each entry of
the dictionary is another dictionary with an entry for each validation metric in the <code>estimator</code>.
Each of these entries is an array that holds the validation metric's value for each dataset, at the
last valid iteration.</p>
<h4><a id="user-content-arguments-2" class="anchor" aria-hidden="true" href="#arguments-2"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Arguments</h4>
<ul>
<li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li>
<li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li>
<li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li>
<li><code>splits</code>: the iterable providing arrays of indices for the training dataset.</li>
<li><code>verbosity::Integer</code>: keyword argument that controls LightGBM's verbosity. <code>&lt; 0</code> for fatal logs
only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li>
</ul>
<h3><a id="user-content-search_cvestimator-x-y-splits-params-verbosity--1-experimentalinterface-may-change" class="anchor" aria-hidden="true" href="#search_cvestimator-x-y-splits-params-verbosity--1-experimentalinterface-may-change"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>search_cv(estimator, X, y, splits, params; [verbosity = 1])</code> (Experimental—interface may change)</h3>
<p>Exhaustive search over the specified sets of parameter values for the <code>estimator</code> with features
data <code>X</code> and label <code>y</code>. The iterable <code>splits</code> provides vectors of indices for the training dataset.
The remaining indices are used to create the validation dataset.</p>
<p>Return an array with a tuple for each set of parameters value, where the first entry is a set of
parameter values and the second entry the cross-validation outcome of those values. This outcome is
a dictionary with an entry for the validation dataset and, if the parameter <code>is_training_metric</code> is
set in the <code>estimator</code>, an entry for the training dataset. Each entry of the dictionary is
another dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these
entries is an array that holds the validation metric's value for each dataset, at the last valid
iteration.</p>
<h4><a id="user-content-arguments-3" class="anchor" aria-hidden="true" href="#arguments-3"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Arguments</h4>
<ul>
<li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li>
<li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li>
<li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li>
<li><code>splits</code>: the iterable providing arrays of indices for the training dataset.</li>
<li><code>params</code>: the iterable providing dictionaries of pairs of parameters (Symbols) and values to
configure the <code>estimator</code> with.</li>
<li><code>verbosity::Integer</code>: keyword argument that controls LightGBM's verbosity. <code>&lt; 0</code> for fatal logs
only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li>
</ul>
<h3><a id="user-content-savemodelestimator-filename-num_iteration---1" class="anchor" aria-hidden="true" href="#savemodelestimator-filename-num_iteration---1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>savemodel(estimator, filename; [num_iteration = -1])</code></h3>
<p>Save the fitted model in <code>estimator</code> as <code>filename</code>.</p>
<h4><a id="user-content-arguments-4" class="anchor" aria-hidden="true" href="#arguments-4"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Arguments</h4>
<ul>
<li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li>
<li><code>filename::String</code>: the name of the file to save the model in.</li>
<li><code>num_iteration::Integer</code>: keyword argument that sets the number of iterations of the model that
should be saved. <code>&lt; 0</code> for all iterations.</li>
</ul>
<h3><a id="user-content-loadmodelestimator-filename" class="anchor" aria-hidden="true" href="#loadmodelestimator-filename"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>loadmodel(estimator, filename)</code></h3>
<p>Load the fitted model <code>filename</code> into <code>estimator</code>. Note that this only loads the fitted model—not
the parameters or data of the estimator whose model was saved as <code>filename</code>.</p>
<h4><a id="user-content-arguments-5" class="anchor" aria-hidden="true" href="#arguments-5"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Arguments</h4>
<ul>
<li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li>
<li><code>filename::String</code>: the name of the file that contains the model.</li>
</ul>
<h2><a id="user-content-estimators" class="anchor" aria-hidden="true" href="#estimators"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Estimators</h2>
<h3><a id="user-content-lgbmregression--lgbmestimator" class="anchor" aria-hidden="true" href="#lgbmregression--lgbmestimator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>LGBMRegression &lt;: LGBMEstimator</code></h3>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">LGBMRegression</span>(;
    objective <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>regression<span class="pl-pds">"</span></span>,
    num_iterations <span class="pl-k">=</span> <span class="pl-c1">10</span>,
    learning_rate <span class="pl-k">=</span> <span class="pl-c1">.1</span>,
    num_leaves <span class="pl-k">=</span> <span class="pl-c1">127</span>,
    max_depth <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1</span>,
    tree_learner <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>serial<span class="pl-pds">"</span></span>,
    num_threads <span class="pl-k">=</span> Sys<span class="pl-k">.</span>CPU_THREADS,
    histogram_pool_size <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1.</span>,
    min_data_in_leaf <span class="pl-k">=</span> <span class="pl-c1">100</span>,
    min_sum_hessian_in_leaf <span class="pl-k">=</span> <span class="pl-c1">10.</span>,
    lambda_l1 <span class="pl-k">=</span> <span class="pl-c1">0.</span>,
    lambda_l2 <span class="pl-k">=</span> <span class="pl-c1">0.</span>,
    min_gain_to_split <span class="pl-k">=</span> <span class="pl-c1">0.</span>,
    feature_fraction <span class="pl-k">=</span> <span class="pl-c1">1.</span>,
    feature_fraction_seed <span class="pl-k">=</span> <span class="pl-c1">2</span>,
    bagging_fraction <span class="pl-k">=</span> <span class="pl-c1">1.</span>,
    bagging_freq <span class="pl-k">=</span> <span class="pl-c1">0</span>,
    bagging_seed <span class="pl-k">=</span> <span class="pl-c1">3</span>,
    early_stopping_round <span class="pl-k">=</span> <span class="pl-c1">0</span>,
    max_bin <span class="pl-k">=</span> <span class="pl-c1">255</span>,
    data_random_seed <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    init_score <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>,
    is_sparse <span class="pl-k">=</span> <span class="pl-c1">true</span>,
    save_binary <span class="pl-k">=</span> <span class="pl-c1">false</span>,
    categorical_feature <span class="pl-k">=</span> Int[],
    is_unbalance <span class="pl-k">=</span> <span class="pl-c1">false</span>,
    metric <span class="pl-k">=</span> [<span class="pl-s"><span class="pl-pds">"</span>l2<span class="pl-pds">"</span></span>],
    metric_freq <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    is_training_metric <span class="pl-k">=</span> <span class="pl-c1">false</span>,
    ndcg_at <span class="pl-k">=</span> Int[],
    num_machines <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    local_listen_port <span class="pl-k">=</span> <span class="pl-c1">12400</span>,
    time_out <span class="pl-k">=</span> <span class="pl-c1">120</span>,
    machine_list_file <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>,
    device_type<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>cpu<span class="pl-pds">"</span></span>,
)</pre></div>
<p>Return an LGBMRegression estimator.</p>
<h3><a id="user-content-lgbmclassification--lgbmestimator" class="anchor" aria-hidden="true" href="#lgbmclassification--lgbmestimator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>LGBMClassification &lt;: LGBMEstimator</code></h3>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">LGBMClassification</span>(;
    objective <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>multiclass<span class="pl-pds">"</span></span>,
    num_iterations <span class="pl-k">=</span> <span class="pl-c1">10</span>,
    learning_rate <span class="pl-k">=</span> <span class="pl-c1">.1</span>,
    num_leaves <span class="pl-k">=</span> <span class="pl-c1">127</span>,
    max_depth <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1</span>,
    tree_learner <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>serial<span class="pl-pds">"</span></span>,
    num_threads <span class="pl-k">=</span> Sys<span class="pl-k">.</span>CPU_THREADS,
    histogram_pool_size <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1.</span>,
    min_data_in_leaf <span class="pl-k">=</span> <span class="pl-c1">100</span>,
    min_sum_hessian_in_leaf <span class="pl-k">=</span> <span class="pl-c1">10.</span>,
    lambda_l1 <span class="pl-k">=</span> <span class="pl-c1">0.</span>,
    lambda_l2 <span class="pl-k">=</span> <span class="pl-c1">0.</span>,
    min_gain_to_split <span class="pl-k">=</span> <span class="pl-c1">0.</span>,
    feature_fraction <span class="pl-k">=</span> <span class="pl-c1">1.</span>,
    feature_fraction_seed <span class="pl-k">=</span> <span class="pl-c1">2</span>,
    bagging_fraction <span class="pl-k">=</span> <span class="pl-c1">1.</span>,
    bagging_freq <span class="pl-k">=</span> <span class="pl-c1">0</span>,
    bagging_seed <span class="pl-k">=</span> <span class="pl-c1">3</span>,
    early_stopping_round <span class="pl-k">=</span> <span class="pl-c1">0</span>,
    max_bin <span class="pl-k">=</span> <span class="pl-c1">255</span>,
    data_random_seed <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    init_score <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>,
    is_sparse <span class="pl-k">=</span> <span class="pl-c1">true</span>,
    save_binary <span class="pl-k">=</span> <span class="pl-c1">false</span>,
    categorical_feature <span class="pl-k">=</span> Int[],
    is_unbalance <span class="pl-k">=</span> <span class="pl-c1">false</span>,
    metric <span class="pl-k">=</span> [<span class="pl-s"><span class="pl-pds">"</span>multi_logloss<span class="pl-pds">"</span></span>],
    metric_freq <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    is_training_metric <span class="pl-k">=</span> <span class="pl-c1">false</span>,
    ndcg_at <span class="pl-k">=</span> Int[],
    num_machines <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    local_listen_port <span class="pl-k">=</span> <span class="pl-c1">12400</span>,
    time_out <span class="pl-k">=</span> <span class="pl-c1">120</span>,
    machine_list_file <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>,
    num_class <span class="pl-k">=</span> <span class="pl-c1">2</span>,
    device_type<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>cpu<span class="pl-pds">"</span></span>,
)</pre></div>
<p>Return an LGBMClassification estimator.</p>
<h1><a id="user-content-mlj-support" class="anchor" aria-hidden="true" href="#mlj-support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MLJ Support</h1>
<p>This package has an interface to <a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a>.
Exhaustive MLJ documentation is out of scope for here, however the main things are:</p>
<p>The MLJ interface models are</p>
<div class="highlight highlight-source-julia"><pre>LightGBM<span class="pl-k">.</span>MLJInterface<span class="pl-k">.</span>LGBMClassifier
LightGBM<span class="pl-k">.</span>MLJInterface<span class="pl-k">.</span>LGBMRegressor</pre></div>
<p>And these have the same interface parameters as the <a href="#estimators">estimators</a></p>
<p>The interface models are generally passed to <code>MLJBase.fit</code> or <code>MLJBase.machine</code>
and integrated as part of a larger MLJ pipeline. <a href="#where">An example is provided</a></p>
</article></div>