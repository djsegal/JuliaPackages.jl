<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-bandits" class="anchor" aria-hidden="true" href="#bandits"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Bandits</h1>
<p><a href="https://travis-ci.org/rawls238/Bandits.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/47a258c88c03eabdab851dbad14b6e9fdebaedb3/68747470733a2f2f7472617669732d63692e6f72672f7261776c733233382f42616e646974732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/rawls238/Bandits.jl.svg?branch=master" style="max-width:100%;"></a></p>
<p>This package provides tools for simulation of <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit" rel="nofollow">multi-armed bandit problems</a>.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<pre><code>Pkg.add("Bandits")
</code></pre>
<h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Documentation</h2>
<p>There are several underlying types that need to be constructed before simulation.</p>
<p>The first is a <code>Bandit</code> type, which specifies the true distribution of each of the arms. Currently only <code>StaticBandit</code> is implemented which takes an array of <code>Distribution</code> types from <code>Distributions.jl</code> (i.e. <code>staticbandit([Normal(0, 1), Uniform(0, 1)])</code>).</p>
<p>The second is a <code>Policy</code> type, which specifies the policy the agent is going to follow. This type is used to specify the arm the agent should choose given the agent's beliefs over the arms.</p>
<p>Currently, the implemented policies are:</p>
<ul>
<li>Greedy</li>
<li>Epsilon-Greedy</li>
<li>ThompsonSampling</li>
<li>UCB1</li>
<li>ExploreThenExploit</li>
</ul>
<p>The third is a <code>Agent</code> type, which requires the prior of the agent, the underlying bandit, and the policy the agent should follow.</p>
<p>Currently, the following Agents are implemented:</p>
<ul>
<li>BasicAgent - this agent forms beliefs over the arms based only on observed rewards (via the empirical mean) and an initial belief about the means of the arms.</li>
<li>BetaBernoulliAgent - this agent has beta priors and should be used wih Bernoulli-distributed arms. Posterior updating is done via the standard Bayesian updating formula for the Beta distribution.</li>
<li>NormalAgent - this agent has Gaussian priors and should be used with Gaussian arms.</li>
</ul>
<p>Now, we can call <code>simulate</code> and get back a <code>BanditStats</code> object which returns the regret and the number of times each arm was pulled.</p>
<p>As well, this package provides an <code>aggregate_simulate</code> function which aggregates the results of N simulations run in parallel and returns the average.</p>
<p>Example usage as follows:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Bandits

thompson_sampling <span class="pl-k">=</span> <span class="pl-c1">ThompsonSampling</span>()
sb <span class="pl-k">=</span> <span class="pl-c1">staticbandit</span>([<span class="pl-c1">Bernoulli</span>(<span class="pl-c1">0.5</span>), <span class="pl-c1">Bernoulli</span>(<span class="pl-c1">0.6</span>)])
beta_agent <span class="pl-k">=</span> <span class="pl-c1">BetaBernoulliAgent</span>([<span class="pl-c1">0.6</span>, <span class="pl-c1">0.5</span>], thompson_sampling, sb)
stats <span class="pl-k">=</span> <span class="pl-c1">simulate</span>(sb, beta_agent, <span class="pl-c1">100</span>)
<span class="pl-c1">print</span>(stats<span class="pl-k">.</span>regret)</pre></div>
<p>License: MIT</p>
</article></div>