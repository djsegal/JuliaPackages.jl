<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p align="center">
<a target="_blank" rel="noopener noreferrer" href="figs/logo.png"><img width="10%" src="figs/logo.png" style="max-width:100%;"></a>
</p>
<h1><a id="user-content-stochasticroundingjl" class="anchor" aria-hidden="true" href="#stochasticroundingjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>StochasticRounding.jl</h1>
<p><a href="https://github.com/milankl/StochasticRounding.jl/actions/workflows/CI.yml"><img src="https://github.com/milankl/StochasticRounding.jl/actions/workflows/CI.yml/badge.svg" alt="CI" style="max-width:100%;"></a><br>
Stochastic rounding for floating-point arithmetic.</p>
<p>This package exports <code>Float32sr</code>,<code>Float16sr</code>, and <code>BFloat16sr</code>, four number formats that behave
like their deterministic counterparts but with stochastic rounding that is proportional to the
distance of the next representable numbers and therefore
<a href="https://en.wikipedia.org/wiki/Rounding#Stochastic_rounding" rel="nofollow">exact in expectation</a>
(see also example below in "Usage").  Although there is currently no/little known hardware implementation available,
<a href="https://www.graphcore.ai/posts/directions-of-ai-research" rel="nofollow">Graphcore is working on IPUs with stochastic rounding</a>.
Stochastic rounding makes the number formats considerably slower, but e.g. Float32+stochastic rounding is only
about 2x slower than Float64.
<a href="https://sunoru.github.io/RandomNumbers.jl/stable/man/xorshifts/#Xorshift-Family-1" rel="nofollow">Xoroshiro128Plus</a>,
a random number generator from the <a href="https://en.wikipedia.org/wiki/Xorshift" rel="nofollow">Xorshift family</a>, is used through the
<a href="https://github.com/sunoru/RandomNumbers.jl">RandomNumbers.jl</a> package, due to its speed and statistical properties.</p>
<p>You are welcome to raise <a href="https://github.com/milankl/StochasticRounding.jl/issues">issues</a>,
ask questions or suggest any changes or new features.</p>
<p><code>BFloat16sr</code> is based on <a href="https://github.com/JuliaMath/BFloat16s.jl">BFloat16s.jl</a><br>
<code>Float16sr</code> is slow in Julia &lt;1.6, but fast in Julia ^1.6 due to LLVM's <code>half</code> support.</p>
<h3><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h3>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; a = BFloat16sr(1.0)
BFloat16sr(1.0)
julia&gt; a/3
BFloat16sr(0.33398438)
julia&gt; a/3
BFloat16sr(0.33203125)
"><pre>julia<span class="pl-k">&gt;</span> a <span class="pl-k">=</span> <span class="pl-c1">BFloat16sr</span>(<span class="pl-c1">1.0</span>)
<span class="pl-c1">BFloat16sr</span>(<span class="pl-c1">1.0</span>)
julia<span class="pl-k">&gt;</span> a<span class="pl-k">/</span><span class="pl-c1">3</span>
<span class="pl-c1">BFloat16sr</span>(<span class="pl-c1">0.33398438</span>)
julia<span class="pl-k">&gt;</span> a<span class="pl-k">/</span><span class="pl-c1">3</span>
<span class="pl-c1">BFloat16sr</span>(<span class="pl-c1">0.33203125</span>)</pre></div>
<p>As <code>1/3</code> is not exactly representable the rounding will be at 66.6% chance towards 0.33398438
and at 33.3% towards 0.33203125 such that in expectation the result is 0.33333... and therefore exact.
You can use <code>BFloat16_chance_roundup(x::Float32)</code> to get the chance that <code>x</code> will be round up.</p>
<p>From v0.3 onwards the random number generator is randomly seeded on every <code>import</code>
or <code>using</code> such that running the same calculations twice, will, in general, not
yield bit-reproducible results. However, you can seed the random number generator
at any time with any integer larger than zero as follows</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; StochasticRounding.seed(2156712)
"><pre>julia<span class="pl-k">&gt;</span> StochasticRounding<span class="pl-k">.</span><span class="pl-c1">seed</span>(<span class="pl-c1">2156712</span>)</pre></div>
<h3><a id="user-content-theory" class="anchor" aria-hidden="true" href="#theory"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Theory</h3>
<p>Round-to-nearest (tie to even) is the standard rounding mode for IEEE floats. Stochastic rounding is explained in the following schematic</p>
<p><a target="_blank" rel="noopener noreferrer" href="figs/schematic.png"><img src="figs/schematic.png" style="max-width:100%;"></a></p>
<p>The exact result x of an arithmetic operation (located at one fifth between x₂ and x₃ in this example) is always round down to x₂ for round-to-nearest.
For stochastic rounding, only at 80% chance x is round down. At 20% chance it is round up to x₃, proportional to the distance of x between x₂ and x₃.</p>
<h3><a id="user-content-subnormals" class="anchor" aria-hidden="true" href="#subnormals"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Subnormals</h3>
<p>From v0.6 onwards all subnormals of Float32, Float16, BFloat16 are always accounted for in the stochastic rounding.</p>
<h3><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h3>
<p>StochasticRounding.jl is registered in the Julia registry. Hence, simply do</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt;] add StochasticRounding
"><pre>julia<span class="pl-k">&gt;</span>] add StochasticRounding</pre></div>
<p>where <code>]</code> opens the package manager.</p>
<h3><a id="user-content-performance" class="anchor" aria-hidden="true" href="#performance"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Performance</h3>
<p>StochasticRounding.jl is among the fastest software implementation of stochastic rounding for floating-point arithmetic. Define a few random 1000000-element arrays</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; using StochasticRounding, BenchmarkTools, BFloat16s
julia&gt; A = rand(Float64,1000000);
julia&gt; B = rand(Float64,1000000);   # A, B shouldn't be identical as a+a=2a is not round
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> StochasticRounding, BenchmarkTools, BFloat16s
julia<span class="pl-k">&gt;</span> A <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float64,<span class="pl-c1">1000000</span>);
julia<span class="pl-k">&gt;</span> B <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float64,<span class="pl-c1">1000000</span>);   <span class="pl-c"><span class="pl-c">#</span> A, B shouldn't be identical as a+a=2a is not round</span></pre></div>
<p>And similarly for the other number types. Then with Julia 1.6 on an Intel(R) Core(R) i5 (Ice Lake) @ 1.1GHz timings via <code>@btime +($A,$B)</code> are</p>
<table>
<thead>
<tr>
<th>rounding mode</th>
<th>Float64</th>
<th>Float32</th>
<th>Float16</th>
<th>BFloat16</th>
</tr>
</thead>
<tbody>
<tr>
<td>round to nearest</td>
<td>1132 μs</td>
<td>452 μs</td>
<td>1588 μs</td>
<td>354 μs</td>
</tr>
<tr>
<td>stochastic rounding</td>
<td>n/a</td>
<td>2815 μs</td>
<td>3310 μs</td>
<td>4100 μs</td>
</tr>
</tbody>
</table>
<p>Stochastic rounding imposes an about x5 performance decrease for Float32, only x2 for Float16, but &gt;10x for BFloat16.
For more complicated benchmarks the performance decrease is usually within x10.
About 50% of the time is spend on the random number generation with Xoroshiro128+.</p>
</article></div>