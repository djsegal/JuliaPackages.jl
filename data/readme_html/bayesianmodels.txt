<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-ppca" class="anchor" aria-hidden="true" href="#ppca"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>PPCA</h1>
<p>Julia package for Probabilistic Principal Components Analysis as
described in <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/bishop-vpca-icann-99.pdf" rel="nofollow">"Variational Principal Components Analysis"</a>.</p>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<p>You first need to create a <code>PPCAModel</code>:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; model = PPCAModel(datadim = 2, latentdim = 2)
PPCAModelHP{Float64,2,2}:
  αprior:
    ExpFamilyDistributions.Gamma{Float64}:
      α = 0.001
      β = 0.001
  wprior:
    ExpFamilyDistributions.Normal{Float64,3}:
      μ = [0.0, 0.0, 0.0]
      Σ = [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0]
  hprior:
    ExpFamilyDistributions.Normal{Float64,2}:
      μ = [0.0, 0.0]
      Σ = [1.0 0.0; 0.0 1.0]
  λprior:
    ExpFamilyDistributions.Gamma{Float64}:
      α = 0.001
      β = 0.001
"><pre>julia<span class="pl-k">&gt;</span> model <span class="pl-k">=</span> <span class="pl-c1">PPCAModel</span>(datadim <span class="pl-k">=</span> <span class="pl-c1">2</span>, latentdim <span class="pl-k">=</span> <span class="pl-c1">2</span>)
PPCAModelHP{Float64,<span class="pl-c1">2</span>,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
  αprior<span class="pl-k">:</span>
    ExpFamilyDistributions<span class="pl-k">.</span>Gamma{Float64}<span class="pl-k">:</span>
      α <span class="pl-k">=</span> <span class="pl-c1">0.001</span>
      β <span class="pl-k">=</span> <span class="pl-c1">0.001</span>
  wprior<span class="pl-k">:</span>
    ExpFamilyDistributions<span class="pl-k">.</span>Normal{Float64,<span class="pl-c1">3</span>}<span class="pl-k">:</span>
      μ <span class="pl-k">=</span> [<span class="pl-c1">0.0</span>, <span class="pl-c1">0.0</span>, <span class="pl-c1">0.0</span>]
      Σ <span class="pl-k">=</span> [<span class="pl-c1">1.0</span> <span class="pl-c1">0.0</span> <span class="pl-c1">0.0</span>; <span class="pl-c1">0.0</span> <span class="pl-c1">1.0</span> <span class="pl-c1">0.0</span>; <span class="pl-c1">0.0</span> <span class="pl-c1">0.0</span> <span class="pl-c1">1.0</span>]
  hprior<span class="pl-k">:</span>
    ExpFamilyDistributions<span class="pl-k">.</span>Normal{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
      μ <span class="pl-k">=</span> [<span class="pl-c1">0.0</span>, <span class="pl-c1">0.0</span>]
      Σ <span class="pl-k">=</span> [<span class="pl-c1">1.0</span> <span class="pl-c1">0.0</span>; <span class="pl-c1">0.0</span> <span class="pl-c1">1.0</span>]
  λprior<span class="pl-k">:</span>
    ExpFamilyDistributions<span class="pl-k">.</span>Gamma{Float64}<span class="pl-k">:</span>
      α <span class="pl-k">=</span> <span class="pl-c1">0.001</span>
      β <span class="pl-k">=</span> <span class="pl-c1">0.001</span></pre></div>
<p>In practice, you should set <code>latentdim</code> between <code>1</code> and <code>datadim - 1</code>
(included). If you set, as in the example above, <code>latentdim</code> greater or
equal to <code>datadim</code>, the model will automatically shrink the extra
bases to zero during training (see illustration).</p>
<p>Then, you need to initialize the variational posteriors. This is easily
done by:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; θposts = θposteriors(model)
Dict{Symbol,Any} with 3 entries:
  :α =&gt; ExpFamilyDistributions.Gamma{Float64}[Gamma{Float64}:…
  :w =&gt; ExpFamilyDistributions.Normal{Float64,2}[Normal{Float64,2}:…
  :λ =&gt; Gamma{Float64}:…
"><pre>julia<span class="pl-k">&gt;</span> θposts <span class="pl-k">=</span> <span class="pl-c1">θposteriors</span>(model)
Dict{Symbol,Any} with <span class="pl-c1">3</span> entries<span class="pl-k">:</span>
  <span class="pl-c1">:α</span> <span class="pl-k">=&gt;</span> ExpFamilyDistributions<span class="pl-k">.</span>Gamma{Float64}[Gamma{Float64}<span class="pl-k">:</span>…
  <span class="pl-c1">:w</span> <span class="pl-k">=&gt;</span> ExpFamilyDistributions<span class="pl-k">.</span>Normal{Float64,<span class="pl-c1">2</span>}[Normal{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>…
  <span class="pl-c1">:λ</span> <span class="pl-k">=&gt;</span> Gamma{Float64}<span class="pl-k">:</span>…</pre></div>
<p>For training, you need to provide a data loader from the
<a href="https://github.com/lucasondel/BasicDataLoaders">BasicDataLoaders</a>
package to access the data, and simply call <code>fit!</code>:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; dl = ... # Data loader
julia&gt; fit!(model, dl, θposts, epochs = 10)
"><pre>julia<span class="pl-k">&gt;</span> dl <span class="pl-k">=</span> <span class="pl-k">...</span> <span class="pl-c"><span class="pl-c">#</span> Data loader</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">fit!</span>(model, dl, θposts, epochs <span class="pl-k">=</span> <span class="pl-c1">10</span>)</pre></div>
<p>The training will be run in parallel if there are several workers
available. To add workers, see
<a href="https://docs.julialang.org/en/v1/stdlib/Distributed/" rel="nofollow"><code>addprocs</code></a>.</p>
<p>Finally, to extract the latent posteriors:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; X = dl[1] # Use the 1st batch of the data loader
julia&gt; hposteriors(model, X, θposts)
10-element Array{Normal{Float64,2},1}:
 Normal{Float64,2}:
  μ = [1.7512436452299205, -9.956494453759758e-8]
  Σ = [0.028248509216655084 5.1464934731583015e-8; 5.1464934731583015e-8 0.9657413079963144]
 Normal{Float64,2}:
  μ = [-1.7016493202424885, 9.674530645698072e-8]
  Σ = [0.028248509216655084 5.1464934731583015e-8; 5.1464934731583015e-8 0.9657413079963144]
...
"><pre>julia<span class="pl-k">&gt;</span> X <span class="pl-k">=</span> dl[<span class="pl-c1">1</span>] <span class="pl-c"><span class="pl-c">#</span> Use the 1st batch of the data loader</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">hposteriors</span>(model, X, θposts)
<span class="pl-c1">10</span><span class="pl-k">-</span>element Array{Normal{Float64,<span class="pl-c1">2</span>},<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 Normal{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
  μ <span class="pl-k">=</span> [<span class="pl-c1">1.7512436452299205</span>, <span class="pl-k">-</span><span class="pl-c1">9.956494453759758e-8</span>]
  Σ <span class="pl-k">=</span> [<span class="pl-c1">0.028248509216655084</span> <span class="pl-c1">5.1464934731583015e-8</span>; <span class="pl-c1">5.1464934731583015e-8</span> <span class="pl-c1">0.9657413079963144</span>]
 Normal{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
  μ <span class="pl-k">=</span> [<span class="pl-k">-</span><span class="pl-c1">1.7016493202424885</span>, <span class="pl-c1">9.674530645698072e-8</span>]
  Σ <span class="pl-k">=</span> [<span class="pl-c1">0.028248509216655084</span> <span class="pl-c1">5.1464934731583015e-8</span>; <span class="pl-c1">5.1464934731583015e-8</span> <span class="pl-c1">0.9657413079963144</span>]
<span class="pl-k">...</span></pre></div>
<p>For a complete example, have a look at the <a href="https://github.com/BUTSpeechFIT/PPCA/blob/master/examples/PPCA.ipynb">example jupyter notebook</a>.
<a target="_blank" rel="noopener noreferrer" href="https://github.com/BUTSpeechFIT/PPCA/blob/master/examples/demo.gif"><img src="https://github.com/BUTSpeechFIT/PPCA/raw/master/examples/demo.gif" alt="Alt Text" style="max-width:100%;"></a></p>
</article></div>