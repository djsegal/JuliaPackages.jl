<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a href="https://doi.org/10.5281/zenodo.5083368" rel="nofollow"><img src="https://camo.githubusercontent.com/cf41dd4ca6331e10b48560c3eee67c545d059c1571f8da5159e8c764de372adb/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e353038333336382e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.5083368.svg" style="max-width: 100%;"></a></p>
<h1 dir="auto"><a id="user-content-differentialevolutionmcmc" class="anchor" aria-hidden="true" href="#differentialevolutionmcmc"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DifferentialEvolutionMCMC</h1>
<p dir="auto">DifferentialEvolutionMCMC.jl is a Differential Evolution MCMC sampler written in Julia and uses the AbstractMCMC interface. DifferentialEvolutionMCMC.jl works with any model, provided that it returns an exact or approximate log likeilhood. An annotated example is provided below. Other examples can be found in the examples subfolder.</p>
<h2 dir="auto"><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h2>
<p dir="auto">First, load the required libraries.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using DifferentialEvolutionMCMC, Random, Distributions

Random.seed!(50514)"><pre><span class="pl-k">using</span> DifferentialEvolutionMCMC, Random, Distributions

Random<span class="pl-k">.</span><span class="pl-c1">seed!</span>(<span class="pl-c1">50514</span>)</pre></div>
<p dir="auto">Define a function that returns the prior log likelihood of parameters μ and σ. Note
that order matters for parameters throughout. The algorithm expects parameters to have
the same order.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="function prior_loglike(μ, σ)
    LL = 0.0
    LL += logpdf(Normal(0, 1), μ)
    LL += logpdf(truncated(Cauchy(0, 1), 0, Inf), σ)
    return LL
end"><pre><span class="pl-k">function</span> <span class="pl-en">prior_loglike</span>(μ, σ)
    LL <span class="pl-k">=</span> <span class="pl-c1">0.0</span>
    LL <span class="pl-k">+=</span> <span class="pl-c1">logpdf</span>(<span class="pl-c1">Normal</span>(<span class="pl-c1">0</span>, <span class="pl-c1">1</span>), μ)
    LL <span class="pl-k">+=</span> <span class="pl-c1">logpdf</span>(<span class="pl-c1">truncated</span>(<span class="pl-c1">Cauchy</span>(<span class="pl-c1">0</span>, <span class="pl-c1">1</span>), <span class="pl-c1">0</span>, <span class="pl-c1">Inf</span>), σ)
    <span class="pl-k">return</span> LL
<span class="pl-k">end</span></pre></div>
<p dir="auto">Define a function for the initial sample. Sampling from the prior distribution is
a reasonable choice for most applications.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="function sample_prior()
    μ = rand(Normal(0, 1))
    σ = rand(truncated(Cauchy(0, 1), 0, Inf))
    return [μ,σ]
end"><pre><span class="pl-k">function</span> <span class="pl-en">sample_prior</span>()
    μ <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">Normal</span>(<span class="pl-c1">0</span>, <span class="pl-c1">1</span>))
    σ <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">truncated</span>(<span class="pl-c1">Cauchy</span>(<span class="pl-c1">0</span>, <span class="pl-c1">1</span>), <span class="pl-c1">0</span>, <span class="pl-c1">Inf</span>))
    <span class="pl-k">return</span> [μ,σ]
<span class="pl-k">end</span></pre></div>
<p dir="auto">Next, define a function for the log likelihood which accepts the data followed by the parameters (in the order specififed in the priors).</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="function loglike(data, μ, σ)
    return sum(logpdf.(Normal(μ, σ), data))
end"><pre><span class="pl-k">function</span> <span class="pl-en">loglike</span>(data, μ, σ)
    <span class="pl-k">return</span> <span class="pl-c1">sum</span>(<span class="pl-c1">logpdf</span>.(<span class="pl-c1">Normal</span>(μ, σ), data))
<span class="pl-k">end</span></pre></div>
<p dir="auto">Specify the upper and lower bounds of the parameters.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="bounds = ((-Inf,Inf),(0.0,Inf))"><pre>bounds <span class="pl-k">=</span> ((<span class="pl-k">-</span><span class="pl-c1">Inf</span>,<span class="pl-c1">Inf</span>),(<span class="pl-c1">0.0</span>,<span class="pl-c1">Inf</span>))</pre></div>
<p dir="auto">Define the names of parameters. Elements of parameter vectors do not need to be named.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="names = (:μ,:σ)"><pre>names <span class="pl-k">=</span> (<span class="pl-c1">:μ</span>,<span class="pl-c1">:σ</span>)</pre></div>
<p dir="auto">Generate simulated data from a normal distribution</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="data = rand(Normal(0.0, 1.0), 50)"><pre>data <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">Normal</span>(<span class="pl-c1">0.0</span>, <span class="pl-c1">1.0</span>), <span class="pl-c1">50</span>)</pre></div>
<p dir="auto">Now we will create a model object containing the sampling and log likelihood functions, the data and parameter names.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="model = DEModel(; 
    sample_prior, 
    prior_loglike, 
    loglike, 
    data,
    names
)
"><pre>model <span class="pl-k">=</span> <span class="pl-c1">DEModel</span>(; 
    sample_prior, 
    prior_loglike, 
    loglike, 
    data,
    names
)
</pre></div>
<p dir="auto">Next, define the DifferentialEvolution sampling object. This requires <code>bounds</code>, <code>burnin</code> and <code>Np</code>, which is the number of particles.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="de = DE(;sample_prior, bounds, burnin = 1000, Np = 6)"><pre>de <span class="pl-k">=</span> <span class="pl-c1">DE</span>(;sample_prior, bounds, burnin <span class="pl-k">=</span> <span class="pl-c1">1000</span>, Np <span class="pl-k">=</span> <span class="pl-c1">6</span>)</pre></div>
<p dir="auto">To run the sampler, pass the model and differential evolution object along with settings for the number of iterations and MCMCMThreads() for multithreading.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="n_iter = 2000
chains = sample(model, de, MCMCThreads(), n_iter, progress=true)
println(chains)"><pre>n_iter <span class="pl-k">=</span> <span class="pl-c1">2000</span>
chains <span class="pl-k">=</span> <span class="pl-c1">sample</span>(model, de, <span class="pl-c1">MCMCThreads</span>(), n_iter, progress<span class="pl-k">=</span><span class="pl-c1">true</span>)
<span class="pl-c1">println</span>(chains)</pre></div>
</article></div>