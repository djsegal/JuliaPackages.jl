<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-daggergpu" class="anchor" aria-hidden="true" href="#daggergpu"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DaggerGPU</h1>
<p dir="auto"><strong>GPU integrations for Dagger.jl</strong></p>
<p dir="auto">DaggerGPU.jl makes use of the <code>Dagger.Processor</code> infrastructure to dispatch Dagger kernels to NVIDIA, AMD, and Apple GPUs, via CUDA.jl, AMDGPU.jl, and Metal.jl respectively. Usage is simple: <code>add</code> or <code>dev</code> DaggerGPU.jl and CUDA.jl/AMDGPU.jl/Metal.jl appropriately, load it with <code>using DaggerGPU</code>, and add <code>DaggerGPU.CuArrayDeviceProc</code>/<code>DaggerGPU.ROCArrayProc</code>/<code>DaggerGPU.MtlArrayDeviceProc</code> to your scheduler or thunk options (see Dagger.jl documentation for details on how to do this).</p>
<p dir="auto">DaggerGPU.jl is still experimental, but we welcome GPU-owning users to try it out and report back on any issues or sharp edges that they encounter. When filing an issue about DaggerGPU.jl, please provide:</p>
<ul dir="auto">
<li>The complete error message and backtrace</li>
<li>Julia version</li>
<li>GPU vendor and model</li>
<li>CUDA/AMDGPU version(s)</li>
</ul>
</article></div>