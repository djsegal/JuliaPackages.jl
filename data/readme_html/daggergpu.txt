<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-daggergpu" class="anchor" aria-hidden="true" href="#daggergpu"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>DaggerGPU</h1>
<p><strong>GPU integrations for Dagger.jl</strong></p>
<p>DaggerGPU.jl makes use of the <code>Dagger.Processor</code> infrastructure to dispatch Dagger kernels to NVIDIA and AMD GPUs, via CuArrays.jl and ROCArrays.jl respectively. Usage is simple: <code>add</code> or <code>dev</code> DaggerGPU.jl and CuArrays.jl/ROCArrays.jl appropriately, load it with <code>using DaggerGPU</code>, and add <code>DaggerGPU.CuArrayProc</code>/<code>DaggerGPU.ROCArrayProc</code> to your scheduler or thunk options (see Dagger.jl documentation for details on how to do this).</p>
<p>DaggerGPU.jl is still experimental, but we welcome GPU-owning users to try it out and report back on any issues or sharp edges that they encounter. When filing an issue about DaggerGPU.jl, please provide your:</p>
<ul>
<li>The complete error message and backtrace</li>
<li>Julia version</li>
<li>GPU vendor and model</li>
<li>CuArrays/ROCArrays version(s)</li>
</ul>
</article></div>