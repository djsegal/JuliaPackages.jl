<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-decisionprogrammingjl" class="anchor" aria-hidden="true" href="#decisionprogrammingjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DecisionProgramming.jl</h1>
<p dir="auto"><a href="https://gamma-opt.github.io/DecisionProgramming.jl/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667" alt="Docs Image" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg" style="max-width: 100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/gamma-opt/DecisionProgramming.jl/workflows/Runtests/badge.svg"><img src="https://github.com/gamma-opt/DecisionProgramming.jl/workflows/Runtests/badge.svg" alt="Runtests" style="max-width: 100%;"></a>
<a href="https://zenodo.org/badge/latestdoi/269314037" rel="nofollow"><img src="https://camo.githubusercontent.com/de93002b4a93de313529a3e702fe71ab003301d37167cf9693d741934ddfb216/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3236393331343033372e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/269314037.svg" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-description" class="anchor" aria-hidden="true" href="#description"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Description</h2>
<p dir="auto"><code>DecisionProgramming.jl</code> is a <a href="https://julialang.org/" rel="nofollow">Julia</a> package for solving multi-stage decision problems under uncertainty, modeled using influence diagrams. Internally, it relies on mathematical optimization. Decision models can be embedded within other optimization models. We designed the package as <a href="https://jump.dev/" rel="nofollow">JuMP</a> extension. We have also developed a <a href="https://python.org" rel="nofollow">Python</a> interface, which is available <a href="https://github.com/gamma-opt/pyDecisionProgramming">here</a>.</p>
<h2 dir="auto"><a id="user-content-citting" class="anchor" aria-hidden="true" href="#citting"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Citting</h2>
<p dir="auto">The Decision Prgramming framework is decribed in this publication. If you found the framework useful in your work, we kindly ask you to cite the following publication (<a href="https://www.sciencedirect.com/science/article/pii/S0377221721010201/pdf" rel="nofollow">pdf</a>):</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="@article{Salo_et_al-2022,
    title = {Decision programming for mixed-integer multi-stage optimization under uncertainty},
    journal = {European Journal of Operational Research},
    volume = {299},
    number = {2},
    pages = {550-565},
    year = {2022},
    issn = {0377-2217},
    doi = {https://doi.org/10.1016/j.ejor.2021.12.013},
    url = {https://www.sciencedirect.com/science/article/pii/S0377221721010201},
    author = {Ahti Salo and Juho Andelmin and Fabricio Oliveira},
    keywords = {Decision analysis, Influence diagrams, Decision trees, Contingent portfolio programming, Stochastic programming}
}"><pre class="notranslate"><code>@article{Salo_et_al-2022,
    title = {Decision programming for mixed-integer multi-stage optimization under uncertainty},
    journal = {European Journal of Operational Research},
    volume = {299},
    number = {2},
    pages = {550-565},
    year = {2022},
    issn = {0377-2217},
    doi = {https://doi.org/10.1016/j.ejor.2021.12.013},
    url = {https://www.sciencedirect.com/science/article/pii/S0377221721010201},
    author = {Ahti Salo and Juho Andelmin and Fabricio Oliveira},
    keywords = {Decision analysis, Influence diagrams, Decision trees, Contingent portfolio programming, Stochastic programming}
}
</code></pre></div>
<h2 dir="auto"><a id="user-content-syntax" class="anchor" aria-hidden="true" href="#syntax"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Syntax</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="examples/figures/simple-id.svg"><img src="examples/figures/simple-id.svg" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">We can create an influence diagram as follows:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using DecisionProgramming

diagram = InfluenceDiagram()

add_node!(diagram, DecisionNode(&quot;A&quot;, [], [&quot;a&quot;, &quot;b&quot;]))
add_node!(diagram, DecisionNode(&quot;D&quot;, [&quot;B&quot;, &quot;C&quot;], [&quot;k&quot;, &quot;l&quot;]))
add_node!(diagram, ChanceNode(&quot;B&quot;, [&quot;A&quot;], [&quot;x&quot;, &quot;y&quot;]))
add_node!(diagram, ChanceNode(&quot;C&quot;, [&quot;A&quot;], [&quot;v&quot;, &quot;w&quot;]))
add_node!(diagram, ValueNode(&quot;V&quot;, [&quot;D&quot;]))

generate_arcs!(diagram)

add_probabilities!(diagram, &quot;B&quot;, [0.4 0.6; 0.6 0.4])
add_probabilities!(diagram, &quot;C&quot;, [0.7 0.3; 0.3 0.7])
add_utilities!(diagram, &quot;V&quot;, [1.5, 1.7])

generate_diagram!(diagram)"><pre><span class="pl-k">using</span> DecisionProgramming

diagram <span class="pl-k">=</span> <span class="pl-c1">InfluenceDiagram</span>()

<span class="pl-c1">add_node!</span>(diagram, <span class="pl-c1">DecisionNode</span>(<span class="pl-s"><span class="pl-pds">"</span>A<span class="pl-pds">"</span></span>, [], [<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>b<span class="pl-pds">"</span></span>]))
<span class="pl-c1">add_node!</span>(diagram, <span class="pl-c1">DecisionNode</span>(<span class="pl-s"><span class="pl-pds">"</span>D<span class="pl-pds">"</span></span>, [<span class="pl-s"><span class="pl-pds">"</span>B<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>C<span class="pl-pds">"</span></span>], [<span class="pl-s"><span class="pl-pds">"</span>k<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>l<span class="pl-pds">"</span></span>]))
<span class="pl-c1">add_node!</span>(diagram, <span class="pl-c1">ChanceNode</span>(<span class="pl-s"><span class="pl-pds">"</span>B<span class="pl-pds">"</span></span>, [<span class="pl-s"><span class="pl-pds">"</span>A<span class="pl-pds">"</span></span>], [<span class="pl-s"><span class="pl-pds">"</span>x<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>y<span class="pl-pds">"</span></span>]))
<span class="pl-c1">add_node!</span>(diagram, <span class="pl-c1">ChanceNode</span>(<span class="pl-s"><span class="pl-pds">"</span>C<span class="pl-pds">"</span></span>, [<span class="pl-s"><span class="pl-pds">"</span>A<span class="pl-pds">"</span></span>], [<span class="pl-s"><span class="pl-pds">"</span>v<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>w<span class="pl-pds">"</span></span>]))
<span class="pl-c1">add_node!</span>(diagram, <span class="pl-c1">ValueNode</span>(<span class="pl-s"><span class="pl-pds">"</span>V<span class="pl-pds">"</span></span>, [<span class="pl-s"><span class="pl-pds">"</span>D<span class="pl-pds">"</span></span>]))

<span class="pl-c1">generate_arcs!</span>(diagram)

<span class="pl-c1">add_probabilities!</span>(diagram, <span class="pl-s"><span class="pl-pds">"</span>B<span class="pl-pds">"</span></span>, [<span class="pl-c1">0.4</span> <span class="pl-c1">0.6</span>; <span class="pl-c1">0.6</span> <span class="pl-c1">0.4</span>])
<span class="pl-c1">add_probabilities!</span>(diagram, <span class="pl-s"><span class="pl-pds">"</span>C<span class="pl-pds">"</span></span>, [<span class="pl-c1">0.7</span> <span class="pl-c1">0.3</span>; <span class="pl-c1">0.3</span> <span class="pl-c1">0.7</span>])
<span class="pl-c1">add_utilities!</span>(diagram, <span class="pl-s"><span class="pl-pds">"</span>V<span class="pl-pds">"</span></span>, [<span class="pl-c1">1.5</span>, <span class="pl-c1">1.7</span>])

<span class="pl-c1">generate_diagram!</span>(diagram)</pre></div>
<p dir="auto">Using the influence diagram, we create the decision model as follow:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using JuMP
model = Model()
z = DecisionVariables(model, diagram)
x_s = PathCompatibilityVariables(model, diagram, z)
EV = expected_value(model, diagram, x_s)
@objective(model, Max, EV)"><pre><span class="pl-k">using</span> JuMP
model <span class="pl-k">=</span> <span class="pl-c1">Model</span>()
z <span class="pl-k">=</span> <span class="pl-c1">DecisionVariables</span>(model, diagram)
x_s <span class="pl-k">=</span> <span class="pl-c1">PathCompatibilityVariables</span>(model, diagram, z)
EV <span class="pl-k">=</span> <span class="pl-c1">expected_value</span>(model, diagram, x_s)
<span class="pl-c1">@objective</span>(model, Max, EV)</pre></div>
<p dir="auto">We can optimize the model using MILP solver.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Gurobi
optimizer = optimizer_with_attributes(
    () -&gt; Gurobi.Optimizer(Gurobi.Env()),
    &quot;IntFeasTol&quot;      =&gt; 1e-9,
)
set_optimizer(model, optimizer)
optimize!(model)"><pre><span class="pl-k">using</span> Gurobi
optimizer <span class="pl-k">=</span> <span class="pl-c1">optimizer_with_attributes</span>(
    () <span class="pl-k">-&gt;</span> Gurobi<span class="pl-k">.</span><span class="pl-c1">Optimizer</span>(Gurobi<span class="pl-k">.</span><span class="pl-c1">Env</span>()),
    <span class="pl-s"><span class="pl-pds">"</span>IntFeasTol<span class="pl-pds">"</span></span>      <span class="pl-k">=&gt;</span> <span class="pl-c1">1e-9</span>,
)
<span class="pl-c1">set_optimizer</span>(model, optimizer)
<span class="pl-c1">optimize!</span>(model)</pre></div>
<p dir="auto">Finally, we extract the decision strategy from the decision variables.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="Z = DecisionStrategy(z)"><pre>Z <span class="pl-k">=</span> <span class="pl-c1">DecisionStrategy</span>(z)</pre></div>
<p dir="auto">See the <a href="https://gamma-opt.github.io/DecisionProgramming.jl/dev/" rel="nofollow">documentation</a> for more detailed examples.</p>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto"><code>DecisionProgramming.jl</code> is registered. You can add it using the command:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; add DecisionProgramming"><pre lang="julia-repl" class="notranslate"><code>pkg&gt; add DecisionProgramming
</code></pre></div>
<p dir="auto">To run examples and develop and solve decision models, you have to install JuMP and a solver capable of solving mixed-integer linear programs (MILP). JuMP documentation contains a list of available solvers.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; add JuMP"><pre lang="julia-repl" class="notranslate"><code>pkg&gt; add JuMP
</code></pre></div>
<p dir="auto">We recommend using the <a href="https://www.gurobi.com/" rel="nofollow">Gurobi</a> solver, which is an efficient commercial solver. Academics use Gurobi for free with an academic license. You also need to install the Julia Gurobi package.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; add Gurobi"><pre lang="julia-repl" class="notranslate"><code>pkg&gt; add Gurobi
</code></pre></div>
<p dir="auto">Now you are ready to use decision programming.</p>
<h2 dir="auto"><a id="user-content-development" class="anchor" aria-hidden="true" href="#development"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Development</h2>
<p dir="auto">Using the package manager, add <code>DecisionProgramming.jl</code> package for development using the command:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; develop DecisionProgramming"><pre lang="julia-repl" class="notranslate"><code>pkg&gt; develop DecisionProgramming
</code></pre></div>
<p dir="auto">If you have already cloned <code>DecisionProgramming</code> from GitHub, you can use the command:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; develop ."><pre lang="julia-repl" class="notranslate"><code>pkg&gt; develop .
</code></pre></div>
<p dir="auto">Inside <code>DecisionProgramming</code> directory, run tests using the commands:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; activate .
(DecisionProgramming) pkg&gt; test"><pre lang="julia-repl" class="notranslate"><code>pkg&gt; activate .
(DecisionProgramming) pkg&gt; test
</code></pre></div>
<p dir="auto">You can find more instruction on how to install packages for development at Julia's <a href="https://docs.julialang.org/en/v1/stdlib/Pkg/" rel="nofollow">Pkg documentation.</a></p>
</article></div>