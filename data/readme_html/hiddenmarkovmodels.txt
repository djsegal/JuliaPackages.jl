<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-hiddenmarkovmodelsjl" class="anchor" aria-hidden="true" href="#hiddenmarkovmodelsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>HiddenMarkovModels.jl</h1>
<p>Basic simulation / parameter estimation / latent state inference for hidden Markov models. Thin front-end package built on top of <a href="https://github.com/BenConnault/DynamicDiscreteModels.jl">DynamicDiscreteModels.jl</a>.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>HiddenMarkovModels<span class="pl-pds">"</span></span>)</pre></div>
<p>##Usage</p>
<p>Let's take a hidden Markov model with hidden/latent state x and emission/observed sate y. x can takes values 1,2, and y can take values 1, 2, 3. x has transition matrix A and y is drawn conditional on x according to the matrix B below:</p>
<pre><code>.
    [ .4   .6 ]        [ .3   .1   .6 ]
A = [ .3   .7 ]    B = [ .5   .2   .3 ]
</code></pre>
<p>Here is the Julia code to initiate the model, draw 10,000 consecutive observations from it, and estimate the value of A and B from the data using the Baum-Welch algorithm. The Baum-Welch algorithm is just the standard EM algorithm, where the optimization step (the M step) is accessible in closed-form thanks to the particular structure of hidden Markov models. We obtain the maximum likelihood estimator.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> HiddenMarkovModels;
julia<span class="pl-k">&gt;</span> a<span class="pl-k">=</span>[<span class="pl-c1">.4</span> <span class="pl-c1">.6</span>; <span class="pl-c1">.3</span> <span class="pl-c1">.7</span>];
julia<span class="pl-k">&gt;</span> b<span class="pl-k">=</span>[<span class="pl-c1">.3</span> <span class="pl-c1">.1</span> <span class="pl-c1">.6</span>; <span class="pl-c1">.5</span> <span class="pl-c1">.2</span> <span class="pl-c1">.3</span>];
julia<span class="pl-k">&gt;</span> model<span class="pl-k">=</span><span class="pl-c1">hmm</span>((a,b));
julia<span class="pl-k">&gt;</span> data<span class="pl-k">=</span><span class="pl-c1">rand</span>(model,<span class="pl-c1">10000</span>);
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@time</span> abhat<span class="pl-k">=</span><span class="pl-c1">em</span>(model,data)
estimating hidden Markov model via Baum<span class="pl-k">-</span>Welch algorithm<span class="pl-k">...</span>
 log<span class="pl-k">-</span>likelihood<span class="pl-k">:</span> <span class="pl-k">-</span><span class="pl-c1">1.0267</span>
 <span class="pl-c1">0.004404</span> seconds (<span class="pl-c1">102</span> allocations<span class="pl-k">:</span> <span class="pl-c1">317.891</span> KB)
(
<span class="pl-c1">2</span>x2 Array{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
<span class="pl-c1">0.398849</span>  <span class="pl-c1">0.601151</span>
<span class="pl-c1">0.300235</span>  <span class="pl-c1">0.699765</span>,

<span class="pl-c1">2</span>x3 Array{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
<span class="pl-c1">0.301938</span>  <span class="pl-c1">0.099349</span>  <span class="pl-c1">0.598713</span>
<span class="pl-c1">0.501222</span>  <span class="pl-c1">0.199013</span>  <span class="pl-c1">0.299765</span>)</pre></div>
<p>In this example it took 4.4 ms to compute the MLE from 10,000 time series observations. The heavy-lifting is done in the back-end package  <a href="https://github.com/BenConnault/DynamicDiscreteModels.jl">DynamicDiscreteModels.jl</a>.</p>
</article></div>