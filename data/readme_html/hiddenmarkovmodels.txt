<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-hiddenmarkovmodelsjl" class="anchor" aria-hidden="true" href="#hiddenmarkovmodelsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>HiddenMarkovModels.jl</h1>
<p>Basic simulation / parameter estimation / latent state inference for hidden Markov models. Thin front-end package built on top of <a href="https://github.com/BenConnault/DynamicDiscreteModels.jl">DynamicDiscreteModels.jl</a>.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>HiddenMarkovModels<span class="pl-pds">"</span></span>)</pre></div>
<p>##Usage</p>
<p>Let's take a hidden Markov model with hidden/latent state x and emission/observed sate y. x can takes values 1,2, and y can take values 1, 2, 3. x has transition matrix A and y is drawn conditional on x according to the matrix B below:</p>
<pre><code>.
    [ .4   .6 ]        [ .3   .1   .6 ]
A = [ .3   .7 ]    B = [ .5   .2   .3 ]
</code></pre>
<p>Here is the Julia code to initiate the model, draw 10,000 consecutive observations from it, and estimate the value of A and B from the data using the Baum-Welch algorithm. The Baum-Welch algorithm is just the standard EM algorithm, where the optimization step (the M step) is accessible in closed-form thanks to the particular structure of hidden Markov models. We obtain the maximum likelihood estimator.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> HiddenMarkovModels;
julia<span class="pl-k">&gt;</span> a<span class="pl-k">=</span>[<span class="pl-c1">.4</span> <span class="pl-c1">.6</span>; <span class="pl-c1">.3</span> <span class="pl-c1">.7</span>];
julia<span class="pl-k">&gt;</span> b<span class="pl-k">=</span>[<span class="pl-c1">.3</span> <span class="pl-c1">.1</span> <span class="pl-c1">.6</span>; <span class="pl-c1">.5</span> <span class="pl-c1">.2</span> <span class="pl-c1">.3</span>];
julia<span class="pl-k">&gt;</span> model<span class="pl-k">=</span><span class="pl-c1">hmm</span>((a,b));
julia<span class="pl-k">&gt;</span> data<span class="pl-k">=</span><span class="pl-c1">rand</span>(model,<span class="pl-c1">10000</span>);
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@time</span> abhat<span class="pl-k">=</span><span class="pl-c1">em</span>(model,data)
estimating hidden Markov model via Baum<span class="pl-k">-</span>Welch algorithm<span class="pl-k">...</span>
 log<span class="pl-k">-</span>likelihood<span class="pl-k">:</span> <span class="pl-k">-</span><span class="pl-c1">1.0267</span>
 <span class="pl-c1">0.004404</span> seconds (<span class="pl-c1">102</span> allocations<span class="pl-k">:</span> <span class="pl-c1">317.891</span> KB)
(
<span class="pl-c1">2</span>x2 Array{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
<span class="pl-c1">0.398849</span>  <span class="pl-c1">0.601151</span>
<span class="pl-c1">0.300235</span>  <span class="pl-c1">0.699765</span>,

<span class="pl-c1">2</span>x3 Array{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
<span class="pl-c1">0.301938</span>  <span class="pl-c1">0.099349</span>  <span class="pl-c1">0.598713</span>
<span class="pl-c1">0.501222</span>  <span class="pl-c1">0.199013</span>  <span class="pl-c1">0.299765</span>)</pre></div>
<p>In this example it took 4.4 ms to compute the MLE from 10,000 time series observations. The heavy-lifting is done in the back-end package  <a href="https://github.com/BenConnault/DynamicDiscreteModels.jl">DynamicDiscreteModels.jl</a>.</p>
</article></div>