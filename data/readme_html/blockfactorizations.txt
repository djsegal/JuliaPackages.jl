<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-blockfactorizationsjl" class="anchor" aria-hidden="true" href="#blockfactorizationsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>BlockFactorizations.jl</h1>
<p dir="auto"><a href="https://github.com/SebastianAment/BlockFactorizations.jl/actions/workflows/CI.yml"><img src="https://github.com/SebastianAment/BlockFactorizations.jl/actions/workflows/CI.yml/badge.svg" alt="CI" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/SebastianAment/BlockFactorizations.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/898fdaeb4fde7fa983bb5a404b2ecaea58088484459f7181ae59f1a3b03d7cad/68747470733a2f2f636f6465636f762e696f2f67682f53656261737469616e416d656e742f426c6f636b466163746f72697a6174696f6e732e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d32374338373633523753" alt="codecov" data-canonical-src="https://codecov.io/gh/SebastianAment/BlockFactorizations.jl/branch/main/graph/badge.svg?token=27C8763R7S" style="max-width: 100%;"></a></p>
<p dir="auto">This package contains a data structure that wraps a matrix of matrices or factorizations and acts like the matrix resulting from concatenating the input matrices (see below).
Notably, this allows the use of canonical linear algebra routines that just need to access <code>mul!</code> or <code>*</code> without special consideration for the block structure.
The structure contained herein differentiates itself from <a href="https://github.com/JuliaArrays/BlockArrays.jl">BlockArrays.jl</a>
in that it allows the blocks to be <code>AbstractMatrix</code> or <code>Factorization</code> types, therefore allowing the exploitation of more general matrix structure for efficient matrix multiplications.
See the <a href="https://en.wikipedia.org/wiki/Block_matrix" rel="nofollow">Wikipedia</a> article for more information on block matrices.</p>
<h2 dir="auto"><a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basic Usage</h2>
<h3 dir="auto"><a id="user-content-block-matrix-with-dense-blocks" class="anchor" aria-hidden="true" href="#block-matrix-with-dense-blocks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Block Matrix with Dense Blocks</h3>
<p dir="auto">Say we need to work with a block matrix <code>A</code> like the following</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LinearAlgebra
d = 512
n, m = 3, 4
A = [randn(d, d) for i in 1:n, j in 1:m]"><pre><span class="pl-k">using</span> LinearAlgebra
d <span class="pl-k">=</span> <span class="pl-c1">512</span>
n, m <span class="pl-k">=</span> <span class="pl-c1">3</span>, <span class="pl-c1">4</span>
A <span class="pl-k">=</span> [<span class="pl-c1">randn</span>(d, d) <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>n, j <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>m]</pre></div>
<p dir="auto">Then Julia already allows for convenient syntax for matrix-vector multiplication,
by using a vector of vectors like so</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using BenchmarkTools
x = [randn(d) for _ in 1:m]
y = [zeros(d) for _ in 1:n]
@btime A*x
  12.652 ms (321 allocations: 1.29 MiB)
@btime mul!(y, A, x);
  12.700 ms (320 allocations: 1.29 MiB)"><pre><span class="pl-k">using</span> BenchmarkTools
x <span class="pl-k">=</span> [<span class="pl-c1">randn</span>(d) <span class="pl-k">for</span> _ <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>m]
y <span class="pl-k">=</span> [<span class="pl-c1">zeros</span>(d) <span class="pl-k">for</span> _ <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>n]
<span class="pl-c1">@btime</span> A<span class="pl-k">*</span>x
  <span class="pl-c1">12.652</span> ms (<span class="pl-c1">321</span> allocations<span class="pl-k">:</span> <span class="pl-c1">1.29</span> MiB)
<span class="pl-c1">@btime</span> <span class="pl-c1">mul!</span>(y, A, x);
  <span class="pl-c1">12.700</span> ms (<span class="pl-c1">320</span> allocations<span class="pl-k">:</span> <span class="pl-c1">1.29</span> MiB)</pre></div>
<p dir="auto">However, we see that even <code>mul!</code> allocates significant memory since <code>mul!</code> is not applied recursively.
Instead <code>*</code> is used to multiply the vector elements.</p>
<p dir="auto">With this package, we can wrap <code>A</code> to act like a normal matrix for multiplication:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using BlockFactorizations
B = BlockFactorization(A)
x = randn(d*m)
y = randn(d*n)
@btime B*x;
  11.589 ms (30 allocations: 67.12 KiB)
@btime mul!(y, B, x);
  11.691 ms (28 allocations: 3.05 KiB)"><pre><span class="pl-k">using</span> BlockFactorizations
B <span class="pl-k">=</span> <span class="pl-c1">BlockFactorization</span>(A)
x <span class="pl-k">=</span> <span class="pl-c1">randn</span>(d<span class="pl-k">*</span>m)
y <span class="pl-k">=</span> <span class="pl-c1">randn</span>(d<span class="pl-k">*</span>n)
<span class="pl-c1">@btime</span> B<span class="pl-k">*</span>x;
  <span class="pl-c1">11.589</span> ms (<span class="pl-c1">30</span> allocations<span class="pl-k">:</span> <span class="pl-c1">67.12</span> KiB)
<span class="pl-c1">@btime</span> <span class="pl-c1">mul!</span>(y, B, x);
  <span class="pl-c1">11.691</span> ms (<span class="pl-c1">28</span> allocations<span class="pl-k">:</span> <span class="pl-c1">3.05</span> KiB)</pre></div>
<p dir="auto">Notably, this allows us to use canonical linear algebra routines that just need to access <code>mul!</code> or <code>*</code> without special consideration for the block structure.</p>
<h3 dir="auto"><a id="user-content-block-matrix-with-diagonal-blocks" class="anchor" aria-hidden="true" href="#block-matrix-with-diagonal-blocks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Block Matrix with Diagonal Blocks</h3>
<p dir="auto">Instead of having dense blocks, we can have more general block types, which can allow for more efficient matrix multiplication:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="A = [Diagonal(randn(d)) for i in 1:n, j in 1:m]
B = BlockFactorization(A)

x = [randn(d) for _ in 1:m]
y = [zeros(d) for _ in 1:n]
@btime A*x
  117.001 μs (321 allocations: 1.29 MiB)
@btime mul!(y, A, x);
  127.356 μs (320 allocations: 1.29 MiB)
  
x = randn(d*m)
y = zeros(d*n)
@btime B*x;
  58.703 μs (158 allocations: 81.12 KiB)
@btime mul!(y, B, x);
  45.743 μs (156 allocations: 17.05 KiB)"><pre>A <span class="pl-k">=</span> [<span class="pl-c1">Diagonal</span>(<span class="pl-c1">randn</span>(d)) <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>n, j <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>m]
B <span class="pl-k">=</span> <span class="pl-c1">BlockFactorization</span>(A)

x <span class="pl-k">=</span> [<span class="pl-c1">randn</span>(d) <span class="pl-k">for</span> _ <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>m]
y <span class="pl-k">=</span> [<span class="pl-c1">zeros</span>(d) <span class="pl-k">for</span> _ <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>n]
<span class="pl-c1">@btime</span> A<span class="pl-k">*</span>x
  <span class="pl-c1">117.001</span> μs (<span class="pl-c1">321</span> allocations<span class="pl-k">:</span> <span class="pl-c1">1.29</span> MiB)
<span class="pl-c1">@btime</span> <span class="pl-c1">mul!</span>(y, A, x);
  <span class="pl-c1">127.356</span> μs (<span class="pl-c1">320</span> allocations<span class="pl-k">:</span> <span class="pl-c1">1.29</span> MiB)
  
x <span class="pl-k">=</span> <span class="pl-c1">randn</span>(d<span class="pl-k">*</span>m)
y <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(d<span class="pl-k">*</span>n)
<span class="pl-c1">@btime</span> B<span class="pl-k">*</span>x;
  <span class="pl-c1">58.703</span> μs (<span class="pl-c1">158</span> allocations<span class="pl-k">:</span> <span class="pl-c1">81.12</span> KiB)
<span class="pl-c1">@btime</span> <span class="pl-c1">mul!</span>(y, B, x);
  <span class="pl-c1">45.743</span> μs (<span class="pl-c1">156</span> allocations<span class="pl-k">:</span> <span class="pl-c1">17.05</span> KiB)</pre></div>
<p dir="auto">Note that as long as <code>mul!</code> and <code>size</code> is defined for the element types, <code>BlockFactorization</code> will be applicable.</p>
<h3 dir="auto"><a id="user-content-block-diagonal-matrix-with-dense-blocks" class="anchor" aria-hidden="true" href="#block-diagonal-matrix-with-dense-blocks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Block Diagonal Matrix with Dense Blocks</h3>
<p dir="auto">Right above, we saw that BlockFactorizations supports <code>Diagonal</code> elements.
Further, it also specializes matrix multiplication in case of a <a href="https://en.wikipedia.org/wiki/Block_matrix#Block_diagonal_matrices" rel="nofollow">block diagonal matrix</a>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="d = 512
n = 16
# testing Diagonal BlockFactorization
A = Diagonal([(randn(d, d)) for i in 1:n])

B = BlockFactorization(A)

# this doesn't work in 1.6.2
# x = [zeros(d) for _ in 1:n]
# @btime A*x; 

x = randn(d*n)
y = zeros(d*n)
@btime B*x;
  1.005 ms (30 allocations: 67.45 KiB)
@btime mul!(y, B, x);
  989.163 μs (28 allocations: 3.38 KiB)"><pre>d <span class="pl-k">=</span> <span class="pl-c1">512</span>
n <span class="pl-k">=</span> <span class="pl-c1">16</span>
<span class="pl-c"><span class="pl-c">#</span> testing Diagonal BlockFactorization</span>
A <span class="pl-k">=</span> <span class="pl-c1">Diagonal</span>([(<span class="pl-c1">randn</span>(d, d)) <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>n])

B <span class="pl-k">=</span> <span class="pl-c1">BlockFactorization</span>(A)

<span class="pl-c"><span class="pl-c">#</span> this doesn't work in 1.6.2</span>
<span class="pl-c"><span class="pl-c">#</span> x = [zeros(d) for _ in 1:n]</span>
<span class="pl-c"><span class="pl-c">#</span> @btime A*x; </span>

x <span class="pl-k">=</span> <span class="pl-c1">randn</span>(d<span class="pl-k">*</span>n)
y <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(d<span class="pl-k">*</span>n)
<span class="pl-c1">@btime</span> B<span class="pl-k">*</span>x;
  <span class="pl-c1">1.005</span> ms (<span class="pl-c1">30</span> allocations<span class="pl-k">:</span> <span class="pl-c1">67.45</span> KiB)
<span class="pl-c1">@btime</span> <span class="pl-c1">mul!</span>(y, B, x);
  <span class="pl-c1">989.163</span> μs (<span class="pl-c1">28</span> allocations<span class="pl-k">:</span> <span class="pl-c1">3.38</span> KiB)</pre></div>
<h2 dir="auto"><a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Notes</h2>
<p dir="auto">Note that the matrix multiplication function is parallelized with <code>@threads</code>.
Also, a BlockFactorization <code>B</code> can be converted to a non-blocked matrix using <code>Matrix(B)</code>.
Reported timings were computed on a 2017 MacBook Pro with a dual core processor and 16GB of RAM.</p>
</article></div>