<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-xdiffjl---expression-differentiation-package" class="anchor" aria-hidden="true" href="#xdiffjl---expression-differentiation-package"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>XDiff.jl - eXpression Differentiation package</h1>
<p><a href="https://travis-ci.org/dfdx/XDiff.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/d79503532028658f24e6b7327888d818f2a86a1b8b97dcc6ab7dc97af815ae1c/68747470733a2f2f7472617669732d63692e6f72672f646664782f58446966662e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/dfdx/XDiff.jl.svg?branch=master" style="max-width:100%;"></a></p>
<blockquote>
<p>This package is unique in that it can differentiate vector-valued expressions in Einstein notation. However, if you only need gradients of scalar-valued functions (which is typicial in machine learning), please use <a href="https://github.com/dfdx/XGrad.jl">XGrad.jl</a> instead. XGrad.jl is re-thought and stabilized version of this package, adding many useful featues in place of (not frequently used) derivatives of vector-valued functions. If nevertheless you want to continue using XDiff.jl, please pin Espresso.jl to version <code>v3.0.0</code>, which is the last supporting Einstein notation.</p>
</blockquote>
<p><strong>XDiff.jl</strong> is an expression differentiation package, supporting fully
symbolic approach to finding tensor derivatives.
Unlike automatic differentiation packages, XDiff.jl can output not only ready-to-use
derivative functions, but also their symbolic expressions suitable for
further optimization and code generation.</p>
<h3><a id="user-content-expression-differentiation" class="anchor" aria-hidden="true" href="#expression-differentiation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Expression differentiation</h3>
<p><code>xdiff</code> takes an expression and a set of "example values" and returns another expression
that calculates the value together with derivatives of an output variable w.r.t each
argument. Example values are anything similar to expected data, i.e. with the same data type
and size.
In the example below we want <code>w</code> and <code>x</code> to be vectors of size <code>(3,)</code> while <code>b</code> to be a scalar.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="# expressions after a semicolon are &quot;example values&quot; - something that looks like expected data
xdiff(:(y = sum(w .* x) + b); w=rand(3), x=rand(3), b=rand())
# quote 
#     dy!dx = @get_or_create(mem, :dy!dx, zeros(Float64, (3,)))
#     dy!dw = @get_or_create(mem, :dy!dw, zeros(Float64, (3,)))
#     y = @get_or_create(mem, :y, zero(Float64))
#     tmp658 = @get_or_create(mem, :tmp658, zero(Float64))
#     dy!dtmp658 = @get_or_create(mem, :dy!dtmp658, zero(Float64))
#     tmp658 = sum(w .* x)
#     y = tmp658 .+ b
#     dy!dtmp658 = 1.0
#     dy!dw .= x
#     dy!dx .= w
#     tmp677 = (y, dy!dw, dy!dx, dy!dtmp658)
# end
"><pre><span class="pl-c"><span class="pl-c">#</span> expressions after a semicolon are "example values" - something that looks like expected data</span>
<span class="pl-c1">xdiff</span>(:(y <span class="pl-k">=</span> <span class="pl-c1">sum</span>(w <span class="pl-k">.*</span> x) <span class="pl-k">+</span> b); w<span class="pl-k">=</span><span class="pl-c1">rand</span>(<span class="pl-c1">3</span>), x<span class="pl-k">=</span><span class="pl-c1">rand</span>(<span class="pl-c1">3</span>), b<span class="pl-k">=</span><span class="pl-c1">rand</span>())
<span class="pl-c"><span class="pl-c">#</span> quote </span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dx = @get_or_create(mem, :dy!dx, zeros(Float64, (3,)))</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dw = @get_or_create(mem, :dy!dw, zeros(Float64, (3,)))</span>
<span class="pl-c"><span class="pl-c">#</span>     y = @get_or_create(mem, :y, zero(Float64))</span>
<span class="pl-c"><span class="pl-c">#</span>     tmp658 = @get_or_create(mem, :tmp658, zero(Float64))</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dtmp658 = @get_or_create(mem, :dy!dtmp658, zero(Float64))</span>
<span class="pl-c"><span class="pl-c">#</span>     tmp658 = sum(w .* x)</span>
<span class="pl-c"><span class="pl-c">#</span>     y = tmp658 .+ b</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dtmp658 = 1.0</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dw .= x</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dx .= w</span>
<span class="pl-c"><span class="pl-c">#</span>     tmp677 = (y, dy!dw, dy!dx, dy!dtmp658)</span>
<span class="pl-c"><span class="pl-c">#</span> end</span></pre></div>
<p>By default, <code>xdiff</code> generates a highly-optimized code that uses a set of buffers stored in
a dictionary <code>mem</code>. You may also generate slower, but more readable expression using <code>VectorCodeGen</code>:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="ctx = Dict(:codegen =&gt; VectorCodeGen())
xdiff(:(y = sum(w .* x) + b); ctx=ctx, w=rand(3), x=rand(3), b=rand())
# quote 
#     tmp691 = w' * x
#     y = tmp691 + b
#     dy!dtmp691 = 1.0
#     dy!db = 1.0
#     dy!dw = x
#     dy!dx = w
#     tmp698 = (y, dy!dw, dy!dx, dy!db)
# end
"><pre>ctx <span class="pl-k">=</span> <span class="pl-c1">Dict</span>(<span class="pl-c1">:codegen</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">VectorCodeGen</span>())
<span class="pl-c1">xdiff</span>(:(y <span class="pl-k">=</span> <span class="pl-c1">sum</span>(w <span class="pl-k">.*</span> x) <span class="pl-k">+</span> b); ctx<span class="pl-k">=</span>ctx, w<span class="pl-k">=</span><span class="pl-c1">rand</span>(<span class="pl-c1">3</span>), x<span class="pl-k">=</span><span class="pl-c1">rand</span>(<span class="pl-c1">3</span>), b<span class="pl-k">=</span><span class="pl-c1">rand</span>())
<span class="pl-c"><span class="pl-c">#</span> quote </span>
<span class="pl-c"><span class="pl-c">#</span>     tmp691 = w' * x</span>
<span class="pl-c"><span class="pl-c">#</span>     y = tmp691 + b</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dtmp691 = 1.0</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!db = 1.0</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dw = x</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dx = w</span>
<span class="pl-c"><span class="pl-c">#</span>     tmp698 = (y, dy!dw, dy!dx, dy!db)</span>
<span class="pl-c"><span class="pl-c">#</span> end</span></pre></div>
<p>or in <a href="https://en.wikipedia.org/wiki/Einstein_notation" rel="nofollow">Einstein indexing notation</a> using <code>EinCodeGen</code>:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="ctx = Dict(:codegen =&gt; EinCodeGen())
xdiff(:(y = sum(w .* x) + b); ctx=ctx, w=rand(3), x=rand(3), b=rand())
# quote
#     tmp700 = w[i] .* x[i]
#     y = tmp700 + b
#     dy!dtmp700 = 1.0
#     dy!db = 1.0
#     dy!dw[j] = dy!dtmp700 .* x[j]
#     dy!dx[j] = dy!dtmp700 .* w[j]
#     tmp707 = (y, dy!dw, dy!dx, dy!db)
# end
"><pre>ctx <span class="pl-k">=</span> <span class="pl-c1">Dict</span>(<span class="pl-c1">:codegen</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">EinCodeGen</span>())
<span class="pl-c1">xdiff</span>(:(y <span class="pl-k">=</span> <span class="pl-c1">sum</span>(w <span class="pl-k">.*</span> x) <span class="pl-k">+</span> b); ctx<span class="pl-k">=</span>ctx, w<span class="pl-k">=</span><span class="pl-c1">rand</span>(<span class="pl-c1">3</span>), x<span class="pl-k">=</span><span class="pl-c1">rand</span>(<span class="pl-c1">3</span>), b<span class="pl-k">=</span><span class="pl-c1">rand</span>())
<span class="pl-c"><span class="pl-c">#</span> quote</span>
<span class="pl-c"><span class="pl-c">#</span>     tmp700 = w[i] .* x[i]</span>
<span class="pl-c"><span class="pl-c">#</span>     y = tmp700 + b</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dtmp700 = 1.0</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!db = 1.0</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dw[j] = dy!dtmp700 .* x[j]</span>
<span class="pl-c"><span class="pl-c">#</span>     dy!dx[j] = dy!dtmp700 .* w[j]</span>
<span class="pl-c"><span class="pl-c">#</span>     tmp707 = (y, dy!dw, dy!dx, dy!db)</span>
<span class="pl-c"><span class="pl-c">#</span> end</span></pre></div>
<h3><a id="user-content-function-differentiation" class="anchor" aria-hidden="true" href="#function-differentiation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Function differentiation</h3>
<p><code>xdiff</code> also provides a convenient interface for generating function derivatives:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="# evaluate using `include(&quot;file_with_function.jl&quot;)` 
f(w, x, b) = sum(w .* x) .+ b

df = xdiff(f; w=rand(3), x=rand(3), b=rand())
df(rand(3), rand(3), rand())
# (0.8922305671741435, [0.936149, 0.80665, 0.189789], [0.735201, 0.000282879, 0.605989], 1.0)
"><pre><span class="pl-c"><span class="pl-c">#</span> evaluate using `include("file_with_function.jl")` </span>
<span class="pl-en">f</span>(w, x, b) <span class="pl-k">=</span> <span class="pl-c1">sum</span>(w <span class="pl-k">.*</span> x) <span class="pl-k">.+</span> b

df <span class="pl-k">=</span> <span class="pl-c1">xdiff</span>(f; w<span class="pl-k">=</span><span class="pl-c1">rand</span>(<span class="pl-c1">3</span>), x<span class="pl-k">=</span><span class="pl-c1">rand</span>(<span class="pl-c1">3</span>), b<span class="pl-k">=</span><span class="pl-c1">rand</span>())
<span class="pl-c1">df</span>(<span class="pl-c1">rand</span>(<span class="pl-c1">3</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">3</span>), <span class="pl-c1">rand</span>())
<span class="pl-c"><span class="pl-c">#</span> (0.8922305671741435, [0.936149, 0.80665, 0.189789], [0.735201, 0.000282879, 0.605989], 1.0)</span></pre></div>
<p>Note, that <code>xdiff</code> will <em>try</em> to extract function body as it was written, but it doesn't always
work smoothly. One сommon case when function body isn't available is when function is defined
in REPL, so for better experience load functions using <code>include(&lt;filename&gt;)</code> or <code>using &lt;module&gt;</code>.</p>
<h3><a id="user-content-limitations" class="anchor" aria-hidden="true" href="#limitations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Limitations</h3>
<ul>
<li>loops are not supported</li>
<li>conditional branching is not supported</li>
</ul>
<p>Loops and conditional operators may introduce discontinuity points, potentially resulting in
very complex and heavy piecewise expressions, and thus are not supported.
However, many such expressions may be rewritten into analytical form. For example, many loops
may be rewritten into some aggregation function like <code>sum()</code> (already supported), and
many conditions may be expressed as multiplication like <code>f(x) * (x &gt; 0) + g(x) * (x &lt;= 0)</code>
(planned). Please, submit an issue if you are interested in supporting some specific feature.</p>
<h3><a id="user-content-how-it-works" class="anchor" aria-hidden="true" href="#how-it-works"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>How it works</h3>
<p>On the high level, scalar expressions are differentiated as follows:</p>
<ol>
<li>Expression is parsed into an <code>ExGraph</code> - a set of primitive expressions,
mostly assignments and single function calls.</li>
<li>Resulting <code>ExGraph</code> is evaluated using example values to determine types and
shape of all variables (forward pass).</li>
<li>Similar to reverse-mode automatic differentiation, derivatives are propagated
backward from output to input variables. Unlike AD, however, derivatives aren't
represented as values, but instead as symbolic exprssions.</li>
</ol>
<p>Tensor expressions exploit very similar pipeline, but act in Einstein notation.</p>
<ol>
<li>Tensor expression is transformed into Einstein notation.</li>
<li>Expression in Einstein notation is parsed into an <code>Einraph</code> (indexed variant of <code>ExGraph</code>).</li>
<li>Resulting <code>EinGraph</code> is evaluated.</li>
<li>Partial derivatives are computed using tensor or element-wise rules for each element
of each tensor, then propagated from output to input variables.</li>
<li>Optionally, derivative expressions are converted back to vectorized notation.</li>
</ol>
</article></div>