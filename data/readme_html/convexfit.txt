<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-convexfitjl" class="anchor" aria-hidden="true" href="#convexfitjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ConvexFit.jl</h1>
<p dir="auto"><em>Fit vectors with convex combinations of data columns</em></p>
<p dir="auto"><a href="https://github.com/junyuan-chen/ConvexFit.jl/actions?query=workflow%3ACI-stable"><img src="https://github.com/junyuan-chen/ConvexFit.jl/workflows/CI-stable/badge.svg" alt="CI-stable" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/junyuan-chen/ConvexFit.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/463af4d2091bf70f52e7d6e8d2b7395a5889e72938aa4864c9e807add74b3b7a/68747470733a2f2f636f6465636f762e696f2f67682f6a756e7975616e2d6368656e2f436f6e7665784669742e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/junyuan-chen/ConvexFit.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a>
<a href="https://juliaci.github.io/NanosoldierReports/pkgeval_badges/C/ConvexFit.html" rel="nofollow"><img src="https://camo.githubusercontent.com/45810fcc68f5c9ef03bed89fb0d6eb839ebb61c2f6262306bafe8c4c195b8ee3/68747470733a2f2f6a756c696163692e6769746875622e696f2f4e616e6f736f6c646965725265706f7274732f706b676576616c5f6261646765732f432f436f6e7665784669742e737667" alt="PkgEval" data-canonical-src="https://juliaci.github.io/NanosoldierReports/pkgeval_badges/C/ConvexFit.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><a href="https://github.com/junyuan-chen/ConvexFit.jl">ConvexFit.jl</a>
is a lightweight Julia package for fitting vectors with convex combinations of data columns.
Notably, the coefficients are always restricted to be nonnegative and sum to one.
This restriction arises naturally in circumstances
where predictions involving extrapolation are undesirable,
for instance, when constructing weights for synthetic controls.</p>
<h2 dir="auto"><a id="user-content-the-optimization-problem" class="anchor" aria-hidden="true" href="#the-optimization-problem"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The Optimization Problem</h2>
<p dir="auto">The coefficients for the convex combinations are obtained by
solving a constrained optimization problem of the following form:</p>
<p align="center" dir="auto">
min<sub>x</sub> ||Ax - b||<sup>2</sup> + λ||x||<sup>2</sup> <br>
st.   x<sub>i</sub> ≥ 0 for all i and Σ<sub>i</sub>x<sub>i</sub> = 1
</p>
<p dir="auto">where <code>A</code> is a matrix containing the data columns;
<code>x</code> is a vector of coefficients on the unit simplex;
<code>b</code> is a vector to be fitted by <code>Ax</code>;
and <code>λ</code> is a nonnegative regularization parameter.
Only the Euclidean norm is supported at this moment.</p>
<p dir="auto">The optimization problem is solved iteratively with a conditional gradient method,
the Frank-Wolfe algorithm,
that directly searches solution candidates on the unit simplex.
In practice, some extent of regularization is often desired
and that can be controlled by the magnitude of <code>λ</code>.
The choice of <code>λ</code> depends on the context of the specific problem
and is left to be zero by default.
If appropriate, one may consider selecting <code>λ</code> based on the leave-one-out cross validation,
which is implemented in this package.</p>
<h2 dir="auto"><a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick Start</h2>
<p dir="auto">Most of the functionality can be accessed by calling <code>convexfit</code>.
To fit a vector <code>b</code> with a convex combination of columns in <code>A</code>
and regularize the coefficients <code>x</code> with some <code>λ</code>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ConvexFit
r = convexfit(A, b, λ)"><pre><span class="pl-k">using</span> ConvexFit
r <span class="pl-k">=</span> <span class="pl-c1">convexfit</span>(A, b, λ)</pre></div>
<p dir="auto">The results are stored in <code>SolverResult</code> and can be retrieved from the corresponding fields.
For example, <code>r.sol</code> gives the optimal <code>x</code>; while <code>r.fit</code> gives the fitted values.</p>
<p dir="auto">To select an optimal <code>λ</code> based on the leave-one-out cross validation,
one may either provide a <code>grid</code> in place of <code>λ</code> to <code>convexfit</code> for exhaustive search
or specify a solver that searches the optimal <code>λ</code> over an interval.
An example for the latter case that uses a solver from
<a href="https://github.com/JuliaNLSolvers/Optim.jl"><code>Optim.jl</code></a> is as follows:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ConvexFit, Optim
# Specify a solver in a function that takes an objective function as argument
# The returned object must be a tuple of the solver result and the minimizer
function fmin(f::Function)
    r = optimize(f, 0.0, 100.0, Brent(), abs_tol=1e-4, store_trace=true)
    return r, minimizer(r)
end
# Fit b under the optimal λ selected from [0, 100] based on leave-one-out cross validation
r = convexfit(A, b, optim(fmin))"><pre><span class="pl-k">using</span> ConvexFit, Optim
<span class="pl-c"><span class="pl-c">#</span> Specify a solver in a function that takes an objective function as argument</span>
<span class="pl-c"><span class="pl-c">#</span> The returned object must be a tuple of the solver result and the minimizer</span>
<span class="pl-k">function</span> <span class="pl-en">fmin</span>(f<span class="pl-k">::</span><span class="pl-c1">Function</span>)
    r <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(f, <span class="pl-c1">0.0</span>, <span class="pl-c1">100.0</span>, <span class="pl-c1">Brent</span>(), abs_tol<span class="pl-k">=</span><span class="pl-c1">1e-4</span>, store_trace<span class="pl-k">=</span><span class="pl-c1">true</span>)
    <span class="pl-k">return</span> r, <span class="pl-c1">minimizer</span>(r)
<span class="pl-k">end</span>
<span class="pl-c"><span class="pl-c">#</span> Fit b under the optimal λ selected from [0, 100] based on leave-one-out cross validation</span>
r <span class="pl-k">=</span> <span class="pl-c1">convexfit</span>(A, b, <span class="pl-c1">optim</span>(fmin))</pre></div>
<p dir="auto">More details can be found in the
<a href="https://docs.julialang.org/en/v1/stdlib/REPL/#Help-mode" rel="nofollow">help</a> mode of Julia REPL.</p>
<h2 dir="auto"><a id="user-content-reference" class="anchor" aria-hidden="true" href="#reference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Reference</h2>
<p dir="auto"><strong>Jaggi, Martin.</strong> 2013. "Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization."
<em>Proceedings of the 30th International Conference on Machine Learning</em> 28 (1): 427-435.</p>
</article></div>