<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><p><a href="https://travis-ci.com/aicenter/ConditionalDists.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/8929ed9f5f9a51d2e9be581ded8eba52bfd49d7e/68747470733a2f2f7472617669732d63692e636f6d2f616963656e7465722f436f6e646974696f6e616c44697374732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/aicenter/ConditionalDists.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/aicenter/ConditionalDists.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/c4dbae6fbf3496f2b93761a1dd495f7fe5847857/68747470733a2f2f636f6465636f762e696f2f67682f616963656e7465722f436f6e646974696f6e616c44697374732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/aicenter/ConditionalDists.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<h1><a id="user-content-conditionaldistsjl" class="anchor" aria-hidden="true" href="#conditionaldistsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>ConditionalDists.jl</h1>
<p>Conditional probability distributions powered by Flux.jl and Distributions.jl.</p>
<p>The conditional PDFs that are defined in this package can be used in
conjunction with Flux models to provide trainable mappings. As an example,
consider a conditional Gaussian for which you want to learn a mapping and a
shared variance:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> ConditionalDists;
julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Flux;

julia<span class="pl-k">&gt;</span> xlen <span class="pl-k">=</span> <span class="pl-c1">3</span>; zlen <span class="pl-k">=</span> <span class="pl-c1">2</span>;
julia<span class="pl-k">&gt;</span> T    <span class="pl-k">=</span> Float32;

julia<span class="pl-k">&gt;</span> cpdf <span class="pl-k">=</span> <span class="pl-c1">CMeanGaussian</span><span class="pl-c1">{DiagVar}</span>(<span class="pl-c1">Dense</span>(xlen, zlen), <span class="pl-c1">ones</span>(T,zlen)<span class="pl-k">*</span><span class="pl-c1">10</span>)
<span class="pl-c1">CMeanGaussian</span><span class="pl-c1">{DiagVar}</span>(mapping<span class="pl-k">=</span><span class="pl-c1">Dense</span>(<span class="pl-c1">3</span>, <span class="pl-c1">2</span>), σ<span class="pl-c1">2</span><span class="pl-k">=</span><span class="pl-c1">2</span><span class="pl-k">-</span>element Array{Float32,<span class="pl-c1">1</span>}

julia<span class="pl-k">&gt;</span> X <span class="pl-k">=</span> <span class="pl-c1">randn</span>(T, xlen, <span class="pl-c1">10</span>);
julia<span class="pl-k">&gt;</span> Z <span class="pl-k">=</span> <span class="pl-c1">randn</span>(T, zlen, <span class="pl-c1">10</span>);
julia<span class="pl-k">&gt;</span> <span class="pl-c1">logpdf</span>(cpdf, X, Z)  <span class="pl-c"><span class="pl-c">#</span> compute p(X|Z)</span>
<span class="pl-c1">1</span><span class="pl-k">×</span><span class="pl-c1">10</span> Array{Float32,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-k">-</span><span class="pl-c1">6.45847</span>  <span class="pl-k">-</span><span class="pl-c1">6.47164</span>  <span class="pl-k">-</span><span class="pl-c1">6.44917</span>  <span class="pl-k">-</span><span class="pl-c1">6.46053</span>  <span class="pl-k">-</span><span class="pl-c1">6.45961</span>  <span class="pl-k">-</span><span class="pl-c1">6.45457</span>  <span class="pl-k">-</span><span class="pl-c1">6.44526</span>  <span class="pl-k">-</span><span class="pl-c1">6.4592</span>  <span class="pl-k">-</span><span class="pl-c1">6.47359</span>  <span class="pl-k">-</span><span class="pl-c1">6.45476</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">rand</span>(cpdf, <span class="pl-c1">randn</span>(T,xlen,<span class="pl-c1">10</span>))  <span class="pl-c"><span class="pl-c">#</span> sample from cpdf</span>
<span class="pl-c1">2</span><span class="pl-k">×</span><span class="pl-c1">5</span> Array{Float32,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-k">-</span><span class="pl-c1">4.75223</span>  <span class="pl-k">-</span><span class="pl-c1">8.37436</span>   <span class="pl-k">-</span><span class="pl-c1">6.79707</span>  <span class="pl-k">-</span><span class="pl-c1">2.32712</span>   <span class="pl-c1">0.236871</span>
 <span class="pl-k">-</span><span class="pl-c1">6.60262</span>   <span class="pl-c1">0.119544</span>  <span class="pl-k">-</span><span class="pl-c1">2.40393</span>   <span class="pl-c1">7.17728</span>  <span class="pl-k">-</span><span class="pl-c1">9.87703</span> </pre></div>
<p>The trainable parameters (W,b of the Dense layer and the shared variance of
<code>cpdf</code>) are accesible as usual through <code>params</code>.  The next few lines show how
to optimize <code>cpdf</code> to match a given Gaussian by using the <code>kl_divergence</code> defined
in <a href="https://github.com/aicenter/IPMeasures.jl">IPMeasures.jl</a>.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> IPMeasures;

julia<span class="pl-k">&gt;</span> pdf <span class="pl-k">=</span> <span class="pl-c1">Gaussian</span>(<span class="pl-c1">zeros</span>(T,zlen), <span class="pl-c1">ones</span>(T,zlen));
julia<span class="pl-k">&gt;</span> <span class="pl-en">loss</span>(x) <span class="pl-k">=</span> <span class="pl-c1">sum</span>(<span class="pl-c1">kl_divergence</span>(cpdf, pdf, x));
julia<span class="pl-k">&gt;</span> ps <span class="pl-k">=</span> <span class="pl-c1">params</span>(cpdf);
julia<span class="pl-k">&gt;</span> opt <span class="pl-k">=</span> <span class="pl-c1">ADAM</span>(<span class="pl-c1">0.1</span>);
julia<span class="pl-k">&gt;</span> data <span class="pl-k">=</span> [(<span class="pl-c1">randn</span>(T, xlen),) <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2000</span>];
julia<span class="pl-k">&gt;</span> Flux<span class="pl-k">.</span><span class="pl-c1">train!</span>(loss, ps, data, opt);</pre></div>
<p>The learnt mean and variance are fairly close to a standard normal:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">mean_var</span>(cpdf, <span class="pl-c1">randn</span>(T,xlen))
(Float32[<span class="pl-k">-</span><span class="pl-c1">0.03580121</span>, <span class="pl-c1">0.002174838</span>], Float32[<span class="pl-c1">1.0000002</span>; <span class="pl-c1">1.0000002</span>])

julia<span class="pl-k">&gt;</span> <span class="pl-c1">rand</span>(cpdf, <span class="pl-c1">rand</span>(T,xlen,<span class="pl-c1">10</span>))  <span class="pl-c"><span class="pl-c">#</span> sample from trained cpdf</span>
<span class="pl-c1">2</span><span class="pl-k">×</span><span class="pl-c1">5</span> Array{Float32,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-c1">1.44779</span>    <span class="pl-c1">0.437584</span>   <span class="pl-k">-</span><span class="pl-c1">0.047717</span>   <span class="pl-c1">1.47545</span>    <span class="pl-c1">0.436742</span>
 <span class="pl-c1">0.596167</span>  <span class="pl-k">-</span><span class="pl-c1">0.0327809</span>   <span class="pl-c1">0.327143</span>  <span class="pl-k">-</span><span class="pl-c1">0.591193</span>  <span class="pl-k">-</span><span class="pl-c1">2.62733</span></pre></div>
</article></div>