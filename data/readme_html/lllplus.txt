<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-lllplusjl" class="anchor" aria-hidden="true" href="#lllplusjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>LLLplus.jl</h1>
<p dir="auto"><a href="https://github.com/christianpeel/LLLplus.jl/actions"><img src="https://github.com/christianpeel/LLLplus.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://christianpeel.github.io/LLLplus.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/41b6a040fc353ba23101738a4944355aa3339a1370feaf2d54a43be648bebaa8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d646576656c2d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-devel-blue.svg" style="max-width: 100%;"></a></p>
<p dir="auto">LLLplus provides lattice tools such as
<a href="https://en.wikipedia.org/wiki/Lenstra%E2%80%93Lenstra%E2%80%93Lov%C3%A1sz_lattice_basis_reduction_algorithm" rel="nofollow">Lenstra-Lenstra-Lovász</a>
(LLL) lattice reduction which are of practical and
theoretical use in cryptography, digital communication, integer
programming, and more.
This package is experimental and not a robust tool; use at your own
risk :-)</p>
<p dir="auto">LLLplus has functions for LLL,
<a href="http://link.springer.com/article/10.1007%2FBF01202355" rel="nofollow">Seysen</a>, and
<a href="http://www.cas.mcmaster.ca/~qiao/publications/ZQW11.pdf" rel="nofollow">Hermite-Korkine-Zolotarev</a>
lattice reduction
techniques. <a href="https://archive.org/stream/skrifterutgitavv201chri#page/300/mode/2up" rel="nofollow">Brun</a>
integer relations is included in the form of lattice
reduction. Solvers for the <a href="https://en.wikipedia.org/wiki/Lattice_problem#Shortest_vector_problem_(SVP)" rel="nofollow">shortest
vector</a>
and the <a href="https://en.wikipedia.org/wiki/Lattice_problem#Closest_vector_problem_.28CVP.29" rel="nofollow">closest
vector</a>
problems are also included; for more see the help text for the <code>lll</code>,
<code>seysen</code>, <code>hkz</code>, <code>brun</code>, <code>svp</code>, and <code>cvp</code> functions. Several toy (demo)
functions are also included; see the  <code>subsetsum</code>, <code>minimalpolynomial</code>,
<code>integerfeasibility</code>, <code>rationalapprox</code>, and  <code>spigotBBP</code> functions.</p>
<details>
   <summary><b>Examples</b> (click for details)</summary>
<p dir="auto">
</p><p dir="auto">Each function contains documentation and examples available via Julia's
built-in documentation system (try <code>?lll</code> or <code>@doc(lll)</code>). Documentation
for all functions is <a href="https://christianpeel.github.io/LLLplus.jl/dev" rel="nofollow">available</a>. A tutorial notebook is
found in the <a href="docs/LLLplusTutorial.ipynb"><code>docs</code></a> directory or on
<a href="https://nbviewer.jupyter.org/github/christianpeel/LLLplus.jl/blob/master/docs/LLLplusTutorial.ipynb" rel="nofollow">nbviewer</a>.</p>
<p dir="auto">Here are a few examples of using the functions in the
package on random lattices.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="Pkg.add(&quot;LLLplus&quot;)
using LLLplus

# do lattice reduction on a matrix with randn entries
N = 40;
H = randn(N,N);
B,T = brun(H);
B,T = lll(H);
B,T = seysen(H);
B,T = hkz(H);

# check out the CVP solver
Q,Rtmp=qr(H); R = UpperTriangular(Rtmp);
u=Int.(rand(0:1e10,N));
y=H*u+rand(N)/100;
uhat=cvp(Q'*y,R);
sum(abs.(u-uhat))"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>LLLplus<span class="pl-pds">"</span></span>)
<span class="pl-k">using</span> LLLplus

<span class="pl-c"><span class="pl-c">#</span> do lattice reduction on a matrix with randn entries</span>
N <span class="pl-k">=</span> <span class="pl-c1">40</span>;
H <span class="pl-k">=</span> <span class="pl-c1">randn</span>(N,N);
B,T <span class="pl-k">=</span> <span class="pl-c1">brun</span>(H);
B,T <span class="pl-k">=</span> <span class="pl-c1">lll</span>(H);
B,T <span class="pl-k">=</span> <span class="pl-c1">seysen</span>(H);
B,T <span class="pl-k">=</span> <span class="pl-c1">hkz</span>(H);

<span class="pl-c"><span class="pl-c">#</span> check out the CVP solver</span>
Q,Rtmp<span class="pl-k">=</span><span class="pl-c1">qr</span>(H); R <span class="pl-k">=</span> <span class="pl-c1">UpperTriangular</span>(Rtmp);
u<span class="pl-k">=</span><span class="pl-c1">Int</span>.(<span class="pl-c1">rand</span>(<span class="pl-c1">0</span><span class="pl-k">:</span><span class="pl-c1">1e10</span>,N));
y<span class="pl-k">=</span>H<span class="pl-k">*</span>u<span class="pl-k">+</span><span class="pl-c1">rand</span>(N)<span class="pl-k">/</span><span class="pl-c1">100</span>;
uhat<span class="pl-k">=</span><span class="pl-c1">cvp</span>(Q<span class="pl-k">'</span><span class="pl-k">*</span>y,R);
<span class="pl-c1">sum</span>(<span class="pl-c1">abs</span>.(u<span class="pl-k">-</span>uhat))</pre></div>
<p dir="auto"></p>
</details>
<details>
   <summary><b>Execution Time results</b> (click for details)</summary>
<p dir="auto">
</p><p dir="auto">In the first test we compare several LLL functions: the <code>lll</code> function from LLLplus, the
<code>l2avx</code> function in the <code>src\l2.jl</code> file in LLLplus, the
<code>lll_with_transform</code> function from
<a href="https://github.com/Nemocas/Nemo.jl">Nemo.jl</a> (which uses FLINT), and
the <code>lll_reduction</code> function from
<a href="https://github.com/fplll/fplll">fplll</a>.  Nemo is written by number
theorists, while fplll is written
by lattice cryptanalysis academics; they are good benchmarks against which to compare.
We first show how the execution time varies as the basis (matrix) size
varies over [4 8 16 32 64]. For each matrix size, 20 random bases are
generated using fplll's <code>gen_qary</code> function with depth of 25 bits,
with the average execution time shown; the <code>eltype</code> is <code>Int64</code> except
for NEMO, which can only use GMP (its own <code>BigInt</code>); in all cases the
<code>δ=.99</code>. The vertical axis shows execution time on a logarithmic
scale; the x-axis is also logarithmic.
The <code>lll</code> function is slower, while <code>l2avx</code> is similar to
fplll. Though not shown, using bases from <code>gen_qary</code> with bit depth of
45 gives fplll a larger advantage. Though the LLLplus functions are
not the fastest, they are in the same ballpark as the C and
C++ tools; if this package gets more users, we'll spend more time on
speed :-)  This figure was generated using code in <code>test/timeLLLs.jl</code>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="docs/src/assets/timeVdim_25bitsInt64.png"><img src="docs/src/assets/timeVdim_25bitsInt64.png" alt="Time vs basis size" style="max-width: 100%;"></a></p>
<p dir="auto">One additional question that could arise when looking at the plot above is what
the quality of the basis is. In the next plot we show execution time
vs the norm of the first vector in the reduced basis, this first
vector is typically the smallest; its norm is an rough indication of
the quality of the reduced basis. We show results averaged over 20
random bases from <code>gen_qary</code> with depth <code>25</code> bits, this time with the
dimension fixed at <code>32</code>. The curve is created by varying the <code>δ</code>
parameter from <code>.29</code> to <code>.99</code> in steps of <code>.2</code>; the larger times and
smaller norms correspond to the largest <code>δ</code> values. Though the <code>l2avx</code>
function is competitive with fplll in this case, in most cases
the fplll code is faster.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="docs/src/assets/timeVsmallest_25bitsInt64.png"><img src="docs/src/assets/timeVsmallest_25bitsInt64.png" alt="Time vs reduction quality" style="max-width: 100%;"></a></p>
<p dir="auto">Finally, we show execution time for several built-in
datatypes (Int32, Int64, Int128, Float32, Float64, BitInt, and
BigFloat) as well as type from external packages (Float128 from
<a href="https://github.com/JuliaMath/Quadmath.jl">Quadmath.jl</a> and Double64
from <a href="https://github.com/JuliaMath/DoubleFloats.jl">DoubleFloat.jl</a>)
which are used to
generate 60 16x16 matrices, over which execution time for the
lattice reduction techniques is averaged.  The vertical axis is a
logarithmic representation of execution time as in the previous
figure. This figure was generated using code in <code>test/perftest.jl</code>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="docs/src/assets/perfVsDataType.png"><img src="docs/src/assets/perfVsDataType.png" alt="Time vs data type" style="max-width: 100%;"></a></p>
<p dir="auto"></p>
</details>
<details>
   <summary><b>Notes</b> (click for details)</summary>
<p dir="auto">
</p><p dir="auto">The 2020 <a href="https://simons.berkeley.edu/programs/lattices2020" rel="nofollow">Simons Institute lattice</a>
workshop, a
<a href="http://www.ant.uni-bremen.de/sixcms/media.php/102/10740/SPM_2011_Wuebben.pdf" rel="nofollow">survey paper by Wuebben</a>, and the
<a href="https://www.amazon.com/Lattice-Basis-Reduction-Introduction-Applications/dp/1439807027" rel="nofollow">monograph by Bremner</a>
were helpful in writing the tools in LLLplus
and are good resources for further study. If you are trying to break
one of the <a href="http://www.latticechallenge.org" rel="nofollow">Lattice Challenge</a>
records or are looking for robust, well-proven lattice tools, look at
<a href="https://github.com/fplll/fplll">fplll</a>. Also, for many
number-theoretic problems the
<a href="https://github.com/Nemocas/Nemo.jl">Nemo.jl</a> package is appropriate;
it uses the <a href="http://flintlib.org/" rel="nofollow">FLINT</a> C library to do LLL
reduction on Nemo-specific data types.  Finally, no number theorists
have worked on LLLplus; please treat the package as experimental.</p>
</details></article></div>