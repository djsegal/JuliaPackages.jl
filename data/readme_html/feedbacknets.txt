<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-feedbacknetsjl" class="anchor" aria-hidden="true" href="#feedbacknetsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>FeedbackNets.jl</h1>
<p>Deep and convolutional neural networks with feedback operations in Flux.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/45b4ffbd594af47fe09a3432f9f8e122c6518aa6352b4ce453a1a2563da2905c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d677265656e2e737667"><img src="https://camo.githubusercontent.com/45b4ffbd594af47fe09a3432f9f8e122c6518aa6352b4ce453a1a2563da2905c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d677265656e2e737667" alt="MIT license badge" data-canonical-src="https://img.shields.io/badge/license-MIT-green.svg" style="max-width:100%;"></a>
<a href="https://travis-ci.org/cJarvers/FeedbackNets.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/b50ffbd30f4806ae604ebbfb0263902b6642277fad12c10109d37b18fa296441/68747470733a2f2f7472617669732d63692e6f72672f634a6172766572732f466565646261636b4e6574732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/cJarvers/FeedbackNets.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/cJarvers/FeedbackNets.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/a77b523e2e96c62a6899e60cbeb187795ce5a0ea53b5b49fd94acba03a8aa8af/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f634a6172766572732f466565646261636b4e6574732e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/cJarvers/FeedbackNets.jl/badge.svg?branch=master" style="max-width:100%;"></a>
<a href="https://cJarvers.github.io/FeedbackNets.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a>
<a href="https://cJarvers.github.io/FeedbackNets.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a></p>
<h2><a id="user-content-description" class="anchor" aria-hidden="true" href="#description"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Description</h2>
<p>This package implements deep neural networks with feedback. This means that the
output of higher/later layers can serve as an input to lower/earlier layers at
the next timestep.</p>
<p>Most deep learning frameworks do not support this form of recurrence in a
straightforward manner. Usually recurrence is limited to a single layer,
implemented as an RNN cell. This package essentially turns the whole network
into a single RNN cell with support for arbitrary connectivity.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>The package can be installed using <code>Pkg.add()</code></p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using Pkg
Pkg.add(&quot;FeedbackNets&quot;)
"><pre><span class="pl-k">using</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>FeedbackNets<span class="pl-pds">"</span></span>)</pre></div>
<p>or using the REPL shorthand</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="] add FeedbackNets
"><pre>] add FeedbackNets</pre></div>
<p>The package depends on <code>Flux</code> and on <code>CuArrays</code> for GPU support. For more
details on Julia package management, look <a href="https://julialang.github.io/Pkg.jl/" rel="nofollow">here</a>.</p>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<p>Once the package is installed, you can access it with Julia's package manager:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using FeedbackNets
"><pre><span class="pl-k">using</span> FeedbackNets</pre></div>
<p>Typically, you'll want to load <code>Flux</code> as well for its network layers:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using Flux
"><pre><span class="pl-k">using</span> Flux</pre></div>
<p>The core of the package is the <code>FeedbackChain</code>, a type that behaves largely
similar to a normal <code>Flux.Chain</code>. It treats normal Flux layers as one would
expect. However, it can contain two additional elements: <code>Splitter</code>s and
<code>Merger</code>s. These two types are used to structure feedback in a network, i.e., to
enable higher levels of the chain to provide input to lower levels in the next
timestep.</p>
<p>A <code>Splitter</code> marks a point in the forward stream from which feedback is provided.
As the <code>FeedbackChain</code> traverses the feedforward stream, it records the
intermediate output at each <code>Splitter</code> and adds it to a state dictionary.</p>
<p>A <code>Merger</code> marks a location at which feedback is folded back into the
feedforward stream. Each <code>Merger</code> contains the name of the <code>Splitter</code> from which
it gets feedback, an operation (e.g., a <code>ConvTranspose</code> or a <code>Chain</code>) to apply
to the feedback and a binary operation (e.g., <code>+</code>) which it applies to combine
forward and feedback input.</p>
<p>For example, a simple <code>FeedbackChain</code> may contain a <code>Dense</code> layer that maps ten
input units to five outputs and a feedback path that has another <code>Dense</code> layer
with the inverse connectivity.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="net = FeedbackChain(
    Merger(&quot;fork1&quot;, Dense(5, 10, relu), +),
    Dense(10, 5, relu),
    Splitter(&quot;fork1&quot;)
)
"><pre>net <span class="pl-k">=</span> <span class="pl-c1">FeedbackChain</span>(
    <span class="pl-c1">Merger</span>(<span class="pl-s"><span class="pl-pds">"</span>fork1<span class="pl-pds">"</span></span>, <span class="pl-c1">Dense</span>(<span class="pl-c1">5</span>, <span class="pl-c1">10</span>, relu), <span class="pl-k">+</span>),
    <span class="pl-c1">Dense</span>(<span class="pl-c1">10</span>, <span class="pl-c1">5</span>, relu),
    <span class="pl-c1">Splitter</span>(<span class="pl-s"><span class="pl-pds">"</span>fork1<span class="pl-pds">"</span></span>)
)</pre></div>
<p>At each timestep, this network will take the previous state of <code>fork1</code>, pass it
through the 5-to-10 unit <code>Dense</code> layer and add it to the 10-unit input. The
result is then passed through the 10-to-5 Dense layer to produce the output of
the network, which is stored for the next timestep by <code>fork1</code>.</p>
<p>In order to apply <code>net</code> to an input, we need to pass it a dictionary with the
current / inital state of <code>fork1</code>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="x = randn(10)
h = Dict(&quot;fork1&quot; =&gt; zeros(5))
h, out = net(h, x)
"><pre>x <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">10</span>)
h <span class="pl-k">=</span> <span class="pl-c1">Dict</span>(<span class="pl-s"><span class="pl-pds">"</span>fork1<span class="pl-pds">"</span></span> <span class="pl-k">=&gt;</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">5</span>))
h, out <span class="pl-k">=</span> <span class="pl-c1">net</span>(h, x)</pre></div>
<p>A FeedbackChain can be wrapped in a <code>Flux.Recur</code> in order to have it handle the
state internally. This requires that an initial state dictionary is provided.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="net = Flux.Recur(net, h)
out = net(x)
"><pre>net <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">Recur</span>(net, h)
out <span class="pl-k">=</span> <span class="pl-c1">net</span>(x)</pre></div>
<h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>License</h2>
<p>The project is MIT licensed. See LICENSE for details.</p>
</article></div>