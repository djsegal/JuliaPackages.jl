<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-unetjl" class="anchor" aria-hidden="true" href="#unetjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>UNet.jl</h1>
<p dir="auto"><a href="https://github.com/dhairyagandhi96/UNet.jl/actions"><img src="https://github.com/dhairyagandhi96/UNet.jl/workflows/CI/badge.svg" alt="Actions Status" style="max-width: 100%;"></a></p>
<p dir="auto">This pacakge provides a generic UNet implemented in Julia.</p>
<p dir="auto">The package is built on top of Flux.jl, and therefore can be extended as needed</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; u = Unet()
UNet:
  ConvDown(64, 64)
  ConvDown(128, 128)
  ConvDown(256, 256)
  ConvDown(512, 512)


  UNetConvBlock(1, 3)
  UNetConvBlock(3, 64)
  UNetConvBlock(64, 128)
  UNetConvBlock(128, 256)
  UNetConvBlock(256, 512)
  UNetConvBlock(512, 1024)
  UNetConvBlock(1024, 1024)


  UNetUpBlock(1024, 512)
  UNetUpBlock(1024, 256)
  UNetUpBlock(512, 128)
  UNetUpBlock(256, 64)"><pre>julia<span class="pl-k">&gt;</span> u <span class="pl-k">=</span> <span class="pl-c1">Unet</span>()
UNet<span class="pl-k">:</span>
  <span class="pl-c1">ConvDown</span>(<span class="pl-c1">64</span>, <span class="pl-c1">64</span>)
  <span class="pl-c1">ConvDown</span>(<span class="pl-c1">128</span>, <span class="pl-c1">128</span>)
  <span class="pl-c1">ConvDown</span>(<span class="pl-c1">256</span>, <span class="pl-c1">256</span>)
  <span class="pl-c1">ConvDown</span>(<span class="pl-c1">512</span>, <span class="pl-c1">512</span>)


  <span class="pl-c1">UNetConvBlock</span>(<span class="pl-c1">1</span>, <span class="pl-c1">3</span>)
  <span class="pl-c1">UNetConvBlock</span>(<span class="pl-c1">3</span>, <span class="pl-c1">64</span>)
  <span class="pl-c1">UNetConvBlock</span>(<span class="pl-c1">64</span>, <span class="pl-c1">128</span>)
  <span class="pl-c1">UNetConvBlock</span>(<span class="pl-c1">128</span>, <span class="pl-c1">256</span>)
  <span class="pl-c1">UNetConvBlock</span>(<span class="pl-c1">256</span>, <span class="pl-c1">512</span>)
  <span class="pl-c1">UNetConvBlock</span>(<span class="pl-c1">512</span>, <span class="pl-c1">1024</span>)
  <span class="pl-c1">UNetConvBlock</span>(<span class="pl-c1">1024</span>, <span class="pl-c1">1024</span>)


  <span class="pl-c1">UNetUpBlock</span>(<span class="pl-c1">1024</span>, <span class="pl-c1">512</span>)
  <span class="pl-c1">UNetUpBlock</span>(<span class="pl-c1">1024</span>, <span class="pl-c1">256</span>)
  <span class="pl-c1">UNetUpBlock</span>(<span class="pl-c1">512</span>, <span class="pl-c1">128</span>)
  <span class="pl-c1">UNetUpBlock</span>(<span class="pl-c1">256</span>, <span class="pl-c1">64</span>)</pre></div>
<p dir="auto">The default input channel dimension is expected to be <code>1</code> ie. grayscale. To support different channel images, you can pass the <code>channels</code> to <code>Unet</code>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; u = Unet(3) # for RGB images"><pre>julia<span class="pl-k">&gt;</span> u <span class="pl-k">=</span> <span class="pl-c1">Unet</span>(<span class="pl-c1">3</span>) <span class="pl-c"><span class="pl-c">#</span> for RGB images</span></pre></div>
<p dir="auto">The input size can be any power of two sized batch. Something like <code>(256,256, channels, batch_size)</code>.</p>
<p dir="auto">The default output channel dimension is the input channel dimension. So, <code>1</code> for a <code>Unet()</code> and e.g. <code>3</code> for a <code>Unet(3)</code>.
The output channel dimension can be set by supplying a second argument:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; u = Unet(3, 5) # 3 input channels, 5 output channels."><pre>julia<span class="pl-k">&gt;</span> u <span class="pl-k">=</span> <span class="pl-c1">Unet</span>(<span class="pl-c1">3</span>, <span class="pl-c1">5</span>) <span class="pl-c"><span class="pl-c">#</span> 3 input channels, 5 output channels.</span></pre></div>
<h2 dir="auto"><a id="user-content-gpu-support" class="anchor" aria-hidden="true" href="#gpu-support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>GPU Support</h2>
<p dir="auto">To train the model on UNet, it is as simple as calling <code>gpu</code> on the model.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; u = Unet();

julia&gt; u = gpu(u);

julia&gt; r = gpu(rand(Float32, 256, 256, 1, 1));

julia&gt; size(u(r))
(256, 256, 1, 1)"><pre>julia<span class="pl-k">&gt;</span> u <span class="pl-k">=</span> <span class="pl-c1">Unet</span>();

julia<span class="pl-k">&gt;</span> u <span class="pl-k">=</span> <span class="pl-c1">gpu</span>(u);

julia<span class="pl-k">&gt;</span> r <span class="pl-k">=</span> <span class="pl-c1">gpu</span>(<span class="pl-c1">rand</span>(Float32, <span class="pl-c1">256</span>, <span class="pl-c1">256</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>));

julia<span class="pl-k">&gt;</span> <span class="pl-c1">size</span>(<span class="pl-c1">u</span>(r))
(<span class="pl-c1">256</span>, <span class="pl-c1">256</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>)</pre></div>
<h2 dir="auto"><a id="user-content-training" class="anchor" aria-hidden="true" href="#training"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Training</h2>
<p dir="auto">Training UNet is a breeze too.</p>
<p dir="auto">You can define your own loss function, or use Flux binary cross entropy implementation.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using UNet, Flux,  Base.Iterators
import Flux.Losses.binarycrossentropy

device = gpu #cpu

function loss(x, y)
    op = clamp.(u(x), 0.001f0, 1.f0)
    binarycrossentropy(op,y)
end

u = Unet() |&gt; device
w = rand(Float32, 256, 256, 1, 1) |&gt; device
w′ = rand(Float32, 256, 256, 1, 1) |&gt; device
rep = Iterators.repeated((w, w′), 10)

opt = ADAM()

Flux.train!(loss, Flux.params(u), rep, opt, cb = () -&gt; @show(loss(w, w′)))"><pre><span class="pl-k">using</span> UNet, Flux,  Base<span class="pl-k">.</span>Iterators
<span class="pl-k">import</span> Flux<span class="pl-k">.</span>Losses<span class="pl-k">.</span>binarycrossentropy

device <span class="pl-k">=</span> gpu <span class="pl-c"><span class="pl-c">#</span>cpu</span>

<span class="pl-k">function</span> <span class="pl-en">loss</span>(x, y)
    op <span class="pl-k">=</span> <span class="pl-c1">clamp</span>.(<span class="pl-c1">u</span>(x), <span class="pl-c1">0.001f0</span>, <span class="pl-c1">1.f0</span>)
    <span class="pl-c1">binarycrossentropy</span>(op,y)
<span class="pl-k">end</span>

u <span class="pl-k">=</span> <span class="pl-c1">Unet</span>() <span class="pl-k">|&gt;</span> device
w <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float32, <span class="pl-c1">256</span>, <span class="pl-c1">256</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>) <span class="pl-k">|&gt;</span> device
w′ <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float32, <span class="pl-c1">256</span>, <span class="pl-c1">256</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>) <span class="pl-k">|&gt;</span> device
rep <span class="pl-k">=</span> Iterators<span class="pl-k">.</span><span class="pl-c1">repeated</span>((w, w′), <span class="pl-c1">10</span>)

opt <span class="pl-k">=</span> <span class="pl-c1">ADAM</span>()

Flux<span class="pl-k">.</span><span class="pl-c1">train!</span>(loss, Flux<span class="pl-k">.</span><span class="pl-c1">params</span>(u), rep, opt, cb <span class="pl-k">=</span> () <span class="pl-k">-&gt;</span> <span class="pl-c1">@show</span>(<span class="pl-c1">loss</span>(w, w′)))</pre></div>
<h2 dir="auto"><a id="user-content-further-reading" class="anchor" aria-hidden="true" href="#further-reading"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Further Reading</h2>
<p dir="auto">The package is an implementation of the <a href="https://arxiv.org/pdf/1505.04597.pdf" rel="nofollow">paper</a>, and all credits of the model itself go to the respective authors.</p>
</article></div>