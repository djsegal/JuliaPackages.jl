<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><p align="center">
<a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/neurallayer/Photon.jl/master/docs/src/assets/logo.png"><img width="400px" src="https://raw.githubusercontent.com/neurallayer/Photon.jl/master/docs/src/assets/logo.png" style="max-width:100%;"></a>
</p>
<p><a href="LICENSE.md"><img src="https://camo.githubusercontent.com/4440d5deb3a53c4f8661ee765378e6071e7878e8/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c6174" alt="License" data-canonical-src="http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" style="max-width:100%;"></a>
<a href="https://travis-ci.org/neurallayer/Photon.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/b24cadea5716a93fbc56e98fe14fbad9fd4f8e6a/68747470733a2f2f7472617669732d63692e6f72672f6e657572616c6c617965722f50686f746f6e2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/neurallayer/Photon.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://neurallayer.github.io/Photon.jl/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/3e353c26ddfe819150acbc732248f4f2a37f5175/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/neurallayer/Photon.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/cca4902e4a0cc5c28b3323e7169d33661b69ae0f/68747470733a2f2f636f6465636f762e696f2f67682f6e657572616c6c617965722f50686f746f6e2e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/neurallayer/Photon.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a>
<a href="https://slackinvite.julialang.org" rel="nofollow"><img src="https://camo.githubusercontent.com/db723db19a092d001b6a28affedee50407e3fa50/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d736c61636b25323370686f746f6e2d79656c6c6f772e737667" alt="Join the julia slack" data-canonical-src="https://img.shields.io/badge/chat-slack%23photon-yellow.svg" style="max-width:100%;"></a></p>
<p><strong>Photon</strong> is a developer friendly framework for Deep Learning in Julia. Under the hood
it leverages <strong>Knet</strong> and it provides a Keras like API on top of that.</p>
<p>Photon is right now still beta quality and the main goal is to see what API's work best.
So expect still to see some API changes in the upcoming releases.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<p>Since Photon is improving rapidly, the package can be best installed with the Julia package manager directly from the Github repository.</p>
<p>From the Julia REPL, type <code>]</code> to enter the Pkg REPL mode and run:</p>
<pre><code>pkg&gt; add https://github.com/neurallayer/Photon.jl
</code></pre>
<p>In the future it will be possible to use:</p>
<pre><code>pkg&gt; add Photon
</code></pre>
<h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Documentation</h2>
<p>Click <a href="https://neurallayer.github.io/Photon.jl/dev/" rel="nofollow">here</a> to go to the documentation site.</p>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Usage</h2>
<p>Defining a model is straightforward and should look familiar if you used Keras
or MXnet in the past:</p>
<p>A two layers fully connected network:</p>
<div class="highlight highlight-source-julia"><pre>model <span class="pl-k">=</span> <span class="pl-c1">Sequential</span>(
      <span class="pl-c1">Dense</span>(<span class="pl-c1">256</span>, relu),
      <span class="pl-c1">Dense</span>(<span class="pl-c1">10</span>)
  )</pre></div>
<p>A convolutional network with maxpooling (note that Photon takes care
of the flattening so you can connect a Dense layer directly to a convolutional
layer):</p>
<div class="highlight highlight-source-julia"><pre>model <span class="pl-k">=</span> <span class="pl-c1">Sequential</span>(
      <span class="pl-c1">Conv2D</span>(<span class="pl-c1">16</span>, <span class="pl-c1">3</span>, relu),
      <span class="pl-c1">Conv2D</span>(<span class="pl-c1">16</span>, <span class="pl-c1">3</span>, relu),
      <span class="pl-c1">MaxPool2D</span>(),
      <span class="pl-c1">Dense</span>(<span class="pl-c1">256</span>, relu),
      <span class="pl-c1">Dense</span>(<span class="pl-c1">10</span>)
  )</pre></div>
<p>Or a recurrent LSTM network:</p>
<div class="highlight highlight-source-julia"><pre>model <span class="pl-k">=</span> <span class="pl-c1">Sequential</span>(
      <span class="pl-c1">LSTM</span>(<span class="pl-c1">256</span>, <span class="pl-c1">3</span>),
      <span class="pl-c1">Dense</span>(<span class="pl-c1">64</span>, relu),
      <span class="pl-c1">Dense</span>(<span class="pl-c1">10</span>)
  )</pre></div>
<p>And also the training of the model can be done through an
easy API:</p>
<div class="highlight highlight-source-julia"><pre>workout <span class="pl-k">=</span> <span class="pl-c1">Workout</span>(model, nll)
<span class="pl-c1">train!</span>(workout, data, epochs<span class="pl-k">=</span><span class="pl-c1">10</span>)</pre></div>
<h2><a id="user-content-performance" class="anchor" aria-hidden="true" href="#performance"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Performance</h2>
<p>The combination of Deep Learning and Julia is a very performant one. Especially
when running the models on a GPU. Some tests reveal <strong>speedups of up to 100%</strong> when
compared one of the most popular framework Keras/Tensorflow 2.0.</p>
<p>The code that has been used to test is available in the <em>performance</em> sub directory.</p>
<h2><a id="user-content-features" class="anchor" aria-hidden="true" href="#features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Features</h2>
<p>The main goal is to provide a user friendly API for Machine Learning that enables
developing both prototype and production ready solutions while remaining fast.</p>
<p>Some of the key features:</p>
<ul>
<li>
<p>Good support for the various ways you can to retrieve and transform your data.</p>
</li>
<li>
<p>Develop models with a minimal amount of code.</p>
</li>
<li>
<p>Get all the required insights and visualizations into the performance of the model.</p>
</li>
</ul>
<h2><a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Todo</h2>
<p>There remain many things to do.</p>
<ul>
<li>Add more typing to assist the compiler and development</li>
<li>Extend unit tests to cover more code (&gt; 90%)</li>
<li>Implement more models including trained weights (resnet,...)</li>
<li>Write tutorials and improve code documentation</li>
<li>Finalise the API's so we can release 1.0</li>
<li>Implement more complex layers like attention</li>
<li>More loss functions</li>
<li>Once stable, create proper back-end abstraction to support other frameworks</li>
</ul>
<p>And b.t.w, we are always open in accepting contributions ;)</p>
<h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>License</h2>
<p>Photon is provided under the MIT open source license.</p>
<h2><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>References</h2>
<p>We used several other open source frameworks for code and inspiration</p>
<ul>
<li>
<p>Knet (pronounced "kay-net") is the Ko√ß University deep learning framework
implemented in Julia by Deniz Yuret and collaborators. It is right now the
back-end for Photon, partially due to its excellent performance on GPU's.</p>
</li>
<li>
<p>Flux, we use it for inspiration. This has to be one of the most
beautiful code bases out there.</p>
</li>
<li>
<p>Keras and MXNet for their well thought out API's. Also copied some of their
excellent documentation for layers and losses.</p>
</li>
<li>
<p>And of course Julia, that enables writing very fast deep learning applications.</p>
</li>
</ul>
</article></div>