<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-textencodebase" class="anchor" aria-hidden="true" href="#textencodebase"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>TextEncodeBase</h1>
<p dir="auto"><a href="https://chengchingwen.github.io/TextEncodeBase.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://chengchingwen.github.io/TextEncodeBase.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/chengchingwen/TextEncodeBase.jl/actions/workflows/CI.yml?query=branch%3Amain"><img src="https://github.com/chengchingwen/TextEncodeBase.jl/actions/workflows/CI.yml/badge.svg?branch=main" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/chengchingwen/TextEncodeBase.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/bdb0aab5d2cacc398585ae62004804d65b00f206c2e12cdcb770bd3a6548aa59/68747470733a2f2f636f6465636f762e696f2f67682f6368656e676368696e6777656e2f54657874456e636f6465426173652e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/chengchingwen/TextEncodeBase.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">An api for encoding text, built on top of <a href="https://github.com/JuliaText/WordTokenizers.jl">WordTokenizers.jl</a>.
Providing a framework to easily define custom methods to convert strings into indices.</p>
<h1 dir="auto"><a id="user-content-usages" class="anchor" aria-hidden="true" href="#usages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usages</h1>
<p dir="auto">Here are some explanation and examples for using <code>TextEncodeBase.jl</code>, you can also find other information
from the <a href="https://chengchingwen.github.io/TextEncodeBase.jl/dev" rel="nofollow">docs</a> or <a href="/test/runtests.jl">test</a></p>
<h2 dir="auto"><a id="user-content-vocabulary" class="anchor" aria-hidden="true" href="#vocabulary"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Vocabulary</h2>
<p dir="auto">The vocabulary part contains only two api, the <code>Vocab</code> struct and the <code>lookup</code> function.
The <code>lookup</code> function is bidirectional (convert string to indices and back).</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; vocab = Vocab([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;])
Vocab{String, StaticArrays.SizedVector{3, String, Vector{String}}}(size = 3, unk = [UNK], unki = 0)

julia&gt; vocab_unk = Vocab([&quot;a&quot;, &quot;b&quot;, &quot;xxx&quot;], &quot;xxx&quot;)
Vocab{String, StaticArrays.SizedVector{3, String, Vector{String}}}(size = 3, unk = xxx, unki = 3)

julia&gt; lookup(vocab, &quot;b&quot;)
2

julia&gt; lookup(vocab, &quot;d&quot;)
0

julia&gt; lookup(vocab_unk, &quot;d&quot;)
3

julia&gt; lookup(vocab, 1)
&quot;a&quot;

julia&gt; lookup(vocab, 10000)
&quot;[UNK]&quot;

julia&gt; lookup(vocab_unk, 10000)
&quot;xxx&quot;

julia&gt; lookup(vocab, [&quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;A&quot;, &quot;[UNK]&quot;])
5-element Vector{Int64}:
 2
 3
 1
 0
 0

julia&gt; lookup(OneHot, vocab, &quot;a&quot;)
3-element OneHot{3}:
 1
 0
 0

julia&gt; lookup(OneHot, vocab, 3)
ERROR: DomainError with c:
cannot convert `lookup(::Vocab, 3)` = &quot;c&quot; into one-hot representation.
Stacktrace:
[...]

julia&gt; oha = lookup(OneHot, vocab, [&quot;a&quot; &quot;b&quot;; &quot;c&quot; &quot;d&quot;])
3x2x2 OneHotArray{3, 3, Matrix{OneHot{0x00000003}}}:
[:, :, 1] =
 1  0
 0  0
 0  1

[:, :, 2] =
 0  0
 1  0
 0  0

julia&gt; lookup(vocab, oha)
2×2 Matrix{String}:
 &quot;a&quot;  &quot;b&quot;
 &quot;c&quot;  &quot;[UNK]&quot;
"><pre>julia<span class="pl-k">&gt;</span> vocab <span class="pl-k">=</span> <span class="pl-c1">Vocab</span>([<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>b<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>c<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>b<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>c<span class="pl-pds">"</span></span>])
<span class="pl-c1">Vocab</span><span class="pl-c1">{String, StaticArrays.SizedVector{3, String, Vector{String}}}</span>(size <span class="pl-k">=</span> <span class="pl-c1">3</span>, unk <span class="pl-k">=</span> [UNK], unki <span class="pl-k">=</span> <span class="pl-c1">0</span>)

julia<span class="pl-k">&gt;</span> vocab_unk <span class="pl-k">=</span> <span class="pl-c1">Vocab</span>([<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>b<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>xxx<span class="pl-pds">"</span></span>], <span class="pl-s"><span class="pl-pds">"</span>xxx<span class="pl-pds">"</span></span>)
<span class="pl-c1">Vocab</span><span class="pl-c1">{String, StaticArrays.SizedVector{3, String, Vector{String}}}</span>(size <span class="pl-k">=</span> <span class="pl-c1">3</span>, unk <span class="pl-k">=</span> xxx, unki <span class="pl-k">=</span> <span class="pl-c1">3</span>)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">lookup</span>(vocab, <span class="pl-s"><span class="pl-pds">"</span>b<span class="pl-pds">"</span></span>)
<span class="pl-c1">2</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">lookup</span>(vocab, <span class="pl-s"><span class="pl-pds">"</span>d<span class="pl-pds">"</span></span>)
<span class="pl-c1">0</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">lookup</span>(vocab_unk, <span class="pl-s"><span class="pl-pds">"</span>d<span class="pl-pds">"</span></span>)
<span class="pl-c1">3</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">lookup</span>(vocab, <span class="pl-c1">1</span>)
<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">lookup</span>(vocab, <span class="pl-c1">10000</span>)
<span class="pl-s"><span class="pl-pds">"</span>[UNK]<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">lookup</span>(vocab_unk, <span class="pl-c1">10000</span>)
<span class="pl-s"><span class="pl-pds">"</span>xxx<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">lookup</span>(vocab, [<span class="pl-s"><span class="pl-pds">"</span>b<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>c<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>A<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>[UNK]<span class="pl-pds">"</span></span>])
<span class="pl-c1">5</span><span class="pl-k">-</span>element Vector{Int64}<span class="pl-k">:</span>
 <span class="pl-c1">2</span>
 <span class="pl-c1">3</span>
 <span class="pl-c1">1</span>
 <span class="pl-c1">0</span>
 <span class="pl-c1">0</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">lookup</span>(OneHot, vocab, <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>)
<span class="pl-c1">3</span><span class="pl-k">-</span>element OneHot{<span class="pl-c1">3</span>}<span class="pl-k">:</span>
 <span class="pl-c1">1</span>
 <span class="pl-c1">0</span>
 <span class="pl-c1">0</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">lookup</span>(OneHot, vocab, <span class="pl-c1">3</span>)
ERROR<span class="pl-k">:</span> DomainError with c<span class="pl-k">:</span>
cannot convert <span class="pl-s"><span class="pl-pds">`</span>lookup(::Vocab, 3)<span class="pl-pds">`</span></span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>c<span class="pl-pds">"</span></span> into one<span class="pl-k">-</span>hot representation.
Stacktrace<span class="pl-k">:</span>
[<span class="pl-k">...</span>]

julia<span class="pl-k">&gt;</span> oha <span class="pl-k">=</span> <span class="pl-c1">lookup</span>(OneHot, vocab, [<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>b<span class="pl-pds">"</span></span>; <span class="pl-s"><span class="pl-pds">"</span>c<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span>d<span class="pl-pds">"</span></span>])
<span class="pl-c1">3</span>x2x2 OneHotArray{<span class="pl-c1">3</span>, <span class="pl-c1">3</span>, Matrix{OneHot{<span class="pl-c1">0x00000003</span>}}}<span class="pl-k">:</span>
[:, :, <span class="pl-c1">1</span>] <span class="pl-k">=</span>
 <span class="pl-c1">1</span>  <span class="pl-c1">0</span>
 <span class="pl-c1">0</span>  <span class="pl-c1">0</span>
 <span class="pl-c1">0</span>  <span class="pl-c1">1</span>

[:, :, <span class="pl-c1">2</span>] <span class="pl-k">=</span>
 <span class="pl-c1">0</span>  <span class="pl-c1">0</span>
 <span class="pl-c1">1</span>  <span class="pl-c1">0</span>
 <span class="pl-c1">0</span>  <span class="pl-c1">0</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">lookup</span>(vocab, oha)
<span class="pl-c1">2</span><span class="pl-k">×</span><span class="pl-c1">2</span> Matrix{String}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>  <span class="pl-s"><span class="pl-pds">"</span>b<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>c<span class="pl-pds">"</span></span>  <span class="pl-s"><span class="pl-pds">"</span>[UNK]<span class="pl-pds">"</span></span>
</pre></div>
<h2 dir="auto"><a id="user-content-pipelines" class="anchor" aria-hidden="true" href="#pipelines"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Pipelines</h2>
<p dir="auto"><em>Reexport from <a href="https://github.com/chengchingwen/FuncPipelines.jl">FuncPipelines.jl</a></em></p>
<p dir="auto">The Pipeline api help you define a series of functions that can easily be decomposed and then combined with
other function to form a new pipeline. A function (<code>Pipeline</code>) is tagged with one (or multiple) <code>Symbol</code>s.
The return values of that <code>Pipeline</code> will be bound to those symbols storing in a <code>NamedTuple</code>. Precisely,
A <code>Pipeline</code> take two inputs, a regular input value (<code>source</code>) and a <code>NamedTuple</code> (<code>target</code>) that stores
the results, applying the function to them, and then store the result with the name it carried with into <code>target</code>.
We can then chaining multiple <code>Pipeline</code>s into a <code>Pipelines</code>. For example:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; pipes = Pipeline{:x}(identity, 1) |&gt; Pipeline{(:sinx, :cosx)}((x,y)-&gt;sincos(x))

julia&gt; pipes(0.3)
(x = 0.3, sinx = 0.29552020666133955, cosx = 0.955336489125606)

# define a series of function
julia&gt; pipes = Pipeline{:θ}(Base.Fix1(*, 2), 1) |&gt;
           Pipeline{(:sinθ, :cosθ)}(sincos, :θ) |&gt;
           Pipeline{:tanθ}(2) do target
               target.sinθ / target.cosθ
           end

Pipelines:
  target[θ] := *(2, source)
  target[(sinθ, cosθ)] := sincos(target.θ)
  target[tanθ] := #68(target)

# get the wanted results
julia&gt; pipes2 = pipes |&gt; PipeGet{(:tanθ, :θ)}()
Pipelines:
  target[θ] := *(2, source)
  target[(sinθ, cosθ)] := sincos(target.θ)
  target[tanθ] := #68(target)
  target := (target.tanθ, target.θ)

julia&gt; pipes2(ℯ)
(tanθ = -1.1306063769531505, θ = 5.43656365691809)

# replace some functions in pipeline
julia&gt; pipes3 = pipes2[1] |&gt; Pipeline{:tanθ}(tan, :θ) |&gt; pipes2[end]
Pipelines:
  target[θ] := *(2, source)
  target[tanθ] := tan(target.θ)
  target := (target.tanθ, target.θ)

julia&gt; pipes3(ℯ)
(tanθ = -1.1306063769531507, θ = 5.43656365691809)

# and the pipelines is type stable
julia&gt; using Test; @inferred pipes3(ℯ)
(tanθ = -1.1306063769531507, θ = 5.43656365691809)
"><pre>julia<span class="pl-k">&gt;</span> pipes <span class="pl-k">=</span> <span class="pl-c1">Pipeline</span><span class="pl-c1">{:x}</span>(identity, <span class="pl-c1">1</span>) <span class="pl-k">|&gt;</span> <span class="pl-c1">Pipeline</span><span class="pl-c1">{(:sinx, :cosx)}</span>((x,y)<span class="pl-k">-&gt;</span><span class="pl-c1">sincos</span>(x))

julia<span class="pl-k">&gt;</span> <span class="pl-c1">pipes</span>(<span class="pl-c1">0.3</span>)
(x <span class="pl-k">=</span> <span class="pl-c1">0.3</span>, sinx <span class="pl-k">=</span> <span class="pl-c1">0.29552020666133955</span>, cosx <span class="pl-k">=</span> <span class="pl-c1">0.955336489125606</span>)

<span class="pl-c"><span class="pl-c">#</span> define a series of function</span>
julia<span class="pl-k">&gt;</span> pipes <span class="pl-k">=</span> <span class="pl-c1">Pipeline</span><span class="pl-c1">{:θ}</span>(Base<span class="pl-k">.</span><span class="pl-c1">Fix1</span>(<span class="pl-k">*</span>, <span class="pl-c1">2</span>), <span class="pl-c1">1</span>) <span class="pl-k">|&gt;</span>
           <span class="pl-c1">Pipeline</span><span class="pl-c1">{(:sinθ, :cosθ)}</span>(sincos, <span class="pl-c1">:θ</span>) <span class="pl-k">|&gt;</span>
           <span class="pl-c1">Pipeline</span><span class="pl-c1">{:tanθ}</span>(<span class="pl-c1">2</span>) <span class="pl-k">do</span> target
               target<span class="pl-k">.</span>sinθ <span class="pl-k">/</span> target<span class="pl-k">.</span>cosθ
           <span class="pl-k">end</span>

Pipelines<span class="pl-k">:</span>
  target[θ] <span class="pl-k">:=</span> <span class="pl-k">*</span>(<span class="pl-c1">2</span>, source)
  target[(sinθ, cosθ)] <span class="pl-k">:=</span> <span class="pl-c1">sincos</span>(target<span class="pl-k">.</span>θ)
  target[tanθ] <span class="pl-k">:=</span> <span class="pl-c"><span class="pl-c">#</span>68(target)</span>

<span class="pl-c"><span class="pl-c">#</span> get the wanted results</span>
julia<span class="pl-k">&gt;</span> pipes2 <span class="pl-k">=</span> pipes <span class="pl-k">|&gt;</span> <span class="pl-c1">PipeGet</span><span class="pl-c1">{(:tanθ, :θ)}</span>()
Pipelines<span class="pl-k">:</span>
  target[θ] <span class="pl-k">:=</span> <span class="pl-k">*</span>(<span class="pl-c1">2</span>, source)
  target[(sinθ, cosθ)] <span class="pl-k">:=</span> <span class="pl-c1">sincos</span>(target<span class="pl-k">.</span>θ)
  target[tanθ] <span class="pl-k">:=</span> <span class="pl-c"><span class="pl-c">#</span>68(target)</span>
  target <span class="pl-k">:=</span> (target<span class="pl-k">.</span>tanθ, target<span class="pl-k">.</span>θ)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">pipes2</span>(ℯ)
(tanθ <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1.1306063769531505</span>, θ <span class="pl-k">=</span> <span class="pl-c1">5.43656365691809</span>)

<span class="pl-c"><span class="pl-c">#</span> replace some functions in pipeline</span>
julia<span class="pl-k">&gt;</span> pipes3 <span class="pl-k">=</span> pipes2[<span class="pl-c1">1</span>] <span class="pl-k">|&gt;</span> <span class="pl-c1">Pipeline</span><span class="pl-c1">{:tanθ}</span>(tan, <span class="pl-c1">:θ</span>) <span class="pl-k">|&gt;</span> pipes2[<span class="pl-c1">end</span>]
Pipelines<span class="pl-k">:</span>
  target[θ] <span class="pl-k">:=</span> <span class="pl-k">*</span>(<span class="pl-c1">2</span>, source)
  target[tanθ] <span class="pl-k">:=</span> <span class="pl-c1">tan</span>(target<span class="pl-k">.</span>θ)
  target <span class="pl-k">:=</span> (target<span class="pl-k">.</span>tanθ, target<span class="pl-k">.</span>θ)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">pipes3</span>(ℯ)
(tanθ <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1.1306063769531507</span>, θ <span class="pl-k">=</span> <span class="pl-c1">5.43656365691809</span>)

<span class="pl-c"><span class="pl-c">#</span> and the pipelines is type stable</span>
julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Test; <span class="pl-c1">@inferred</span> <span class="pl-c1">pipes3</span>(ℯ)
(tanθ <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1.1306063769531507</span>, θ <span class="pl-k">=</span> <span class="pl-c1">5.43656365691809</span>)
</pre></div>
<h2 dir="auto"><a id="user-content-tokenizer" class="anchor" aria-hidden="true" href="#tokenizer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Tokenizer</h2>
<p dir="auto">The tokenizer part is built ontop of <code>WordTokenizers.jl</code> and provide a high-level api
to control/augment the tokenization. There're some differences between <code>WordTokenizers.jl</code>.
<code>WordTokenizers.jl</code> provides a set of tokenizers and a low-level api (<code>TokenBuffer</code>) for define
custom tokenizers. It's mainly focus on how to split a setnece into tokens. We, on the other hand,
focus on how to combine different tokenizer or include other information during the tokenization.
For example, sometimes you might want to prevent urls from being splited or add some extra tags to it,
these can be done by defining a custom <code>AbstractTokenizer</code> and overload some methods. Besides, we
force the user to explicit wrap the input as one of the stages (<code>Document</code>/<code>Sentence</code>/<code>Word</code>/...),
so no confusion.</p>
<h3 dir="auto"><a id="user-content-example-of-using-the-tokenizer-api" class="anchor" aria-hidden="true" href="#example-of-using-the-tokenizer-api"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example of using the Tokenizer api</h3>
<p dir="auto">Here is an example that wrapped the word tokenizer and wordpiece from <code>Transformers.jl</code> into our Tokenizer api.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Transformers
using Transformers.Pretrain
using Transformers.BidirectionalEncoder: WordPiece, bert_cased_tokenizer

using TextEncodeBase
using TextEncodeBase: NestedTokenizer, BaseTokenization, Sentence, Word, SubWord, getvalue, Splittable

struct BertCasedTokenization &lt;: BaseTokenization
    wordpiece::WordPiece
end

# split sentence with `bert_cased_tokenizer` (define with WordTokenizers.jl's `TokenBuffer`)
TextEncodeBase.splitting(::BertCasedTokenization, s::Sentence) = bert_cased_tokenizer(getvalue(s))

# word is splittable with WordPiece
TextEncodeBase.splittability(::BertCasedTokenization, w::Word) = Splittable()

# split word with `WordPiece`
TextEncodeBase.splitting(t::BertCasedTokenization, w::Word) = t.wordpiece(getvalue(w))

tokenizer = pretrain&quot;bert-cased_L-12_H-768_A-12:tokenizer&quot; # this is just `bert_cased_tokenizer`
wordpiece = pretrain&quot;bert-cased_L-12_H-768_A-12:wordpiece&quot;

tkr = NestedTokenizer(BertCasedTokenization(wordpiece))

text1 = &quot;Peter Piper picked a peck of pickled peppers&quot;
single_without_TEB = text1 |&gt; tokenizer |&gt; wordpiece
single_with_TEB = tkr(Sentence(text1))

# `NestedTokenizer` return vector of vector
@assert single_without_TEB == map(getvalue, single_with_TEB[])

julia&gt; single_without_TEB
11-element Vector{String}:
 &quot;Peter&quot;
 &quot;Piper&quot;
 &quot;picked&quot;
 &quot;a&quot;
 &quot;p&quot;
 &quot;##eck&quot;
 &quot;of&quot;
 &quot;pick&quot;
 &quot;##led&quot;
 &quot;pepper&quot;
 &quot;##s&quot;

julia&gt; single_with_TEB
1-element Vector{Vector{TextEncodeBase.TokenStage}}:
 [Token(&quot;Peter&quot;), Token(&quot;Piper&quot;), Token(&quot;picked&quot;), Token(&quot;a&quot;), Token(&quot;p&quot;), Token(&quot;##eck&quot;), Token(&quot;of&quot;), Token(&quot;pick&quot;), Token(&quot;##led&quot;), Token(&quot;pepper&quot;), Token(&quot;##s&quot;)]

julia&gt; single_without_TEB == map(getvalue, single_with_TEB[])
true


# define stage for batch of data
# equivalent to TextEncodeBase.@stage BatchSentence{A&lt;:AbstractVector, M} DocumentStage
struct BatchSentence{A&lt;:AbstractVector, M} &lt;: TextEncodeBase.DocumentStage
    x::A
    meta::M
end

BatchSentence(x) = BatchSentence(x, nothing)
TextEncodeBase.setmeta(x::BatchSentence, meta) = BatchSentence(x.x, meta)
TextEncodeBase.setvalue(x::BatchSentence, y) = BatchSentence(y, x.meta)

# splittability and split behavior for `BatchSentence`
TextEncodeBase.splittability(::BertCasedTokenization, ::BatchSentence) = Splittable()
TextEncodeBase.splitting(::BertCasedTokenization, s::BatchSentence) = s.x

text2 = &quot;Fuzzy Wuzzy was a bear&quot;
texts = [text1, text2]

batch_without_TEB = map(wordpiece∘tokenizer, texts)
batch_with_TEB = tkr(BatchSentence(texts))

@assert batch_without_TEB == TextEncodeBase.nestedcall(getvalue, batch_with_TEB)

julia&gt; batch_without_TEB
2-element Vector{Vector{String}}:
 [&quot;Peter&quot;, &quot;Piper&quot;, &quot;picked&quot;, &quot;a&quot;, &quot;p&quot;, &quot;##eck&quot;, &quot;of&quot;, &quot;pick&quot;, &quot;##led&quot;, &quot;pepper&quot;, &quot;##s&quot;]
 [&quot;Fu&quot;, &quot;##zzy&quot;, &quot;Wu&quot;, &quot;##zzy&quot;, &quot;was&quot;, &quot;a&quot;, &quot;bear&quot;]

julia&gt; batch_with_TEB
2-element Vector{Vector{TextEncodeBase.TokenStage}}:
 [Token(&quot;Peter&quot;), Token(&quot;Piper&quot;), Token(&quot;picked&quot;), Token(&quot;a&quot;), Token(&quot;p&quot;), Token(&quot;##eck&quot;), Token(&quot;of&quot;), Token(&quot;pick&quot;), Token(&quot;##led&quot;), Token(&quot;pepper&quot;), Token(&quot;##s&quot;)]
 [Token(&quot;Fu&quot;), Token(&quot;##zzy&quot;), Token(&quot;Wu&quot;), Token(&quot;##zzy&quot;), Token(&quot;was&quot;), Token(&quot;a&quot;), Token(&quot;bear&quot;)]

julia&gt; batch_without_TEB == TextEncodeBase.nestedcall(getvalue, batch_with_TEB)
true
"><pre><span class="pl-k">using</span> Transformers
<span class="pl-k">using</span> Transformers<span class="pl-k">.</span>Pretrain
<span class="pl-k">using</span> Transformers<span class="pl-k">.</span>BidirectionalEncoder<span class="pl-k">:</span> WordPiece, bert_cased_tokenizer

<span class="pl-k">using</span> TextEncodeBase
<span class="pl-k">using</span> TextEncodeBase<span class="pl-k">:</span> NestedTokenizer, BaseTokenization, Sentence, Word, SubWord, getvalue, Splittable

<span class="pl-k">struct</span> BertCasedTokenization <span class="pl-k">&lt;:</span> <span class="pl-c1">BaseTokenization</span>
    wordpiece<span class="pl-k">::</span><span class="pl-c1">WordPiece</span>
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> split sentence with `bert_cased_tokenizer` (define with WordTokenizers.jl's `TokenBuffer`)</span>
TextEncodeBase<span class="pl-k">.</span><span class="pl-en">splitting</span>(<span class="pl-k">::</span><span class="pl-c1">BertCasedTokenization</span>, s<span class="pl-k">::</span><span class="pl-c1">Sentence</span>) <span class="pl-k">=</span> <span class="pl-c1">bert_cased_tokenizer</span>(<span class="pl-c1">getvalue</span>(s))

<span class="pl-c"><span class="pl-c">#</span> word is splittable with WordPiece</span>
TextEncodeBase<span class="pl-k">.</span><span class="pl-en">splittability</span>(<span class="pl-k">::</span><span class="pl-c1">BertCasedTokenization</span>, w<span class="pl-k">::</span><span class="pl-c1">Word</span>) <span class="pl-k">=</span> <span class="pl-c1">Splittable</span>()

<span class="pl-c"><span class="pl-c">#</span> split word with `WordPiece`</span>
TextEncodeBase<span class="pl-k">.</span><span class="pl-en">splitting</span>(t<span class="pl-k">::</span><span class="pl-c1">BertCasedTokenization</span>, w<span class="pl-k">::</span><span class="pl-c1">Word</span>) <span class="pl-k">=</span> t<span class="pl-k">.</span><span class="pl-c1">wordpiece</span>(<span class="pl-c1">getvalue</span>(w))

tokenizer <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds"><span class="pl-c1">pretrain</span>"</span>bert-cased_L-12_H-768_A-12:tokenizer<span class="pl-pds">"</span></span> <span class="pl-c"><span class="pl-c">#</span> this is just `bert_cased_tokenizer`</span>
wordpiece <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds"><span class="pl-c1">pretrain</span>"</span>bert-cased_L-12_H-768_A-12:wordpiece<span class="pl-pds">"</span></span>

tkr <span class="pl-k">=</span> <span class="pl-c1">NestedTokenizer</span>(<span class="pl-c1">BertCasedTokenization</span>(wordpiece))

text1 <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Peter Piper picked a peck of pickled peppers<span class="pl-pds">"</span></span>
single_without_TEB <span class="pl-k">=</span> text1 <span class="pl-k">|&gt;</span> tokenizer <span class="pl-k">|&gt;</span> wordpiece
single_with_TEB <span class="pl-k">=</span> <span class="pl-c1">tkr</span>(<span class="pl-c1">Sentence</span>(text1))

<span class="pl-c"><span class="pl-c">#</span> `NestedTokenizer` return vector of vector</span>
<span class="pl-c1">@assert</span> single_without_TEB <span class="pl-k">==</span> <span class="pl-c1">map</span>(getvalue, single_with_TEB[])

julia<span class="pl-k">&gt;</span> single_without_TEB
<span class="pl-c1">11</span><span class="pl-k">-</span>element Vector{String}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>Peter<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>Piper<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>picked<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>p<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>##eck<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>of<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>pick<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>##led<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>pepper<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>##s<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> single_with_TEB
<span class="pl-c1">1</span><span class="pl-k">-</span>element Vector{Vector{TextEncodeBase<span class="pl-k">.</span>TokenStage}}<span class="pl-k">:</span>
 [<span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>Peter<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>Piper<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>picked<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>p<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##eck<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>of<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>pick<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##led<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>pepper<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##s<span class="pl-pds">"</span></span>)]

julia<span class="pl-k">&gt;</span> single_without_TEB <span class="pl-k">==</span> <span class="pl-c1">map</span>(getvalue, single_with_TEB[])
<span class="pl-c1">true</span>


<span class="pl-c"><span class="pl-c">#</span> define stage for batch of data</span>
<span class="pl-c"><span class="pl-c">#</span> equivalent to TextEncodeBase.@stage BatchSentence{A&lt;:AbstractVector, M} DocumentStage</span>
<span class="pl-k">struct</span> BatchSentence{A<span class="pl-k">&lt;:</span><span class="pl-c1">AbstractVector</span>, M} <span class="pl-k">&lt;:</span> <span class="pl-c1">TextEncodeBase.DocumentStage</span>
    x<span class="pl-k">::</span><span class="pl-c1">A</span>
    meta<span class="pl-k">::</span><span class="pl-c1">M</span>
<span class="pl-k">end</span>

<span class="pl-en">BatchSentence</span>(x) <span class="pl-k">=</span> <span class="pl-c1">BatchSentence</span>(x, <span class="pl-c1">nothing</span>)
TextEncodeBase<span class="pl-k">.</span><span class="pl-en">setmeta</span>(x<span class="pl-k">::</span><span class="pl-c1">BatchSentence</span>, meta) <span class="pl-k">=</span> <span class="pl-c1">BatchSentence</span>(x<span class="pl-k">.</span>x, meta)
TextEncodeBase<span class="pl-k">.</span><span class="pl-en">setvalue</span>(x<span class="pl-k">::</span><span class="pl-c1">BatchSentence</span>, y) <span class="pl-k">=</span> <span class="pl-c1">BatchSentence</span>(y, x<span class="pl-k">.</span>meta)

<span class="pl-c"><span class="pl-c">#</span> splittability and split behavior for `BatchSentence`</span>
TextEncodeBase<span class="pl-k">.</span><span class="pl-en">splittability</span>(<span class="pl-k">::</span><span class="pl-c1">BertCasedTokenization</span>, <span class="pl-k">::</span><span class="pl-c1">BatchSentence</span>) <span class="pl-k">=</span> <span class="pl-c1">Splittable</span>()
TextEncodeBase<span class="pl-k">.</span><span class="pl-en">splitting</span>(<span class="pl-k">::</span><span class="pl-c1">BertCasedTokenization</span>, s<span class="pl-k">::</span><span class="pl-c1">BatchSentence</span>) <span class="pl-k">=</span> s<span class="pl-k">.</span>x

text2 <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Fuzzy Wuzzy was a bear<span class="pl-pds">"</span></span>
texts <span class="pl-k">=</span> [text1, text2]

batch_without_TEB <span class="pl-k">=</span> <span class="pl-c1">map</span>(wordpiece<span class="pl-k">∘</span>tokenizer, texts)
batch_with_TEB <span class="pl-k">=</span> <span class="pl-c1">tkr</span>(<span class="pl-c1">BatchSentence</span>(texts))

<span class="pl-c1">@assert</span> batch_without_TEB <span class="pl-k">==</span> TextEncodeBase<span class="pl-k">.</span><span class="pl-c1">nestedcall</span>(getvalue, batch_with_TEB)

julia<span class="pl-k">&gt;</span> batch_without_TEB
<span class="pl-c1">2</span><span class="pl-k">-</span>element Vector{Vector{String}}<span class="pl-k">:</span>
 [<span class="pl-s"><span class="pl-pds">"</span>Peter<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Piper<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>picked<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>p<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>##eck<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>of<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>pick<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>##led<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>pepper<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>##s<span class="pl-pds">"</span></span>]
 [<span class="pl-s"><span class="pl-pds">"</span>Fu<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>##zzy<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Wu<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>##zzy<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>was<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>bear<span class="pl-pds">"</span></span>]

julia<span class="pl-k">&gt;</span> batch_with_TEB
<span class="pl-c1">2</span><span class="pl-k">-</span>element Vector{Vector{TextEncodeBase<span class="pl-k">.</span>TokenStage}}<span class="pl-k">:</span>
 [<span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>Peter<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>Piper<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>picked<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>p<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##eck<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>of<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>pick<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##led<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>pepper<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##s<span class="pl-pds">"</span></span>)]
 [<span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>Fu<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##zzy<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>Wu<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##zzy<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>was<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>), <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>bear<span class="pl-pds">"</span></span>)]

julia<span class="pl-k">&gt;</span> batch_without_TEB <span class="pl-k">==</span> TextEncodeBase<span class="pl-k">.</span><span class="pl-c1">nestedcall</span>(getvalue, batch_with_TEB)
<span class="pl-c1">true</span>
</pre></div>
<p dir="auto">Since the wordpiece break word into subword, we might want to know which word each subword belongs to:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; itkr = NestedTokenizer(TextEncodeBase.IndexedTokenization(BertCasedTokenization(wordpiece)));

julia&gt; ibatch_with_TEB = itkr(BatchSentence(texts));

# subword from same word having the same `word_id`
julia&gt; ibatch_with_TEB[1]
11-element Vector{TextEncodeBase.TokenStage}:
 Token(&quot;Peter&quot;, (sentence_id = 1, word_id = 1, token_id = 1))
 Token(&quot;Piper&quot;, (sentence_id = 1, word_id = 2, token_id = 2))
 Token(&quot;picked&quot;, (sentence_id = 1, word_id = 3, token_id = 3))
 Token(&quot;a&quot;, (sentence_id = 1, word_id = 4, token_id = 4))
 Token(&quot;p&quot;, (sentence_id = 1, word_id = 5, token_id = 5))
 Token(&quot;##eck&quot;, (sentence_id = 1, word_id = 5, token_id = 6))
 Token(&quot;of&quot;, (sentence_id = 1, word_id = 6, token_id = 7))
 Token(&quot;pick&quot;, (sentence_id = 1, word_id = 7, token_id = 8))
 Token(&quot;##led&quot;, (sentence_id = 1, word_id = 7, token_id = 9))
 Token(&quot;pepper&quot;, (sentence_id = 1, word_id = 8, token_id = 10))
 Token(&quot;##s&quot;, (sentence_id = 1, word_id = 8, token_id = 11))

julia&gt; ibatch_with_TEB[2]
7-element Vector{TextEncodeBase.TokenStage}:
 Token(&quot;Fu&quot;, (sentence_id = 2, word_id = 1, token_id = 1))
 Token(&quot;##zzy&quot;, (sentence_id = 2, word_id = 1, token_id = 2))
 Token(&quot;Wu&quot;, (sentence_id = 2, word_id = 2, token_id = 3))
 Token(&quot;##zzy&quot;, (sentence_id = 2, word_id = 2, token_id = 4))
 Token(&quot;was&quot;, (sentence_id = 2, word_id = 3, token_id = 5))
 Token(&quot;a&quot;, (sentence_id = 2, word_id = 4, token_id = 6))
 Token(&quot;bear&quot;, (sentence_id = 2, word_id = 5, token_id = 7))
"><pre>julia<span class="pl-k">&gt;</span> itkr <span class="pl-k">=</span> <span class="pl-c1">NestedTokenizer</span>(TextEncodeBase<span class="pl-k">.</span><span class="pl-c1">IndexedTokenization</span>(<span class="pl-c1">BertCasedTokenization</span>(wordpiece)));

julia<span class="pl-k">&gt;</span> ibatch_with_TEB <span class="pl-k">=</span> <span class="pl-c1">itkr</span>(<span class="pl-c1">BatchSentence</span>(texts));

<span class="pl-c"><span class="pl-c">#</span> subword from same word having the same `word_id`</span>
julia<span class="pl-k">&gt;</span> ibatch_with_TEB[<span class="pl-c1">1</span>]
<span class="pl-c1">11</span><span class="pl-k">-</span>element Vector{TextEncodeBase<span class="pl-k">.</span>TokenStage}<span class="pl-k">:</span>
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>Peter<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">1</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>Piper<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">2</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">2</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>picked<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">3</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">3</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">4</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">4</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>p<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">5</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">5</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##eck<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">5</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">6</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>of<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">6</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">7</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>pick<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">7</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">8</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##led<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">7</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">9</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>pepper<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">8</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">10</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##s<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">8</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">11</span>))

julia<span class="pl-k">&gt;</span> ibatch_with_TEB[<span class="pl-c1">2</span>]
<span class="pl-c1">7</span><span class="pl-k">-</span>element Vector{TextEncodeBase<span class="pl-k">.</span>TokenStage}<span class="pl-k">:</span>
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>Fu<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">2</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">1</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##zzy<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">2</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">1</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">2</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>Wu<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">2</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">2</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">3</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>##zzy<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">2</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">2</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">4</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>was<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">2</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">3</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">5</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">2</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">4</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">6</span>))
 <span class="pl-c1">Token</span>(<span class="pl-s"><span class="pl-pds">"</span>bear<span class="pl-pds">"</span></span>, (sentence_id <span class="pl-k">=</span> <span class="pl-c1">2</span>, word_id <span class="pl-k">=</span> <span class="pl-c1">5</span>, token_id <span class="pl-k">=</span> <span class="pl-c1">7</span>))
</pre></div>
<h2 dir="auto"><a id="user-content-textencoder" class="anchor" aria-hidden="true" href="#textencoder"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>TextEncoder</h2>
<p dir="auto">The text encoder is just a combination of vocabulary and tokenizer. We also
provide some helper function like (<code>with_head_tail</code>/<code>nested2batch</code>/...) for
transform the tokenizer result into <code>lookup</code>-able format.</p>
<h3 dir="auto"><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using TextEncodeBase: nestedcall, with_head_tail, trunc_and_pad, nested2batch

# construct `Vocab` with `WordPiece`
vocab = Vocab(wordpiece.vocab, wordpiece.vocab[wordpiece.unk_idx])

# define encoder with `TextEncoder`
enc = TextEncoder(
    itkr, vocab,
    nested2batch ∘ trunc_and_pad(nothing, vocab.unk) ∘ with_head_tail(&quot;[CLS]&quot;, &quot;[SEP]&quot;) ∘ nestedcall(getvalue)
)

julia&gt; encode(enc, BatchSentence(texts))
28996x13x2 OneHotArray{28996, 3, Matrix{OneHot{0x00007144}}}:
[...]

julia&gt; decode(enc, ans)
13×2 Matrix{String}:
 &quot;[CLS]&quot;   &quot;[CLS]&quot;
 &quot;Peter&quot;   &quot;Fu&quot;
 &quot;Piper&quot;   &quot;##zzy&quot;
 &quot;picked&quot;  &quot;Wu&quot;
 &quot;a&quot;       &quot;##zzy&quot;
 &quot;p&quot;       &quot;was&quot;
 &quot;##eck&quot;   &quot;a&quot;
 &quot;of&quot;      &quot;bear&quot;
 &quot;pick&quot;    &quot;[SEP]&quot;
 &quot;##led&quot;   &quot;[UNK]&quot;
 &quot;pepper&quot;  &quot;[UNK]&quot;
 &quot;##s&quot;     &quot;[UNK]&quot;
 &quot;[SEP]&quot;   &quot;[UNK]&quot;
"><pre><span class="pl-k">using</span> TextEncodeBase<span class="pl-k">:</span> nestedcall, with_head_tail, trunc_and_pad, nested2batch

<span class="pl-c"><span class="pl-c">#</span> construct `Vocab` with `WordPiece`</span>
vocab <span class="pl-k">=</span> <span class="pl-c1">Vocab</span>(wordpiece<span class="pl-k">.</span>vocab, wordpiece<span class="pl-k">.</span>vocab[wordpiece<span class="pl-k">.</span>unk_idx])

<span class="pl-c"><span class="pl-c">#</span> define encoder with `TextEncoder`</span>
enc <span class="pl-k">=</span> <span class="pl-c1">TextEncoder</span>(
    itkr, vocab,
    nested2batch <span class="pl-k">∘</span> <span class="pl-c1">trunc_and_pad</span>(<span class="pl-c1">nothing</span>, vocab<span class="pl-k">.</span>unk) <span class="pl-k">∘</span> <span class="pl-c1">with_head_tail</span>(<span class="pl-s"><span class="pl-pds">"</span>[CLS]<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>[SEP]<span class="pl-pds">"</span></span>) <span class="pl-k">∘</span> <span class="pl-c1">nestedcall</span>(getvalue)
)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">encode</span>(enc, <span class="pl-c1">BatchSentence</span>(texts))
<span class="pl-c1">28996</span>x13x2 OneHotArray{<span class="pl-c1">28996</span>, <span class="pl-c1">3</span>, Matrix{OneHot{<span class="pl-c1">0x00007144</span>}}}<span class="pl-k">:</span>
[<span class="pl-k">...</span>]

julia<span class="pl-k">&gt;</span> <span class="pl-c1">decode</span>(enc, ans)
<span class="pl-c1">13</span><span class="pl-k">×</span><span class="pl-c1">2</span> Matrix{String}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>[CLS]<span class="pl-pds">"</span></span>   <span class="pl-s"><span class="pl-pds">"</span>[CLS]<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>Peter<span class="pl-pds">"</span></span>   <span class="pl-s"><span class="pl-pds">"</span>Fu<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>Piper<span class="pl-pds">"</span></span>   <span class="pl-s"><span class="pl-pds">"</span>##zzy<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>picked<span class="pl-pds">"</span></span>  <span class="pl-s"><span class="pl-pds">"</span>Wu<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>       <span class="pl-s"><span class="pl-pds">"</span>##zzy<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>p<span class="pl-pds">"</span></span>       <span class="pl-s"><span class="pl-pds">"</span>was<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>##eck<span class="pl-pds">"</span></span>   <span class="pl-s"><span class="pl-pds">"</span>a<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>of<span class="pl-pds">"</span></span>      <span class="pl-s"><span class="pl-pds">"</span>bear<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>pick<span class="pl-pds">"</span></span>    <span class="pl-s"><span class="pl-pds">"</span>[SEP]<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>##led<span class="pl-pds">"</span></span>   <span class="pl-s"><span class="pl-pds">"</span>[UNK]<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>pepper<span class="pl-pds">"</span></span>  <span class="pl-s"><span class="pl-pds">"</span>[UNK]<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>##s<span class="pl-pds">"</span></span>     <span class="pl-s"><span class="pl-pds">"</span>[UNK]<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>[SEP]<span class="pl-pds">"</span></span>   <span class="pl-s"><span class="pl-pds">"</span>[UNK]<span class="pl-pds">"</span></span>
</pre></div>
</article></div>