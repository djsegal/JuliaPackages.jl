<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-reinforcementlearningcore" class="anchor" aria-hidden="true" href="#reinforcementlearningcore"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ReinforcementLearningCore</h1>
<p><g-emoji class="g-emoji" alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png">⚠️</g-emoji> This package is moved into <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl">ReinforcementLearning.jl</a> (2021-05-06)</p>
<p><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningCore.jl/actions?query=workflow%3ACI"><img src="https://github.com/JuliaReinforcementLearning/ReinforcementLearningCore.jl/workflows/CI/badge.svg" alt="CI" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/JuliaReinforcementLearning/ReinforcementLearningCore.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/5426c48eda8fc7ebcc0de6fe18cf817a22fc8cfda54c670a320e003310c304af/68747470733a2f2f636f6465636f762e696f2f67682f4a756c69615265696e666f7263656d656e744c6561726e696e672f5265696e666f7263656d656e744c6561726e696e67436f72652e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="CodeCoverage" data-canonical-src="https://codecov.io/gh/JuliaReinforcementLearning/ReinforcementLearningCore.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p>This package is the core component of <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl">ReinforcementLearning.jl</a>. It provides some typical implementations of the interfaces defined in <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningBase.jl">ReinforcementLearningBase.jl</a>.</p>
<h2><a id="user-content-code-structure" class="anchor" aria-hidden="true" href="#code-structure"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Code Structure</h2>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="./src
├── core (define how policies interact with environments)
├── extensions (patch code for upstream packages are stored here)
├── policies (all policies are put here)
│   ├── agents (= policy + trajectory)
│   ├── q_based_policies
│   │   ├── explorers (select action from action-values)
│   │   └── learners (learn state-value, state-action-value, distributional value...)
│   │       └── approximators (= NN + Optimiser)
│   └── (some other common policies).jl
└── utils (Reusable functions/structures)
"><pre><code>./src
├── core (define how policies interact with environments)
├── extensions (patch code for upstream packages are stored here)
├── policies (all policies are put here)
│   ├── agents (= policy + trajectory)
│   ├── q_based_policies
│   │   ├── explorers (select action from action-values)
│   │   └── learners (learn state-value, state-action-value, distributional value...)
│   │       └── approximators (= NN + Optimiser)
│   └── (some other common policies).jl
└── utils (Reusable functions/structures)
</code></pre></div>
<p>For developers who are interested in contributing, I suggest you read the source code in the following top-down order:</p>
<ul>
<li><code>core/run.jl</code></li>
<li><code>policies/base.jl</code></li>
<li><code>policies/agents/agent.jl</code></li>
<li><code>policies/agents/trajectories/trajectory.jl</code></li>
<li><code>policies/q_based_policies/q_based_policy.jl</code></li>
<li><code>policies/q_based_policies/learners/approximators/neural_network_approximator.jl</code></li>
<li><code>policies/q_based_policies/explorers/weighted_explorer.jl</code></li>
</ul>
<p>Then play with the <code>E`JuliaRL_BasicDQN_CartPole` </code> experiment in <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningZoo.jl">ReinforcementLearningZoo.jl</a> and try to understand the runtime logic step by step. After that, you can explore other components on demand.</p>
</article></div>