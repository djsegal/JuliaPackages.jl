<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-arrayallezjl" class="anchor" aria-hidden="true" href="#arrayallezjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ArrayAllez.jl</h1>
<p><a href="https://travis-ci.com/mcabbott/ArrayAllez.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/968448b9376fea56e08d252bdf11110eaedf4efbed570e9524768ce551cdbb6c/68747470733a2f2f7472617669732d63692e636f6d2f6d636162626f74742f4172726179416c6c657a2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Travis CI" data-canonical-src="https://travis-ci.com/mcabbott/ArrayAllez.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://github.com/mcabbott/ArrayAllez.jl/actions?query=workflow%3ACI+branch%3Amaster"><img src="https://github.com/mcabbott/ArrayAllez.jl/workflows/CI/badge.svg" alt="Github CI" style="max-width:100%;"></a></p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="] add ArrayAllez
"><pre><code>] add ArrayAllez
</code></pre></div>
<h3><a id="user-content-log--exp" class="anchor" aria-hidden="true" href="#log--exp"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>log! ∘ exp!</code></h3>
<p>This began as a way to more conveniently choose between <a href="https://github.com/JuliaMath/Yeppp.jl">Yeppp!</a>
and <a href="https://github.com/JuliaMath/AppleAccelerate.jl">AppleAccelerate</a>
and <a href="https://github.com/JuliaMath/IntelVectorMath.jl">IntelVectorMath</a>,
without requiring that any by installed.
The fallback version is just a loop, with <code>@threads</code> for large enough arrays.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="x = rand(1,100);

y = exp0(x)  # precisely = exp.(x)
x ≈ log!(y)  # in-place, just a loop

using AppleAccelerate  # or using IntelVectorMath, or using Yeppp

y = exp!(x)  # with ! mutates
x = log_(y)  # with _ copies
"><pre>x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">1</span>,<span class="pl-c1">100</span>);

y <span class="pl-k">=</span> <span class="pl-c1">exp0</span>(x)  <span class="pl-c"><span class="pl-c">#</span> precisely = exp.(x)</span>
x <span class="pl-k">≈</span> <span class="pl-c1">log!</span>(y)  <span class="pl-c"><span class="pl-c">#</span> in-place, just a loop</span>

<span class="pl-k">using</span> AppleAccelerate  <span class="pl-c"><span class="pl-c">#</span> or using IntelVectorMath, or using Yeppp</span>

y <span class="pl-k">=</span> <span class="pl-c1">exp!</span>(x)  <span class="pl-c"><span class="pl-c">#</span> with ! mutates</span>
x <span class="pl-k">=</span> <span class="pl-c1">log_</span>(y)  <span class="pl-c"><span class="pl-c">#</span> with _ copies</span></pre></div>
<p>Besides <code>log!</code> and <code>exp!</code>, there is also <code>scale!</code> which understands rows/columns.
And <code>iscale!</code> which divides, and <code>inv!</code> which is an element-wise inverse.
All have non-mutating versions ending <code>_</code> instead of <code>!</code>, and simple broadcast-ed versions with <code>0</code>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="m = ones(3,7)
v = rand(3)
r = rand(7)'

scale0(m, 99)  # simply m .* 99
scale_(m, v)   # like m .* v but using rmul!
iscale!(m, r)  # like m ./ r but mutating.
m
"><pre>m <span class="pl-k">=</span> <span class="pl-c1">ones</span>(<span class="pl-c1">3</span>,<span class="pl-c1">7</span>)
v <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">3</span>)
r <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">7</span>)<span class="pl-k">'</span>

<span class="pl-c1">scale0</span>(m, <span class="pl-c1">99</span>)  <span class="pl-c"><span class="pl-c">#</span> simply m .* 99</span>
<span class="pl-c1">scale_</span>(m, v)   <span class="pl-c"><span class="pl-c">#</span> like m .* v but using rmul!</span>
<span class="pl-c1">iscale!</span>(m, r)  <span class="pl-c"><span class="pl-c">#</span> like m ./ r but mutating.</span>
m</pre></div>
<h3><a id="" class="anchor" aria-hidden="true" href="#"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>∇</code></h3>
<p>These commands all make some attempt to define gradients for use with
<a href="https://github.com/FluxML/Tracker.jl">Tracker</a> ans
<a href="https://github.com/FluxML/Zygote.jl">Zygote</a>, but caveat emptor.
There is also an <code>exp!!</code> which mutates both its forward input and its backward gradient,
which may be a terrible idea.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using Tracker
x = param(randn(5));
y = exp_(x)

Tracker.back!(sum_(exp!(x)))
x.data == y # true
x.grad
"><pre><span class="pl-k">using</span> Tracker
x <span class="pl-k">=</span> <span class="pl-c1">param</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">5</span>));
y <span class="pl-k">=</span> <span class="pl-c1">exp_</span>(x)

Tracker<span class="pl-k">.</span><span class="pl-c1">back!</span>(<span class="pl-c1">sum_</span>(<span class="pl-c1">exp!</span>(x)))
x<span class="pl-k">.</span>data <span class="pl-k">==</span> y <span class="pl-c"><span class="pl-c">#</span> true</span>
x<span class="pl-k">.</span>grad</pre></div>
<p>This package also defines gradients for <code>prod</code> (overwriting an incorrect one) and <code>cumprod</code>,
as in <a href="https://github.com/FluxML/Flux.jl/pull/524">this PR</a>.</p>
<h3><a id="user-content-array_" class="anchor" aria-hidden="true" href="#array_"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>Array_</code></h3>
<p>An experiment with <a href="https://github.com/JuliaCollections/LRUCache.jl">LRUCache</a> for working space:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="x = rand(2000)' # turns off below this size

copy_(:copy, x)
similar_(:sim, x)
Array_{Float64}(:new, 5,1000) # @btime 200 ns, 32 bytes

inv_(:inv, x) # most of the _ functions can opt-in
"><pre>x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">2000</span>)<span class="pl-k">'</span> <span class="pl-c"><span class="pl-c">#</span> turns off below this size</span>

<span class="pl-c1">copy_</span>(<span class="pl-c1">:copy</span>, x)
<span class="pl-c1">similar_</span>(<span class="pl-c1">:sim</span>, x)
<span class="pl-c1">Array_</span><span class="pl-c1">{Float64}</span>(<span class="pl-c1">:new</span>, <span class="pl-c1">5</span>,<span class="pl-c1">1000</span>) <span class="pl-c"><span class="pl-c">#</span> @btime 200 ns, 32 bytes</span>

<span class="pl-c1">inv_</span>(<span class="pl-c1">:inv</span>, x) <span class="pl-c"><span class="pl-c">#</span> most of the _ functions can opt-in</span></pre></div>
<h3><a id="user-content-dropdims" class="anchor" aria-hidden="true" href="#dropdims"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>@dropdims</code></h3>
<p>This macro wraps reductions like <code>sum(A; dims=...)</code> in <code>dropdims()</code>.
It understands things like this:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="@dropdims sum(10 .* randn(2,10); dims=2) do x
    trunc(Int, x)
end
"><pre><span class="pl-c1">@dropdims</span> <span class="pl-c1">sum</span>(<span class="pl-c1">10</span> <span class="pl-k">.*</span> <span class="pl-c1">randn</span>(<span class="pl-c1">2</span>,<span class="pl-c1">10</span>); dims<span class="pl-k">=</span><span class="pl-c1">2</span>) <span class="pl-k">do</span> x
    <span class="pl-c1">trunc</span>(Int, x)
<span class="pl-k">end</span></pre></div>
<h3><a id="user-content-removed" class="anchor" aria-hidden="true" href="#removed"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Removed</h3>
<p>This package used to provide two functions generalising matrix multiplication. They are now better handled by other packages:</p>
<ul>
<li><code>TensorCore.boxdot</code> contracts neighbours: <code>rand(2,3,5) ⊡ rand(5,7,11) |&gt; size == (2,3,7,11)</code></li>
<li><code>NNlib.batched_mul</code> keeps a batch dimension: <code>rand(2,3,10) ⊠ rand(3,5,10) |&gt; size == (2,5,10)</code></li>
</ul>
<h3><a id="user-content-see-also" class="anchor" aria-hidden="true" href="#see-also"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>See Also</h3>
<ul>
<li>
<p><a href="https://github.com/rprechelt/Vectorize.jl">Vectorize.jl</a> is a more comprehensive wrapper.</p>
</li>
<li>
<p><a href="https://github.com/Jutho/Strided.jl">Strided.jl</a> adds <code>@threads</code> to broadcasting.</p>
</li>
<li>
<p><a href="https://github.com/chriselrod/LoopVectorization.jl">LoopVectorization.jl</a> adds AVX black magic.</p>
</li>
</ul>
</article></div>