<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><div align="center" dir="auto"> 
<a href="http://incompleteideas.net/book/the-book-2nd.html" rel="nofollow">
<img src="RLIntro2Cover-min.jpg" alt="RLIntro2Cover-min.jpg" title="RLIntro" width="200" style="max-width: 100%;"> 
</a>
<p dir="auto"> "To think is to forget a difference, to generalize, to abstract."</p>
<p dir="auto">― <a href="https://en.wikipedia.org/wiki/Jorge_Luis_Borges" rel="nofollow">Jorge Luis Borges</a>, <a href="https://en.wikipedia.org/wiki/Funes_the_Memorious" rel="nofollow">Funes the Memorious</a></p>
</div>
<hr>
<p align="center" dir="auto">
    <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl">
        <img src="https://camo.githubusercontent.com/b6157145a93cab7ac2a646fa814d7f24aaa206f8f3cebc5ca4016616951bf26a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706f776572656425323062792d5265696e666f7263656d656e744c6561726e696e672e6a6c2d627269676874677265656e" data-canonical-src="https://img.shields.io/badge/powered%20by-ReinforcementLearning.jl-brightgreen" style="max-width: 100%;">
    </a>
</p>
<p dir="auto">This project provides the <a href="https://www.julialang.org/" rel="nofollow">Julia</a> code to generate figures in the book
<a href="http://incompleteideas.net/book/the-book-2nd.html" rel="nofollow">Reinforcement Learning: An
Introduction(2nd)</a>. One of
our main goals is to help users understand the basic concepts of reinforcement
learning from an engineer's perspective. Once you have grasped how different
components are organized, you're ready to explore a wide variety of modern deep
reinforcement learning algorithms in <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/tree/master/src/ReinforcementLearningZoo">ReinforcementLearningZoo.jl</a>.</p>
<h2 dir="auto"><a id="user-content-how-to-use" class="anchor" aria-hidden="true" href="#how-to-use"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How to use?</h2>
<p dir="auto">If you are new to Julia or reinforcement learning, you can preview the
<a href="https://juliareinforcementlearning.org/ReinforcementLearningAnIntroduction.jl/" rel="nofollow">notebooks</a> first. (Credit goes to <a href="https://github.com/kir0ul">Andrea PIERRÉ</a>)</p>
<p dir="auto">For experienced users with the latest stable Julia properly installed:</p>
<ol dir="auto">
<li>Clone this project.</li>
<li>Start the Julia REPL inside the project folder.</li>
<li>Activate and instantiate the environment
<ol dir="auto">
<li><code>import Pkg</code></li>
<li><code>Pkg.activate(".")</code></li>
<li><code>Pkg.instantiate()</code></li>
</ol>
</li>
<li>Start <a href="https://github.com/fonsp/Pluto.jl">Pluto.jl</a>
<ol dir="auto">
<li><code>import Pluto</code></li>
<li><code>Pluto.run()</code></li>
</ol>
</li>
<li>Now you can see the Pluto page is opened in your browser. Paste
<code>notebooks/Chapter01_Tic_Tac_Toe.jl</code> (or any other file under the <code>notebooks</code> folder) into
the input box and click the <code>Open</code> button.</li>
</ol>
<h2 dir="auto"><a id="user-content-useful-links" class="anchor" aria-hidden="true" href="#useful-links"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Useful Links</h2>
<ul dir="auto">
<li><a href="https://github.com/LyWangPX/Reinforcement-Learning-2nd-Edition-by-Sutton-Exercise-Solutions">Solutions of the book exercises : Reinforcement Learning 2nd Edition</a></li>
</ul>
</article></div>