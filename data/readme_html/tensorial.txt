<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-tensorial" class="anchor" aria-hidden="true" href="#tensorial"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Tensorial</h1>
<p dir="auto"><em>Statically sized tensors and related operations for Julia</em></p>
<p dir="auto"><a href="https://KeitaNakamura.github.io/Tensorial.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/KeitaNakamura/Tensorial.jl/actions?query=workflow%3ACI"><img src="https://github.com/KeitaNakamura/Tensorial.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/KeitaNakamura/Tensorial.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/061f06f9d3d61dcc2d018dc379bf8fdcf9f4fb14e893f7ec9d4b9e28880fec66/68747470733a2f2f636f6465636f762e696f2f67682f4b656974614e616b616d7572612f54656e736f7269616c2e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d56353844584449315235" alt="codecov" data-canonical-src="https://codecov.io/gh/KeitaNakamura/Tensorial.jl/branch/main/graph/badge.svg?token=V58DXDI1R5" style="max-width: 100%;"></a></p>
<p dir="auto">Tensorial provides useful tensor operations (e.g., contraction; tensor product, <code>⊗</code>; <code>inv</code>; etc.) written in the <a href="https://julialang.org" rel="nofollow">Julia programming language</a>.
The library supports arbitrary size of non-symmetric and symmetric tensors, where symmetries should be specified to avoid wasteful duplicate computations.
The way to give a size of the tensor is similar to <a href="https://github.com/JuliaArrays/StaticArrays.jl">StaticArrays.jl</a>, and symmetries of tensors can be specified by using <code>@Symmetry</code>.
For example, symmetric fourth-order tensor (symmetrizing tensor) is represented in this library as <code>Tensor{Tuple{@Symmetry{3,3}, @Symmetry{3,3}}}</code>.
Einstein summation macro and automatic differentiation functions are also provided.</p>
<h2 dir="auto"><a id="user-content-speed" class="anchor" aria-hidden="true" href="#speed"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Speed</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="a = rand(Vec{3})                         # vector of length 3
A = rand(SecondOrderTensor{3})           # 3x3 second order tensor
S = rand(SymmetricSecondOrderTensor{3})  # 3x3 symmetric second order tensor
B = rand(Tensor{Tuple{3,3,3}})           # 3x3x3 third order tensor
AA = rand(FourthOrderTensor{3})          # 3x3x3x3 fourth order tensor
SS = rand(SymmetricFourthOrderTensor{3}) # 3x3x3x3 symmetric fourth order tensor (symmetrizing tensor)"><pre>a <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Vec{<span class="pl-c1">3</span>})                         <span class="pl-c"><span class="pl-c">#</span> vector of length 3</span>
A <span class="pl-k">=</span> <span class="pl-c1">rand</span>(SecondOrderTensor{<span class="pl-c1">3</span>})           <span class="pl-c"><span class="pl-c">#</span> 3x3 second order tensor</span>
S <span class="pl-k">=</span> <span class="pl-c1">rand</span>(SymmetricSecondOrderTensor{<span class="pl-c1">3</span>})  <span class="pl-c"><span class="pl-c">#</span> 3x3 symmetric second order tensor</span>
B <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Tensor{Tuple{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>,<span class="pl-c1">3</span>}})           <span class="pl-c"><span class="pl-c">#</span> 3x3x3 third order tensor</span>
AA <span class="pl-k">=</span> <span class="pl-c1">rand</span>(FourthOrderTensor{<span class="pl-c1">3</span>})          <span class="pl-c"><span class="pl-c">#</span> 3x3x3x3 fourth order tensor</span>
SS <span class="pl-k">=</span> <span class="pl-c1">rand</span>(SymmetricFourthOrderTensor{<span class="pl-c1">3</span>}) <span class="pl-c"><span class="pl-c">#</span> 3x3x3x3 symmetric fourth order tensor (symmetrizing tensor)</span></pre></div>
<p dir="auto">See <a href="https://keitanakamura.github.io/Tensorial.jl/stable/Cheat%20Sheet/#Aliases" rel="nofollow">here</a> for above aliases.</p>
<table>
<thead>
<tr>
<th align="left">Operation</th>
<th align="right"><code>Tensor</code></th>
<th align="right"><code>Array</code></th>
<th align="right">speed-up</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>Single contraction</strong></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr>
<td align="left"><code>a ⋅ a</code></td>
<td align="right">1.537 ns</td>
<td align="right">16.943 ns</td>
<td align="right">×11.0</td>
</tr>
<tr>
<td align="left"><code>A ⋅ a</code></td>
<td align="right">1.538 ns</td>
<td align="right">80.647 ns</td>
<td align="right">×52.4</td>
</tr>
<tr>
<td align="left"><code>S ⋅ a</code></td>
<td align="right">1.545 ns</td>
<td align="right">79.630 ns</td>
<td align="right">×51.5</td>
</tr>
<tr>
<td align="left"><strong>Double contraction</strong></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr>
<td align="left"><code>A ⊡ A</code></td>
<td align="right">2.730 ns</td>
<td align="right">17.909 ns</td>
<td align="right">×6.6</td>
</tr>
<tr>
<td align="left"><code>S ⊡ S</code></td>
<td align="right">1.704 ns</td>
<td align="right">19.099 ns</td>
<td align="right">×11.2</td>
</tr>
<tr>
<td align="left"><code>B ⊡ A</code></td>
<td align="right">4.886 ns</td>
<td align="right">183.789 ns</td>
<td align="right">×37.6</td>
</tr>
<tr>
<td align="left"><code>AA ⊡ A</code></td>
<td align="right">7.035 ns</td>
<td align="right">193.607 ns</td>
<td align="right">×27.5</td>
</tr>
<tr>
<td align="left"><code>SS ⊡ S</code></td>
<td align="right">3.589 ns</td>
<td align="right">192.727 ns</td>
<td align="right">×53.7</td>
</tr>
<tr>
<td align="left"><strong>Tensor product</strong></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr>
<td align="left"><code>a ⊗ a</code></td>
<td align="right">2.035 ns</td>
<td align="right">53.872 ns</td>
<td align="right">×26.5</td>
</tr>
<tr>
<td align="left"><strong>Cross product</strong></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr>
<td align="left"><code>a × a</code></td>
<td align="right">2.035 ns</td>
<td align="right">53.872 ns</td>
<td align="right">×26.5</td>
</tr>
<tr>
<td align="left"><strong>Determinant</strong></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr>
<td align="left"><code>det(A)</code></td>
<td align="right">1.541 ns</td>
<td align="right">223.537 ns</td>
<td align="right">×145.1</td>
</tr>
<tr>
<td align="left"><code>det(S)</code></td>
<td align="right">1.542 ns</td>
<td align="right">227.196 ns</td>
<td align="right">×147.3</td>
</tr>
<tr>
<td align="left"><strong>Inverse</strong></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr>
<td align="left"><code>inv(A)</code></td>
<td align="right">5.432 ns</td>
<td align="right">544.122 ns</td>
<td align="right">×100.2</td>
</tr>
<tr>
<td align="left"><code>inv(S)</code></td>
<td align="right">3.872 ns</td>
<td align="right">552.627 ns</td>
<td align="right">×142.7</td>
</tr>
<tr>
<td align="left"><code>inv(AA)</code></td>
<td align="right">854.691 ns</td>
<td align="right">1.727 μs</td>
<td align="right">×2.0</td>
</tr>
<tr>
<td align="left"><code>inv(SS)</code></td>
<td align="right">310.218 ns</td>
<td align="right">1.728 μs</td>
<td align="right">×5.6</td>
</tr>
</tbody>
</table>
<p dir="auto">The benchmarks are generated by
<a href="https://github.com/KeitaNakamura/Tensorial.jl/blob/master/benchmark/runbenchmarks.jl"><code>runbenchmarks.jl</code></a>
on the following system:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; versioninfo()
Julia Version 1.6.3
Commit ae8452a9e0 (2021-09-23 17:34 UTC)
Platform Info:
  OS: macOS (x86_64-apple-darwin19.5.0)
  CPU: Intel(R) Core(TM) i7-7567U CPU @ 3.50GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">versioninfo</span>()
Julia Version <span class="pl-c1">1.6</span>.<span class="pl-c1">3</span>
Commit ae8452a9e0 (<span class="pl-c1">2021</span><span class="pl-k">-</span><span class="pl-c1">09</span><span class="pl-k">-</span><span class="pl-c1">23</span> <span class="pl-c1">17</span><span class="pl-k">:</span><span class="pl-c1">34</span> UTC)
Platform Info<span class="pl-k">:</span>
  OS<span class="pl-k">:</span> macOS (x86_64<span class="pl-k">-</span>apple<span class="pl-k">-</span>darwin19.<span class="pl-c1">5.0</span>)
  CPU<span class="pl-k">:</span> <span class="pl-c1">Intel</span>(R) <span class="pl-c1">Core</span>(TM) i7<span class="pl-k">-</span><span class="pl-c1">7567</span>U CPU @ <span class="pl-c1">3.50</span>GHz
  WORD_SIZE<span class="pl-k">:</span> <span class="pl-c1">64</span>
  LIBM<span class="pl-k">:</span> libopenlibm
  LLVM<span class="pl-k">:</span> libLLVM<span class="pl-k">-</span><span class="pl-c1">11.0</span>.<span class="pl-c1">1</span> (ORCJIT, skylake)
</pre></div>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="pkg&gt; add Tensorial"><pre>pkg<span class="pl-k">&gt;</span> add Tensorial</pre></div>
<h2 dir="auto"><a id="user-content-cheat-sheet" class="anchor" aria-hidden="true" href="#cheat-sheet"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Cheat Sheet</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# identity tensors
one(Tensor{Tuple{3,3}})            == Matrix(1I,3,3) # second-order identity tensor
one(Tensor{Tuple{@Symmetry{3,3}}}) == Matrix(1I,3,3) # symmetric second-order identity tensor
I  = one(Tensor{NTuple{4,3}})               # fourth-order identity tensor
Is = one(Tensor{NTuple{2, @Symmetry{3,3}}}) # symmetric fourth-order identity tensor

# zero tensors
zero(Tensor{Tuple{2,3}}) == zeros(2, 3)
zero(Tensor{Tuple{@Symmetry{3,3}}}) == zeros(3, 3)

# random tensors
rand(Tensor{Tuple{2,3}})
randn(Tensor{Tuple{2,3}})

# macros (same interface as StaticArrays.jl)
@Vec [1,2,3]
@Vec rand(4)
@Mat [1 2
      3 4]
@Mat rand(4,4)
@Tensor rand(2,2,2)

# statically sized getindex by `@Tensor`
x = @Mat [1 2
          3 4
          5 6]
@Tensor(x[2:3, :])   == @Mat [3 4
                              5 6]
@Tensor(x[[1,3], :]) == @Mat [1 2
                              5 6]

# contraction and tensor product
x = rand(Mat{2,2})
y = rand(Tensor{Tuple{@Symmetry{2,2}}})
x ⊗ y isa Tensor{Tuple{2,2,@Symmetry{2,2}}} # tensor product
x ⋅ y isa Tensor{Tuple{2,2}}                # single contraction (x_ij * y_jk)
x ⊡ y isa Real                              # double contraction (x_ij * y_ij)

# det/inv for 2nd-order tensor
A = rand(SecondOrderTensor{3})          # equal to one(Tensor{Tuple{3,3}})
S = rand(SymmetricSecondOrderTensor{3}) # equal to one(Tensor{Tuple{@Symmetry{3,3}}})
det(A); det(S)
inv(A) ⋅ A ≈ one(A)
inv(S) ⋅ S ≈ one(S)

# inv for 4th-order tensor
AA = rand(FourthOrderTensor{3})          # equal to one(Tensor{Tuple{3,3,3,3}})
SS = rand(SymmetricFourthOrderTensor{3}) # equal to one(Tensor{Tuple{@Symmetry{3,3}, @Symmetry{3,3}}})
inv(AA) ⊡ AA ≈ one(AA)
inv(SS) ⊡ SS ≈ one(SS)

# Einstein summation convention
A = rand(Mat{3,3})
B = rand(Mat{3,3})
@einsum (i,j) -&gt; A[i,k] * B[k,j]
@einsum A[i,j] * B[i,j]

# Automatic differentiation
gradient(tr, rand(Mat{3,3})) == one(Mat{3,3}) # Tensor -&gt; Real
gradient(identity, rand(SymmetricSecondOrderTensor{3})) == one(SymmetricFourthOrderTensor{3}) # Tensor -&gt; Tensor"><pre><span class="pl-c"><span class="pl-c">#</span> identity tensors</span>
<span class="pl-c1">one</span>(Tensor{Tuple{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>}})            <span class="pl-k">==</span> <span class="pl-c1">Matrix</span>(<span class="pl-c1">1</span>I,<span class="pl-c1">3</span>,<span class="pl-c1">3</span>) <span class="pl-c"><span class="pl-c">#</span> second-order identity tensor</span>
<span class="pl-c1">one</span>(Tensor{Tuple{<span class="pl-c1">@Symmetry</span>{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>}}}) <span class="pl-k">==</span> <span class="pl-c1">Matrix</span>(<span class="pl-c1">1</span>I,<span class="pl-c1">3</span>,<span class="pl-c1">3</span>) <span class="pl-c"><span class="pl-c">#</span> symmetric second-order identity tensor</span>
I  <span class="pl-k">=</span> <span class="pl-c1">one</span>(Tensor{NTuple{<span class="pl-c1">4</span>,<span class="pl-c1">3</span>}})               <span class="pl-c"><span class="pl-c">#</span> fourth-order identity tensor</span>
Is <span class="pl-k">=</span> <span class="pl-c1">one</span>(Tensor{NTuple{<span class="pl-c1">2</span>, <span class="pl-c1">@Symmetry</span>{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>}}}) <span class="pl-c"><span class="pl-c">#</span> symmetric fourth-order identity tensor</span>

<span class="pl-c"><span class="pl-c">#</span> zero tensors</span>
<span class="pl-c1">zero</span>(Tensor{Tuple{<span class="pl-c1">2</span>,<span class="pl-c1">3</span>}}) <span class="pl-k">==</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>)
<span class="pl-c1">zero</span>(Tensor{Tuple{<span class="pl-c1">@Symmetry</span>{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>}}}) <span class="pl-k">==</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">3</span>, <span class="pl-c1">3</span>)

<span class="pl-c"><span class="pl-c">#</span> random tensors</span>
<span class="pl-c1">rand</span>(Tensor{Tuple{<span class="pl-c1">2</span>,<span class="pl-c1">3</span>}})
<span class="pl-c1">randn</span>(Tensor{Tuple{<span class="pl-c1">2</span>,<span class="pl-c1">3</span>}})

<span class="pl-c"><span class="pl-c">#</span> macros (same interface as StaticArrays.jl)</span>
<span class="pl-c1">@Vec</span> [<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>]
<span class="pl-c1">@Vec</span> <span class="pl-c1">rand</span>(<span class="pl-c1">4</span>)
<span class="pl-c1">@Mat</span> [<span class="pl-c1">1</span> <span class="pl-c1">2</span>
      <span class="pl-c1">3</span> <span class="pl-c1">4</span>]
<span class="pl-c1">@Mat</span> <span class="pl-c1">rand</span>(<span class="pl-c1">4</span>,<span class="pl-c1">4</span>)
<span class="pl-c1">@Tensor</span> <span class="pl-c1">rand</span>(<span class="pl-c1">2</span>,<span class="pl-c1">2</span>,<span class="pl-c1">2</span>)

<span class="pl-c"><span class="pl-c">#</span> statically sized getindex by `@Tensor`</span>
x <span class="pl-k">=</span> <span class="pl-c1">@Mat</span> [<span class="pl-c1">1</span> <span class="pl-c1">2</span>
          <span class="pl-c1">3</span> <span class="pl-c1">4</span>
          <span class="pl-c1">5</span> <span class="pl-c1">6</span>]
<span class="pl-c1">@Tensor</span>(x[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">3</span>, :])   <span class="pl-k">==</span> <span class="pl-c1">@Mat</span> [<span class="pl-c1">3</span> <span class="pl-c1">4</span>
                              <span class="pl-c1">5</span> <span class="pl-c1">6</span>]
<span class="pl-c1">@Tensor</span>(x[[<span class="pl-c1">1</span>,<span class="pl-c1">3</span>], :]) <span class="pl-k">==</span> <span class="pl-c1">@Mat</span> [<span class="pl-c1">1</span> <span class="pl-c1">2</span>
                              <span class="pl-c1">5</span> <span class="pl-c1">6</span>]

<span class="pl-c"><span class="pl-c">#</span> contraction and tensor product</span>
x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Mat{<span class="pl-c1">2</span>,<span class="pl-c1">2</span>})
y <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Tensor{Tuple{<span class="pl-c1">@Symmetry</span>{<span class="pl-c1">2</span>,<span class="pl-c1">2</span>}}})
x ⊗ y <span class="pl-k">isa</span> Tensor{Tuple{<span class="pl-c1">2</span>,<span class="pl-c1">2</span>,<span class="pl-c1">@Symmetry</span>{<span class="pl-c1">2</span>,<span class="pl-c1">2</span>}}} <span class="pl-c"><span class="pl-c">#</span> tensor product</span>
x <span class="pl-k">⋅</span> y <span class="pl-k">isa</span> Tensor{Tuple{<span class="pl-c1">2</span>,<span class="pl-c1">2</span>}}                <span class="pl-c"><span class="pl-c">#</span> single contraction (x_ij * y_jk)</span>
x ⊡ y <span class="pl-k">isa</span> Real                              <span class="pl-c"><span class="pl-c">#</span> double contraction (x_ij * y_ij)</span>

<span class="pl-c"><span class="pl-c">#</span> det/inv for 2nd-order tensor</span>
A <span class="pl-k">=</span> <span class="pl-c1">rand</span>(SecondOrderTensor{<span class="pl-c1">3</span>})          <span class="pl-c"><span class="pl-c">#</span> equal to one(Tensor{Tuple{3,3}})</span>
S <span class="pl-k">=</span> <span class="pl-c1">rand</span>(SymmetricSecondOrderTensor{<span class="pl-c1">3</span>}) <span class="pl-c"><span class="pl-c">#</span> equal to one(Tensor{Tuple{@Symmetry{3,3}}})</span>
<span class="pl-c1">det</span>(A); <span class="pl-c1">det</span>(S)
<span class="pl-c1">inv</span>(A) <span class="pl-k">⋅</span> A <span class="pl-k">≈</span> <span class="pl-c1">one</span>(A)
<span class="pl-c1">inv</span>(S) <span class="pl-k">⋅</span> S <span class="pl-k">≈</span> <span class="pl-c1">one</span>(S)

<span class="pl-c"><span class="pl-c">#</span> inv for 4th-order tensor</span>
AA <span class="pl-k">=</span> <span class="pl-c1">rand</span>(FourthOrderTensor{<span class="pl-c1">3</span>})          <span class="pl-c"><span class="pl-c">#</span> equal to one(Tensor{Tuple{3,3,3,3}})</span>
SS <span class="pl-k">=</span> <span class="pl-c1">rand</span>(SymmetricFourthOrderTensor{<span class="pl-c1">3</span>}) <span class="pl-c"><span class="pl-c">#</span> equal to one(Tensor{Tuple{@Symmetry{3,3}, @Symmetry{3,3}}})</span>
<span class="pl-c1">inv</span>(AA) ⊡ AA <span class="pl-k">≈</span> <span class="pl-c1">one</span>(AA)
<span class="pl-c1">inv</span>(SS) ⊡ SS <span class="pl-k">≈</span> <span class="pl-c1">one</span>(SS)

<span class="pl-c"><span class="pl-c">#</span> Einstein summation convention</span>
A <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Mat{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>})
B <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Mat{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>})
<span class="pl-c1">@einsum</span> (i,j) <span class="pl-k">-&gt;</span> A[i,k] <span class="pl-k">*</span> B[k,j]
<span class="pl-c1">@einsum</span> A[i,j] <span class="pl-k">*</span> B[i,j]

<span class="pl-c"><span class="pl-c">#</span> Automatic differentiation</span>
<span class="pl-c1">gradient</span>(tr, <span class="pl-c1">rand</span>(Mat{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>})) <span class="pl-k">==</span> <span class="pl-c1">one</span>(Mat{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>}) <span class="pl-c"><span class="pl-c">#</span> Tensor -&gt; Real</span>
<span class="pl-c1">gradient</span>(identity, <span class="pl-c1">rand</span>(SymmetricSecondOrderTensor{<span class="pl-c1">3</span>})) <span class="pl-k">==</span> <span class="pl-c1">one</span>(SymmetricFourthOrderTensor{<span class="pl-c1">3</span>}) <span class="pl-c"><span class="pl-c">#</span> Tensor -&gt; Tensor</span></pre></div>
<h2 dir="auto"><a id="user-content-other-tensor-packages" class="anchor" aria-hidden="true" href="#other-tensor-packages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Other tensor packages</h2>
<ul dir="auto">
<li><a href="https://github.com/ahwillia/Einsum.jl">Einsum.jl</a></li>
<li><a href="https://github.com/Jutho/TensorOperations.jl">TensorOprations.jl</a></li>
<li><a href="https://github.com/KristofferC/Tensors.jl">Tensors.jl</a></li>
</ul>
<h2 dir="auto"><a id="user-content-inspiration" class="anchor" aria-hidden="true" href="#inspiration"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Inspiration</h2>
<ul dir="auto">
<li><a href="https://github.com/JuliaArrays/StaticArrays.jl">StaticArrays.jl</a></li>
<li><a href="https://github.com/KristofferC/Tensors.jl">Tensors.jl</a></li>
</ul>
</article></div>