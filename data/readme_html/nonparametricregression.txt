<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-nonparametricregressionjl" class="anchor" aria-hidden="true" href="#nonparametricregressionjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>NonparametricRegression.jl</h1>

<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/0058ce9713cb93a553c2f23207afbb49b1b852a70a4a24de20e2e816c58b299e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6966656379636c652d6578706572696d656e74616c2d6f72616e67652e737667"><img src="https://camo.githubusercontent.com/0058ce9713cb93a553c2f23207afbb49b1b852a70a4a24de20e2e816c58b299e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6966656379636c652d6578706572696d656e74616c2d6f72616e67652e737667" alt="lifecycle" data-canonical-src="https://img.shields.io/badge/lifecycle-experimental-orange.svg" style="max-width: 100%;"></a>
<a href="https://github.com/tbeason/NonparametricRegression.jl/actions?query=workflow%3ACI"><img src="https://github.com/tbeason/NonparametricRegression.jl/workflows/CI/badge.svg" alt="build" style="max-width: 100%;"></a>
<a href="http://codecov.io/github/tbeason/NonparametricRegression.jl?branch=main" rel="nofollow"><img src="https://camo.githubusercontent.com/18677d5d8dc8743498c9d64538de73fdd9de8c1cfa0f9e951b4f5266f0f21222/687474703a2f2f636f6465636f762e696f2f6769746875622f74626561736f6e2f4e6f6e706172616d657472696352656772657373696f6e2e6a6c2f636f7665726167652e7376673f6272616e63683d6d61696e" alt="codecov.io" data-canonical-src="http://codecov.io/github/tbeason/NonparametricRegression.jl/coverage.svg?branch=main" style="max-width: 100%;"></a></p>


<p dir="auto">This package implements non-parametric regression, also called local regression or kernel regression. Currently the functionality is limited to univariate regressions and to only the local constant (<code>localconstant</code>) and local linear (<code>locallinear</code>,<code>llalphabeta</code>) estimators. Automatic bandwidth selection is done by leave-one-out cross validation or by optimizing the bias-corrected AICc statistic.</p>
<p dir="auto">The two important exported convenience methods are <code>npregress</code> and <code>optimalbandwidth</code> which abstract from a lot of the implementation detail and allow you to easily switch estimators or bandwidth selection procedures.</p>
<h2 dir="auto"><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using NonparametricRegression

npregress
"><pre><span class="pl-k">using</span> NonparametricRegression

npregress
</pre></div>
<h2 dir="auto"><a id="user-content-detail" class="anchor" aria-hidden="true" href="#detail"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Detail</h2>
<ul dir="auto">
<li>Scaled Gaussian kernel (<code>GaussianKernel</code>) by default (aliased by <code>NormalKernel(h)</code> where <code>h</code> is the bandwidth). Other available kernels are <code>UniformKernel</code> and <code>EpanechnikovKernel</code>. Adding a new kernel would be a relatively easy PR, see <code>src/kernels.jl</code>.</li>
<li>For local linear estimation, two functions are provided. The first is <code>locallinear</code> which explicitly computes a weighted average of <code>y</code> as in <code>localconstant</code>. The second is <code>llalphabeta</code> which computes (and returns) the intercept and slope terms of the local linear regression, the intercept of which is the expected <code>y</code>. <code>llalphabeta</code> requires only one pass over the data, so is more performant than <code>locallinear</code> because computing the weights requires 2 passes, but the results are identical modulo any small numerical epsilons.</li>
<li>Care was taken to make things non-allocating and performant. The package does not use the "binning" technique that other packages use (R's KernSmooth, for example), so on very large datasets there could be a performance loss relative to those packages. The package does not use multithreading, so again some performance gain could be had here if needed. PRs welcome.</li>
</ul>
<h2 dir="auto"><a id="user-content-related" class="anchor" aria-hidden="true" href="#related"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Related</h2>
<p dir="auto">KernelDensity.jl is a nice package for doing kernel density estimation.</p>
<p dir="auto">KernelEstimators.jl is an outdated package which I found after already implementing most of this package. Consider this an updated version I guess.</p>
<p dir="auto">LOESS.jl is a package implementing a similar but different type of local regression (loess, obviously).</p>
</article></div>