<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-boltzmannjl" class="anchor" aria-hidden="true" href="#boltzmannjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Boltzmann.jl</h1>
<p><a href="https://travis-ci.org/dfdx/Boltzmann.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/2471972c9a2f9a7de11714a211b5bb5fbc870d4cdb081bde25e3ef92be7d0180/68747470733a2f2f7472617669732d63692e6f72672f646664782f426f6c747a6d616e6e2e6a6c2e737667" alt="Build Status" data-canonical-src="https://travis-ci.org/dfdx/Boltzmann.jl.svg" style="max-width:100%;"></a>
<a href="http://codecov.io/github/dfdx/Boltzmann.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/ca9f47b260f6d70a35e301a5105579523cf61f4a17ee16790c1b98561f6e55ad/687474703a2f2f636f6465636f762e696f2f6769746875622f646664782f426f6c747a6d616e6e2e6a6c2f636f7665726167652e737667" alt="codecov.io" data-canonical-src="http://codecov.io/github/dfdx/Boltzmann.jl/coverage.svg" style="max-width:100%;"></a></p>
<p>Restricted Boltzmann machines and deep belief networks in Julia</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Pkg.add(&quot;Boltzmann&quot;)
"><pre><code>Pkg.add("Boltzmann")
</code></pre></div>
<p>installing latest development version:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Pkg.clone(&quot;https://github.com/dfdx/Boltzmann.jl&quot;)
"><pre><code>Pkg.clone("https://github.com/dfdx/Boltzmann.jl")
</code></pre></div>
<h2><a id="user-content-rbm-basic-usage" class="anchor" aria-hidden="true" href="#rbm-basic-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>RBM Basic Usage</h2>
<p>Train RBM:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="using Boltzmann

X = randn(100, 2000)    # 2000 observations (examples) 
                        #  with 100 variables (features) each
X = (X + abs(minimum(X))) / (maximum(X) - minimum(X)) # scale X to [0..1]
rbm = GRBM(100, 50)     # define Gaussian RBM with 100 visible (input) 
                        #  and 50 hidden (output) variables
fit(rbm, X)             # fit model to data 
"><pre><code>using Boltzmann

X = randn(100, 2000)    # 2000 observations (examples) 
                        #  with 100 variables (features) each
X = (X + abs(minimum(X))) / (maximum(X) - minimum(X)) # scale X to [0..1]
rbm = GRBM(100, 50)     # define Gaussian RBM with 100 visible (input) 
                        #  and 50 hidden (output) variables
fit(rbm, X)             # fit model to data 
</code></pre></div>
<p>(for more meaningful dataset see <a href="https://github.com/dfdx/Boltzmann.jl/blob/master/examples/mnistexample.jl">MNIST Example</a>)</p>
<p>After model is fitted, you can <strong>extract learned coefficients</strong> (a.k.a. weights):</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="W = coef(rbm)
"><pre><code>W = coef(rbm)
</code></pre></div>
<p><strong>transform</strong> data vectors into new higher-level representation (e.g. for further classification):</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Xt = transform(rbm, X)  # vectors of X have length 100, vectors of Xt - length 50
"><pre><code>Xt = transform(rbm, X)  # vectors of X have length 100, vectors of Xt - length 50
</code></pre></div>
<p>or <strong>generate</strong> vectors similar to given ones (e.g. for recommendation, see example <a href="https://github.com/dfdx/lastfm-rbm">here</a>)</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="x = ... 
x_new = generate(rbm, x)
"><pre><code>x = ... 
x_new = generate(rbm, x)
</code></pre></div>
<p>RBMs can handle both - dense and sparse arrays. It cannot, however, handle DataArrays because it's up to application how to treat missing values.</p>
<h2><a id="user-content-rbm-kinds" class="anchor" aria-hidden="true" href="#rbm-kinds"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>RBM Kinds</h2>
<p>This package provides implementation of the 2 most popular kinds of restricted Boltzmann machines:</p>
<ul>
<li><code>BernoulliRBM</code>: RBM with binary visible and hidden units</li>
<li><code>GRBM</code>: RBM with Gaussian visible and binary hidden units</li>
</ul>
<p>Bernoulli RBM is classic one and works great for modeling binary (e.g. like/dislike) and nearly binary (e.g. logistic-based) data. Gaussian RBM works better when visible variables approximately follow normal distribution, which is often the case e.g. for image data.</p>
<h2><a id="user-content-deep-belief-networks" class="anchor" aria-hidden="true" href="#deep-belief-networks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Deep Belief Networks</h2>
<p>DBNs are created as a stack of named RBMs. Below is an example of training DBN for MNIST dataset:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="using Boltzmann
using MNIST

X, y = traindata()
X = X[:, 1:1000]                     # take only 1000 observations for speed
X = X / (maximum(X) - (minimum(X)))  # normalize to [0..1]

layers = [(&quot;vis&quot;, GRBM(784, 256)),
          (&quot;hid1&quot;, BernoulliRBM(256, 100)),
          (&quot;hid2&quot;, BernoulliRBM(100, 100))]
dbn = DBN(layers)
fit(dbn, X)
transform(dbn, X)
"><pre><code>using Boltzmann
using MNIST

X, y = traindata()
X = X[:, 1:1000]                     # take only 1000 observations for speed
X = X / (maximum(X) - (minimum(X)))  # normalize to [0..1]

layers = [("vis", GRBM(784, 256)),
          ("hid1", BernoulliRBM(256, 100)),
          ("hid2", BernoulliRBM(100, 100))]
dbn = DBN(layers)
fit(dbn, X)
transform(dbn, X)
</code></pre></div>
<h2><a id="user-content-deep-autoencoders" class="anchor" aria-hidden="true" href="#deep-autoencoders"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Deep Autoencoders</h2>
<p>Once built, DBN can be converted into a deep autoencoder. Continuing previous example:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="dae = unroll(dbn)
"><pre><code>dae = unroll(dbn)
</code></pre></div>
<p>DAEs cannot be trained directly, but can be used to transform input data:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="transform(dae, X)
"><pre><code>transform(dae, X)
</code></pre></div>
<p>In this case output will have the same dimensionality as input, but with a noise removed.</p>
<h2><a id="user-content-integration-with-mocha" class="anchor" aria-hidden="true" href="#integration-with-mocha"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Integration with Mocha</h2>
<p><a href="https://github.com/pluskid/Mocha.jl">Mocha.jl</a> is an excellent deep learning framework implementing auto-encoders and a number of fine-tuning algorithms. Boltzmann.jl allows to save pretrained model in a Mocha-compatible file format to be used later on for supervised learning. Below is a snippet of the essential API, while complete code is available in <a href="https://github.com/dfdx/Boltzmann.jl/blob/master/examples/mocha_export_example.jl">Mocha Export Example</a>:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="# pretraining and exporting in Boltzmann.jl
dbn_layers = [(&quot;vis&quot;, GRBM(100, 50)),
              (&quot;hid1&quot;, BernoulliRBM(50, 25)),
              (&quot;hid2&quot;, BernoulliRBM(25, 20))]
dbn = DBN(dbn_layers)
fit(dbn, X)
save_params(DBN_PATH, dbn)

# loading in Mocha.jl
backend = CPUBackend()
data = MemoryDataLayer(tops=[:data, :label], batch_size=500, data=Array[X, y])
vis = InnerProductLayer(name=&quot;vis&quot;, output_dim=50, tops=[:vis], bottoms=[:data])
hid1 = InnerProductLayer(name=&quot;hid1&quot;, output_dim=25, tops=[:hid1], bottoms=[:vis])
hid2 = InnerProductLayer(name=&quot;hid2&quot;, output_dim=20, tops=[:hid2], bottoms=[:hid1])
loss = SoftmaxLossLayer(name=&quot;loss&quot;,bottoms=[:hid2, :label])
net = Net(&quot;TEST&quot;, backend, [data, vis, hid1, hid2])

h5open(DBN_PATH) do h5
    load_network(h5, net)
end
"><pre><code># pretraining and exporting in Boltzmann.jl
dbn_layers = [("vis", GRBM(100, 50)),
              ("hid1", BernoulliRBM(50, 25)),
              ("hid2", BernoulliRBM(25, 20))]
dbn = DBN(dbn_layers)
fit(dbn, X)
save_params(DBN_PATH, dbn)

# loading in Mocha.jl
backend = CPUBackend()
data = MemoryDataLayer(tops=[:data, :label], batch_size=500, data=Array[X, y])
vis = InnerProductLayer(name="vis", output_dim=50, tops=[:vis], bottoms=[:data])
hid1 = InnerProductLayer(name="hid1", output_dim=25, tops=[:hid1], bottoms=[:vis])
hid2 = InnerProductLayer(name="hid2", output_dim=20, tops=[:hid2], bottoms=[:hid1])
loss = SoftmaxLossLayer(name="loss",bottoms=[:hid2, :label])
net = Net("TEST", backend, [data, vis, hid1, hid2])

h5open(DBN_PATH) do h5
    load_network(h5, net)
end
</code></pre></div>
</article></div>