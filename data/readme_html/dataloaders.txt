<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-dataloaders" class="anchor" aria-hidden="true" href="#dataloaders"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DataLoaders</h1>
<p><a href="https://lorenzoh.github.io/DataLoaders.jl/dev" rel="nofollow">Documentation (latest)</a></p>
<p>A threaded data iterator for machine learning on out-of-memory datasets. Inspired by PyTorch's DataLoader.</p>
<p>It uses  to load data <strong>in parallel</strong> while keeping the primary thread free. It can also load data <strong>inplace</strong> to avoid allocations.</p>
<p>Many data containers work out of the box and it is easy to <a href="docs/datacontainers.md">extend with your own</a>.</p>
<p><code>DataLoaders</code> is built on top of and fully compatible with <code>MLDataPattern.jl</code>'s <a href="https://mldatautilsjl.readthedocs.io/en/latest/data/pattern.html" rel="nofollow">Data Access Pattern</a>, a functional interface for machine learning datasets.</p>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="x = rand(128, 10000)  #  10000 observations of size 128
y = rand(1, 10000)

dataloader = DataLoader((x, y), 16)

for (xs, ys) in dataloader
    @assert size(xs) == (128, 16)
    @assert size(ys) == (1, 16)
end
"><pre>x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">128</span>, <span class="pl-c1">10000</span>)  <span class="pl-c"><span class="pl-c">#</span>  10000 observations of size 128</span>
y <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">1</span>, <span class="pl-c1">10000</span>)

dataloader <span class="pl-k">=</span> <span class="pl-c1">DataLoader</span>((x, y), <span class="pl-c1">16</span>)

<span class="pl-k">for</span> (xs, ys) <span class="pl-k">in</span> dataloader
    <span class="pl-c1">@assert</span> <span class="pl-c1">size</span>(xs) <span class="pl-k">==</span> (<span class="pl-c1">128</span>, <span class="pl-c1">16</span>)
    <span class="pl-c1">@assert</span> <span class="pl-c1">size</span>(ys) <span class="pl-k">==</span> (<span class="pl-c1">1</span>, <span class="pl-c1">16</span>)
<span class="pl-k">end</span></pre></div>
<p>Of course, in the above example, we can keep the dataset in memory and don't need parallel workers. See <a href="docs/datacontainers.md">Custom data containers</a> for a more realistic example.</p>
<h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Getting Started</h2>
<p>If you get the idea and know it from PyTorch, see <a href="docs/quickstartpytorch.md">Quickstart for PyTorch users</a>.</p>
<p>Otherwise, read on <a href="docs/motivation.md">here</a>.</p>
<p>Available methods are documented <a href="docstrings.md">here</a>.</p>
<h2><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Acknowledgements</h2>
<ul>
<li><a href="https://github.com/JuliaML/MLDataPattern.jl"><code>MLDataPattern.jl</code></a></li>
<li><a href="https://github.com/tro3/ThreadPools.jl"><code>ThreadPools.jl</code></a></li>
<li><a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" rel="nofollow">PyTorch <code>DataLoader</code></a></li>
</ul>
</article></div>