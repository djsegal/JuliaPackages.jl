<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-dataloadersjl" class="anchor" aria-hidden="true" href="#dataloadersjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DataLoaders.jl</h1>
<p dir="auto"><a href="https://lorenzoh.github.io/DataLoaders.jl/dev" rel="nofollow">Documentation (latest)</a></p>
<p dir="auto">A Julia package implementing performant data loading for deep learning on out-of-memory datasets that. Works like PyTorch's <code>DataLoader</code>.</p>
<h3 dir="auto"><a id="user-content-what-does-it-do" class="anchor" aria-hidden="true" href="#what-does-it-do"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>What does it do?</h3>
<ul dir="auto">
<li>Uses multi-threading to load data in parallel while keeping the primary thread free for the training loop</li>
<li>Handles batching and <a href="docs/collate.md">collating</a></li>
<li>Is simple to <a href="docs/interface.md">extend</a> for custom datasets</li>
<li>Integrates well with other packages in the <a href="docs/ecosystem.md">ecosystem</a></li>
<li>Allows for <a href="docs/inplaceloading.md">inplace loading</a> to reduce memory load</li>
</ul>
<h3 dir="auto"><a id="user-content-when-should-you-use-it" class="anchor" aria-hidden="true" href="#when-should-you-use-it"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>When should you use it?</h3>
<ul dir="auto">
<li>You have a dataset that does not fit into memory</li>
<li>You want to reduce the time your training loop is waiting for the next batch of data</li>
</ul>
<h3 dir="auto"><a id="user-content-how-do-you-use-it" class="anchor" aria-hidden="true" href="#how-do-you-use-it"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How do you use it?</h3>
<p dir="auto">Install like any other Julia package using the package manager (see <a href="docs/setup.md">setup</a>):</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="]add DataLoaders"><pre lang="julia-repl" class="notranslate"><code>]add DataLoaders
</code></pre></div>
<p dir="auto">After installation, import it, create a <code>DataLoader</code> from a dataset and batch size, and iterate over it:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using DataLoaders
# 10.000 observations of inputs with 128 features and one target feature
data = (rand(128, 10000), rand(1, 10000))
dataloader = DataLoader(data, 16)

for (xs, ys) in dataloader
    @assert size(xs) == (128, 16)
    @assert size(ys) == (1, 16)
end"><pre><span class="pl-k">using</span> DataLoaders
<span class="pl-c"><span class="pl-c">#</span> 10.000 observations of inputs with 128 features and one target feature</span>
data <span class="pl-k">=</span> (<span class="pl-c1">rand</span>(<span class="pl-c1">128</span>, <span class="pl-c1">10000</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">1</span>, <span class="pl-c1">10000</span>))
dataloader <span class="pl-k">=</span> <span class="pl-c1">DataLoader</span>(data, <span class="pl-c1">16</span>)

<span class="pl-k">for</span> (xs, ys) <span class="pl-k">in</span> dataloader
    <span class="pl-c1">@assert</span> <span class="pl-c1">size</span>(xs) <span class="pl-k">==</span> (<span class="pl-c1">128</span>, <span class="pl-c1">16</span>)
    <span class="pl-c1">@assert</span> <span class="pl-c1">size</span>(ys) <span class="pl-k">==</span> (<span class="pl-c1">1</span>, <span class="pl-c1">16</span>)
<span class="pl-k">end</span></pre></div>
<h3 dir="auto"><a id="user-content-next-you-may-want-to-read" class="anchor" aria-hidden="true" href="#next-you-may-want-to-read"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Next, you may want to read</h3>
<ul dir="auto">
<li><a href="docs/datacontainers.md">What datasets you can use it with</a></li>
<li><a href="docs/quickstartpytorch.md">How it compares to PyTorch's data loader</a></li>
</ul>
</article></div>