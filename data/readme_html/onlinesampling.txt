<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/wazizian/OnlineSampling.jl/actions/workflows/test.yml/badge.svg?branch=main"><img src="https://github.com/wazizian/OnlineSampling.jl/actions/workflows/test.yml/badge.svg?branch=main" alt="tests" style="max-width: 100%;"></a><a href="https://wazizian.github.io/OnlineSampling.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="doc" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a></p>
<h1 dir="auto"><a id="user-content-onlinesampling" class="anchor" aria-hidden="true" href="#onlinesampling"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>OnlineSampling</h1>
<p dir="auto">OnlineSampling.jl is a Julia package for online inference on reactive probabilistic models inspired by <a href="https://github.com/IBM/probzelus">ProbZelus</a>.
This package provides a small domain specific language to program reactive models and a semi-symbolic inference engine based on belief propagation to perform online Bayesian inference.</p>
<p dir="auto">Probabilistic programs are used to describe models and automatically infer latent parameters from statistical observations.
OnlineSampling focuses on reactive models, i.e., streaming probabilistic models based on the synchronous model of execution.</p>
<p dir="auto">Programs execute synchronously in lockstep on a global discrete logical clock.
Inputs and outputs are data streams, programs are stream processors.
For such models, inference is a reactive process that returns the distribution of parameters at the current time step given the observations so far.</p>
<p dir="auto">The full documentation is available at <a href="https://wazizian.github.io/OnlineSampling.jl/dev" rel="nofollow">wazizian.github.io/OnlineSampling.jl/dev</a>.</p>
<h2 dir="auto"><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Overview</h2>
<p dir="auto">See the video below from JuliaCon 2022 for a quick introduction to OnlineSampling.
<a href="https://youtu.be/puXsMJOc7xE" rel="nofollow"><img src="https://camo.githubusercontent.com/c5b548375243ee326ae6805cc157b1a34829fdeb60f7dcd828bbc3ffe0023104/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f707558734d4a4f633778452f302e6a7067" alt="JuliaCon 2022 OnlineSampling.jl presentation" data-canonical-src="https://img.youtube.com/vi/puXsMJOc7xE/0.jpg" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h2>
<p dir="auto">The following example is a HMM where we try to estimate the position of a moving agent from noisy observations.
At each step, we assume that the current position <code>x</code> is normally distributed around the previous position <code>@prev(x)</code>, and we assume that the current observation <code>y</code> is normally distributed around the current position.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="speed = 1.0
noise = 0.5
    
@node function model()
    @init x = rand(MvNormal([0.0], ScalMat(1, 1000.0))) # x_0 ~ N(0, 1000)
    x = rand(MvNormal(@prev(x), ScalMat(1, speed)))     # x_t ~ N(x_{t-1}, speed)
    y = rand(MvNormal(x, ScalMat(1, noise)))            # y_t ~ N(x_t, noise)
    return x, y
end
@node function hmm(obs)
    x, y = @nodecall model() # apply model to get x, y
    @observe(y, obs)         # assume y_t is observed with value obs_t 
    return x
end

steps = 100
obs = reshape(Vector{Float64}(1:steps), (steps, 1))  # the first dim of the input must be the number of time steps
cloud = @nodeiter particles = 1000 hmm(eachrow(obs)) # launch the inference with 1000 particles (return an iterator)

for (x, o) in zip(cloud, obs)                                  # at each step
    samples = rand(x, 1000)                                    # sample the 1000 values from the posterior     
    println(&quot;Estimated: &quot;, mean(samples), &quot; Observation: &quot;, o) # print the results
end"><pre>speed <span class="pl-k">=</span> <span class="pl-c1">1.0</span>
noise <span class="pl-k">=</span> <span class="pl-c1">0.5</span>
    
<span class="pl-c1">@node</span> <span class="pl-k">function</span> <span class="pl-en">model</span>()
    <span class="pl-c1">@init</span> x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">MvNormal</span>([<span class="pl-c1">0.0</span>], <span class="pl-c1">ScalMat</span>(<span class="pl-c1">1</span>, <span class="pl-c1">1000.0</span>))) <span class="pl-c"><span class="pl-c">#</span> x_0 ~ N(0, 1000)</span>
    x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">MvNormal</span>(<span class="pl-c1">@prev</span>(x), <span class="pl-c1">ScalMat</span>(<span class="pl-c1">1</span>, speed)))     <span class="pl-c"><span class="pl-c">#</span> x_t ~ N(x_{t-1}, speed)</span>
    y <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">MvNormal</span>(x, <span class="pl-c1">ScalMat</span>(<span class="pl-c1">1</span>, noise)))            <span class="pl-c"><span class="pl-c">#</span> y_t ~ N(x_t, noise)</span>
    <span class="pl-k">return</span> x, y
<span class="pl-k">end</span>
<span class="pl-c1">@node</span> <span class="pl-k">function</span> <span class="pl-en">hmm</span>(obs)
    x, y <span class="pl-k">=</span> <span class="pl-c1">@nodecall</span> <span class="pl-c1">model</span>() <span class="pl-c"><span class="pl-c">#</span> apply model to get x, y</span>
    <span class="pl-c1">@observe</span>(y, obs)         <span class="pl-c"><span class="pl-c">#</span> assume y_t is observed with value obs_t </span>
    <span class="pl-k">return</span> x
<span class="pl-k">end</span>

steps <span class="pl-k">=</span> <span class="pl-c1">100</span>
obs <span class="pl-k">=</span> <span class="pl-c1">reshape</span>(<span class="pl-c1">Vector</span><span class="pl-c1">{Float64}</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>steps), (steps, <span class="pl-c1">1</span>))  <span class="pl-c"><span class="pl-c">#</span> the first dim of the input must be the number of time steps</span>
cloud <span class="pl-k">=</span> <span class="pl-c1">@nodeiter</span> particles <span class="pl-k">=</span> <span class="pl-c1">1000</span> <span class="pl-c1">hmm</span>(<span class="pl-c1">eachrow</span>(obs)) <span class="pl-c"><span class="pl-c">#</span> launch the inference with 1000 particles (return an iterator)</span>

<span class="pl-k">for</span> (x, o) <span class="pl-k">in</span> <span class="pl-c1">zip</span>(cloud, obs)                                  <span class="pl-c"><span class="pl-c">#</span> at each step</span>
    samples <span class="pl-k">=</span> <span class="pl-c1">rand</span>(x, <span class="pl-c1">1000</span>)                                    <span class="pl-c"><span class="pl-c">#</span> sample the 1000 values from the posterior     </span>
    <span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span>Estimated: <span class="pl-pds">"</span></span>, <span class="pl-c1">mean</span>(samples), <span class="pl-s"><span class="pl-pds">"</span> Observation: <span class="pl-pds">"</span></span>, o) <span class="pl-c"><span class="pl-c">#</span> print the results</span>
<span class="pl-k">end</span></pre></div>
<p dir="auto">At each step, this program prints the estimated position and the current observation.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="$ julia --project=. examples/hmm.jl
Estimated: 1.0347103786435585 Observation: 1.0
Estimated: 1.7946457499669912 Observation: 2.0
Estimated: 2.760280175950971 Observation: 3.0
Estimated: 3.673951109330031 Observation: 4.0
..."><pre class="notranslate"><code>$ julia --project=. examples/hmm.jl
Estimated: 1.0347103786435585 Observation: 1.0
Estimated: 1.7946457499669912 Observation: 2.0
Estimated: 2.760280175950971 Observation: 3.0
Estimated: 3.673951109330031 Observation: 4.0
...
</code></pre></div>
</article></div>