<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p><a href="https://travis-ci.com/aicenter/IPMeasures.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/5d808c105994841f9d6f45a684bc5d8da9201995/68747470733a2f2f7472617669732d63692e636f6d2f616963656e7465722f49504d656173757265732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/aicenter/IPMeasures.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/aicenter/IPMeasures.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/2102201a9f29b27e1334091c02322e26cbe164d5/68747470733a2f2f636f6465636f762e696f2f67682f616963656e7465722f49504d656173757265732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/aicenter/IPMeasures.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<h1><a id="user-content-ipmeasuresjl" class="anchor" aria-hidden="true" href="#ipmeasuresjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>IPMeasures.jl</h1>
<p>Implements Integral Probability Measures, such as Maximum Mean Discrepancy
(MMD) with Gaussian, RQ, and IPM kernels, as well as the KL divergence of
conditional Gaussians (based on
<a href="https://github.com/aicenter/ConditionalDists.jl">ConditionalDists.jl</a>). The
package is compatible with Flux.jl and uses the Distances.jl interface.</p>
<h2><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples</h2>
<p>Maximum Mean Discrepancy between <code>x</code> and <code>y</code> using gaussian kernel of bandwidth <code>γ</code></p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> IPMeasures<span class="pl-k">:</span> mmd, GaussianKernel

x <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">2</span>,<span class="pl-c1">100</span>)
y <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">2</span>,<span class="pl-c1">100</span>)
γ <span class="pl-k">=</span> <span class="pl-c1">1.0</span>
<span class="pl-c1">mmd</span>(<span class="pl-c1">GaussianKernel</span>(γ),x,y)
<span class="pl-c1">0.012</span></pre></div>
<p><code>IMQKernel(c)</code> inverse multi-quadratic kernel <code>k(d) = C/(C+d)</code> with <code>d</code> being a
distance as used in [Tolstikhin, Ilya, et al. "Wasserstein
Auto-Encoders." (2017)](arXiv preprint arXiv:1711.01558)</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> IPMeasures
<span class="pl-k">import</span> IPMeasures<span class="pl-k">:</span> mmd, IMQKernel
<span class="pl-c1">mmd</span>(<span class="pl-c1">IMQKernel</span>(<span class="pl-c1">1.0</span>),<span class="pl-c1">randn</span>(<span class="pl-c1">2</span>,<span class="pl-c1">100</span>),<span class="pl-c1">randn</span>(<span class="pl-c1">2</span>,<span class="pl-c1">100</span>))
<span class="pl-c1">0.026</span></pre></div>
<p><code>RQKernel(α)</code> Maximum Mean Discrepancy between <code>x</code> and <code>y</code>  rq kernel from
Bińkowski, Mikołaj, et al. "Demystifying MMD GANs." (2018).</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> IPMeasures
<span class="pl-k">import</span> IPMeasures<span class="pl-k">:</span> mmd, RQKernel
<span class="pl-c1">mmd</span>(<span class="pl-c1">RQKernel</span>(<span class="pl-c1">1.0</span>),<span class="pl-c1">randn</span>(<span class="pl-c1">2</span>,<span class="pl-c1">100</span>),<span class="pl-c1">randn</span>(<span class="pl-c1">2</span>,<span class="pl-c1">100</span>))
<span class="pl-c1">0.026</span></pre></div>
<p>Furthermore, we have estimation of Null Hypothesis of kernel <code>k</code> of samples <code>x</code>
from <code>n</code> random draws of subsets of size <code>l</code></p>
<pre><code>null_distribution(k::AbstractKernel, x, n, l)
</code></pre>
<p>estimates the null distribution</p>
</article></div>