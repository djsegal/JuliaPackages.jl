<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-odinn" class="anchor" aria-hidden="true" href="#odinn"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ODINN</h1>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ODINN-SciML/odinn_toy/blob/main/plots/ODINN_logo_final.png"><img src="https://github.com/ODINN-SciML/odinn_toy/raw/main/plots/ODINN_logo_final.png" width="250" style="max-width: 100%;"></a></p>
<h3 dir="auto"><a id="user-content-oggm-open-global-glacier-model--differential-equation-neural-networks" class="anchor" aria-hidden="true" href="#oggm-open-global-glacier-model--differential-equation-neural-networks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>OGGM (Open Global Glacier Model) + DIfferential equation Neural Networks</h3>
<p dir="auto">Global glacier model using Universal Differential Equations to model and discover processes of climate-glacier interactions.</p>
<p dir="auto"><code>ODINN.jl</code> uses neural networks and differential equations in order to combine mechanistic models describing glacier physical processes (e.g. ice creep, basal sliding, surface mass balance) with machine learning. Neural networks are used to learn parts of the equations, which then can be interpreted in a mathematical form (e.g. using SINDy) in order to update the original equation from the process. ODINN uses the Open Global Glacier Model (OGGM, Maussion et al., 2019) as a basic framework to retrieve all the topographical and climate data for the initial state of the simulations. This is done calling Python from Julia using PyCall. Then, all the simulations and processing are performed in Julia, benefitting from its high performance and the SciML ecosystem.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ODINN-SciML/odinn_toy/blob/main/plots/overview_figure.png"><img src="https://github.com/ODINN-SciML/odinn_toy/raw/main/plots/overview_figure.png" width="700" style="max-width: 100%;"></a></p>
<blockquote>
<p dir="auto"><strong>Overview of <code>ODINN.jl</code>’s workflow to perform functional inversions of glacier physical processes using Universal Differential Equations</strong>. The parameters (<math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="eece798a142b0d09ae9c8526ffdbc003">$θ$</math-renderer>) of a function determining a given physical process (<math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="eece798a142b0d09ae9c8526ffdbc003">$D_θ$</math-renderer>), expressed by a neural network <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="eece798a142b0d09ae9c8526ffdbc003">$NN_θ$</math-renderer>, are optimized in order to minimize a loss function. In this example, the physical to be inferred law was constrained only by climate data, but any other proxies of interest can be used to design it. The climate data, and therefore the glacier mass balance, are downscaled (i.e. it depends on <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="eece798a142b0d09ae9c8526ffdbc003">$S$</math-renderer>), with <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="eece798a142b0d09ae9c8526ffdbc003">$S$</math-renderer> being updated by the solver, thus dynamically updating the state of the simulation for a given timestep.</p>
</blockquote>
<h2 dir="auto">
<a id="user-content-installing-odinn" class="anchor" aria-hidden="true" href="#installing-odinn"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installing ODINN</h2>
<p dir="auto">In order to install <code>ODINN</code> in a given environment, just do in the REPL:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; ] # enter Pkg mode
(@v1.8) pkg&gt; activate MyEnvironment # or activate whatever path for the Julia environment
(MyEnvironment) pkg&gt; add ODINN"><pre>julia<span class="pl-k">&gt;</span> ] <span class="pl-c"><span class="pl-c">#</span> enter Pkg mode</span>
(<span class="pl-c1">@v1</span>.<span class="pl-c1">8</span>) pkg<span class="pl-k">&gt;</span> activate MyEnvironment <span class="pl-c"><span class="pl-c">#</span> or activate whatever path for the Julia environment</span>
(MyEnvironment) pkg<span class="pl-k">&gt;</span> add ODINN</pre></div>
<h2 dir="auto">
<a id="user-content-odinn-initialization-integration-with-oggm-and-multiprocessing" class="anchor" aria-hidden="true" href="#odinn-initialization-integration-with-oggm-and-multiprocessing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ODINN initialization: integration with OGGM and multiprocessing</h2>
<p dir="auto">In order to call OGGM in Python from Julia, a Python installation is needed, which then can be used in Julia using <a href="https://github.com/JuliaPy/PyCall.jl">PyCall</a>. We recommend splitting the Julia (i.e. ODINN) and Python (i.e. OGGM) files in separate folders, which we chose to name <code>Julia</code> and <code>Python</code>, both placed at root level. As indicated in the <a href="https://docs.oggm.org/en/stable/installing-oggm.html" rel="nofollow">OGGM documentation</a>, when installing OGGM it is best to create a new dedicated conda environment for it (e.g. <code>oggm_env</code>). In the same environment, install also the <a href="https://github.com/OGGM/massbalance-sandbox">OGGM Mass-Balance sandbox</a> following the instructions in the repository.</p>
<p dir="auto">The path to this conda environment needs to be specified in the <code>ENV["PYTHON"]</code> variable in Julia, for PyCall to find it. This configuration is very easy to implement, it just requires activating the conda environment before the first time you run ODINN in your machine. In the terminal (not in a Julia session), run:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="conda activate oggm_env # replace `oggm_env` with whatever conda environment where you have installed OGGM and the MBSandbox"><pre class="notranslate"><code>conda activate oggm_env # replace `oggm_env` with whatever conda environment where you have installed OGGM and the MBSandbox
</code></pre></div>
<p dir="auto">Then, you need to configure PyCall to use the Python path for that conda environment:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia # start Julia session

julia&gt; global ENV[&quot;PYTHON&quot;] = read(`which python`, String)[1:end-1] # trim backspace
julia&gt; import Pkg; Pkg.build(&quot;PyCall&quot;)
julia&gt; exit()

# Now you can run your code using ODINN in a new Julia session; e.g.:
using ODINN"><pre>julia <span class="pl-c"><span class="pl-c">#</span> start Julia session</span>

julia<span class="pl-k">&gt;</span> <span class="pl-k">global</span> <span class="pl-c1">ENV</span>[<span class="pl-s"><span class="pl-pds">"</span>PYTHON<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-c1">read</span>(<span class="pl-s"><span class="pl-pds">`</span>which python<span class="pl-pds">`</span></span>, String)[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-c"><span class="pl-c">#</span> trim backspace</span>
julia<span class="pl-k">&gt;</span> <span class="pl-k">import</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">build</span>(<span class="pl-s"><span class="pl-pds">"</span>PyCall<span class="pl-pds">"</span></span>)
julia<span class="pl-k">&gt;</span> <span class="pl-c1">exit</span>()

<span class="pl-c"><span class="pl-c">#</span> Now you can run your code using ODINN in a new Julia session; e.g.:</span>
<span class="pl-k">using</span> ODINN</pre></div>
<p dir="auto">So now you can start working with ODINN with PyCall correctly configured. These configuration step only needs to be done the first time, so from now on ODINN should be able to correctly find your Python libraries. If you ever want to change your conda environment, you would just need to repeat the steps above. The next step is to start a new Julia session and import <code>ODINN</code> (or just run your script which uses ODINN, e.g. <code>toy_model.jl</code>). If you want to run ODINN using multiprocessing you can enable it using the following command in Julia:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="processes = 16
ODINN.enable_multiprocessing(processes)"><pre>processes <span class="pl-k">=</span> <span class="pl-c1">16</span>
ODINN<span class="pl-k">.</span><span class="pl-c1">enable_multiprocessing</span>(processes)</pre></div>
<p dir="auto">From this point, it is possible to use ODINN with multiprocessing and to run Python from Julia running the different commands available in the PyCall documentation. In order to get a better idea on how this works, we recommend checking the toy model example <a href="https://github.com/ODINN-SciML/ODINN/blob/main/src/scripts/toy_model.jl">toy_model.jl</a>.</p>
<h3 dir="auto">
<a id="user-content-using-oggm-for-the-initial-conditions-of-the-trainingsimulations" class="anchor" aria-hidden="true" href="#using-oggm-for-the-initial-conditions-of-the-trainingsimulations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Using OGGM for the initial conditions of the training/simulations</h3>
<p dir="auto">ODINN works as a back-end of OGGM, utilizing all its tools to retrieve RGI data, topographical data, climate data and other datasets from the OGGM shop. We use these data to specify the initial state of the simulations, and to retrieve the climate data to force the model. Everything related to the mass balance and ice flow dynamics models is written 100% in Julia. This allows us to run tests with this toy model for any glacier on Earth. In order to choose a glacier, you just need to specify the RGI ID, which you can find <a href="https://www.glims.org/maps/glims" rel="nofollow">here</a>.</p>
<h2 dir="auto">
<a id="user-content-running-the-toy-model" class="anchor" aria-hidden="true" href="#running-the-toy-model"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Running the toy model</h2>
<p dir="auto">A demostration with a toy model is showcased in <a href="https://github.com/ODINN-SciML/ODINN.jl/blob/main/scripts/toy_model.jl"><code>src/scripts/toy_model.jl</code></a>. The <code>Project.toml</code> includes all the required dependencies. If you are running this code from zero, you may need to install the libraries using <code>Pkg.instantiate()</code>. In case you want to include this package to the project manifest, you can also use <code>Pkg.resolve()</code> before instantiating the project. You can replace the preamble in <code>src/scripts/toy_model.jl</code> to</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import Pkg
Pkg.activate(dirname(Base.current_project()))
Pkg.instantiate()
Pkg.precompile()"><pre><span class="pl-k">import</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">activate</span>(<span class="pl-c1">dirname</span>(Base<span class="pl-k">.</span><span class="pl-c1">current_project</span>()))
Pkg<span class="pl-k">.</span><span class="pl-c1">instantiate</span>()
Pkg<span class="pl-k">.</span><span class="pl-c1">precompile</span>()</pre></div>
<h2 dir="auto">
<a id="user-content-upcoming-changes" class="anchor" aria-hidden="true" href="#upcoming-changes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Upcoming changes</h2>
<p dir="auto">A stable API is still being designed, which will be available in the next release. If you plan to start using the model, please contact us, although we recommend to wait until next release for a smoother experience.</p>
</article></div>