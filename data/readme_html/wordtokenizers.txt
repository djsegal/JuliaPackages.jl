<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-wordtokenizers" class="anchor" aria-hidden="true" href="#wordtokenizers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>WordTokenizers</h1>
<p dir="auto"><a href="https://github.com/SciML/ColPrac"><img src="https://camo.githubusercontent.com/a6c1efcb19a957860ecb25966a730260b03d6e05380d0c27992ee7f9e3b1feb3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f6c507261632d436f6e7472696275746f72277325323047756964652d626c756576696f6c6574" alt="ColPrac: Contributor's Guide on Collaborative Practices for Community Packages" data-canonical-src="https://img.shields.io/badge/ColPrac-Contributor's%20Guide-blueviolet" style="max-width: 100%;"></a>
<a href="https://github.com/JuliaText/WordTokenizers.jl/releases/"><img src="https://camo.githubusercontent.com/5cdba0cd175d307784b3b428bdd469e250c51dc2a8d159217c41adf21debfdbd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f4a756c6961546578742f576f7264546f6b656e697a6572732e6a6c2e737667" alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/JuliaText/WordTokenizers.jl.svg" style="max-width: 100%;"></a>
<a href="https://travis-ci.org/JuliaText/WordTokenizers.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/2cc208b23dca187d32586b304946bca7f1d95c88e8f7aff94aca14862a86d865/68747470733a2f2f7472617669732d63692e6f72672f4a756c6961546578742f576f7264546f6b656e697a6572732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/JuliaText/WordTokenizers.jl.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/JuliaText/WordTokenizers.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/90ac177bb92c32950a4e4025b645756431b327f1b3dca8292679639d14d20b07/68747470733a2f2f636f6465636f762e696f2f67682f4a756c6961546578742f576f7264546f6b656e697a6572732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/JuliaText/WordTokenizers.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a>
<a href="https://ci.appveyor.com/project/oxinabox/wordtokenizers-jl/history" rel="nofollow"><img src="https://camo.githubusercontent.com/d5338ff1b56d41f1ac1bb3f3fa2badb475e90bcac2a8d005228c8c067c529616/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f4a756c6961546578742f576f7264546f6b656e697a6572732e6a6c3f6272616e63683d6d6173746572267376673d74727565" alt="Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/JuliaText/WordTokenizers.jl?branch=master&amp;svg=true" style="max-width: 100%;"></a>
<a href="http://hits.dwyl.io/JuliaText/WordTokenizers" rel="nofollow"><img src="https://camo.githubusercontent.com/f83103a8ec3445df160cc234872bab7feb46884cec4daf93f2f8a407ef36363e/687474703a2f2f686974732e6477796c2e696f2f4a756c6961546578742f576f7264546f6b656e697a6572732e737667" alt="HitCount" data-canonical-src="http://hits.dwyl.io/JuliaText/WordTokenizers.svg" style="max-width: 100%;"></a></p>
<p dir="auto">Some basic tokenizers for Natural Language Processing.</p>
<h3 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation:</h3>
<p dir="auto">As per standard <a href="https://julialang.github.io/Pkg.jl/dev/managing-packages/#Adding-registered-packages-1" rel="nofollow">Julia package installation</a>:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; add WordTokenizers"><pre class="notranslate"><code>pkg&gt; add WordTokenizers
</code></pre></div>
<h3 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h3>
<p dir="auto">The normal way to use this package is to call
<code>tokenize(str)</code> to split up a string into words
or <code>split_sentences(str)</code> to split up a string into sentences.
Maybe even <code>tokenize.(split_sentences(str))</code> to do both.</p>
<p dir="auto"><code>tokenize</code> and <code>split_sentences</code> are configurable functions
that call one of the tokenizers or sentence splitters defined below.
They have sensible defaults set,
but you can override the method used by calling
<code>set_tokenizer(func)</code> or <code>set_sentence_splitter(func)</code> passing in your preferred
function <code>func</code> from the list below (or from elsewhere)
Configuring them this way will throw up a method overwritten warning, and trigger recompilation of any methods that use them.</p>
<p dir="auto">This means if you are using a package that uses WordTokenizers.jl to do tokenization/sentence splitting via the default methods,
changing the tokenizer/splitter will change the behavior of that package.
This is a feature of <a href="https://github.com/JuliaText/CorpusLoaders.jl">CorpusLoaders.jl</a>.
If as a package author you don't want to allow the user to change the tokenizer in this way, you should use the tokenizer you want explicitly, rather than using the  <code>tokenize</code> method.</p>
<h3 dir="auto"><a id="user-content-example-setting-tokenizer-tinysegmenterjl" class="anchor" aria-hidden="true" href="#example-setting-tokenizer-tinysegmenterjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example Setting Tokenizer (TinySegmenter.jl)</h3>
<p dir="auto">You might like to, for example use <a href="https://github.com/JuliaStrings/TinySegmenter.jl">TinySegmenter.jl's tokenizer</a> for Japanese text.
We do not include TinySegmenter in this package, because making use of it within WordTokenizers.jl is trivial.
Just <code>import TinySegmenter; set_tokenizer(TinySegmenter.tokenize)</code>.</p>
<p dir="auto">Full example:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using WordTokenizers

julia&gt; text = &quot;私の名前は中野です&quot;;

julia&gt; tokenize(text) |&gt; print # Default tokenizer
[&quot;私の名前は中野です&quot;]

julia&gt; import TinySegmenter

julia&gt; set_tokenizer(TinySegmenter.tokenize)

julia&gt; tokenize(text) |&gt; print # TinySegmenter's tokenizer
SubString{String}[&quot;私&quot;, &quot;の&quot;, &quot;名前&quot;, &quot;は&quot;, &quot;中野&quot;, &quot;です&quot;]"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> WordTokenizers

julia<span class="pl-k">&gt;</span> text <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>私の名前は中野です<span class="pl-pds">"</span></span>;

julia<span class="pl-k">&gt;</span> <span class="pl-c1">tokenize</span>(text) <span class="pl-k">|&gt;</span> print <span class="pl-c"><span class="pl-c">#</span> Default tokenizer</span>
[<span class="pl-s"><span class="pl-pds">"</span>私の名前は中野です<span class="pl-pds">"</span></span>]

julia<span class="pl-k">&gt;</span> <span class="pl-k">import</span> TinySegmenter

julia<span class="pl-k">&gt;</span> <span class="pl-c1">set_tokenizer</span>(TinySegmenter<span class="pl-k">.</span>tokenize)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">tokenize</span>(text) <span class="pl-k">|&gt;</span> print <span class="pl-c"><span class="pl-c">#</span> TinySegmenter's tokenizer</span>
SubString{String}[<span class="pl-s"><span class="pl-pds">"</span>私<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>の<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>名前<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>は<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>中野<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>です<span class="pl-pds">"</span></span>]</pre></div>
<h1 dir="auto"><a id="user-content-word-tokenizers" class="anchor" aria-hidden="true" href="#word-tokenizers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>(Word) Tokenizers</h1>
<p dir="auto">The word tokenizers basically assume sentence splitting has already been done.</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Poorman's tokenizer:</strong> (<code>poormans_tokenize</code>) Deletes all punctuation, and splits on spaces. (In some ways worse than just using <code>split</code>)</p>
</li>
<li>
<p dir="auto"><strong>Punctuation space tokenize:</strong> (<code>punctuation_space_tokenize</code>) Marginally improved version of the poorman's tokenizer, only deletes punctuation occurring outside words.</p>
</li>
<li>
<p dir="auto"><strong>Penn Tokenizer:</strong> (<code>penn_tokenize</code>) This is Robert MacIntyre's original tokenizer used for the Penn Treebank. Splits contractions.</p>
</li>
<li>
<p dir="auto"><strong>Improved Penn Tokenizer:</strong> (<code>improved_penn_tokenize</code>) NLTK's improved Penn Treebank Tokenizer. Very similar to the original, some improvements on punctuation and contractions. This matches to NLTK's <code>nltk.tokenize.TreeBankWordTokenizer.tokenize</code>.</p>
</li>
<li>
<p dir="auto"><strong>NLTK Word tokenizer:</strong> (<code>nltk_word_tokenize</code>) NLTK's even more improved version of the Penn Tokenizer. This version has better Unicode handling and some other changes. This matches to the most commonly used <code>nltk.word_tokenize</code>, minus the sentence tokenizing step.</p>
</li>
</ul>
<p dir="auto">(To me it seems like a weird historical thing that NLTK has 2 successive variations on improving the Penn tokenizer, but for now, I am matching it and having both.  See <a href="https://github.com/nltk/nltk/issues/2005" data-hovercard-type="issue" data-hovercard-url="/nltk/nltk/issues/2005/hovercard">[NLTK#2005]</a>.)</p>
<ul dir="auto">
<li><strong>Reversible Tokenizer:</strong> (<code>rev_tokenize</code> and <code>rev_detokenize</code>) This tokenizer splits on punctuations, space and special symbols. The generated tokens can be de-tokenized by using the <code>rev_detokenizer</code> function into the state before tokenization.</li>
<li><strong>TokTok Tokenizer:</strong> (<code>toktok_tokenize</code>) This tokenizer is a simple, general tokenizer, where the input has one sentence per line; thus only final period is tokenized. This is an enhanced version of the <a href="https://github.com/jonsafari/tok-tok">original toktok Tokenizer</a>. It has been tested on and gives reasonably good results for English, Persian, Russian, Czech, French, German, Vietnamese, Tajik, and a few others. <strong>(default tokenizer)</strong></li>
<li><strong>Tweet Tokenizer:</strong> (<code>tweet_tokenizer</code>) NLTK's casual tokenizer for that is solely designed for tweets. Apart from being twitter specific, this tokenizer has good handling for emoticons and other web aspects like support for HTML Entities. This closely matches NLTK's <code>nltk.tokenize.TweetTokenizer</code></li>
</ul>
<h1 dir="auto"><a id="user-content-sentence-splitters" class="anchor" aria-hidden="true" href="#sentence-splitters"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Sentence Splitters</h1>
<p dir="auto">We currently only have one sentence splitter.</p>
<ul dir="auto">
<li><strong>Rule-Based Sentence Spitter:</strong> (<code>rulebased_split_sentences</code>), uses a rule that periods, question marks, and exclamation marks, followed by white-space end sentences. With a large list of exceptions.</li>
</ul>
<p dir="auto"><code>split_sentences</code> is exported as an alias for the most useful sentence splitter currently implemented.
(Which ATM is the only sentence splitter: <code>rulebased_split_sentences</code>) <strong>(default sentence_splitter)</strong></p>
<h1 dir="auto"><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h1>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; tokenize(&quot;The package's tokenizers range from simple (e.g. poorman's), to complex (e.g. Penn).&quot;) |&gt; print
SubString{String}[&quot;The&quot;, &quot;package&quot;, &quot;'s&quot;, &quot;tokenizers&quot;, &quot;range&quot;, &quot;from&quot;, &quot;simple&quot;, &quot;(&quot;, &quot;e.g.&quot;, &quot;poorman&quot;, &quot;'s&quot;, &quot;)&quot;,&quot;,&quot;, &quot;to&quot;, &quot;complex&quot;, &quot;(&quot;, &quot;e.g.&quot;, &quot;Penn&quot;, &quot;)&quot;, &quot;.&quot;]"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">tokenize</span>(<span class="pl-s"><span class="pl-pds">"</span>The package's tokenizers range from simple (e.g. poorman's), to complex (e.g. Penn).<span class="pl-pds">"</span></span>) <span class="pl-k">|&gt;</span> print
SubString{String}[<span class="pl-s"><span class="pl-pds">"</span>The<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>package<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>'s<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>tokenizers<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>range<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>from<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>simple<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>(<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>e.g.<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>poorman<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>'s<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>)<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>,<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>to<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>complex<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>(<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>e.g.<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Penn<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>)<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>.<span class="pl-pds">"</span></span>]</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; text = &quot;The leatherback sea turtle is the largest, measuring six or seven feet (2 m) in length at maturity, and three to five feet (1 to 1.5 m) in width, weighing up to 2000 pounds (about 900 kg). Most other species are smaller, being two to four feet in length (0.5 to 1 m) and proportionally less wide. The Flatback turtle is found solely on the northerncoast of Australia.&quot;;

julia&gt; split_sentences(text)
3-element Array{SubString{String},1}:
 &quot;The leatherback sea turtle is the largest, measuring six or seven feet (2 m) in length at maturity, and three to five feet (1 to 1.5 m) in width, weighing up to 2000 pounds (about900 kg). &quot;
 &quot;Most other species are smaller, being two to four feet in length (0.5 to 1 m) and proportionally less wide. &quot;
 &quot;The Flatback turtle is found solely on the northern coast of Australia.&quot;

julia&gt; tokenize.(split_sentences(text))
3-element Array{Array{SubString{String},1},1}:
 SubString{String}[&quot;The&quot;, &quot;leatherback&quot;, &quot;sea&quot;, &quot;turtle&quot;, &quot;is&quot;, &quot;the&quot;, &quot;largest&quot;, &quot;,&quot;, &quot;measuring&quot;, &quot;six&quot;  …  &quot;up&quot;, &quot;to&quot;, &quot;2000&quot;, &quot;pounds&quot;, &quot;(&quot;, &quot;about&quot;, &quot;900&quot;, &quot;kg&quot;, &quot;)&quot;, &quot;.&quot;]
 SubString{String}[&quot;Most&quot;, &quot;other&quot;, &quot;species&quot;, &quot;are&quot;, &quot;smaller&quot;, &quot;,&quot;, &quot;being&quot;, &quot;two&quot;, &quot;to&quot;, &quot;four&quot;  …  &quot;0.5&quot;, &quot;to&quot;, &quot;1&quot;, &quot;m&quot;, &quot;)&quot;, &quot;and&quot;, &quot;proportionally&quot;, &quot;less&quot;, &quot;wide&quot;, &quot;.&quot;]
 SubString{String}[&quot;The&quot;, &quot;Flatback&quot;, &quot;turtle&quot;, &quot;is&quot;, &quot;found&quot;, &quot;solely&quot;, &quot;on&quot;, &quot;the&quot;, &quot;northern&quot;, &quot;coast&quot;, &quot;of&quot;, &quot;Australia&quot;, &quot;.&quot;]"><pre>julia<span class="pl-k">&gt;</span> text <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>The leatherback sea turtle is the largest, measuring six or seven feet (2 m) in length at maturity, and three to five feet (1 to 1.5 m) in width, weighing up to 2000 pounds (about 900 kg). Most other species are smaller, being two to four feet in length (0.5 to 1 m) and proportionally less wide. The Flatback turtle is found solely on the northerncoast of Australia.<span class="pl-pds">"</span></span>;

julia<span class="pl-k">&gt;</span> <span class="pl-c1">split_sentences</span>(text)
<span class="pl-c1">3</span><span class="pl-k">-</span>element Array{SubString{String},<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>The leatherback sea turtle is the largest, measuring six or seven feet (2 m) in length at maturity, and three to five feet (1 to 1.5 m) in width, weighing up to 2000 pounds (about900 kg). <span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>Most other species are smaller, being two to four feet in length (0.5 to 1 m) and proportionally less wide. <span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>The Flatback turtle is found solely on the northern coast of Australia.<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">tokenize</span>.(<span class="pl-c1">split_sentences</span>(text))
<span class="pl-c1">3</span><span class="pl-k">-</span>element Array{Array{SubString{String},<span class="pl-c1">1</span>},<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 SubString{String}[<span class="pl-s"><span class="pl-pds">"</span>The<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>leatherback<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>sea<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>turtle<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>is<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>the<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>largest<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>,<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>measuring<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>six<span class="pl-pds">"</span></span>  …  <span class="pl-s"><span class="pl-pds">"</span>up<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>to<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>2000<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>pounds<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>(<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>about<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>900<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>kg<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>)<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>.<span class="pl-pds">"</span></span>]
 SubString{String}[<span class="pl-s"><span class="pl-pds">"</span>Most<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>other<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>species<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>are<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>smaller<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>,<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>being<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>two<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>to<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>four<span class="pl-pds">"</span></span>  …  <span class="pl-s"><span class="pl-pds">"</span>0.5<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>to<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>1<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>m<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>)<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>and<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>proportionally<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>less<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>wide<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>.<span class="pl-pds">"</span></span>]
 SubString{String}[<span class="pl-s"><span class="pl-pds">"</span>The<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Flatback<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>turtle<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>is<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>found<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>solely<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>on<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>the<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>northern<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>coast<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>of<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Australia<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>.<span class="pl-pds">"</span></span>]</pre></div>
<h2 dir="auto"><a id="user-content-experimental-api" class="anchor" aria-hidden="true" href="#experimental-api"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Experimental API</h2>
<p dir="auto">I am trying out an experimental API
where these are added as dispatches to <code>Base.split</code>.</p>
<p dir="auto">So<br>
<code>split(foo, Words)</code> is the same as <code>tokenize(foo)</code>,<br>
and<br>
<code>split(foo, Sentences)</code> is the same as <code>split_sentences(foo)</code>.</p>
<h2 dir="auto"><a id="user-content-using-tokenbuffer-api-for-custom-tokenizers" class="anchor" aria-hidden="true" href="#using-tokenbuffer-api-for-custom-tokenizers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Using TokenBuffer API for Custom Tokenizers</h2>
<p dir="auto">We offer a <code>TokenBuffer</code> API and supporting utility lexers
for high-speed tokenization.</p>
<h4 dir="auto"><a id="user-content-writing-your-own-tokenbuffer-tokenizers" class="anchor" aria-hidden="true" href="#writing-your-own-tokenbuffer-tokenizers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Writing your own TokenBuffer tokenizers</h4>
<p dir="auto"><code>TokenBuffer</code> turns a string into a readable stream, used for building tokenizers.
Utility lexers such as <code>spaces</code> and <code>&lt;span class="x x-first x-last"&gt;number&lt;/span&gt;</code> read characters from the
stream and into an array of tokens.</p>
<p dir="auto">Lexers return <code>true</code> or <code>false</code> to indicate whether they matched
in the input stream. They can, therefore, be combined easily, e.g.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="spacesornumber(ts) = spaces(ts) || number(ts)"><pre class="notranslate"><code>spacesornumber(ts) = spaces(ts) || number(ts)
</code></pre></div>
<p dir="auto">either skips whitespace or parses a number token, if possible.</p>
<p dir="auto">The simplest useful tokenizer splits on spaces.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using WordTokenizers: TokenBuffer, isdone, spaces, character

function tokenise(input)
    ts = TokenBuffer(input)
    while !isdone(ts)
        spaces(ts) || character(ts)
    end
    return ts.tokens
end

tokenise(&quot;foo bar baz&quot;) # [&quot;foo&quot;, &quot;bar&quot;, &quot;baz&quot;]"><pre class="notranslate"><code>using WordTokenizers: TokenBuffer, isdone, spaces, character

function tokenise(input)
    ts = TokenBuffer(input)
    while !isdone(ts)
        spaces(ts) || character(ts)
    end
    return ts.tokens
end

tokenise("foo bar baz") # ["foo", "bar", "baz"]
</code></pre></div>
<p dir="auto">Many prewritten components for building custom tokenizers
can be found in <code>src/words/fast.jl</code> and <code>src/words/tweet_tokenizer.jl</code>
These components can be mixed and matched to create more complex tokenizers.</p>
<p dir="auto">Here is a more complex example.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using WordTokenizers: TokenBuffer, isdone, character, spaces # Present in fast.jl

julia&gt; using WordTokenizers: nltk_url1, nltk_url2, nltk_phonenumbers # Present in tweet_tokenizer.jl

julia&gt; function tokeinze(input)
           urls(ts) = nltk_url1(ts) || nltk_url2(ts)

           ts = TokenBuffer(input)
           while !isdone(ts)
               spaces(ts) &amp;&amp; continue
               urls(ts) ||
               nltk_phonenumbers(ts) ||
               character(ts)
           end
           return ts.tokens
       end
tokeinze (generic function with 1 method)

julia&gt; tokeinze(&quot;A url https://github.com/JuliaText/WordTokenizers.jl/ and phonenumber +0 (987) - 2344321&quot;)
6-element Array{String,1}:
 &quot;A&quot;
 &quot;url&quot;
 &quot;https://github.com/JuliaText/WordTokenizers.jl/&quot; # URL detected.
 &quot;and&quot;
 &quot;phonenumber&quot;
 &quot;+0 (987) - 2344321&quot; # Phone number detected."><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> WordTokenizers<span class="pl-k">:</span> TokenBuffer, isdone, character, spaces <span class="pl-c"><span class="pl-c">#</span> Present in fast.jl</span>

julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> WordTokenizers<span class="pl-k">:</span> nltk_url1, nltk_url2, nltk_phonenumbers <span class="pl-c"><span class="pl-c">#</span> Present in tweet_tokenizer.jl</span>

julia<span class="pl-k">&gt;</span> <span class="pl-k">function</span> <span class="pl-en">tokeinze</span>(input)
           <span class="pl-en">urls</span>(ts) <span class="pl-k">=</span> <span class="pl-c1">nltk_url1</span>(ts) <span class="pl-k">||</span> <span class="pl-c1">nltk_url2</span>(ts)

           ts <span class="pl-k">=</span> <span class="pl-c1">TokenBuffer</span>(input)
           <span class="pl-k">while</span> <span class="pl-k">!</span><span class="pl-c1">isdone</span>(ts)
               <span class="pl-c1">spaces</span>(ts) <span class="pl-k">&amp;&amp;</span> <span class="pl-k">continue</span>
               <span class="pl-c1">urls</span>(ts) <span class="pl-k">||</span>
               <span class="pl-c1">nltk_phonenumbers</span>(ts) <span class="pl-k">||</span>
               <span class="pl-c1">character</span>(ts)
           <span class="pl-k">end</span>
           <span class="pl-k">return</span> ts<span class="pl-k">.</span>tokens
       <span class="pl-k">end</span>
tokeinze (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">tokeinze</span>(<span class="pl-s"><span class="pl-pds">"</span>A url https://github.com/JuliaText/WordTokenizers.jl/ and phonenumber +0 (987) - 2344321<span class="pl-pds">"</span></span>)
<span class="pl-c1">6</span><span class="pl-k">-</span>element Array{String,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>A<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>url<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>https://github.com/JuliaText/WordTokenizers.jl/<span class="pl-pds">"</span></span> <span class="pl-c"><span class="pl-c">#</span> URL detected.</span>
 <span class="pl-s"><span class="pl-pds">"</span>and<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>phonenumber<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>+0 (987) - 2344321<span class="pl-pds">"</span></span> <span class="pl-c"><span class="pl-c">#</span> Phone number detected.</span></pre></div>
<h4 dir="auto"><a id="user-content-tips-for-writing-custom-tokenizers-and-your-own-tokenbuffer-lexer" class="anchor" aria-hidden="true" href="#tips-for-writing-custom-tokenizers-and-your-own-tokenbuffer-lexer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Tips for writing custom tokenizers and your own TokenBuffer Lexer</h4>
<ol dir="auto">
<li>The order in which the lexers are written needs to be taken care of in some cases-</li>
</ol>
<p dir="auto">For example: <code>987-654-3210</code> matches as a phone number
as well as numbers, but <code>number</code> will only match up to <code>987</code>
and split after it.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using WordTokenizers: TokenBuffer, isdone, character, spaces, nltk_phonenumbers, number

julia&gt; order1(ts) = number(ts) || nltk_phonenumbers(ts)
order1 (generic function with 1 method)

julia&gt; order2(ts) = nltk_phonenumbers(ts) || number(ts)
order2 (generic function with 1 method)

julia&gt; function tokenize1(input)
           ts = TokenBuffer(input)
           while !isdone(ts)
               order1(ts) ||
               character(ts)
           end
           return ts.tokens
       end
tokenize1 (generic function with 1 method)

julia&gt; function tokenize2(input)
           ts = TokenBuffer(input)
           while !isdone(ts)
               order2(ts) ||
               character(ts)
           end
           return ts.tokens
       end
tokenize2 (generic function with 1 method)

julia&gt; tokenize1(&quot;987-654-3210&quot;) # number(ts) || nltk_phonenumbers(ts)
5-element Array{String,1}:
 &quot;987&quot;
 &quot;-&quot;
 &quot;654&quot;
 &quot;-&quot;
 &quot;3210&quot;

julia&gt; tokenize2(&quot;987-654-3210&quot;) # nltk_phonenumbers(ts) || number(ts)
1-element Array{String,1}:
 &quot;987-654-3210&quot;"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> WordTokenizers<span class="pl-k">:</span> TokenBuffer, isdone, character, spaces, nltk_phonenumbers, number

julia<span class="pl-k">&gt;</span> <span class="pl-en">order1</span>(ts) <span class="pl-k">=</span> <span class="pl-c1">number</span>(ts) <span class="pl-k">||</span> <span class="pl-c1">nltk_phonenumbers</span>(ts)
order1 (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> <span class="pl-en">order2</span>(ts) <span class="pl-k">=</span> <span class="pl-c1">nltk_phonenumbers</span>(ts) <span class="pl-k">||</span> <span class="pl-c1">number</span>(ts)
order2 (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> <span class="pl-k">function</span> <span class="pl-en">tokenize1</span>(input)
           ts <span class="pl-k">=</span> <span class="pl-c1">TokenBuffer</span>(input)
           <span class="pl-k">while</span> <span class="pl-k">!</span><span class="pl-c1">isdone</span>(ts)
               <span class="pl-c1">order1</span>(ts) <span class="pl-k">||</span>
               <span class="pl-c1">character</span>(ts)
           <span class="pl-k">end</span>
           <span class="pl-k">return</span> ts<span class="pl-k">.</span>tokens
       <span class="pl-k">end</span>
tokenize1 (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> <span class="pl-k">function</span> <span class="pl-en">tokenize2</span>(input)
           ts <span class="pl-k">=</span> <span class="pl-c1">TokenBuffer</span>(input)
           <span class="pl-k">while</span> <span class="pl-k">!</span><span class="pl-c1">isdone</span>(ts)
               <span class="pl-c1">order2</span>(ts) <span class="pl-k">||</span>
               <span class="pl-c1">character</span>(ts)
           <span class="pl-k">end</span>
           <span class="pl-k">return</span> ts<span class="pl-k">.</span>tokens
       <span class="pl-k">end</span>
tokenize2 (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">tokenize1</span>(<span class="pl-s"><span class="pl-pds">"</span>987-654-3210<span class="pl-pds">"</span></span>) <span class="pl-c"><span class="pl-c">#</span> number(ts) || nltk_phonenumbers(ts)</span>
<span class="pl-c1">5</span><span class="pl-k">-</span>element Array{String,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>987<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>-<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>654<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>-<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>3210<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">tokenize2</span>(<span class="pl-s"><span class="pl-pds">"</span>987-654-3210<span class="pl-pds">"</span></span>) <span class="pl-c"><span class="pl-c">#</span> nltk_phonenumbers(ts) || number(ts)</span>
<span class="pl-c1">1</span><span class="pl-k">-</span>element Array{String,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>987-654-3210<span class="pl-pds">"</span></span></pre></div>
<ol start="2" dir="auto">
<li>
<p dir="auto">BoundsError and errors while handling edge cases are most common
and need to be taken of while writing the TokenBuffer lexers.</p>
</li>
<li>
<p dir="auto">For some TokenBuffer <code>ts</code>, use <code>flush!(ts)</code>
over <code>push!(ts.tokens, input[i:j])</code>, to make sure that characters
in the Buffer (i.e. ts.Buffer) also gets flushed out as separate tokens.</p>
</li>
</ol>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using WordTokenizers: TokenBuffer, flush!, spaces, character, isdone

julia&gt; function tokenize(input)
           ts = TokenBuffer(input)

           while !isdone(ts)
               spaces(ts) &amp;&amp; continue
               my_pattern(ts) ||
               character(ts)
           end
           return ts.tokens
       end

julia&gt; function my_pattern(ts) # Matches the pattern for 2 continuous `_`
           ts.idx + 1 &lt;= length(ts.input) || return false

           if ts[ts.idx] == '_' &amp;&amp; ts[ts.idx + 1] == '_'
               flush!(ts, &quot;__&quot;) # Using flush!
               ts.idx += 2
               return true
           end

           return false
       end
my_pattern (generic function with 1 method)

julia&gt; tokenize(&quot;hi__hello&quot;)
3-element Array{String,1}:
 &quot;hi&quot;
 &quot;__&quot;
 &quot;hello&quot;

julia&gt; function my_pattern(ts) # Matches the pattern for 2 continuous `_`
           ts.idx + 1 &lt;= length(ts.input) || return false

           if ts[ts.idx] == '_' &amp;&amp; ts[ts.idx + 1] == '_'
               push!(ts.tokens, &quot;__&quot;) # Without using flush!
               ts.idx += 2
               return true
           end

           return false
       end
my_pattern (generic function with 1 method)

julia&gt; tokenize(&quot;hi__hello&quot;)
2-element Array{String,1}:
 &quot;__&quot;
 &quot;hihello&quot;"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> WordTokenizers<span class="pl-k">:</span> TokenBuffer, flush!, spaces, character, isdone

julia<span class="pl-k">&gt;</span> <span class="pl-k">function</span> <span class="pl-en">tokenize</span>(input)
           ts <span class="pl-k">=</span> <span class="pl-c1">TokenBuffer</span>(input)

           <span class="pl-k">while</span> <span class="pl-k">!</span><span class="pl-c1">isdone</span>(ts)
               <span class="pl-c1">spaces</span>(ts) <span class="pl-k">&amp;&amp;</span> <span class="pl-k">continue</span>
               <span class="pl-c1">my_pattern</span>(ts) <span class="pl-k">||</span>
               <span class="pl-c1">character</span>(ts)
           <span class="pl-k">end</span>
           <span class="pl-k">return</span> ts<span class="pl-k">.</span>tokens
       <span class="pl-k">end</span>

julia<span class="pl-k">&gt;</span> <span class="pl-k">function</span> <span class="pl-en">my_pattern</span>(ts) <span class="pl-c"><span class="pl-c">#</span> Matches the pattern for 2 continuous `_`</span>
           ts<span class="pl-k">.</span>idx <span class="pl-k">+</span> <span class="pl-c1">1</span> <span class="pl-k">&lt;=</span> <span class="pl-c1">length</span>(ts<span class="pl-k">.</span>input) <span class="pl-k">||</span> <span class="pl-k">return</span> <span class="pl-c1">false</span>

           <span class="pl-k">if</span> ts[ts<span class="pl-k">.</span>idx] <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">'</span>_<span class="pl-pds">'</span></span> <span class="pl-k">&amp;&amp;</span> ts[ts<span class="pl-k">.</span>idx <span class="pl-k">+</span> <span class="pl-c1">1</span>] <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">'</span>_<span class="pl-pds">'</span></span>
               <span class="pl-c1">flush!</span>(ts, <span class="pl-s"><span class="pl-pds">"</span>__<span class="pl-pds">"</span></span>) <span class="pl-c"><span class="pl-c">#</span> Using flush!</span>
               ts<span class="pl-k">.</span>idx <span class="pl-k">+=</span> <span class="pl-c1">2</span>
               <span class="pl-k">return</span> <span class="pl-c1">true</span>
           <span class="pl-k">end</span>

           <span class="pl-k">return</span> <span class="pl-c1">false</span>
       <span class="pl-k">end</span>
my_pattern (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">tokenize</span>(<span class="pl-s"><span class="pl-pds">"</span>hi__hello<span class="pl-pds">"</span></span>)
<span class="pl-c1">3</span><span class="pl-k">-</span>element Array{String,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>hi<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>__<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>hello<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> <span class="pl-k">function</span> <span class="pl-en">my_pattern</span>(ts) <span class="pl-c"><span class="pl-c">#</span> Matches the pattern for 2 continuous `_`</span>
           ts<span class="pl-k">.</span>idx <span class="pl-k">+</span> <span class="pl-c1">1</span> <span class="pl-k">&lt;=</span> <span class="pl-c1">length</span>(ts<span class="pl-k">.</span>input) <span class="pl-k">||</span> <span class="pl-k">return</span> <span class="pl-c1">false</span>

           <span class="pl-k">if</span> ts[ts<span class="pl-k">.</span>idx] <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">'</span>_<span class="pl-pds">'</span></span> <span class="pl-k">&amp;&amp;</span> ts[ts<span class="pl-k">.</span>idx <span class="pl-k">+</span> <span class="pl-c1">1</span>] <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">'</span>_<span class="pl-pds">'</span></span>
               <span class="pl-c1">push!</span>(ts<span class="pl-k">.</span>tokens, <span class="pl-s"><span class="pl-pds">"</span>__<span class="pl-pds">"</span></span>) <span class="pl-c"><span class="pl-c">#</span> Without using flush!</span>
               ts<span class="pl-k">.</span>idx <span class="pl-k">+=</span> <span class="pl-c1">2</span>
               <span class="pl-k">return</span> <span class="pl-c1">true</span>
           <span class="pl-k">end</span>

           <span class="pl-k">return</span> <span class="pl-c1">false</span>
       <span class="pl-k">end</span>
my_pattern (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">tokenize</span>(<span class="pl-s"><span class="pl-pds">"</span>hi__hello<span class="pl-pds">"</span></span>)
<span class="pl-c1">2</span><span class="pl-k">-</span>element Array{String,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>__<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>hihello<span class="pl-pds">"</span></span></pre></div>
<h1 dir="auto"><a id="user-content-statistical-tokenizer" class="anchor" aria-hidden="true" href="#statistical-tokenizer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Statistical Tokenizer</h1>
<p dir="auto"><strong>Sentencepiece Unigram Encoder</strong> is basically  the Sentencepiece processor's re-implementation in julia. It can used vocab file generated by sentencepiece library containing both vocab and log probability.</p>
<p dir="auto">For more detail about implementation refer the blog post <a href="https://tejasvaidhyadev.github.io/blog/Sentencepiece" rel="nofollow">here</a></p>
<p dir="auto"><strong>Note</strong> :</p>
<ul dir="auto">
<li>SentencePiece escapes the whitespace with a meta symbol "▁" (U+2581).</li>
</ul>
<h3 dir="auto"><a id="user-content-pretrained" class="anchor" aria-hidden="true" href="#pretrained"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Pretrained</h3>
<p dir="auto">Wordtokenizer provides pretrained vocab file of Albert (both version-1 and version-2)</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; subtypes(PretrainedTokenizer)
2-element Array{Any,1}:
 ALBERT_V1
 ALBERT_V2

julia&gt; tokenizerfiles(ALBERT_V1)
4-element Array{String,1}:
 &quot;albert_base_v1_30k-clean.vocab&quot;   
 &quot;albert_large_v1_30k-clean.vocab&quot;  
 &quot;albert_xlarge_v1_30k-clean.vocab&quot; 
 &quot;albert_xxlarge_v1_30k-clean.vocab&quot;"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">subtypes</span>(PretrainedTokenizer)
<span class="pl-c1">2</span><span class="pl-k">-</span>element Array{Any,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 ALBERT_V1
 ALBERT_V2

julia<span class="pl-k">&gt;</span> <span class="pl-c1">tokenizerfiles</span>(ALBERT_V1)
<span class="pl-c1">4</span><span class="pl-k">-</span>element Array{String,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>albert_base_v1_30k-clean.vocab<span class="pl-pds">"</span></span>   
 <span class="pl-s"><span class="pl-pds">"</span>albert_large_v1_30k-clean.vocab<span class="pl-pds">"</span></span>  
 <span class="pl-s"><span class="pl-pds">"</span>albert_xlarge_v1_30k-clean.vocab<span class="pl-pds">"</span></span> 
 <span class="pl-s"><span class="pl-pds">"</span>albert_xxlarge_v1_30k-clean.vocab<span class="pl-pds">"</span></span></pre></div>
<p dir="auto"><code>DataDeps</code> will handle all the downloading part for us.  You can also create an issue or PR for other pretrained models or directly load by providing path in <code>load</code> function</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; spm = load(Albert_Version1) #loading Default Albert-base vocab in Sentencepiece
WordTokenizers.SentencePieceModel(Dict(&quot;▁shots&quot;=&gt;(-11.2373, 7281),&quot;▁ordered&quot;=&gt;(-9.84973, 1906),&quot;dev&quot;=&gt;(-12.0915, 14439),&quot;▁silv&quot;=&gt;(-12.6564, 21065),&quot;▁doubtful&quot;=&gt;(-12.7799, 22569),&quot;▁without&quot;=&gt;(-8.34227, 367),&quot;▁pol&quot;=&gt;(-10.7694, 4828),&quot;chem&quot;=&gt;(-12.3713, 17661),&quot;▁1947,&quot;=&gt;(-11.7544, 11199),&quot;▁disrespect&quot;=&gt;(-13.13, 26682)…), 2)

julia&gt; tk = tokenizer(spm, &quot;i love the julia language&quot;) #or tk = spm(&quot;i love the julia language&quot;)
4-element Array{String,1}:
 &quot;▁i&quot;       
 &quot;▁love&quot;
 &quot;▁the&quot;    
 &quot;▁julia&quot;   
 &quot;▁language&quot;

julia&gt; subword = tokenizer(spm, &quot;unfriendly&quot;)
2-element Array{String,1}:
 &quot;▁un&quot;
 &quot;friendly&quot;

julia&gt; para = spm(&quot;Julia is a high-level, high-performance dynamic language for technical computing&quot;)
17-element Array{String,1}:
 &quot;▁&quot;          
 &quot;J&quot;          
 &quot;ulia&quot;       
 &quot;▁is&quot;        
 &quot;▁a&quot;         
 &quot;▁high&quot;      
 &quot;-&quot;          
 &quot;level&quot;      
 &quot;,&quot;          
 &quot;▁high&quot;      
 &quot;-&quot;          
 &quot;performance&quot;
 &quot;▁dynamic&quot;   
 &quot;▁language&quot;  
 &quot;▁for&quot;       
 &quot;▁technical&quot; 
 &quot;▁computing&quot; "><pre>julia<span class="pl-k">&gt;</span> spm <span class="pl-k">=</span> <span class="pl-c1">load</span>(Albert_Version1) <span class="pl-c"><span class="pl-c">#</span>loading Default Albert-base vocab in Sentencepiece</span>
WordTokenizers<span class="pl-k">.</span><span class="pl-c1">SentencePieceModel</span>(<span class="pl-c1">Dict</span>(<span class="pl-s"><span class="pl-pds">"</span>▁shots<span class="pl-pds">"</span></span><span class="pl-k">=&gt;</span>(<span class="pl-k">-</span><span class="pl-c1">11.2373</span>, <span class="pl-c1">7281</span>),<span class="pl-s"><span class="pl-pds">"</span>▁ordered<span class="pl-pds">"</span></span><span class="pl-k">=&gt;</span>(<span class="pl-k">-</span><span class="pl-c1">9.84973</span>, <span class="pl-c1">1906</span>),<span class="pl-s"><span class="pl-pds">"</span>dev<span class="pl-pds">"</span></span><span class="pl-k">=&gt;</span>(<span class="pl-k">-</span><span class="pl-c1">12.0915</span>, <span class="pl-c1">14439</span>),<span class="pl-s"><span class="pl-pds">"</span>▁silv<span class="pl-pds">"</span></span><span class="pl-k">=&gt;</span>(<span class="pl-k">-</span><span class="pl-c1">12.6564</span>, <span class="pl-c1">21065</span>),<span class="pl-s"><span class="pl-pds">"</span>▁doubtful<span class="pl-pds">"</span></span><span class="pl-k">=&gt;</span>(<span class="pl-k">-</span><span class="pl-c1">12.7799</span>, <span class="pl-c1">22569</span>),<span class="pl-s"><span class="pl-pds">"</span>▁without<span class="pl-pds">"</span></span><span class="pl-k">=&gt;</span>(<span class="pl-k">-</span><span class="pl-c1">8.34227</span>, <span class="pl-c1">367</span>),<span class="pl-s"><span class="pl-pds">"</span>▁pol<span class="pl-pds">"</span></span><span class="pl-k">=&gt;</span>(<span class="pl-k">-</span><span class="pl-c1">10.7694</span>, <span class="pl-c1">4828</span>),<span class="pl-s"><span class="pl-pds">"</span>chem<span class="pl-pds">"</span></span><span class="pl-k">=&gt;</span>(<span class="pl-k">-</span><span class="pl-c1">12.3713</span>, <span class="pl-c1">17661</span>),<span class="pl-s"><span class="pl-pds">"</span>▁1947,<span class="pl-pds">"</span></span><span class="pl-k">=&gt;</span>(<span class="pl-k">-</span><span class="pl-c1">11.7544</span>, <span class="pl-c1">11199</span>),<span class="pl-s"><span class="pl-pds">"</span>▁disrespect<span class="pl-pds">"</span></span><span class="pl-k">=&gt;</span>(<span class="pl-k">-</span><span class="pl-c1">13.13</span>, <span class="pl-c1">26682</span>)…), <span class="pl-c1">2</span>)

julia<span class="pl-k">&gt;</span> tk <span class="pl-k">=</span> <span class="pl-c1">tokenizer</span>(spm, <span class="pl-s"><span class="pl-pds">"</span>i love the julia language<span class="pl-pds">"</span></span>) <span class="pl-c"><span class="pl-c">#</span>or tk = spm("i love the julia language")</span>
<span class="pl-c1">4</span><span class="pl-k">-</span>element Array{String,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>▁i<span class="pl-pds">"</span></span>       
 <span class="pl-s"><span class="pl-pds">"</span>▁love<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>▁the<span class="pl-pds">"</span></span>    
 <span class="pl-s"><span class="pl-pds">"</span>▁julia<span class="pl-pds">"</span></span>   
 <span class="pl-s"><span class="pl-pds">"</span>▁language<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> subword <span class="pl-k">=</span> <span class="pl-c1">tokenizer</span>(spm, <span class="pl-s"><span class="pl-pds">"</span>unfriendly<span class="pl-pds">"</span></span>)
<span class="pl-c1">2</span><span class="pl-k">-</span>element Array{String,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>▁un<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>friendly<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> para <span class="pl-k">=</span> <span class="pl-c1">spm</span>(<span class="pl-s"><span class="pl-pds">"</span>Julia is a high-level, high-performance dynamic language for technical computing<span class="pl-pds">"</span></span>)
<span class="pl-c1">17</span><span class="pl-k">-</span>element Array{String,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>▁<span class="pl-pds">"</span></span>          
 <span class="pl-s"><span class="pl-pds">"</span>J<span class="pl-pds">"</span></span>          
 <span class="pl-s"><span class="pl-pds">"</span>ulia<span class="pl-pds">"</span></span>       
 <span class="pl-s"><span class="pl-pds">"</span>▁is<span class="pl-pds">"</span></span>        
 <span class="pl-s"><span class="pl-pds">"</span>▁a<span class="pl-pds">"</span></span>         
 <span class="pl-s"><span class="pl-pds">"</span>▁high<span class="pl-pds">"</span></span>      
 <span class="pl-s"><span class="pl-pds">"</span>-<span class="pl-pds">"</span></span>          
 <span class="pl-s"><span class="pl-pds">"</span>level<span class="pl-pds">"</span></span>      
 <span class="pl-s"><span class="pl-pds">"</span>,<span class="pl-pds">"</span></span>          
 <span class="pl-s"><span class="pl-pds">"</span>▁high<span class="pl-pds">"</span></span>      
 <span class="pl-s"><span class="pl-pds">"</span>-<span class="pl-pds">"</span></span>          
 <span class="pl-s"><span class="pl-pds">"</span>performance<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>▁dynamic<span class="pl-pds">"</span></span>   
 <span class="pl-s"><span class="pl-pds">"</span>▁language<span class="pl-pds">"</span></span>  
 <span class="pl-s"><span class="pl-pds">"</span>▁for<span class="pl-pds">"</span></span>       
 <span class="pl-s"><span class="pl-pds">"</span>▁technical<span class="pl-pds">"</span></span> 
 <span class="pl-s"><span class="pl-pds">"</span>▁computing<span class="pl-pds">"</span></span> </pre></div>
<p dir="auto">Indices is usually used for deep learning models.
Index of special tokens in ALBERT are given below:</p>
<p dir="auto">1 ⇒ [PAD]<br>
2 ⇒ [UNK]<br>
3 ⇒ [CLS]<br>
4 ⇒ [SEP]<br>
5 ⇒ [MASK]</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; ids_from_tokens(spm, tk)
4-element Array{Int64,1}:
   32
  340
   15
 5424
  817
#we can also get sentences back from tokens
julia&gt; sentence_from_tokens(tk)
 &quot;i love the julia language&quot;

julia&gt; sentence_from_token(subword)
 &quot;unfriendly&quot;

julia&gt; sentence_from_tokens(para)
 &quot;Julia is a high-level, high-performance dynamic language for technical computing&quot;"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">ids_from_tokens</span>(spm, tk)
<span class="pl-c1">4</span><span class="pl-k">-</span>element Array{Int64,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
   <span class="pl-c1">32</span>
  <span class="pl-c1">340</span>
   <span class="pl-c1">15</span>
 <span class="pl-c1">5424</span>
  <span class="pl-c1">817</span>
<span class="pl-c"><span class="pl-c">#</span>we can also get sentences back from tokens</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">sentence_from_tokens</span>(tk)
 <span class="pl-s"><span class="pl-pds">"</span>i love the julia language<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">sentence_from_token</span>(subword)
 <span class="pl-s"><span class="pl-pds">"</span>unfriendly<span class="pl-pds">"</span></span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">sentence_from_tokens</span>(para)
 <span class="pl-s"><span class="pl-pds">"</span>Julia is a high-level, high-performance dynamic language for technical computing<span class="pl-pds">"</span></span></pre></div>
<h2 dir="auto"><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributing</h2>
<p dir="auto">Contributions, in the form of bug-reports, pull-requests, additional documentation are encouraged.
They can be made to the GitHub repository.</p>
<p dir="auto">We follow the <a href="https://github.com/SciML/ColPrac">ColPrac guide for collaborative practices</a>.
New contributor should make sure to read that guide.</p>
<p dir="auto"><strong>All contributions and communications should abide by the <a href="https://julialang.org/community/standards/" rel="nofollow">Julia Community Standards</a>.</strong></p>
<p dir="auto">Software contributions should follow the prevailing style within the code-base.
If your pull request (or issues) are not getting responses within a few days do not hesitate to "bump" them,
by posting a comment such as "Any update on the status of this?".
Sometimes GitHub notifications get lost.</p>
<h2 dir="auto"><a id="user-content-support" class="anchor" aria-hidden="true" href="#support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Support</h2>
<p dir="auto">Feel free to ask for help on the <a href="https://discourse.julialang.org/" rel="nofollow">Julia Discourse forum</a>,
or in the <code>#natural-language</code> channel on julia-slack. (Which you can <a href="https://slackinvite.julialang.org/" rel="nofollow">join here</a>).
You can also raise issues in this repository to request improvements to the documentation.</p>
</article></div>