<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/carstenbauer/BinningAnalysis.jl/blob/master/docs/src/assets/logo_with_text.png"><img src="https://github.com/carstenbauer/BinningAnalysis.jl/raw/master/docs/src/assets/logo_with_text.png" alt="logo" style="max-width: 100%;"></a></p>
<table>
<thead>
<tr>
<th align="center"><strong>Build Status</strong></th>
<th align="center"><strong>Community</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f8b75bf59f0258f267d191f906b5d1309741f821beaf3e8d7473eacc02e5b2e7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6966656379636c652d737461626c652d626c75652e737667"><img src="https://camo.githubusercontent.com/f8b75bf59f0258f267d191f906b5d1309741f821beaf3e8d7473eacc02e5b2e7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6966656379636c652d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/lifecycle-stable-blue.svg" style="max-width: 100%;"></a> <a href="https://github.com/carstenbauer/BinningAnalysis.jl/actions?query=workflow%3A%22Run+tests%22"><img src="https://github.com/carstenbauer/BinningAnalysis.jl/workflows/Run%20tests/badge.svg" alt="" style="max-width: 100%;"></a> <a href="http://codecov.io/github/carstenbauer/BinningAnalysis.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/07728041f0abafa8855ffaab002e28f1c295b0e3d628fb895b07c00528be1f1f/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f6769746875622f6361727374656e62617565722f42696e6e696e67416e616c797369732e6a6c2f6d61737465722e7376673f6c6162656c3d636f6465636f76" alt="" data-canonical-src="https://img.shields.io/codecov/c/github/carstenbauer/BinningAnalysis.jl/master.svg?label=codecov" style="max-width: 100%;"></a> <a href="https://juliaci.github.io/NanosoldierReports/pkgeval_badges/report.html" rel="nofollow"><img src="https://camo.githubusercontent.com/7609feedd7d088cbe6dd1d3a76f27630cfc8a8e68bb1474dfb1614a5831defcf/68747470733a2f2f6a756c696163692e6769746875622e696f2f4e616e6f736f6c646965725265706f7274732f706b676576616c5f6261646765732f422f42696e6e696e67416e616c797369732e737667" alt="" data-canonical-src="https://juliaci.github.io/NanosoldierReports/pkgeval_badges/B/BinningAnalysis.svg" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://slackinvite.julialang.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/c192b6b30d22427a9ad86f7832a70c27f8dcbb028dae7dc2ca07181ef7dd9e13/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230736c61636b2d79656c6c6f772e737667" alt="" data-canonical-src="https://img.shields.io/badge/chat-on%20slack-yellow.svg" style="max-width: 100%;"></a> <a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/3a50d5c687932b4693d23d07cfa8fc5a7b6738c97689f8631e26f23d8740ee14/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d7265642e737667" alt="" data-canonical-src="https://img.shields.io/badge/License-MIT-red.svg" style="max-width: 100%;"></a> <a href="https://doi.org/10.5281/zenodo.3603347" rel="nofollow"><img src="https://camo.githubusercontent.com/dbc1512a83fc27014564a13ebded340a49fc7f7f2df226d507cefcf4ce3cac3a/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e333630333334372e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.3603347.svg" style="max-width: 100%;"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">This package provides tools to estimate <a href="https://en.wikipedia.org/wiki/Standard_error" rel="nofollow">standard errors</a> and <a href="https://en.wikipedia.org/wiki/Autocorrelation" rel="nofollow">autocorrelation times</a> of correlated time series. A typical example is a <a href="https://en.wikipedia.org/wiki/Markov_chain" rel="nofollow">Markov chain</a> obtained in a <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm" rel="nofollow">Metropolis Monte Carlo simulation</a>.</p>
<p dir="auto"><strong>Binning tools:</strong></p>
<ul dir="auto">
<li>Logarithmic Binning (bins data directly in a logarithmic manner)
<ul dir="auto">
<li>Size complexity: <code>O(log(N))</code></li>
<li>Time complexity: <code>O(N)</code></li>
</ul>
</li>
<li>Full Binning (keeps all data and allows for any bin size)</li>
<li>ErrorPropagator (logarithmic binning, can calculate errors of functions of the inputs, experimental)</li>
</ul>
<p dir="auto"><strong>Statistical resampling methods:</strong></p>
<ul dir="auto">
<li>Jackknife resampling (calculates errors for subsamples of the original data)</li>
</ul>
<br>
<p dir="auto">As per usual, you can install the registered package with</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="] add BinningAnalysis"><pre>] add BinningAnalysis</pre></div>
<p dir="auto">[<strong>OUTDATED</strong> as of v0.6] Note that there is <a href="https://github.com/carstenbauer/BinningAnalysisPlots.jl">BinningAnalysisPlots.jl</a> which defines some <a href="https://github.com/JuliaPlots/Plots.jl">Plots.jl</a> recipes for <code>LogBinner</code> and <code>FullBinner</code> to facilitate visualizing the error convergence.</p>
<h2 dir="auto"><a id="user-content-binning-tools" class="anchor" aria-hidden="true" href="#binning-tools"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Binning tools</h2>
<p dir="auto">All the different binners follow a common interface.</p>
<h3 dir="auto"><a id="user-content-full-binning" class="anchor" aria-hidden="true" href="#full-binning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Full Binning</h3>
<p dir="auto">The <code>FullBinner</code> is a thin wrapper around <code>Vector</code> which keeps track of a series of (correlated) data points. To estimate correlation free statistics the data is averaged in bins of variable size. This creates a smaller, less or optimally uncorrelated data set whose statistics are taken in place of the full data set. Since this method features no data compression the bin size can chosen freely.</p>
<h3 dir="auto"><a id="user-content-logarithmic-binning" class="anchor" aria-hidden="true" href="#logarithmic-binning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Logarithmic Binning</h3>
<p dir="auto">The <code>LogBinner</code> is a compressive binning structure. Rather than keeping all the data around, it only keeps data relevant to bin sizes 2^l where l is the binning level. Thus the memory usage drops to <code>O(log₂(N))</code> where N is the number of data points, and the choice of bin size becomes a choice of binning level.</p>
<h3 dir="auto"><a id="user-content-errorpropagator" class="anchor" aria-hidden="true" href="#errorpropagator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ErrorPropagator</h3>
<p dir="auto">The <code>ErrorPropagator</code> is a derivative of <code>LogBinner</code>. It performs logarithmic binning of multiple samples at once, also keeping track of covariances between the samples. Through this errors of functions depending on multiple samples can be derived. The memory complexity of this tool is <code>O(∏ₖ Dₖ ⋅ log₂(N))</code> where Dₖ refers to the size of a data point in data set k.</p>
<p dir="auto">To derive statistics for a function <code>f</code> that applies to the samples in <code>ErrorPropagator</code> the gradient of <code>f</code> at the mean of those values is needed.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Function we want to evaluate
# &lt;x&gt;&lt;y&gt; / &lt;xy&gt;
f(v) = v[1] * v[2] / v[3]  

# gradient of f
grad_f(v) = [v[2]/v[3], v[1]/v[3], -v[1]*v[2]/v[3]^2]

# Error propagator with 3 samples
ep = ErrorPropagator(N_args=3)

# Add measurements
x = rand(100)
y = rand(100)
append!(ep, x, y, x .* y)

# calculate mean and error of f
g_mean = mean(ep, f)
Δg = std_error(ep, grad_f)"><pre><span class="pl-c"><span class="pl-c">#</span> Function we want to evaluate</span>
<span class="pl-c"><span class="pl-c">#</span> &lt;x&gt;&lt;y&gt; / &lt;xy&gt;</span>
<span class="pl-en">f</span>(v) <span class="pl-k">=</span> v[<span class="pl-c1">1</span>] <span class="pl-k">*</span> v[<span class="pl-c1">2</span>] <span class="pl-k">/</span> v[<span class="pl-c1">3</span>]  

<span class="pl-c"><span class="pl-c">#</span> gradient of f</span>
<span class="pl-en">grad_f</span>(v) <span class="pl-k">=</span> [v[<span class="pl-c1">2</span>]<span class="pl-k">/</span>v[<span class="pl-c1">3</span>], v[<span class="pl-c1">1</span>]<span class="pl-k">/</span>v[<span class="pl-c1">3</span>], <span class="pl-k">-</span>v[<span class="pl-c1">1</span>]<span class="pl-k">*</span>v[<span class="pl-c1">2</span>]<span class="pl-k">/</span>v[<span class="pl-c1">3</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>]

<span class="pl-c"><span class="pl-c">#</span> Error propagator with 3 samples</span>
ep <span class="pl-k">=</span> <span class="pl-c1">ErrorPropagator</span>(N_args<span class="pl-k">=</span><span class="pl-c1">3</span>)

<span class="pl-c"><span class="pl-c">#</span> Add measurements</span>
x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">100</span>)
y <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">100</span>)
<span class="pl-c1">append!</span>(ep, x, y, x <span class="pl-k">.*</span> y)

<span class="pl-c"><span class="pl-c">#</span> calculate mean and error of f</span>
g_mean <span class="pl-k">=</span> <span class="pl-c1">mean</span>(ep, f)
Δg <span class="pl-k">=</span> <span class="pl-c1">std_error</span>(ep, grad_f)</pre></div>
<h3 dir="auto"><a id="user-content-interface" class="anchor" aria-hidden="true" href="#interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Interface</h3>
<p dir="auto">You can construct each binner with or without initial data:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Create an empty Binner
FB = FullBinner()

# Create a Binner with data
x = rand(100)
LB = LogBinner(x)"><pre><span class="pl-c"><span class="pl-c">#</span> Create an empty Binner</span>
FB <span class="pl-k">=</span> <span class="pl-c1">FullBinner</span>()

<span class="pl-c"><span class="pl-c">#</span> Create a Binner with data</span>
x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">100</span>)
LB <span class="pl-k">=</span> <span class="pl-c1">LogBinner</span>(x)</pre></div>
<p dir="auto">The element type defaults to <code>Float64</code> but can also be adjusted in the constructor. Note that for Array inputs consistent data sizes are assumed and  <code>LogBinner</code> and <code>ErrorPropagator</code> need a "zero":</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Create an empty Binner accepting 2x2 Matrices
EP = ErrorPropagator(zeros(2, 2), zeros(2, 2))

# Create a Binner with Complex data
x = rand(ComplexF64, 100)
LB = LogBinner(x)

# Create an empty Binner accepting Complex data
FB = FullBinner(ComplexF64)"><pre><span class="pl-c"><span class="pl-c">#</span> Create an empty Binner accepting 2x2 Matrices</span>
EP <span class="pl-k">=</span> <span class="pl-c1">ErrorPropagator</span>(<span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>, <span class="pl-c1">2</span>), <span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>, <span class="pl-c1">2</span>))

<span class="pl-c"><span class="pl-c">#</span> Create a Binner with Complex data</span>
x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(ComplexF64, <span class="pl-c1">100</span>)
LB <span class="pl-k">=</span> <span class="pl-c1">LogBinner</span>(x)

<span class="pl-c"><span class="pl-c">#</span> Create an empty Binner accepting Complex data</span>
FB <span class="pl-k">=</span> <span class="pl-c1">FullBinner</span>(ComplexF64)</pre></div>
<p dir="auto">Further note that <code>LogBinner</code> and <code>ErrorPropagator</code> have a static capacity which can be set with the <code>capicity</code> keyword argument in the constructor. By default the capacity is set to 2^32 (about 4.3 billion values) or the next power of 2 above the <code>length(data)</code> when a data set is used to create the binner. Note that you can also create a copy of a binner with a different capacity via <code>LogBinner(old_binner, capacity = new_capacity)</code>.</p>
<p dir="auto">Beyond adding data on creation it can be pushed or appended to a binner:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="FB = FullBinner(ComplexF64)
LB = LogBinner(zeros(3))
EP = ErrorPropagator(Float64, 2)

# Add data
push!(FB, 4.2 + 0.9im)
push!(LB, rand(3))
append!(EP, [1,2,3], [2,3,4])"><pre>FB <span class="pl-k">=</span> <span class="pl-c1">FullBinner</span>(ComplexF64)
LB <span class="pl-k">=</span> <span class="pl-c1">LogBinner</span>(<span class="pl-c1">zeros</span>(<span class="pl-c1">3</span>))
EP <span class="pl-k">=</span> <span class="pl-c1">ErrorPropagator</span>(Float64, <span class="pl-c1">2</span>)

<span class="pl-c"><span class="pl-c">#</span> Add data</span>
<span class="pl-c1">push!</span>(FB, <span class="pl-c1">4.2</span> <span class="pl-k">+</span> <span class="pl-c1">0.9im</span>)
<span class="pl-c1">push!</span>(LB, <span class="pl-c1">rand</span>(<span class="pl-c1">3</span>))
<span class="pl-c1">append!</span>(EP, [<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>], [<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>])</pre></div>
<p dir="auto">And after all the data has been accumulated we can get statistics of binned data. By default the bin sizes/binning level is picked so that at least 32 bins are included:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Get statistics with at least 32 bins
x  = mean(LB)

# Variance
v = var(FB)

# standard error of the mean
Δx = std_error(LB) 

# autocorrelation time
tau_x = tau(FB) "><pre><span class="pl-c"><span class="pl-c">#</span> Get statistics with at least 32 bins</span>
x  <span class="pl-k">=</span> <span class="pl-c1">mean</span>(LB)

<span class="pl-c"><span class="pl-c">#</span> Variance</span>
v <span class="pl-k">=</span> <span class="pl-c1">var</span>(FB)

<span class="pl-c"><span class="pl-c">#</span> standard error of the mean</span>
Δx <span class="pl-k">=</span> <span class="pl-c1">std_error</span>(LB) 

<span class="pl-c"><span class="pl-c">#</span> autocorrelation time</span>
tau_x <span class="pl-k">=</span> <span class="pl-c1">tau</span>(FB) </pre></div>
<p dir="auto">Note that for <code>ErrorPropagator</code> you need to specify the data set you want to get statistics from. Alternatively you can also ask for statistics of all included samples by adding an <code>s</code> to the functions:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# mean of first data set
x = mean(EP, 1)

# standard error of the mean for the second
Δy = std_error(EP, 2)

# the autocorrelation time for each data set
tau_xy = taus(EP)"><pre><span class="pl-c"><span class="pl-c">#</span> mean of first data set</span>
x <span class="pl-k">=</span> <span class="pl-c1">mean</span>(EP, <span class="pl-c1">1</span>)

<span class="pl-c"><span class="pl-c">#</span> standard error of the mean for the second</span>
Δy <span class="pl-k">=</span> <span class="pl-c1">std_error</span>(EP, <span class="pl-c1">2</span>)

<span class="pl-c"><span class="pl-c">#</span> the autocorrelation time for each data set</span>
tau_xy <span class="pl-k">=</span> <span class="pl-c1">taus</span>(EP)</pre></div>
<p dir="auto">If you are interested in a different binning level you can specify it through an optional argument. You can also get statistics for all binning levels through functions with the <code>all_</code> prefix:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Standard error with binsize 2^(3-1) = 4
Δx4 = std_error(LB, 3)

# autocorrelation time with binsize 7
Δx7 = tau(FB, 7)

# Variance for every binning levels
vs = all_vars(LB)"><pre><span class="pl-c"><span class="pl-c">#</span> Standard error with binsize 2^(3-1) = 4</span>
Δx4 <span class="pl-k">=</span> <span class="pl-c1">std_error</span>(LB, <span class="pl-c1">3</span>)

<span class="pl-c"><span class="pl-c">#</span> autocorrelation time with binsize 7</span>
Δx7 <span class="pl-k">=</span> <span class="pl-c1">tau</span>(FB, <span class="pl-c1">7</span>)

<span class="pl-c"><span class="pl-c">#</span> Variance for every binning levels</span>
vs <span class="pl-k">=</span> <span class="pl-c1">all_vars</span>(LB)</pre></div>
<p dir="auto">Note that the <code>all_</code> functions include all bin sizes from 1 to <code>div(length(FB), 32)</code> for a <code>FullBinner</code>. For large samples this can be a lot, so it maybe preferable to sample bin sizes manually instead. For <code>LogBinner</code> and <code>ErrorPropagator</code> there are only <code>log₂(N)</code> binsizes so this shouldn't be a problem.</p>
<h2 dir="auto"><a id="user-content-resampling-methods" class="anchor" aria-hidden="true" href="#resampling-methods"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Resampling methods</h2>
<p dir="auto">The resampling methods currently only include jackknife.</p>
<h3 dir="auto"><a id="user-content-jackknife" class="anchor" aria-hidden="true" href="#jackknife"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Jackknife</h3>
<p dir="auto">The jackknife algorithm estimates the mean and standard error of a function applied to a sample <code>x</code>. A general k-jackknife does this by creating sub-samples with N-k values, applying the function to the means of these sub-samples and calculating statistics of the results. Our implementation uses <code>k = 1</code> and allows for any number of samples:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="x = rand(100)

# jackknife estimates for mean and standard error of &lt;x&gt;
xmean, Δx = jackknife(identity, x)

# in this example
# isapprox(Δx, std(x)/sqrt(length(x))) == true

# jackknife estimates for mean and standard error of &lt;1/x&gt;
x_inv_mean, Δx_inv = jackknife(identity, 1 ./ x) 

# Multiple time series
x = rand(100)
y = rand(100)

# The inputs of the function `g` must be provided as arguments in `jackknife`.
g(x, y, xy) = x * y / xy  # &lt;x&gt;&lt;y&gt; / &lt;xy&gt;
g_mean, Δg = jackknife(g, x, y, x .* y)"><pre>x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">100</span>)

<span class="pl-c"><span class="pl-c">#</span> jackknife estimates for mean and standard error of &lt;x&gt;</span>
xmean, Δx <span class="pl-k">=</span> <span class="pl-c1">jackknife</span>(identity, x)

<span class="pl-c"><span class="pl-c">#</span> in this example</span>
<span class="pl-c"><span class="pl-c">#</span> isapprox(Δx, std(x)/sqrt(length(x))) == true</span>

<span class="pl-c"><span class="pl-c">#</span> jackknife estimates for mean and standard error of &lt;1/x&gt;</span>
x_inv_mean, Δx_inv <span class="pl-k">=</span> <span class="pl-c1">jackknife</span>(identity, <span class="pl-c1">1</span> <span class="pl-k">./</span> x) 

<span class="pl-c"><span class="pl-c">#</span> Multiple time series</span>
x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">100</span>)
y <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">100</span>)

<span class="pl-c"><span class="pl-c">#</span> The inputs of the function `g` must be provided as arguments in `jackknife`.</span>
<span class="pl-en">g</span>(x, y, xy) <span class="pl-k">=</span> x <span class="pl-k">*</span> y <span class="pl-k">/</span> xy  <span class="pl-c"><span class="pl-c">#</span> &lt;x&gt;&lt;y&gt; / &lt;xy&gt;</span>
g_mean, Δg <span class="pl-k">=</span> <span class="pl-c1">jackknife</span>(g, x, y, x <span class="pl-k">.*</span> y)</pre></div>
<h3 dir="auto"><a id="user-content-error-propagator" class="anchor" aria-hidden="true" href="#error-propagator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Error Propagator</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="ep = ErrorPropagator(N_args=1)
# Essentially a LogBinner that can hold multiple variables. Errors can be derived
# for functions which depend on these variables. The memory overhead of this
# type is O(N_args^2 log(N_samples)), making it much cheaper than jackknife for
# few variables

push!(ep, rand())
append!(ep, rand(99))

# Mean and error of the (first) input
xmean = mean(ep, 1)
Δx = std_error(ep, 1)

# To compute the mean and error of a function we need its gradient
f(x) = x.^2
dfdx(x) = 2x
y = mean(ep, f)[1]
Δy = std_error(ep, dfdx)[1]

# Error propagator with multiple variables:
ep = ErrorPropagator(N_args=3)

# Multiple time series
x = rand(100)
y = rand(100)
append!(ep, x, y, x.*y)

# means and standard error of inputs:
xs = means(ep)
Δxs = std_errors(ep)

# mean and error of a function dependant on x, y and xy
# Note that this function takes a vector input
g(v) = v[1] * v[2] / v[3]  # &lt;x&gt;&lt;y&gt; / &lt;xy&gt;
dgdx(v) = [v[2]/v[3], v[1]/v[3], -v[1]*v[2]/v[3]^2]
g_mean = mean(ep, g)
Δg = std_error(ep, dgdx)"><pre>ep <span class="pl-k">=</span> <span class="pl-c1">ErrorPropagator</span>(N_args<span class="pl-k">=</span><span class="pl-c1">1</span>)
<span class="pl-c"><span class="pl-c">#</span> Essentially a LogBinner that can hold multiple variables. Errors can be derived</span>
<span class="pl-c"><span class="pl-c">#</span> for functions which depend on these variables. The memory overhead of this</span>
<span class="pl-c"><span class="pl-c">#</span> type is O(N_args^2 log(N_samples)), making it much cheaper than jackknife for</span>
<span class="pl-c"><span class="pl-c">#</span> few variables</span>

<span class="pl-c1">push!</span>(ep, <span class="pl-c1">rand</span>())
<span class="pl-c1">append!</span>(ep, <span class="pl-c1">rand</span>(<span class="pl-c1">99</span>))

<span class="pl-c"><span class="pl-c">#</span> Mean and error of the (first) input</span>
xmean <span class="pl-k">=</span> <span class="pl-c1">mean</span>(ep, <span class="pl-c1">1</span>)
Δx <span class="pl-k">=</span> <span class="pl-c1">std_error</span>(ep, <span class="pl-c1">1</span>)

<span class="pl-c"><span class="pl-c">#</span> To compute the mean and error of a function we need its gradient</span>
<span class="pl-en">f</span>(x) <span class="pl-k">=</span> x<span class="pl-k">.^</span><span class="pl-c1">2</span>
<span class="pl-en">dfdx</span>(x) <span class="pl-k">=</span> <span class="pl-c1">2</span>x
y <span class="pl-k">=</span> <span class="pl-c1">mean</span>(ep, f)[<span class="pl-c1">1</span>]
Δy <span class="pl-k">=</span> <span class="pl-c1">std_error</span>(ep, dfdx)[<span class="pl-c1">1</span>]

<span class="pl-c"><span class="pl-c">#</span> Error propagator with multiple variables:</span>
ep <span class="pl-k">=</span> <span class="pl-c1">ErrorPropagator</span>(N_args<span class="pl-k">=</span><span class="pl-c1">3</span>)

<span class="pl-c"><span class="pl-c">#</span> Multiple time series</span>
x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">100</span>)
y <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">100</span>)
<span class="pl-c1">append!</span>(ep, x, y, x<span class="pl-k">.*</span>y)

<span class="pl-c"><span class="pl-c">#</span> means and standard error of inputs:</span>
xs <span class="pl-k">=</span> <span class="pl-c1">means</span>(ep)
Δxs <span class="pl-k">=</span> <span class="pl-c1">std_errors</span>(ep)

<span class="pl-c"><span class="pl-c">#</span> mean and error of a function dependant on x, y and xy</span>
<span class="pl-c"><span class="pl-c">#</span> Note that this function takes a vector input</span>
<span class="pl-en">g</span>(v) <span class="pl-k">=</span> v[<span class="pl-c1">1</span>] <span class="pl-k">*</span> v[<span class="pl-c1">2</span>] <span class="pl-k">/</span> v[<span class="pl-c1">3</span>]  <span class="pl-c"><span class="pl-c">#</span> &lt;x&gt;&lt;y&gt; / &lt;xy&gt;</span>
<span class="pl-en">dgdx</span>(v) <span class="pl-k">=</span> [v[<span class="pl-c1">2</span>]<span class="pl-k">/</span>v[<span class="pl-c1">3</span>], v[<span class="pl-c1">1</span>]<span class="pl-k">/</span>v[<span class="pl-c1">3</span>], <span class="pl-k">-</span>v[<span class="pl-c1">1</span>]<span class="pl-k">*</span>v[<span class="pl-c1">2</span>]<span class="pl-k">/</span>v[<span class="pl-c1">3</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>]
g_mean <span class="pl-k">=</span> <span class="pl-c1">mean</span>(ep, g)
Δg <span class="pl-k">=</span> <span class="pl-c1">std_error</span>(ep, dgdx)</pre></div>
<h2 dir="auto"><a id="user-content-convenience-wrapper" class="anchor" aria-hidden="true" href="#convenience-wrapper"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Convenience wrapper</h2>
<p dir="auto">If you want to calculate the standard error of an existing time series there you can use the convenience wrapper <code>std_error(x[; method=:log])</code>. It takes a keyword argument <code>method</code>, which can be <code>:log</code>, <code>:full</code>, or <code>:jackknife</code>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="ts = rand(1000);
std_error(ts) # default is logarithmic binning
std_error(ts, method=:full)"><pre>ts <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">1000</span>);
<span class="pl-c1">std_error</span>(ts) <span class="pl-c"><span class="pl-c">#</span> default is logarithmic binning</span>
<span class="pl-c1">std_error</span>(ts, method<span class="pl-k">=</span><span class="pl-c1">:full</span>)</pre></div>
<h2 dir="auto"><a id="user-content-supported-types" class="anchor" aria-hidden="true" href="#supported-types"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Supported types</h2>
<p dir="auto">All statistical tools should work with number-like (<code>&lt;: Number</code>) and array-like (<code>&lt;: AbstractArray</code>) elements. Regarding complex numbers, we follow base Julia and define
<code>var(x) = var(real(x)) + var(imag(x))</code>.</p>
<p dir="auto">If you observe unexpected behavior please file an issue!</p>
<h2 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<ul dir="auto">
<li>J. Gubernatis, N. Kawashima, and P. Werner, <a href="https://www.cambridge.org/core/books/quantum-monte-carlo-methods/AEA92390DA497360EEDA153CF1CEC7AC" rel="nofollow">Quantum Monte Carlo Methods: Algorithms for Lattice Models</a>, Book (2016)</li>
<li>V. Ambegaokar, and M. Troyer, <a href="http://aapt.scitation.org/doi/10.1119/1.3247985" rel="nofollow">Estimating errors reliably in Monte Carlo simulations of the Ehrenfest model</a>, American Journal of Physics 78, 150 (2010)</li>
</ul>
</article></div>