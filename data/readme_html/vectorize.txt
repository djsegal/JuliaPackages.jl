<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-vectorize" class="anchor" aria-hidden="true" href="#vectorize"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Vectorize</h1>
<p><a href="http://vectorizejl.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img src="https://camo.githubusercontent.com/2accbe2f98e3ec1dbe15828abb2fa4161bb6978fcce7e8d33ad2000aa75b9d94/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f766563746f72697a656a6c2f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/vectorizejl/badge/?version=latest" style="max-width:100%;"></a>
<a href=""><img src="https://camo.githubusercontent.com/11eea6a85beaefb8a65ac1cfc630bdec37a1de6fcc6b62388d412b829a302da9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6173686170652f6170697374617475732e7376673f6d61784167653d32353932303030" alt="license" data-canonical-src="https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000" style="max-width:100%;"></a>
<a href="https://travis-ci.org/rprechelt/Vectorize.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/59ab610afb2a0c3799536a6c1921114b6a4d98dec310ade628539e8f44bb4338/68747470733a2f2f7472617669732d63692e6f72672f727072656368656c742f566563746f72697a652e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/rprechelt/Vectorize.jl.svg?branch=master" style="max-width:100%;"></a></p>
<h2><a id="user-content-features" class="anchor" aria-hidden="true" href="#features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Features</h2>
<p>Vectorize.jl provides a unified interface to the high-performance vectorized functions provided by Apple's <a href="https://developer.apple.com/reference/accelerate" rel="nofollow">Accelerate</a> framework (OS X only), Intel's <a href="https://software.intel.com/en-us/node/521751" rel="nofollow">VML</a> (part of MKL) and <a href="http://www.yeppp.info/" rel="nofollow">Yeppp!</a>; currently, over 160 functions are supported. These can be accessed using the <code>Vectorize.LibraryName.Function()</code> syntax i.e.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Vectorize.Accelerate.exp(X)
Vectorize.VML.erf(X)
Vectorize.Yeppp.log(x)
"><pre><code>Vectorize.Accelerate.exp(X)
Vectorize.VML.erf(X)
Vectorize.Yeppp.log(x)
</code></pre></div>
<p>Furthermore, a complete benchmarking suite is run during package installation that automatically selects the fastest implementation <em>for your architecture</em> on a function-by-function basis; this means that calls to</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Vectorize.sin(X)
"><pre><code>Vectorize.sin(X)
</code></pre></div>
<p>will be transparently mapped to the Accelerate, VML or Yeppp! implementation based upon the performance of these frameworks on <em>your particular machine</em> and the type of <code>X</code>. This mapping happens during package installation and so occurs no runtime overhead (expect to wait a few extra seconds than normal to install this package as the benchmarking suite needs to be run).</p>
<p>Vectorize.jl provides a <code>@vectorize</code> macro that automatically converts a call to Julia's standard implementation into the fastest vectorized equivalent available on your machine, i.e.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="cos(X)    # Standard Julia implementation
@vectorize cos(X)    # Converted to Yeppp, VML, or Accelerate at compile time
"><pre><code>cos(X)    # Standard Julia implementation
@vectorize cos(X)    # Converted to Yeppp, VML, or Accelerate at compile time
</code></pre></div>
<p>This macro provides an easy method for code to be quickly converted to use Vectorize.jl with little additional effort.</p>
<p>Vectorize.jl also provides a <code>@replacebase</code> macro that automatically overloads base broadcasting calls into the fastest vectorized equivalent available.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="X.^(-1/3)  # Standard Julia broadcast implementation
Z .= cis.(X)   # Standard Julia in-place broadcast implementation

@replacebase cis # Overloads both in-place and out-of-place broadcast calls to cis, provided cis is not fused in the broadcast
@replacebase ^ # Note: ^ (pow) is currently only available for VML

X.^(-1/3)  # This call now uses Vectorize.pow(X, -1/3)
Z .= cis.(X)   # This call now uses Vectorize.cis!

@replacebase # This will overload all functions that were benchmarked by Vectorize.jl
"><pre><code>X.^(-1/3)  # Standard Julia broadcast implementation
Z .= cis.(X)   # Standard Julia in-place broadcast implementation

@replacebase cis # Overloads both in-place and out-of-place broadcast calls to cis, provided cis is not fused in the broadcast
@replacebase ^ # Note: ^ (pow) is currently only available for VML

X.^(-1/3)  # This call now uses Vectorize.pow(X, -1/3)
Z .= cis.(X)   # This call now uses Vectorize.cis!

@replacebase # This will overload all functions that were benchmarked by Vectorize.jl
</code></pre></div>
<p>This macro allows pre-existing code to take advantage of optimized vectorized implementations with only a line of code. Note that if the broadcast call is multiple function calls fused together, the Vectorize.jl version will not be used, so some care must be taken to write simple broadcasts.</p>
<p>The performance benefits are significant; the two plots below the runtime reduction for a small selection of operators available in Vectorize.jl. This data was collected on a 2.5GHz Intel i7 running on OS X; each function was called immediately prior to benchmarking to ensure precompilation, before calculating the average over ten executions using <code>Vector{Float64}</code> of length 100.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/rprechelt/Vectorize.jl/master/doc/images/accelerate.png"><img src="https://raw.githubusercontent.com/rprechelt/Vectorize.jl/master/doc/images/accelerate.png" alt="Accelerate Benchmark" style="max-width:100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/rprechelt/Vectorize.jl/master/doc/images/vectorize.png"><img src="https://raw.githubusercontent.com/rprechelt/Vectorize.jl/master/doc/images/vectorize.png" alt="Vectorize Benchmark" style="max-width:100%;"></a></p>
<p>These functions can provide orders of magnitude higher-performance than the standard functions in Julia; over 10-fold improvements are common for functions throughout the three libraries. Since these functions are designed to operate on moderate-to-large sized arrays, they tend to be less performant that standard Julia functions for arrays of length less than 10 elements; in that case, it is best not to use Vectorize.jl.</p>
<p>Vectorize.jl will transparently select from the different frameworks that are available on your machine; you are not required to have any particular framework installed (although having all three tends to provide the best performance as different frameworks have different strengths). For users not running OS X, we strongly recommend installing Intel's VML (free for open-source projects under the community license - other licenses are available) as the only other library available for non-OSX systems is Yeppp, and Yeppp only provides a very small collection of functions.</p>
<p>This package currently supports over 40 functions over <code>Float32</code>, <code>Float64</code>, <code>Complex{Float32}</code>, and <code>Complex{Float64}</code>; <code>Vectorize.Yeppp</code> also provides access to various Yeppp functions over <code>UInt8</code>, <code>UInt16</code>, <code>UInt32</code>, <code>UInt64</code>, <code>Int8</code>, <code>Int16</code>, <code>Int32</code>, and <code>Int64</code> (although these are not benchmarked as neither Accelerate or VML provide equivalent functions). Every function provided by VML is currently supported, alongside the vast majority of optimized Yeppp functions and an equivalent portion of Accelerate. Please see the documentation for a complete list of provided functions and implementations.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>To install the latest version of Vectorize from <code>master</code>, run</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Pkg.clone(&quot;http://github.com/rprechelt/Vectorize.jl&quot;)
"><pre><code>Pkg.clone("http://github.com/rprechelt/Vectorize.jl")
</code></pre></div>
<p>from a Julia REPL on OS X, Linux, or Windows.</p>
<p>On Windows, you will need <code>wget64</code> and <code>7-Zip</code> installed and available in your <code>PATH</code> (in order to download and decompress Yeppp)</p>
<p>Once the package has finished cloning, run</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Pkg.build(&quot;Vectorize&quot;)
"><pre><code>Pkg.build("Vectorize")
</code></pre></div>
<p>This will print the build status to the terminal; you will be notified if the build completes successfully. This will attempt to determine which frameworks are available on your machine and incorporate those frameworks into the benchmarking process; if it is unable to locate Yeppp!, it will download a local copy and store it in the Vectorize.jl package directory (no changes are made to your system by installing Vectorize.jl). The build process will report what frameworks it is able to find - if it unable to find your system-installed version of Yeppp! or MKL, please ensure that they are both in your system PATH.</p>
<p>If the build fails, or it is unable to find system-installed packages correctly, please create an issue on Github and copy the output of <code>Pkg.build()</code> into the issue. This will help in debugging the build failures.</p>
</article></div>