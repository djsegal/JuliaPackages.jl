<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-covariancematricesjl" class="anchor" aria-hidden="true" href="#covariancematricesjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>CovarianceMatrices.jl</h1>
<p dir="auto"><a href="https://travis-ci.org/gragusa/CovarianceMatrices.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/8dfde2984169265eccae3c0f1672a2859d0ca7a675d05be7e399f579935a5ba0/68747470733a2f2f7472617669732d63692e6f72672f677261677573612f436f76617269616e63654d617472696365732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/gragusa/CovarianceMatrices.jl.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://coveralls.io/github/gragusa/CovarianceMatrices.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/44f731469ca22ff74e738c21531b4320627a6cde4f5db113a3d21069b8a5bad6/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f677261677573612f436f76617269616e63654d617472696365732e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/gragusa/CovarianceMatrices.jl/badge.svg?branch=master&amp;service=github" style="max-width: 100%;"></a>
<a href="http://codecov.io/github/gragusa/CovarianceMatrices.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/f053ec49378b8079a5cb7ccd07aeb2811f26907f4215c8e5e9a63b73229d9d7d/687474703a2f2f636f6465636f762e696f2f6769746875622f677261677573612f436f76617269616e63654d617472696365732e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/gragusa/CovarianceMatrices.jl/coverage.svg?branch=master" style="max-width: 100%;"></a></p>
<p dir="auto">Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimation for Julia.</p>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="Pkg.add(&quot;CovarianceMatrices&quot;)"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>CovarianceMatrices<span class="pl-pds">"</span></span>)</pre></div>
<hr>
<h2 dir="auto"><a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Introduction</h2>
<p dir="auto">This package provides types and methods useful to obtain consistent estimates of the long run covariance matrix of a random process.</p>
<p dir="auto">Three classes of estimators are considered:</p>
<ol dir="auto">
<li><strong>HAC</strong> - heteroskedasticity and autocorrelation consistent (Andrews, 1996; Newey and West, 1994)</li>
<li><strong>VARHAC</strong> - Vector Autoregression based HAC (Den Haan and Levine)</li>
<li><strong>Smoothed</strong> - (Smith, 2014)</li>
<li><strong>HC</strong>  - hetheroskedasticity consistent (White, 1982)</li>
<li><strong>CRVE</strong> - cluster robust (Arellano, 1986)</li>
</ol>
<p dir="auto">The typical application of these estimators is to conduct robust inference about parameters of a statistical model.</p>
<p dir="auto">The package extends methods defined in <a href="http://github.com/JuliaStat/StatsBase.jl">StatsBase.jl</a> and <a href="http://github.com/JuliaStat/GLM.jl">GLM.jl</a> to provide a plug-and-play replacement for the  standard errors calculated by default by <a href="http://github.com/JuliaStat/GLM.jl">GLM.jl</a>.</p>
<p dir="auto">The API can be used regardless of whether the model is fit with <a href="http://github.com/JuliaStat/GLM.jl">GLM.jl</a> and developer can extend their fit functions to provides robust standard errors.</p>
<h1 dir="auto"><a id="user-content-quick-tour" class="anchor" aria-hidden="true" href="#quick-tour"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick tour</h1>
<h2 dir="auto"><a id="user-content-hac-heteroskedasticity-and-autocorrelation-consistent" class="anchor" aria-hidden="true" href="#hac-heteroskedasticity-and-autocorrelation-consistent"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>HAC (Heteroskedasticity and Autocorrelation Consistent)</h2>
<p dir="auto">Available kernel types are:</p>
<ul dir="auto">
<li><code>TruncatedKernel</code></li>
<li><code>BartlettKernel</code></li>
<li><code>ParzenKernel</code></li>
<li><code>TukeyHanningKernel</code></li>
<li><code>QuadraticSpectralKernel</code></li>
</ul>
<p dir="auto">For example, <code>ParzenKernel{NeweyWest}()</code> return an instance of <code>TruncatedKernel</code> parametrized by <code>NeweyWest</code>, the type that corresponds to the optimal bandwidth calculated following Newey and West (1994).  Similarly, <code>ParzenKernel{Andrews}()</code> corresponds to the optimal bandwidth obtained in Andrews (1991). If the bandwidth is known, it can be directly passed, i.e. <code>TruncatedKernel(2)</code>.</p>
<h3 dir="auto"><a id="user-content-long-run-variance-of-regression-coefficients" class="anchor" aria-hidden="true" href="#long-run-variance-of-regression-coefficients"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Long run variance of regression coefficients</h3>
<p dir="auto">In the regression context, the function <code>vcov</code> does all the work:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="vcov(::HAC, ::DataFrameRegressionModel; prewhite = true)"><pre><span class="pl-c1">vcov</span>(<span class="pl-k">::</span><span class="pl-c1">HAC</span>, <span class="pl-k">::</span><span class="pl-c1">DataFrameRegressionModel</span>; prewhite <span class="pl-k">=</span> <span class="pl-c1">true</span>)</pre></div>
<p dir="auto">Consider the following artificial data (a regression with autoregressive error component):</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using CovarianceMatrices
using Random, DataFrames, GLM
Random.seed!(1)
n = 500
x = randn(n,5)
u = zeros(2*n)
u[1] = rand()
for j in 2:2*n
    u[j] = 0.78*u[j-1] + randn()
end
u = u[n+1:2*n]
y = 0.1 .+ x*[0.2, 0.3, 0.0, 0.0, 0.5] + u

df = convert(DataFrame,x)
df[!,:y] = y"><pre><span class="pl-k">using</span> CovarianceMatrices
<span class="pl-k">using</span> Random, DataFrames, GLM
Random<span class="pl-k">.</span><span class="pl-c1">seed!</span>(<span class="pl-c1">1</span>)
n <span class="pl-k">=</span> <span class="pl-c1">500</span>
x <span class="pl-k">=</span> <span class="pl-c1">randn</span>(n,<span class="pl-c1">5</span>)
u <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">2</span><span class="pl-k">*</span>n)
u[<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">rand</span>()
<span class="pl-k">for</span> j <span class="pl-k">in</span> <span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">*</span>n
    u[j] <span class="pl-k">=</span> <span class="pl-c1">0.78</span><span class="pl-k">*</span>u[j<span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-k">+</span> <span class="pl-c1">randn</span>()
<span class="pl-k">end</span>
u <span class="pl-k">=</span> u[n<span class="pl-k">+</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">*</span>n]
y <span class="pl-k">=</span> <span class="pl-c1">0.1</span> <span class="pl-k">.+</span> x<span class="pl-k">*</span>[<span class="pl-c1">0.2</span>, <span class="pl-c1">0.3</span>, <span class="pl-c1">0.0</span>, <span class="pl-c1">0.0</span>, <span class="pl-c1">0.5</span>] <span class="pl-k">+</span> u

df <span class="pl-k">=</span> <span class="pl-c1">convert</span>(DataFrame,x)
df[<span class="pl-k">!</span>,<span class="pl-c1">:y</span>] <span class="pl-k">=</span> y</pre></div>
<p dir="auto">Using the data in <code>df</code>, the coefficient of the regression can be estimated using <code>GLM</code></p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="lm1 = glm(@formula(y~x1+x2+x3+x4+x5), df, Normal(), IdentityLink())"><pre>lm1 <span class="pl-k">=</span> <span class="pl-c1">glm</span>(<span class="pl-c1">@formula</span>(y<span class="pl-k">~</span>x1<span class="pl-k">+</span>x2<span class="pl-k">+</span>x3<span class="pl-k">+</span>x4<span class="pl-k">+</span>x5), df, <span class="pl-c1">Normal</span>(), <span class="pl-c1">IdentityLink</span>())</pre></div>
<p dir="auto">To get a consistent estimate of the long run variance of the estimated coefficients using a Quadratic Spectral kernel with automatic bandwidth selection  <em>à la</em> Andrews</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="vcov(QuadraticSpectralKernel{Andrews}(), lm1, prewhite = false)"><pre><span class="pl-c1">vcov</span>(<span class="pl-c1">QuadraticSpectralKernel</span><span class="pl-c1">{Andrews}</span>(), lm1, prewhite <span class="pl-k">=</span> <span class="pl-c1">false</span>)</pre></div>
<p dir="auto">If one wants to estimate the long-time variance using the same kernel, but with a bandwidth selected <em>à la</em> Newey-West</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="vcov(QuadraticSpectralKernel{NeweyWest}(), lm1, prewhite = false)"><pre><span class="pl-c1">vcov</span>(<span class="pl-c1">QuadraticSpectralKernel</span><span class="pl-c1">{NeweyWest}</span>(), lm1, prewhite <span class="pl-k">=</span> <span class="pl-c1">false</span>)</pre></div>
<p dir="auto">The standard errors can be obtained by the <code>stderror</code> method</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="stderror( ::HAC, ::DataFrameRegressionModel; prewhite::Bool)"><pre><span class="pl-c1">stderror</span>( <span class="pl-k">::</span><span class="pl-c1">HAC</span>, <span class="pl-k">::</span><span class="pl-c1">DataFrameRegressionModel</span>; prewhite<span class="pl-k">::</span><span class="pl-c1">Bool</span>)</pre></div>
<p dir="auto">For the previous example:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="stderror(QuadraticSpectralKernel{NeweyWest}(), lm1, prewhite = false)"><pre><span class="pl-c1">stderror</span>(<span class="pl-c1">QuadraticSpectralKernel</span><span class="pl-c1">{NeweyWest}</span>(), lm1, prewhite <span class="pl-k">=</span> <span class="pl-c1">false</span>)</pre></div>
<p dir="auto">Sometime is useful to access the bandwidth selected by the automatic procedures. This can be done using the <code>optimalbandwidth</code> method</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="optimalbandwidth(QuadraticSpectralKernel{NeweyWest}(), lm1; prewhite = false)
optimalbandwidth(QuadraticSpectralKernel{Andrews}(), lm1; prewhite = false)"><pre><span class="pl-c1">optimalbandwidth</span>(<span class="pl-c1">QuadraticSpectralKernel</span><span class="pl-c1">{NeweyWest}</span>(), lm1; prewhite <span class="pl-k">=</span> <span class="pl-c1">false</span>)
<span class="pl-c1">optimalbandwidth</span>(<span class="pl-c1">QuadraticSpectralKernel</span><span class="pl-c1">{Andrews}</span>(), lm1; prewhite <span class="pl-k">=</span> <span class="pl-c1">false</span>)</pre></div>
<p dir="auto">Alternatively, the optimal bandwidth is stored in the kernel structure (upon calculation of the variance) and can be accessed. This requires however that the kernel type is materialized:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="kernel = QuadraticSpectralKernel{NeweyWest}()
stderror(kernel, lm1, prewhite = false)
bw = CovarianceMatrices.bandwidth(kernel)"><pre>kernel <span class="pl-k">=</span> <span class="pl-c1">QuadraticSpectralKernel</span><span class="pl-c1">{NeweyWest}</span>()
<span class="pl-c1">stderror</span>(kernel, lm1, prewhite <span class="pl-k">=</span> <span class="pl-c1">false</span>)
bw <span class="pl-k">=</span> CovarianceMatrices<span class="pl-k">.</span><span class="pl-c1">bandwidth</span>(kernel)</pre></div>
<h3 dir="auto"><a id="user-content-covariances-without-glmjl" class="anchor" aria-hidden="true" href="#covariances-without-glmjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Covariances without <code>GLM.jl</code></h3>
<p dir="auto">One might want to calculate variance estimator when the regression (or some other model) is fit "manually". Below is an example of how this can be accomplished.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="X   = [ones(n) x]
_,K = size(X)
b   = X\y
res = y .- X*b
momentmatrix = X.*res
B   = inv(X'X)      # Jacobian of moment conditions
bw = CovarianceMatrices.optimalbandwidth(kernel, momentmatrix, prewhite=false)
A   = lrvar(QuadraticSpectralKernel(bw), momentmatrix, scale = n^2/(n-K))   # df adjustment is built into vcov
Σ   = B*A*B
Σ .- vcov(QuadraticSpectralKernel(bw), lm1, dof_adjustment=true)"><pre>X   <span class="pl-k">=</span> [<span class="pl-c1">ones</span>(n) x]
_,K <span class="pl-k">=</span> <span class="pl-c1">size</span>(X)
b   <span class="pl-k">=</span> X<span class="pl-k">\</span>y
res <span class="pl-k">=</span> y <span class="pl-k">.-</span> X<span class="pl-k">*</span>b
momentmatrix <span class="pl-k">=</span> X<span class="pl-k">.*</span>res
B   <span class="pl-k">=</span> <span class="pl-c1">inv</span>(X<span class="pl-k">'</span>X)      <span class="pl-c"><span class="pl-c">#</span> Jacobian of moment conditions</span>
bw <span class="pl-k">=</span> CovarianceMatrices<span class="pl-k">.</span><span class="pl-c1">optimalbandwidth</span>(kernel, momentmatrix, prewhite<span class="pl-k">=</span><span class="pl-c1">false</span>)
A   <span class="pl-k">=</span> <span class="pl-c1">lrvar</span>(<span class="pl-c1">QuadraticSpectralKernel</span>(bw), momentmatrix, scale <span class="pl-k">=</span> n<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">/</span>(n<span class="pl-k">-</span>K))   <span class="pl-c"><span class="pl-c">#</span> df adjustment is built into vcov</span>
Σ   <span class="pl-k">=</span> B<span class="pl-k">*</span>A<span class="pl-k">*</span>B
Σ <span class="pl-k">.-</span> <span class="pl-c1">vcov</span>(<span class="pl-c1">QuadraticSpectralKernel</span>(bw), lm1, dof_adjustment<span class="pl-k">=</span><span class="pl-c1">true</span>)</pre></div>
<p dir="auto">The utility function <code>sandwich</code> does all this automatically:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="vcov(QuadraticSpectralKernel(bw[1]), lm1, dof_adjustment=true) ≈ CovarianceMatrices.sandwich(QuadraticSpectralKernel(bw[1]), B, momentmatrix, dof = K)
vcov(QuadraticSpectralKernel(bw[1]), lm1, dof_adjustment=false) ≈ CovarianceMatrices.sandwich(QuadraticSpectralKernel(bw[1]), B, momentmatrix, dof = 0)"><pre><span class="pl-c1">vcov</span>(<span class="pl-c1">QuadraticSpectralKernel</span>(bw[<span class="pl-c1">1</span>]), lm1, dof_adjustment<span class="pl-k">=</span><span class="pl-c1">true</span>) <span class="pl-k">≈</span> CovarianceMatrices<span class="pl-k">.</span><span class="pl-c1">sandwich</span>(<span class="pl-c1">QuadraticSpectralKernel</span>(bw[<span class="pl-c1">1</span>]), B, momentmatrix, dof <span class="pl-k">=</span> K)
<span class="pl-c1">vcov</span>(<span class="pl-c1">QuadraticSpectralKernel</span>(bw[<span class="pl-c1">1</span>]), lm1, dof_adjustment<span class="pl-k">=</span><span class="pl-c1">false</span>) <span class="pl-k">≈</span> CovarianceMatrices<span class="pl-k">.</span><span class="pl-c1">sandwich</span>(<span class="pl-c1">QuadraticSpectralKernel</span>(bw[<span class="pl-c1">1</span>]), B, momentmatrix, dof <span class="pl-k">=</span> <span class="pl-c1">0</span>)</pre></div>
<h2 dir="auto"><a id="user-content-hc-heteroskedastic-consistent" class="anchor" aria-hidden="true" href="#hc-heteroskedastic-consistent"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>HC (Heteroskedastic consistent)</h2>
<p dir="auto">As in the HAC case, <code>vcov</code> and <code>stderror</code> are the main functions. They know get as argument the type of robust variance being sought</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="vcov(::HC, ::DataFrameRegressionModel)"><pre><span class="pl-c1">vcov</span>(<span class="pl-k">::</span><span class="pl-c1">HC</span>, <span class="pl-k">::</span><span class="pl-c1">DataFrameRegressionModel</span>)</pre></div>
<p dir="auto">Where HC is an abstract type with the following concrete types:</p>
<ul dir="auto">
<li><code>HC0</code></li>
<li><code>HC1</code> (this is <code>HC0</code> with the degree of freedom adjustment)</li>
<li><code>HC2</code></li>
<li><code>HC3</code></li>
<li><code>HC4</code></li>
<li><code>HC4m</code></li>
<li><code>HC5</code></li>
</ul>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using CovarianceMatrices, DataFrames, GLM
# A Gamma example, from McCullagh &amp; Nelder (1989, pp. 300-2)
# The weights are added just to test the interface and are not part
# of the original data
clotting = DataFrame(
    u    = log.([5,10,15,20,30,40,60,80,100]),
    lot1 = [118,58,42,35,27,25,21,19,18],
    lot2 = [69,35,26,21,18,16,13,12,12],
    w    = 9*[1/8, 1/9, 1/25, 1/6, 1/14, 1/25, 1/15, 1/13, 0.3022039]
)
wOLS = fit(GeneralizedLinearModel, @formula(lot1~u), clotting, Normal(), wts = clotting[!,:w])

vcov(HC0(),wOLS)
vcov(HC1(),wOLS)
vcov(HC2(),wOLS)
vcov(HC3(),wOLS)
vcov(HC4(),wOLS)
vcov(HC4m(),wOLS)
vcov(HC5(),wOLS)
"><pre><span class="pl-k">using</span> CovarianceMatrices, DataFrames, GLM
<span class="pl-c"><span class="pl-c">#</span> A Gamma example, from McCullagh &amp; Nelder (1989, pp. 300-2)</span>
<span class="pl-c"><span class="pl-c">#</span> The weights are added just to test the interface and are not part</span>
<span class="pl-c"><span class="pl-c">#</span> of the original data</span>
clotting <span class="pl-k">=</span> <span class="pl-c1">DataFrame</span>(
    u    <span class="pl-k">=</span> <span class="pl-c1">log</span>.([<span class="pl-c1">5</span>,<span class="pl-c1">10</span>,<span class="pl-c1">15</span>,<span class="pl-c1">20</span>,<span class="pl-c1">30</span>,<span class="pl-c1">40</span>,<span class="pl-c1">60</span>,<span class="pl-c1">80</span>,<span class="pl-c1">100</span>]),
    lot1 <span class="pl-k">=</span> [<span class="pl-c1">118</span>,<span class="pl-c1">58</span>,<span class="pl-c1">42</span>,<span class="pl-c1">35</span>,<span class="pl-c1">27</span>,<span class="pl-c1">25</span>,<span class="pl-c1">21</span>,<span class="pl-c1">19</span>,<span class="pl-c1">18</span>],
    lot2 <span class="pl-k">=</span> [<span class="pl-c1">69</span>,<span class="pl-c1">35</span>,<span class="pl-c1">26</span>,<span class="pl-c1">21</span>,<span class="pl-c1">18</span>,<span class="pl-c1">16</span>,<span class="pl-c1">13</span>,<span class="pl-c1">12</span>,<span class="pl-c1">12</span>],
    w    <span class="pl-k">=</span> <span class="pl-c1">9</span><span class="pl-k">*</span>[<span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">8</span>, <span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">9</span>, <span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">25</span>, <span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">6</span>, <span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">14</span>, <span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">25</span>, <span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">15</span>, <span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">13</span>, <span class="pl-c1">0.3022039</span>]
)
wOLS <span class="pl-k">=</span> <span class="pl-c1">fit</span>(GeneralizedLinearModel, <span class="pl-c1">@formula</span>(lot1<span class="pl-k">~</span>u), clotting, <span class="pl-c1">Normal</span>(), wts <span class="pl-k">=</span> clotting[<span class="pl-k">!</span>,<span class="pl-c1">:w</span>])

<span class="pl-c1">vcov</span>(<span class="pl-c1">HC0</span>(),wOLS)
<span class="pl-c1">vcov</span>(<span class="pl-c1">HC1</span>(),wOLS)
<span class="pl-c1">vcov</span>(<span class="pl-c1">HC2</span>(),wOLS)
<span class="pl-c1">vcov</span>(<span class="pl-c1">HC3</span>(),wOLS)
<span class="pl-c1">vcov</span>(<span class="pl-c1">HC4</span>(),wOLS)
<span class="pl-c1">vcov</span>(<span class="pl-c1">HC4m</span>(),wOLS)
<span class="pl-c1">vcov</span>(<span class="pl-c1">HC5</span>(),wOLS)
</pre></div>
<h2 dir="auto"><a id="user-content-crhc-cluster-robust-heteroskedasticity-consistent" class="anchor" aria-hidden="true" href="#crhc-cluster-robust-heteroskedasticity-consistent"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>CRHC (Cluster robust heteroskedasticity consistent)</h2>
<p dir="auto">The API of this class of estimators is subject to change, so please use with care. The difficulty is that <code>CRHC</code> type needs to have access to the variable along which dimension the clustering must take place. For the moment, the following approach works</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using RDatasets
df = dataset(&quot;plm&quot;, &quot;Grunfeld&quot;)
lm = glm(@formula(Inv~Value+Capital), df, Normal(), IdentityLink())
vcov(CRHC1(:Firm, df), lm)
stderror(CRHC1(:Firm, df),lm)"><pre><span class="pl-k">using</span> RDatasets
df <span class="pl-k">=</span> <span class="pl-c1">dataset</span>(<span class="pl-s"><span class="pl-pds">"</span>plm<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Grunfeld<span class="pl-pds">"</span></span>)
lm <span class="pl-k">=</span> <span class="pl-c1">glm</span>(<span class="pl-c1">@formula</span>(Inv<span class="pl-k">~</span>Value<span class="pl-k">+</span>Capital), df, <span class="pl-c1">Normal</span>(), <span class="pl-c1">IdentityLink</span>())
<span class="pl-c1">vcov</span>(<span class="pl-c1">CRHC1</span>(<span class="pl-c1">:Firm</span>, df), lm)
<span class="pl-c1">stderror</span>(<span class="pl-c1">CRHC1</span>(<span class="pl-c1">:Firm</span>, df),lm)</pre></div>
<p dir="auto">Alternatively, the cluster indicator can be passed directly (but this will only work if there are not missing values)</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="vcov(CRHC1(df[:Firm]), lm)
stderror(CRHC1(df[:Firm]),lm)"><pre><span class="pl-c1">vcov</span>(<span class="pl-c1">CRHC1</span>(df[<span class="pl-c1">:Firm</span>]), lm)
<span class="pl-c1">stderror</span>(<span class="pl-c1">CRHC1</span>(df[<span class="pl-c1">:Firm</span>]),lm)</pre></div>
<p dir="auto">As in the <code>HAC</code> case, <code>sandwich</code> and <code>lrvar</code> can be leveraged to constract cluster-robust variances without relying on <code>GLM.jl</code>.</p>
<h2 dir="auto"><a id="user-content-performances" class="anchor" aria-hidden="true" href="#performances"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Performances</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using BenchmarkTools
## Calculating a HAC on a large matrix
Z = randn(10000, 10)
@btime lrvar(BartlettKernel{Andrews}(), Z, prewhite = true) 
## 2.085 ms (180 allocations: 6.20 MiB)"><pre><span class="pl-k">using</span> BenchmarkTools
<span class="pl-c"><span class="pl-c">#</span># Calculating a HAC on a large matrix</span>
Z <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">10000</span>, <span class="pl-c1">10</span>)
<span class="pl-c1">@btime</span> <span class="pl-c1">lrvar</span>(<span class="pl-c1">BartlettKernel</span><span class="pl-c1">{Andrews}</span>(), Z, prewhite <span class="pl-k">=</span> <span class="pl-c1">true</span>) 
<span class="pl-c"><span class="pl-c">#</span># 2.085 ms (180 allocations: 6.20 MiB)</span></pre></div>
<div class="highlight highlight-source-r notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="library(sandwich)
library(microbenchmark)
Z &lt;- matrix(rnorm(10000*10), 10000, 10)
microbenchmark( &quot;Bartlett/Newey&quot; = {lrvar(Z, type = &quot;Andrews&quot;, kernel = &quot;Bartlett&quot;)})
#Unit: milliseconds
#           expr      min       lq     mean   median       uq      max     neval
# Bartlett/Andrews 135.1839 148.3426 186.1966 155.0156 246.3178 355.3174   100"><pre>library(<span class="pl-smi">sandwich</span>)
library(<span class="pl-smi">microbenchmark</span>)
<span class="pl-smi">Z</span> <span class="pl-k">&lt;-</span> <span class="pl-k">matrix</span>(rnorm(<span class="pl-c1">10000</span><span class="pl-k">*</span><span class="pl-c1">10</span>), <span class="pl-c1">10000</span>, <span class="pl-c1">10</span>)
microbenchmark( <span class="pl-s"><span class="pl-pds">"</span>Bartlett/Newey<span class="pl-pds">"</span></span> <span class="pl-k">=</span> {lrvar(<span class="pl-smi">Z</span>, <span class="pl-v">type</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Andrews<span class="pl-pds">"</span></span>, <span class="pl-v">kernel</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Bartlett<span class="pl-pds">"</span></span>)})
<span class="pl-c"><span class="pl-c">#</span>Unit: milliseconds</span>
<span class="pl-c"><span class="pl-c">#</span>           expr      min       lq     mean   median       uq      max     neval</span>
<span class="pl-c"><span class="pl-c">#</span> Bartlett/Andrews 135.1839 148.3426 186.1966 155.0156 246.3178 355.3174   100</span></pre></div>
</article></div>