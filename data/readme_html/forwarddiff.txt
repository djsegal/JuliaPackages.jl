<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a href="https://github.com/JuliaDiff/ForwardDiff.jl/actions/workflows/ci.yml"><img src="https://github.com/JuliaDiff/ForwardDiff.jl/workflows/CI/badge.svg" alt="CI" style="max-width: 100%;"></a>
<a href="https://coveralls.io/github/JuliaDiff/ForwardDiff.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/cafac43248ae489f42c32698e6f35b0cc73928c46933f11226ef2385f806dc13/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c6961446966662f466f7277617264446966662e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/JuliaDiff/ForwardDiff.jl/badge.svg?branch=master&amp;service=github" style="max-width: 100%;"></a></p>
<p dir="auto"><a href="https://juliadiff.org/ForwardDiff.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://juliadiff.org/ForwardDiff.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a></p>
<h1 dir="auto"><a id="user-content-forwarddiffjl" class="anchor" aria-hidden="true" href="#forwarddiffjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ForwardDiff.jl</h1>
<p dir="auto">ForwardDiff implements methods to take <strong>derivatives</strong>, <strong>gradients</strong>, <strong>Jacobians</strong>, <strong>Hessians</strong>, and higher-order derivatives of native Julia functions (or any callable object, really) using <strong>forward mode automatic differentiation (AD)</strong>.</p>
<p dir="auto">While performance can vary depending on the functions you evaluate, the algorithms implemented by ForwardDiff generally outperform non-AD algorithms (such as finite-differencing) in both speed and accuracy.</p>
<p dir="auto">Here's a simple example showing the package in action:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using ForwardDiff

julia&gt; f(x::Vector) = sin(x[1]) + prod(x[2:end]);  # returns a scalar

julia&gt; x = vcat(pi/4, 2:4)
4-element Vector{Float64}:
 0.7853981633974483
 2.0
 3.0
 4.0

julia&gt; ForwardDiff.gradient(f, x)
4-element Vector{Float64}:
  0.7071067811865476
 12.0
  8.0
  6.0

julia&gt; ForwardDiff.hessian(f, x)
4×4 Matrix{Float64}:
 -0.707107  0.0  0.0  0.0
  0.0       0.0  4.0  3.0
  0.0       4.0  0.0  2.0
  0.0       3.0  2.0  0.0"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> ForwardDiff

julia<span class="pl-k">&gt;</span> <span class="pl-en">f</span>(x<span class="pl-k">::</span><span class="pl-c1">Vector</span>) <span class="pl-k">=</span> <span class="pl-c1">sin</span>(x[<span class="pl-c1">1</span>]) <span class="pl-k">+</span> <span class="pl-c1">prod</span>(x[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]);  <span class="pl-c"><span class="pl-c">#</span> returns a scalar</span>

julia<span class="pl-k">&gt;</span> x <span class="pl-k">=</span> <span class="pl-c1">vcat</span>(<span class="pl-c1">pi</span><span class="pl-k">/</span><span class="pl-c1">4</span>, <span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">4</span>)
<span class="pl-c1">4</span><span class="pl-k">-</span>element Vector{Float64}<span class="pl-k">:</span>
 <span class="pl-c1">0.7853981633974483</span>
 <span class="pl-c1">2.0</span>
 <span class="pl-c1">3.0</span>
 <span class="pl-c1">4.0</span>

julia<span class="pl-k">&gt;</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">gradient</span>(f, x)
<span class="pl-c1">4</span><span class="pl-k">-</span>element Vector{Float64}<span class="pl-k">:</span>
  <span class="pl-c1">0.7071067811865476</span>
 <span class="pl-c1">12.0</span>
  <span class="pl-c1">8.0</span>
  <span class="pl-c1">6.0</span>

julia<span class="pl-k">&gt;</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">hessian</span>(f, x)
<span class="pl-c1">4</span><span class="pl-k">×</span><span class="pl-c1">4</span> Matrix{Float64}<span class="pl-k">:</span>
 <span class="pl-k">-</span><span class="pl-c1">0.707107</span>  <span class="pl-c1">0.0</span>  <span class="pl-c1">0.0</span>  <span class="pl-c1">0.0</span>
  <span class="pl-c1">0.0</span>       <span class="pl-c1">0.0</span>  <span class="pl-c1">4.0</span>  <span class="pl-c1">3.0</span>
  <span class="pl-c1">0.0</span>       <span class="pl-c1">4.0</span>  <span class="pl-c1">0.0</span>  <span class="pl-c1">2.0</span>
  <span class="pl-c1">0.0</span>       <span class="pl-c1">3.0</span>  <span class="pl-c1">2.0</span>  <span class="pl-c1">0.0</span></pre></div>
<p dir="auto">Functions like <code>f</code> which map a vector to a scalar are the best case for reverse-mode automatic differentiation,
but ForwardDiff may still be a good choice if <code>x</code> is not too large, as it is much simpler.
The best case for forward-mode differentiation is a function which maps a scalar to a vector, like this <code>g</code>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; g(y::Real) = [sin(y), cos(y), tan(y)];  # returns a vector

julia&gt; ForwardDiff.derivative(g, pi/4)
3-element Vector{Float64}:
  0.7071067811865476
 -0.7071067811865475
  1.9999999999999998

julia&gt; ForwardDiff.jacobian(x) do x  # anonymous function, returns a length-2 vector
         [sin(x[1]), prod(x[2:end])]
       end
2×4 Matrix{Float64}:
 0.707107   0.0  0.0  0.0
 0.0       12.0  8.0  6.0"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-en">g</span>(y<span class="pl-k">::</span><span class="pl-c1">Real</span>) <span class="pl-k">=</span> [<span class="pl-c1">sin</span>(y), <span class="pl-c1">cos</span>(y), <span class="pl-c1">tan</span>(y)];  <span class="pl-c"><span class="pl-c">#</span> returns a vector</span>

julia<span class="pl-k">&gt;</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">derivative</span>(g, <span class="pl-c1">pi</span><span class="pl-k">/</span><span class="pl-c1">4</span>)
<span class="pl-c1">3</span><span class="pl-k">-</span>element Vector{Float64}<span class="pl-k">:</span>
  <span class="pl-c1">0.7071067811865476</span>
 <span class="pl-k">-</span><span class="pl-c1">0.7071067811865475</span>
  <span class="pl-c1">1.9999999999999998</span>

julia<span class="pl-k">&gt;</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">jacobian</span>(x) <span class="pl-k">do</span> x  <span class="pl-c"><span class="pl-c">#</span> anonymous function, returns a length-2 vector</span>
         [<span class="pl-c1">sin</span>(x[<span class="pl-c1">1</span>]), <span class="pl-c1">prod</span>(x[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>])]
       <span class="pl-k">end</span>
<span class="pl-c1">2</span><span class="pl-k">×</span><span class="pl-c1">4</span> Matrix{Float64}<span class="pl-k">:</span>
 <span class="pl-c1">0.707107</span>   <span class="pl-c1">0.0</span>  <span class="pl-c1">0.0</span>  <span class="pl-c1">0.0</span>
 <span class="pl-c1">0.0</span>       <span class="pl-c1">12.0</span>  <span class="pl-c1">8.0</span>  <span class="pl-c1">6.0</span></pre></div>
<p dir="auto">See <a href="https://juliadiff.org/ForwardDiff.jl/stable" rel="nofollow">ForwardDiff's documentation</a> for full details on how to use this package.
ForwardDiff relies on <a href="https://github.com/JuliaDiff/DiffRules.jl">DiffRules</a> for the derivatives of many simple function such as <code>sin</code>.</p>
<p dir="auto">See the <a href="https://juliadiff.org" rel="nofollow">JuliaDiff web page</a> for other automatic differentiation packages.</p>
<h2 dir="auto"><a id="user-content-publications" class="anchor" aria-hidden="true" href="#publications"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Publications</h2>
<p dir="auto">If you find ForwardDiff useful in your work, we kindly request that you cite <a href="https://arxiv.org/abs/1607.07892" rel="nofollow">the following paper</a>:</p>
<div class="highlight highlight-text-bibtex notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="@article{RevelsLubinPapamarkou2016,
    title = {Forward-Mode Automatic Differentiation in {J}ulia},
   author = {{Revels}, J. and {Lubin}, M. and {Papamarkou}, T.},
  journal = {arXiv:1607.07892 [cs.MS]},
     year = {2016},
      url = {https://arxiv.org/abs/1607.07892}
}"><pre><span class="pl-k">@article</span>{<span class="pl-en">RevelsLubinPapamarkou2016</span>,
    <span class="pl-s">title</span> = <span class="pl-s"><span class="pl-pds">{</span>Forward-Mode Automatic Differentiation in {J}ulia<span class="pl-pds">}</span></span>,
   <span class="pl-s">author</span> = <span class="pl-s"><span class="pl-pds">{</span>{Revels}, J. and {Lubin}, M. and {Papamarkou}, T.<span class="pl-pds">}</span></span>,
  <span class="pl-s">journal</span> = <span class="pl-s"><span class="pl-pds">{</span>arXiv:1607.07892 [cs.MS]<span class="pl-pds">}</span></span>,
     <span class="pl-s">year</span> = <span class="pl-s"><span class="pl-pds">{</span>2016<span class="pl-pds">}</span></span>,
      <span class="pl-s">url</span> = <span class="pl-s"><span class="pl-pds">{</span>https://arxiv.org/abs/1607.07892<span class="pl-pds">}</span></span>
}</pre></div>
</article></div>