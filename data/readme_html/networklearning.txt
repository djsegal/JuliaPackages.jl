<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-networklearning" class="anchor" aria-hidden="true" href="#networklearning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>NetworkLearning</h1>
<p>A Julia package for network learning.</p>
<p><a href="LICENSE.md"><img src="https://camo.githubusercontent.com/4440d5deb3a53c4f8661ee765378e6071e7878e8/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c6174" alt="License" data-canonical-src="http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" style="max-width:100%;"></a>
<a href="http://pkg.julialang.org/detail/NetworkLearning" rel="nofollow"><img src="https://camo.githubusercontent.com/8d36191bb9bbca6747d57c854c55f8084d6711af/687474703a2f2f706b672e6a756c69616c616e672e6f72672f6261646765732f4e6574776f726b4c6561726e696e675f302e362e737667" alt="NetworkLearning" data-canonical-src="http://pkg.julialang.org/badges/NetworkLearning_0.6.svg" style="max-width:100%;"></a>
<a href="https://travis-ci.org/zgornel/NetworkLearning.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/d1d7188aff3468a804ae86b8ec2dc8f4f24495c9/68747470733a2f2f7472617669732d63692e6f72672f7a676f726e656c2f4e6574776f726b4c6561726e696e672e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/zgornel/NetworkLearning.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/zgornel/NetworkLearning.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/b296ca28c3ce4f168a0de3b5ee7f18de53adb6a8/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7a676f726e656c2f4e6574776f726b4c6561726e696e672e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/zgornel/NetworkLearning.jl/badge.svg?branch=master" style="max-width:100%;"></a></p>
<h2><a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Introduction</h2>
<p>NetworkLearning implements a generic framework for network classification. It could in theory be used to provide additional functionality (i.e. semi-supervised learning, regression),
provided that appropriate methods for relational learning (i.e. relational variable generation) and collective inference are added. The framework is designed to make as little assumptions as possible on the elements involved in the process.</p>
<p>Two scenarios or usecases are covered:</p>
<ul>
<li>
<p><em>Observation-based learning</em>, in which the network structure is pertinent to the observations and consequently, estimates (i.e. class probabilities) are associated to the observations; in the estimation process, relational structures can either make use the training data (in-graph learning) or not (out-of-graph learning). For example, in the case of document classifcation, an observation would correspond to a publication that has to be classified into an arbitrary category, given a representation of its local content-based information as well on the its relational information (links to other documents, citations etc.).</p>
</li>
<li>
<p><em>Entity-based learning</em>, in which observations are pertinent to one or more abstract entities for which estimates are calculated. In entity-based network learning, observations can modify either the local or relational information of one or more entities.</p>
</li>
</ul>
<h2><a id="user-content-features" class="anchor" aria-hidden="true" href="#features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Features</h2>
<ul>
<li>
<p><strong>Learner type</strong></p>
<ul>
<li>observation-based</li>
<li>entity-based</li>
</ul>
</li>
<li>
<p><strong>Relational learners</strong></p>
<ul>
<li>simple relational neighbour</li>
<li>weighted/probabilistic relational neighbour</li>
<li>naive bayes</li>
<li>class distribution</li>
</ul>
</li>
<li>
<p><strong>Collective inference</strong></p>
<ul>
<li>relaxation labeling</li>
<li>collective classification</li>
<li>gibbs sampling (EXPERIMENTAL, slow)</li>
</ul>
</li>
<li>
<p><strong>Adjacency strucures</strong></p>
<ul>
<li>matrices</li>
<li>graphs</li>
<li>tuples containing functions and data from which adjacency matrices or graphs can be computed</li>
</ul>
</li>
</ul>
<h2><a id="user-content-observation-based-network-learning-example" class="anchor" aria-hidden="true" href="#observation-based-network-learning-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Observation-based network learning example</h2>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> DecisionTree
<span class="pl-k">using</span> NetworkLearning, MLDataPattern, MLLabelUtils, LossFunctions

<span class="pl-c"><span class="pl-c">#</span> Download the CORA dataset, and return data and citing/cited papers indices (relative to order in X,y)</span>
(X,y), cited_papers, citing_papers <span class="pl-k">=</span> NetworkLearning<span class="pl-k">.</span><span class="pl-c1">grab_cora_data</span>()
n <span class="pl-k">=</span> <span class="pl-c1">nobs</span>(X)
yᵤ <span class="pl-k">=</span> <span class="pl-c1">sort</span>(<span class="pl-c1">unique</span>(y))
C <span class="pl-k">=</span> <span class="pl-c1">length</span>(yᵤ)

<span class="pl-c"><span class="pl-c">#</span> Split data</span>
idx <span class="pl-k">=</span> <span class="pl-c1">collect</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>n);
<span class="pl-c1">shuffle!</span>(idx)
p <span class="pl-k">=</span> <span class="pl-c1">0.5</span>
idxtr,idxts <span class="pl-k">=</span> <span class="pl-c1">splitobs</span>(idx,p)
Xtr <span class="pl-k">=</span> X[:,idxtr]
ytr <span class="pl-k">=</span> y[idxtr]
Xts <span class="pl-k">=</span> X[:,idxts]

<span class="pl-c"><span class="pl-c">#</span> Build adjacency matrices</span>
Atr <span class="pl-k">=</span> NetworkLearning<span class="pl-k">.</span><span class="pl-c1">generate_partial_adjacency</span>(cited_papers, citing_papers, idxtr);

<span class="pl-c"><span class="pl-c">#</span> Construct necessary arguments for training the network learner</span>
fl_train <span class="pl-k">=</span> (X<span class="pl-k">::</span><span class="pl-c1">Tuple{Matrix{Float64}, Vector{Int}}</span>)<span class="pl-k">-&gt;</span>  DecisionTree<span class="pl-k">.</span><span class="pl-c1">build_tree</span>(X[<span class="pl-c1">2</span>],X[<span class="pl-c1">1</span>]')
<span class="pl-en">fl_exec</span>(C) <span class="pl-k">=</span> (m,X)<span class="pl-k">-&gt;</span> DecisionTree<span class="pl-k">.</span><span class="pl-c1">apply_tree_proba</span>(m, X<span class="pl-k">'</span>, <span class="pl-c1">collect</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>C))<span class="pl-k">'</span>

fr_train <span class="pl-k">=</span> (X)<span class="pl-k">-&gt;</span>  DecisionTree<span class="pl-k">.</span><span class="pl-c1">build_tree</span>(X[<span class="pl-c1">2</span>],X[<span class="pl-c1">1</span>]')
<span class="pl-en">fr_exec</span>(C) <span class="pl-k">=</span> (m,X)<span class="pl-k">-&gt;</span> DecisionTree<span class="pl-k">.</span><span class="pl-c1">apply_tree_proba</span>(m, X<span class="pl-k">'</span>, <span class="pl-c1">collect</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>C))<span class="pl-k">'</span>

AV <span class="pl-k">=</span> [<span class="pl-c1">adjacency</span>(Atr)]

<span class="pl-c"><span class="pl-c">#</span> Train</span>
<span class="pl-c1">info</span>(<span class="pl-s"><span class="pl-pds">"</span>Training ...<span class="pl-pds">"</span></span>)
nlmodel <span class="pl-k">=</span> NetworkLearning<span class="pl-k">.</span><span class="pl-c1">fit</span>(NetworkLearnerObs, 
	      Xtr,
	      ytr,
	      AV,
	      fl_train, <span class="pl-c1">fl_exec</span>(C),
	      fr_train, <span class="pl-c1">fr_exec</span>(C);
	      learner <span class="pl-k">=</span> <span class="pl-c1">:wrn</span>,
	      inference <span class="pl-k">=</span> <span class="pl-c1">:ic</span>,
	      use_local_data <span class="pl-k">=</span> <span class="pl-c1">false</span>, <span class="pl-c"><span class="pl-c">#</span> use only relational variables</span>
	      f_targets <span class="pl-k">=</span> x<span class="pl-k">-&gt;</span><span class="pl-c1">targets</span>(indmax,x),
	      normalize <span class="pl-k">=</span> <span class="pl-c1">true</span>,
	      maxiter <span class="pl-k">=</span> <span class="pl-c1">10</span>,
	      α <span class="pl-k">=</span> <span class="pl-c1">0.95</span>
	  )



<span class="pl-c"><span class="pl-c">#</span>########################</span>
<span class="pl-c"><span class="pl-c">#</span> Out-of-Graph learning #</span>
<span class="pl-c"><span class="pl-c">#</span>########################</span>

<span class="pl-c"><span class="pl-c">#</span> Add adjacency pertinent to the test data</span>
Ats <span class="pl-k">=</span> NetworkLearning<span class="pl-k">.</span><span class="pl-c1">generate_partial_adjacency</span>(cited_papers, citing_papers, idxts);
<span class="pl-c1">add_adjacency!</span>(nlmodel, [Ats])

<span class="pl-c"><span class="pl-c">#</span> Make predictions</span>
<span class="pl-c1">info</span>(<span class="pl-s"><span class="pl-pds">"</span>Predicting (out-of-graph) ...<span class="pl-pds">"</span></span>)
ŷts <span class="pl-k">=</span> <span class="pl-c1">predict</span>(nlmodel, Xts)

<span class="pl-c"><span class="pl-c">#</span> Squared loss</span>
yts <span class="pl-k">=</span> <span class="pl-c1">convertlabel</span>(LabelEnc<span class="pl-k">.</span><span class="pl-c1">OneOfK</span>(C), y[idxts], yᵤ)
<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span>L2 loss (out-of-graph):<span class="pl-pds">"</span></span>, <span class="pl-c1">value</span>(<span class="pl-c1">L2DistLoss</span>(), yts, ŷts, AvgMode<span class="pl-k">.</span><span class="pl-c1">Mean</span>()))
<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span>Average error (out-of-graph):<span class="pl-pds">"</span></span>, <span class="pl-c1">mean</span>(<span class="pl-c1">targets</span>(indmax,yts)<span class="pl-k">.!=</span><span class="pl-c1">targets</span>(indmax,ŷts)))



<span class="pl-c"><span class="pl-c">#</span>####################</span>
<span class="pl-c"><span class="pl-c">#</span> In-Graph learning #</span>
<span class="pl-c"><span class="pl-c">#</span>####################</span>

<span class="pl-c"><span class="pl-c">#</span> Initialize output structure</span>
Xo <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(C,<span class="pl-c1">nobs</span>(X))
Xo[:,idxtr] <span class="pl-k">=</span> <span class="pl-c1">convertlabel</span>(LabelEnc<span class="pl-k">.</span><span class="pl-c1">OneOfK</span>(C), y[idxtr] ,yᵤ)

<span class="pl-c"><span class="pl-c">#</span> Add adjacency pertinent to the test data</span>
Ats <span class="pl-k">=</span> NetworkLearning<span class="pl-k">.</span><span class="pl-c1">generate_partial_adjacency</span>(cited_papers, citing_papers, <span class="pl-c1">collect</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">nobs</span>(X)));
<span class="pl-c1">add_adjacency!</span>(nlmodel, [Ats])

<span class="pl-c"><span class="pl-c">#</span> Make predictions</span>
<span class="pl-c1">info</span>(<span class="pl-s"><span class="pl-pds">"</span>Predicting (in-graph) ...<span class="pl-pds">"</span></span>)
update_mask <span class="pl-k">=</span> <span class="pl-c1">trues</span>(<span class="pl-c1">nobs</span>(X));
update_mask[idxtr] <span class="pl-k">=</span> <span class="pl-c1">false</span> <span class="pl-c"><span class="pl-c">#</span> estimates for training samples will not be used</span>
<span class="pl-c1">predict!</span>(Xo, nlmodel, X, update_mask)

<span class="pl-c"><span class="pl-c">#</span> Squared loss</span>
ŷts <span class="pl-k">=</span> Xo[:,idxts]
yts <span class="pl-k">=</span> <span class="pl-c1">convertlabel</span>(LabelEnc<span class="pl-k">.</span><span class="pl-c1">OneOfK</span>(C), y[idxts], yᵤ)
<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span>L2 loss (in-graph):<span class="pl-pds">"</span></span>, <span class="pl-c1">value</span>(<span class="pl-c1">L2DistLoss</span>(), yts, ŷts, AvgMode<span class="pl-k">.</span><span class="pl-c1">Mean</span>()))
<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span>Average error (in-graph):<span class="pl-pds">"</span></span>, <span class="pl-c1">mean</span>(<span class="pl-c1">targets</span>(indmax,yts)<span class="pl-k">.!=</span><span class="pl-c1">targets</span>(indmax,ŷts)))</pre></div>
<p>The output of the above code is:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span>   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span>
<span class="pl-c"><span class="pl-c">#</span>                                  Dload  Upload   Total   Spent    Left  Speed</span>
<span class="pl-c"><span class="pl-c">#</span> 100  163k  100  163k    0     0   163k      0  0:00:01  0:00:01 --:--:-- 86695</span>
<span class="pl-c"><span class="pl-c">#</span> cora/</span>
<span class="pl-c"><span class="pl-c">#</span> cora/README</span>
<span class="pl-c"><span class="pl-c">#</span> cora/cora.content</span>
<span class="pl-c"><span class="pl-c">#</span> cora/cora.cites</span>
<span class="pl-c"><span class="pl-c">#</span> INFO: Training ...</span>
<span class="pl-c"><span class="pl-c">#</span> INFO: Predicting (out-of-graph) ...</span>
<span class="pl-c"><span class="pl-c">#</span> 	  L2 loss (out-of-graph):0.13011389156615571</span>
<span class="pl-c"><span class="pl-c">#</span> 	  Average error (out-of-graph):0.5310192023633677</span>
<span class="pl-c"><span class="pl-c">#</span> INFO: Predicting (in-graph) ...</span>
<span class="pl-c"><span class="pl-c">#</span> 	  L2 loss (in-graph):0.06473003424857691</span>
<span class="pl-c"><span class="pl-c">#</span>	  Average error (in-graph):0.24963072378138848</span></pre></div>
<h2><a id="user-content-entity-based-network-learning-example" class="anchor" aria-hidden="true" href="#entity-based-network-learning-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Entity-based network learning example</h2>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> DecisionTree
<span class="pl-k">using</span> NetworkLearning, MLDataPattern, MLLabelUtils, LossFunctions

<span class="pl-c"><span class="pl-c">#</span> Download the CORA dataset, and return data and citing/cited papers indices (relative to order in X,y)</span>
(X,y), cited_papers, citing_papers <span class="pl-k">=</span> NetworkLearning<span class="pl-k">.</span><span class="pl-c1">grab_cora_data</span>()
n <span class="pl-k">=</span> <span class="pl-c1">nobs</span>(X)
yᵤ <span class="pl-k">=</span> <span class="pl-c1">sort</span>(<span class="pl-c1">unique</span>(y))
C <span class="pl-k">=</span> <span class="pl-c1">length</span>(yᵤ)

<span class="pl-c"><span class="pl-c">#</span> Split data</span>
idx <span class="pl-k">=</span> <span class="pl-c1">collect</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>n);
<span class="pl-c1">shuffle!</span>(idx)
p <span class="pl-k">=</span> <span class="pl-c1">0.5</span>
idxtr,idxts <span class="pl-k">=</span> <span class="pl-c1">splitobs</span>(idx,p)

<span class="pl-c"><span class="pl-c">#</span>## !!! ###### 	</span>
<span class="pl-c1">sort!</span>(idxtr) <span class="pl-c"><span class="pl-c">#</span> It is important to sort the indices, </span>
<span class="pl-c1">sort!</span>(idxts) <span class="pl-c"><span class="pl-c">#</span> because of the use of the update mask</span>
<span class="pl-c"><span class="pl-c">#</span>## !!! ######</span>

Xtr <span class="pl-k">=</span> X[:,idxtr]
ytr <span class="pl-k">=</span> y[idxtr]
Xts <span class="pl-k">=</span> X[:,idxts]


<span class="pl-c"><span class="pl-c">#</span>############## Remove 70% of the citations to papers in the test data ################## 	</span>
removed_citations <span class="pl-k">=</span> <span class="pl-c1">Vector</span><span class="pl-c1">{Int}</span>()							<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-k">for</span> (i, (ic,oc)) <span class="pl-k">in</span> <span class="pl-c1">enumerate</span>(<span class="pl-c1">zip</span>(cited_papers,citing_papers))				<span class="pl-c"><span class="pl-c">#</span></span>
	<span class="pl-k">if</span> ic <span class="pl-k">in</span> idxts <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">rand</span>() <span class="pl-k">&gt;</span> <span class="pl-c1">0.3</span> 							<span class="pl-c"><span class="pl-c">#</span></span>
		<span class="pl-c1">push!</span>(removed_citations, i)						<span class="pl-c"><span class="pl-c">#</span>	</span>
	<span class="pl-k">end</span>										<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-k">end</span>											<span class="pl-c"><span class="pl-c">#</span></span>
											<span class="pl-c"><span class="pl-c">#</span></span>
cited_incomplete <span class="pl-k">=</span> cited_papers[<span class="pl-c1">setdiff</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">nobs</span>(cited_papers), removed_citations)]	<span class="pl-c"><span class="pl-c">#</span></span>
citing_incomplete <span class="pl-k">=</span> citing_papers[<span class="pl-c1">setdiff</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">nobs</span>(citing_papers), removed_citations)]	<span class="pl-c"><span class="pl-c">#</span></span>
											<span class="pl-c"><span class="pl-c">#</span></span>
cited_removed <span class="pl-k">=</span> cited_papers[removed_citations]						<span class="pl-c"><span class="pl-c">#</span></span>
citing_removed <span class="pl-k">=</span> citing_papers[removed_citations]					<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span>########################################################################################</span>


<span class="pl-c"><span class="pl-c">#</span> Construct adjacencies, local model, etc</span>
Am <span class="pl-k">=</span> <span class="pl-c1">sparse</span>(NetworkLearning<span class="pl-k">.</span><span class="pl-c1">generate_partial_adjacency</span>(cited_incomplete, citing_incomplete, <span class="pl-c1">collect</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>n)));
AV <span class="pl-k">=</span> [<span class="pl-c1">adjacency</span>(Am)]
Ml <span class="pl-k">=</span> DecisionTree<span class="pl-k">.</span><span class="pl-c1">build_tree</span>(ytr,Xtr<span class="pl-k">'</span>)

<span class="pl-c"><span class="pl-c">#</span> Initialize output estimates and update mask</span>
Xo <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(C,n)
update <span class="pl-k">=</span> <span class="pl-c1">falses</span>(n);
update[idx[<span class="pl-c1">findin</span>(idx,idxts)]] <span class="pl-k">=</span> <span class="pl-c1">true</span> <span class="pl-c"><span class="pl-c">#</span> mark only test entities i.e. unknown as updateable</span>
Xo[:,<span class="pl-k">.!</span>update] <span class="pl-k">=</span> <span class="pl-c1">convertlabel</span>(LabelEnc<span class="pl-k">.</span><span class="pl-c1">OneOfK</span>(C), ytr ,yᵤ)
Xo[:,update] <span class="pl-k">=</span> DecisionTree<span class="pl-k">.</span><span class="pl-c1">apply_tree_proba</span>(Ml, Xts<span class="pl-k">'</span>, yᵤ)<span class="pl-k">'</span>
ŷ_tree <span class="pl-k">=</span> <span class="pl-c1">copy</span>(Xo[:, update])

<span class="pl-c"><span class="pl-c">#</span> Construct necessary arguments for training the entity network learner</span>
fr_train <span class="pl-k">=</span> (X)<span class="pl-k">-&gt;</span>  DecisionTree<span class="pl-k">.</span><span class="pl-c1">build_tree</span>(X[<span class="pl-c1">2</span>],X[<span class="pl-c1">1</span>]')
<span class="pl-en">fr_exec</span>(C) <span class="pl-k">=</span> (m,X)<span class="pl-k">-&gt;</span> DecisionTree<span class="pl-k">.</span><span class="pl-c1">apply_tree_proba</span>(m, X<span class="pl-k">'</span>, <span class="pl-c1">collect</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>C))<span class="pl-k">'</span>


<span class="pl-c"><span class="pl-c">#</span> Train</span>
<span class="pl-c1">info</span>(<span class="pl-s"><span class="pl-pds">"</span>Training ...<span class="pl-pds">"</span></span>)
nlmodel <span class="pl-k">=</span> NetworkLearning<span class="pl-k">.</span><span class="pl-c1">fit</span>(NetworkLearnerEnt, 
	      Xo,
	      update,
	      AV,
	      fr_train, <span class="pl-c1">fr_exec</span>(C);
	      learner <span class="pl-k">=</span> <span class="pl-c1">:wrn</span>,
	      inference <span class="pl-k">=</span> <span class="pl-c1">:ic</span>,
	      f_targets <span class="pl-k">=</span> x<span class="pl-k">-&gt;</span><span class="pl-c1">targets</span>(indmax,x),
	      normalize <span class="pl-k">=</span> <span class="pl-c1">true</span>,
	      maxiter <span class="pl-k">=</span> <span class="pl-c1">10</span>,
	      α <span class="pl-k">=</span> <span class="pl-c1">0.95</span>
	  )


<span class="pl-c"><span class="pl-c">#</span> Squared loss (with just a few citations)</span>
ŷts <span class="pl-k">=</span> nlmodel<span class="pl-k">.</span>state<span class="pl-k">.</span>ê[:,update]
yts <span class="pl-k">=</span> <span class="pl-c1">convertlabel</span>(LabelEnc<span class="pl-k">.</span><span class="pl-c1">OneOfK</span>(C), y[idxts], yᵤ)
<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span>L2 loss (few citations):<span class="pl-pds">"</span></span>, <span class="pl-c1">value</span>(<span class="pl-c1">L2DistLoss</span>(), yts, ŷts, AvgMode<span class="pl-k">.</span><span class="pl-c1">Mean</span>()))
<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span>Average error (few citations):<span class="pl-pds">"</span></span>, <span class="pl-c1">mean</span>(<span class="pl-c1">targets</span>(indmax,yts)<span class="pl-k">.!=</span><span class="pl-c1">targets</span>(indmax,ŷts)))

<span class="pl-c"><span class="pl-c">#</span> Add citations (i.e. update adjacency matrices of the model)</span>

<span class="pl-c"><span class="pl-c">#</span> Function that updates an adjacency matrix given two vectors (of same length)</span>
<span class="pl-c"><span class="pl-c">#</span> of cited and citing paper; the function may be more complicated depending on</span>
<span class="pl-c"><span class="pl-c">#</span> how easy the corresponding adjacency matrix coordinates can be determined</span>
<span class="pl-c"><span class="pl-c">#</span> from the input data</span>
<span class="pl-k">function</span> <span class="pl-en">add_citations!</span>(Am, cited, citing)
	<span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">nobs</span>(cited)
		Am[cited[i],citing[i]] <span class="pl-k">+=</span> <span class="pl-c1">1</span>
		Am[citing[i],cited[i]] <span class="pl-k">+=</span> <span class="pl-c1">1</span>
	<span class="pl-k">end</span>
	<span class="pl-k">return</span> Am
<span class="pl-k">end</span>

<span class="pl-c1">info</span>(<span class="pl-s"><span class="pl-pds">"</span>Updating adjacencies ...<span class="pl-pds">"</span></span>)
<span class="pl-en">f_update</span>(ic,oc) <span class="pl-k">=</span> x<span class="pl-k">-&gt;</span><span class="pl-c1">add_citations!</span>(x, ic, oc)
<span class="pl-c1">update_adjacency!</span>(nlmodel<span class="pl-k">.</span>Adj[<span class="pl-c1">1</span>], <span class="pl-c1">f_update</span>(cited_removed, citing_removed))

<span class="pl-c"><span class="pl-c">#</span> Run again collective inference</span>
<span class="pl-c1">info</span>(<span class="pl-s"><span class="pl-pds">"</span>Re-running collective inference ...<span class="pl-pds">"</span></span>)
<span class="pl-c1">infer!</span>(nlmodel)

<span class="pl-c"><span class="pl-c">#</span> Squared loss (with all citations)</span>
ŷts <span class="pl-k">=</span> nlmodel<span class="pl-k">.</span>state<span class="pl-k">.</span>ê[:,update]
yts <span class="pl-k">=</span> <span class="pl-c1">convertlabel</span>(LabelEnc<span class="pl-k">.</span><span class="pl-c1">OneOfK</span>(C), y[idxts], yᵤ)
<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span>L2 loss (all citations):<span class="pl-pds">"</span></span>, <span class="pl-c1">value</span>(<span class="pl-c1">L2DistLoss</span>(), yts, ŷts, AvgMode<span class="pl-k">.</span><span class="pl-c1">Mean</span>()))
<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span>Average error (all citations):<span class="pl-pds">"</span></span>, <span class="pl-c1">mean</span>(<span class="pl-c1">targets</span>(indmax,yts)<span class="pl-k">.!=</span><span class="pl-c1">targets</span>(indmax,ŷts)))</pre></div>
<p>The output of the above code is:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span>   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span>
<span class="pl-c"><span class="pl-c">#</span>                                  Dload  Upload   Total   Spent    Left  Speed</span>
<span class="pl-c"><span class="pl-c">#</span> 100  163k  100  163k    0     0   163k      0  0:00:01  0:00:01 --:--:-- 86382</span>
<span class="pl-c"><span class="pl-c">#</span> cora/</span>
<span class="pl-c"><span class="pl-c">#</span> cora/README</span>
<span class="pl-c"><span class="pl-c">#</span> cora/cora.content</span>
<span class="pl-c"><span class="pl-c">#</span> cora/cora.cites</span>
<span class="pl-c"><span class="pl-c">#</span> INFO: Training ...</span>
<span class="pl-c"><span class="pl-c">#</span> 	  L2 loss (few citations):0.061311528508626575</span>
<span class="pl-c"><span class="pl-c">#</span>	  Average error (few citations):0.27843426883308714</span>
<span class="pl-c"><span class="pl-c">#</span> INFO: Updating adjacencies ...</span>
<span class="pl-c"><span class="pl-c">#</span> INFO: Re-running collective inference ...</span>
<span class="pl-c"><span class="pl-c">#</span>	  L2 loss (all citations):0.04990883428571481</span>
<span class="pl-c"><span class="pl-c">#</span>	  Average error (all citations):0.2119645494830133</span></pre></div>
<h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Documentation</h2>
<p>The documentation is provided in Julia's native docsystem.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>The package can be installed by running <code>Pkg.add("NetworkLearning")</code> or, to check out the latest version,
<code>Pkg.checkout("NetworkLearning.jl")</code> in the Julia REPL. From <code>v0.1.0</code>, only versions of Julia above 0.7
are supported. Julia v.0.6 support can be found in the <code>support_julia_v0.6</code> branch (currently unmantained).</p>
<h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>License</h2>
<p>This code has an MIT license and therefore it is free.</p>
<h2><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>References</h2>
<p>[1] S.A. Macskassy, F. Provost "Classification in networked data: A toolkit and a univariate case study", Journal of Machine learning Research 8, 2007, 935-983</p>
<p>[2] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Gallagher, T. Eliassi-Rad "Collective classification in network data", AI Magazine 29(3), 2008</p>
</article></div>