<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-backward-functions-for-linear-algebra" class="anchor" aria-hidden="true" href="#backward-functions-for-linear-algebra"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Backward functions for Linear Algebra</h1>
<p dir="auto"><a href="https://travis-ci.com/GiggleLiu/BackwardsLinalg.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/8696f2d1f30a3c92371f249a3cf8295d813d9f68db11b5f5db86e710f5e2d9a5/68747470733a2f2f7472617669732d63692e636f6d2f476967676c654c69752f4261636b77617264734c696e616c672e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/GiggleLiu/BackwardsLinalg.jl.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/GiggleLiu/BackwardsLinalg.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/9eca01f5831043884dd19f555b04a6795eab7567469fe53c78fb8d45c1c77c05/68747470733a2f2f636f6465636f762e696f2f67682f476967676c654c69752f4261636b77617264734c696e616c672e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Codecov" data-canonical-src="https://codecov.io/gh/GiggleLiu/BackwardsLinalg.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/2d7906543b9379f6b19505994bf15caa3c1cb74f2af682f1bb6ab8168cb6be26/68747470733a2f2f706c616365686f6c642e69742f31352f6630336331352f3030303030303f746578743d2b"><img src="https://camo.githubusercontent.com/2d7906543b9379f6b19505994bf15caa3c1cb74f2af682f1bb6ab8168cb6be26/68747470733a2f2f706c616365686f6c642e69742f31352f6630336331352f3030303030303f746578743d2b" alt="#f03c15" data-canonical-src="https://placehold.it/15/f03c15/000000?text=+" style="max-width: 100%;"></a> This project is still in progress ...</p>
<p dir="auto">Backward functions for linear algebras, with GPU support.
It is currently ported to <code>Zygote.jl</code> for testing, but these porting codes will be moved to other places (like merging them to <code>Zygote.jl</code>) in the future.</p>
<h2 dir="auto"><a id="user-content-why-we-need-backwardslinalgjl" class="anchor" aria-hidden="true" href="#why-we-need-backwardslinalgjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Why we need BackwardsLinalg.jl?</h2>
<p dir="auto">Not only in Julia, but also in well known machine learning packages in python like pytorch, one can hardly find a numerical stable implementations of linear algebra function. This missing piece is crutial to autodiff applications in tensor networks algorithms.</p>
<h2 dir="auto"><a id="user-content-table-of-supported-functions" class="anchor" aria-hidden="true" href="#table-of-supported-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Table of Supported Functions</h2>
<p dir="auto">Note: it will change the default behavior, we are considering not changing the output type (SVD, QR) latter when Zygote is stronger.</p>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> svd and rsvd (randomized SVD)</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> qr</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> cholesky   # Nabla.jl</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> powermethod   # we need fixed point methods, trying hard ...</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> eigen      # linear BP paper, only symmetric case considered</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> lq         # similar to qr</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> pfaffian    # find it nowhere, lol</li>
</ul>
<p dir="auto">For <code>logdet</code>, <code>det</code> and <code>tr</code>, people can find it in <code>ChainRules.jl</code> and <code>Nabla.jl</code>.</p>
<p dir="auto">Derivation of adjoint backward functions could be found <a href="https://giggleliu.github.io/2019/04/02/einsumbp.html" rel="nofollow">here</a>.</p>
<h2 dir="auto"><a id="user-content-how-to-use" class="anchor" aria-hidden="true" href="#how-to-use"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How to Use</h2>
<p dir="auto">It currently ports into <code>Zygote.jl</code></p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Zygote, BackwardsLinalg

function loss(A)
    M, N = size(A)
    U, S, V = svd(A)
    psi = U[:,1]
    H = randn(ComplexF64, M, M)
    H+=H'
    real(psi'*H*psi)[]
end

a = randn(ComplexF64, 4, 6)
g = loss'(a)"><pre><span class="pl-k">using</span> Zygote, BackwardsLinalg

<span class="pl-k">function</span> <span class="pl-en">loss</span>(A)
    M, N <span class="pl-k">=</span> <span class="pl-c1">size</span>(A)
    U, S, V <span class="pl-k">=</span> <span class="pl-c1">svd</span>(A)
    psi <span class="pl-k">=</span> U[:,<span class="pl-c1">1</span>]
    H <span class="pl-k">=</span> <span class="pl-c1">randn</span>(ComplexF64, M, M)
    H<span class="pl-k">+=</span>H<span class="pl-k">'</span>
    <span class="pl-c1">real</span>(psi<span class="pl-k">'</span><span class="pl-k">*</span>H<span class="pl-k">*</span>psi)[]
<span class="pl-k">end</span>

a <span class="pl-k">=</span> <span class="pl-c1">randn</span>(ComplexF64, <span class="pl-c1">4</span>, <span class="pl-c1">6</span>)
g <span class="pl-k">=</span> loss<span class="pl-k">'</span>(a)</pre></div>
<p dir="auto">Try something interesting (the backward of TRG code, <code>TensorOperations.jl</code> (as well as patch <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="397154351" data-permission-text="Title is private" data-url="https://github.com/Jutho/TensorOperations.jl/issues/59" data-hovercard-type="pull_request" data-hovercard-url="/Jutho/TensorOperations.jl/pull/59/hovercard" href="https://github.com/Jutho/TensorOperations.jl/pull/59">Jutho/TensorOperations.jl#59</a>) is required.)</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia test/trg.py"><pre>julia test/trg.py</pre></div>
</article></div>