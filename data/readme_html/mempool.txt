<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-mempool" class="anchor" aria-hidden="true" href="#mempool"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MemPool</h1>
<p><a href="https://travis-ci.org/JuliaComputing/MemPool.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/09db0adddfba9fb181954c95ee97e47ffb2d4903/68747470733a2f2f7472617669732d63692e6f72672f4a756c6961436f6d707574696e672f4d656d506f6f6c2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/JuliaComputing/MemPool.jl.svg?branch=master" style="max-width:100%;"></a></p>
<p>Simple distributed datastore that supports custom serialization, spilling least recently used data to disk and memory-mapping.</p>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Usage</h2>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">addprocs</span>(<span class="pl-c1">4</span>)
<span class="pl-k">using</span> MemPool
<span class="pl-c1">@everywhere</span> MemPool<span class="pl-k">.</span>max_memsize[] <span class="pl-k">=</span> <span class="pl-c1">10</span><span class="pl-k">^</span><span class="pl-c1">9</span> <span class="pl-c"><span class="pl-c">#</span> 1 GB per worker</span></pre></div>
<p>This sets the memory limit on each process to 10^9 bytes (1GB). If this is exceeded, the least recently used data will be written to disk using <code>movetodisk</code> described below until the total pool size is below 1 GB. Data thus spilled are written in a directory called <code>.mempool</code>. The data can be read back with memory mapping. Overriding <code>mmwrite</code> and <code>mmread</code> described in the next section is recommended for efficiency.</p>
<p>Data store functions:</p>
<ul>
<li><code>poolset(x::Any, pid=myid())</code>: store the object <code>x</code> on <code>pid</code>. Returns a <code>DRef</code> object.</li>
<li><code>poolget(r::DRef)</code>: gets the data stored at <code>DRef</code>. If the data has been moved to disk, it will be read on the caller side.</li>
<li><code>pooldelete(r::DRef)</code>: removes data at <code>r</code>, including any data on disk, that was not saved using <code>savetodisk</code>.</li>
<li><code>movetodisk(r::DRef)</code>: moves data to disk and release it from memory. Uses <code>MemPool.mmwrite</code> to write to disk. See section below. Returns a <code>FileRef</code> which can be passed to <code>poolget</code> to read the data. Further <code>poolget</code> calls to <code>r</code> itself will cause the data to be read from disk and cached in memory and marked most recently used.</li>
<li><code>copytodisk(r::DRef)</code>: copies data to disk keeping the original copy in memory. Subsequent <code>poolget(r)</code> will read data from disk on callee process, or return the cached value if the callee owns the ref.</li>
<li><code>savetodisk(r::DRef, path)</code>: saves data to a given file path. Leaves original data in memory, doesn't affect LRU accounting. Use this when you want to explicitly save data using the format described below.</li>
</ul>
<h2><a id="user-content-mempoolmmwrite-mempoolmmread" class="anchor" aria-hidden="true" href="#mempoolmmwrite-mempoolmmread"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>MemPool.mmwrite</code>, <code>MemPool.mmread</code></h2>
<p><code>mmwrite</code> and <code>mmread</code> are fast alternatives to <code>Base.serialize</code> and <code>Base.deserialize</code> which can memory map if read from disk. They fallback to <code>Base.serialize</code> so as to support all Julia types. This format is only suitable for temporary storage since all four functions can change implementations.</p>
<ul>
<li><code>mmwrite(s::AbstractSerializer, x::Any)</code> is called to write data to the wire / file when data needs to be transferred / written to disk. Packages can define how parts of their datastructure can be written in raw format that can be mmapped back later with <code>mmread</code>. <code>mmwrite</code> must begin with the command <code>Base.serialize_type{MemPool.MMSer{typeof(x)}</code> so that Julia's base serializer will dispatch any deserialization to <code>mmread</code>.</li>
<li><code>mmread(::Type{T}, io::AbstractSerializer)</code> is called to deserialize data written with <code>mmwrite</code>.</li>
</ul>
<p><code>mmwrite</code> can currently store Array{String} much more efficiently than Base. It is also extended for fast storage of NullableArrays, PooledArrays, and IndexedTables by JuliaDB.</p>
</article></div>