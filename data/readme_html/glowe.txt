<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-glowe" class="anchor" aria-hidden="true" href="#glowe"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Glowe</h1>
<p>Julia interface to <a href="https://nlp.stanford.edu/projects/glove/" rel="nofollow">GloVe</a>.</p>
<p><a href="LICENSE.md"><img src="https://camo.githubusercontent.com/4440d5deb3a53c4f8661ee765378e6071e7878e8/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c6174" alt="License" data-canonical-src="http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" style="max-width:100%;"></a>
<a href="https://travis-ci.org/zgornel/Glowe.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/303677cea2b2d6bc845d2a96a7821f839f3a7d35/68747470733a2f2f7472617669732d63692e6f72672f7a676f726e656c2f476c6f77652e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/zgornel/Glowe.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/zgornel/Glowe.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/49f7c0cefff9da2fbd1d0714e508a748d008a9be/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7a676f726e656c2f476c6f77652e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/zgornel/Glowe.jl/badge.svg?branch=master" style="max-width:100%;"></a></p>
<p>This package provides functionality for generating and working with GloVe word embeddings. The training is done using the original C code from the <a href="https://github.com/stanfordnlp/GloVe">GloVe github repository</a>.</p>
<p>Note that there is also a package called <a href="https://github.com/domluna/Glove.jl">Glove.jl</a> that provides a pure Julia implementation of the algorithm.</p>
<ul>
<li><a href="https://github.com/zgornel/Glowe.jl/blob/master/NEWS.md">Release Notes</a></li>
</ul>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">clone</span>(<span class="pl-s"><span class="pl-pds">"</span>https://github.com/zgornel/Glowe.jl<span class="pl-pds">"</span></span>)</pre></div>
<p>for the latest <code>master</code> or</p>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>Glowe<span class="pl-pds">"</span></span>)</pre></div>
<p>for the stable versions.</p>
<h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Documentation</h2>
<p>Most of the documentation is provided in Julia's native docsystem.</p>
<h2><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Examples</h2>
<p>Following Word2Vec.jl's example, considering the corpus from <a href="http://mattmahoney.net/dc/text8.zip" rel="nofollow">http://mattmahoney.net/dc/text8.zip</a> extracted as text file <code>text8</code> in the current working directory, the GloVe model can be obtained with:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c"><span class="pl-c">#</span> Training (may take a while)</span>
       <span class="pl-c1">vocab_count</span>(<span class="pl-s"><span class="pl-pds">"</span>text8<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>vocab.txt<span class="pl-pds">"</span></span>, min_count<span class="pl-k">=</span><span class="pl-c1">5</span>, verbose<span class="pl-k">=</span><span class="pl-c1">1</span>);
       <span class="pl-c1">cooccur</span>(<span class="pl-s"><span class="pl-pds">"</span>text8<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>vocab.txt<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>cooccurrence.bin<span class="pl-pds">"</span></span>, memory<span class="pl-k">=</span><span class="pl-c1">8.0</span>, verbose<span class="pl-k">=</span><span class="pl-c1">1</span>);
       <span class="pl-c1">shuffle</span>(<span class="pl-s"><span class="pl-pds">"</span>cooccurrence.bin<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>cooccurrence.shuf.bin<span class="pl-pds">"</span></span>, memory<span class="pl-k">=</span><span class="pl-c1">8.0</span>, verbose<span class="pl-k">=</span><span class="pl-c1">1</span>);
       <span class="pl-c1">glove</span>(<span class="pl-s"><span class="pl-pds">"</span>cooccurrence.shuf.bin<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>vocab.txt<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>text8-vec<span class="pl-pds">"</span></span>, threads<span class="pl-k">=</span><span class="pl-c1">8</span>,
             x_max<span class="pl-k">=</span><span class="pl-c1">10.0</span>, iter<span class="pl-k">=</span><span class="pl-c1">15</span>, vector_size<span class="pl-k">=</span><span class="pl-c1">300</span>, binary<span class="pl-k">=</span><span class="pl-c1">0</span>, write_header<span class="pl-k">=</span><span class="pl-c1">1</span>,
             verbose<span class="pl-k">=</span><span class="pl-c1">1</span>);
<span class="pl-c"><span class="pl-c">#</span> BUILDING VOCABULARY</span>
<span class="pl-c"><span class="pl-c">#</span> Truncating vocabulary at min count 5.</span>
<span class="pl-c"><span class="pl-c">#</span> Using vocabulary of size 71290.</span>
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> COUNTING COOCCURRENCES</span>
<span class="pl-c"><span class="pl-c">#</span> window size: 15</span>
<span class="pl-c"><span class="pl-c">#</span> context: symmetric</span>
<span class="pl-c"><span class="pl-c">#</span> Merging cooccurrence files: processed 60666468 lines.</span>
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> SHUFFLING COOCCURRENCES</span>
<span class="pl-c"><span class="pl-c">#</span> array size: 510027366</span>
<span class="pl-c"><span class="pl-c">#</span> Merging temp files: processed 60666468 lines.</span>
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> TRAINING MODEL</span>
<span class="pl-c"><span class="pl-c">#</span> Read 60666468 lines.</span>
<span class="pl-c"><span class="pl-c">#</span> vector size: 300</span>
<span class="pl-c"><span class="pl-c">#</span> vocab size: 71290</span>
<span class="pl-c"><span class="pl-c">#</span> x_max: 10.000000</span>
<span class="pl-c"><span class="pl-c">#</span> alpha: 0.750000</span>
<span class="pl-c"><span class="pl-c">#</span> 12/11/18 - 12:58.58AM, iter: 001, cost: 0.070201</span>
<span class="pl-c"><span class="pl-c">#</span> 12/11/18 - 01:00.33AM, iter: 002, cost: 0.052521</span>
<span class="pl-c"><span class="pl-c">#</span> ...</span></pre></div>
<p>The model can be imported with</p>
<div class="highlight highlight-source-julia"><pre>model <span class="pl-k">=</span> <span class="pl-c1">wordvectors</span>(<span class="pl-s"><span class="pl-pds">"</span>text8-vec.txt<span class="pl-pds">"</span></span>, Float32, header<span class="pl-k">=</span><span class="pl-c1">true</span>, kind<span class="pl-k">=</span><span class="pl-c1">:text</span>)
<span class="pl-c"><span class="pl-c">#</span> WordVectors 71291 words, 300-element Float32 vectors</span></pre></div>
<p>The vector representation of a word can be obtained using <code>get_vector</code>.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">get_vector</span>(model, <span class="pl-s"><span class="pl-pds">"</span>book<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">#</span> 300-element Array{Float32,1}:</span>
<span class="pl-c"><span class="pl-c">#</span>   0.006189716</span>
<span class="pl-c"><span class="pl-c">#</span>   0.04822071</span>
<span class="pl-c"><span class="pl-c">#</span>   0.017121462</span>
<span class="pl-c"><span class="pl-c">#</span>   ...</span></pre></div>
<p>The cosine similarity of <code>book</code>, for example, can be computed using <code>cosine_similar_words</code>.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">cosine_similar_words</span>(model, <span class="pl-s"><span class="pl-pds">"</span>book<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">#</span> 10-element Array{String,1}:</span>
<span class="pl-c"><span class="pl-c">#</span>  "book"</span>
<span class="pl-c"><span class="pl-c">#</span>  "books"</span>
<span class="pl-c"><span class="pl-c">#</span>  "published"</span>
<span class="pl-c"><span class="pl-c">#</span>  "domesday"</span>
<span class="pl-c"><span class="pl-c">#</span>  "novel"</span>
<span class="pl-c"><span class="pl-c">#</span>  "comic"</span>
<span class="pl-c"><span class="pl-c">#</span>  "written"</span>
<span class="pl-c"><span class="pl-c">#</span>  "bible"</span>
<span class="pl-c"><span class="pl-c">#</span>  "urantia"</span>
<span class="pl-c"><span class="pl-c">#</span>  "work"</span></pre></div>
<p>Word vectors have many interesting properties. For example,
<code>vector("king") - vector("man") + vector("woman")</code> is close to <code>vector("queen")</code>.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">analogy_words</span>(model, [<span class="pl-s"><span class="pl-pds">"</span>king<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>woman<span class="pl-pds">"</span></span>], [<span class="pl-s"><span class="pl-pds">"</span>man<span class="pl-pds">"</span></span>])
<span class="pl-c"><span class="pl-c">#</span> 5-element Array{String,1}:</span>
<span class="pl-c"><span class="pl-c">#</span>  "queen"</span>
<span class="pl-c"><span class="pl-c">#</span>  "daughter"</span>
<span class="pl-c"><span class="pl-c">#</span>  "children"</span>
<span class="pl-c"><span class="pl-c">#</span>  "wife"</span>
<span class="pl-c"><span class="pl-c">#</span>  "son"</span></pre></div>
<h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>License</h2>
<p>This code has an MIT license and therefore it is free.
GloVe is released under an Apache License v2.0.</p>
<h2><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>References</h2>
<p>[1] <a href="https://nlp.stanford.edu/projects/glove/" rel="nofollow">GloVe: Global Vectors for Word Representation</a></p>
<p>[2] <a href="https://github.com/domluna/Glove.jl">Glove.jl - native Julia implementation</a></p>
<h2><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Acknowledgements</h2>
<p>The design of the package relies on design concepts from <a href="https://github.com/zgornel/Word2Vec.jl">the word2vec Julia interface, Word2Vec.jl</a>.</p>
<h2><a id="user-content-reporting-bugs" class="anchor" aria-hidden="true" href="#reporting-bugs"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reporting Bugs</h2>
<p>Please <a href="https://github.com/zgornel/Glowe.jl/issues/new">file an issue</a> to report a bug or request a feature.</p>
</article></div>