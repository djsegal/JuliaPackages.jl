<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h2><a id="user-content-causal-inference-with-invariant-prediction" class="anchor" aria-hidden="true" href="#causal-inference-with-invariant-prediction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Causal Inference with Invariant Prediction</h2>
<p><a href="LICENSE.md"><img src="https://camo.githubusercontent.com/bbf49a2eb96e6f718803f2493bd7aa3baae61abb09b7f8fc185a94e08c504dc6/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c6174" alt="License" data-canonical-src="http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" style="max-width:100%;"></a> <a href="https://travis-ci.org/github/richardkwo/InvariantCausal.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/771d806a88161fdf164f65e421b87930de833578b357918f812f03b09735df9a/68747470733a2f2f7472617669732d63692e6f72672f726963686172646b776f2f496e76617269616e7443617573616c2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/richardkwo/InvariantCausal.jl.svg?branch=master" style="max-width:100%;"></a> <a href="https://codecov.io/gh/richardkwo/InvariantCausal.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/663fb346d5ac7eca185e7d0c2da6e6ffde2f672dc98aa51db3b294175b36a16f/68747470733a2f2f636f6465636f762e696f2f67682f726963686172646b776f2f496e76617269616e7443617573616c2e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d47414b67556854543645" alt="codecov" data-canonical-src="https://codecov.io/gh/richardkwo/InvariantCausal.jl/branch/master/graph/badge.svg?token=GAKgUhTT6E" style="max-width:100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="docs/college.png"><img src="docs/college.png" alt="college" style="max-width:100%;"></a></p>
<p>This is a <strong>Julia 1.x</strong> implementation for the <strong>Invariant Causal Prediction</strong> algorithm of <a href="https://doi.org/10.1111/rssb.12167" rel="nofollow">Peters, Bühlmann and Meinshausen</a>. The method uncovers direct causes of a target variable from datasets under different environments (e.g., interventions or experimental settings).</p>
<p>See also this <a href="https://cran.r-project.org/package=InvariantCausalPrediction" rel="nofollow">R package</a> and <a href="docs/InvariantCausal.pdf">this report</a>.</p>
<h4><a id="user-content-changelog" class="anchor" aria-hidden="true" href="#changelog"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Changelog</h4>
<ul>
<li>2020/12/03: version 1.0.0 (Julia 1.x)</li>
<li>2018/06/20: version 0.1.1 (Julia 0.6)</li>
</ul>
<h4><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Dependencies</h4>
<p><a href="https://github.com/JuliaCollections/DataStructures.jl">DataStructures.jl</a>, <a href="https://github.com/JuliaStats/StatsBase.jl">StatsBase.jl</a>, <a href="https://github.com/JuliaStats/GLM.jl">GLM.jl</a>, <a href="https://github.com/JuliaData/DataFrames.jl">DataFrames.jl</a>, <a href="https://github.com/JuliaStats/GLMNet.jl">GLMNet.jl</a> (for lasso screening and requires <code>gfortran</code>) and <a href="https://github.com/Evizero/UnicodePlots.jl">UnicodePlots.jl</a>.</p>
<h3><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h3>
<p>Install the package via typing the following in Julia REPL.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; using Pkg
julia&gt; Pkg.add(&quot;InvariantCausal&quot;)
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Pkg
julia<span class="pl-k">&gt;</span> Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>InvariantCausal<span class="pl-pds">"</span></span>)</pre></div>
<p>Alternatively, you can install the latest from GitHub.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; Pkg.add(url=&quot;https://github.com/richardkwo/InvariantCausal.git&quot;)
"><pre>julia<span class="pl-k">&gt;</span> Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(url<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>https://github.com/richardkwo/InvariantCausal.git<span class="pl-pds">"</span></span>)</pre></div>
<p>Use the following to run a full test.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; using InvariantCausal
julia&gt; InvariantCausal._test_full()
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> InvariantCausal
julia<span class="pl-k">&gt;</span> InvariantCausal<span class="pl-k">.</span><span class="pl-c1">_test_full</span>()</pre></div>
<h3><a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Quick Start</h3>
<p>Generate a simple <a href="https://en.wikipedia.org/wiki/Structural_equation_modeling?oldformat=true" rel="nofollow">Gaussian structure equation model</a> (SEM) with random graph with 21 variables and average degree 3. Note that we assume the SEM is acyclic. The model can be represented as <code>X = B X + ϵ</code> with zeros on the diagonals of B (no self-loop). <code>ϵ</code> is a vector of independent Gaussian errors. For a variable <code>i</code>, variables <code>j</code> with coefficients <code>B[i,j]</code> non-zero are called the direct causes of <code>i</code>. We assume <code>B</code> is sparse, and its sparsity pattern is visualized with <a href="https://github.com/Evizero/UnicodePlots.jl">UnicodePlots.jl</a>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; using InvariantCausal
julia&gt; using Random
julia&gt; Random.seed!(77)
julia&gt; sem_obs = random_gaussian_SEM(21, 3)

Gaussian SEM with 21 variables:
B =
      Sparsity Pattern
      ┌───────────┐
    1 │⠀⠠⠀⠀⢐⠀⠀⠄⠀⢔⠀│ &gt; 0
      │⠠⠀⠠⠨⠁⠀⠄⠀⠀⠸⠀│ &lt; 0
      │⠠⠈⠈⠀⠌⠠⠀⠅⠀⠩⠉│
      │⠠⣨⠴⠰⠪⠠⠄⠀⠸⠉⣐│
      │⢀⠲⠈⢠⠠⠀⠀⠂⠀⠲⠁│
   21 │⠀⠐⠀⠀⠠⠠⠀⠀⠀⠔⠀│
      └───────────┘
      1          21
        nz = 70σ² = [1.9727697778060356, 1.1224733663047743, 1.1798805640594814, 1.2625825149076064, 0.8503782631176267, 0.5262963446298372, 1.3835334059064883, 1.788996301274282, 1.759286517329432, 0.842571682652995, 1.713382150423666, 1.4524484793202235, 1.9464648511794784, 1.7729995603828317, 0.7110857327642559, 1.6837378902964577, 1.085405687408806, 1.3069888003095986, 1.3933773717634643, 1.0571823834646068, 1.9187793877731028]
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> InvariantCausal
julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Random
julia<span class="pl-k">&gt;</span> Random<span class="pl-k">.</span><span class="pl-c1">seed!</span>(<span class="pl-c1">77</span>)
julia<span class="pl-k">&gt;</span> sem_obs <span class="pl-k">=</span> <span class="pl-c1">random_gaussian_SEM</span>(<span class="pl-c1">21</span>, <span class="pl-c1">3</span>)

Gaussian SEM with <span class="pl-c1">21</span> variables<span class="pl-k">:</span>
B <span class="pl-k">=</span>
      Sparsity Pattern
      ┌───────────┐
    <span class="pl-c1">1</span> │⠀⠠⠀⠀⢐⠀⠀⠄⠀⢔⠀│ <span class="pl-k">&gt;</span> <span class="pl-c1">0</span>
      │⠠⠀⠠⠨⠁⠀⠄⠀⠀⠸⠀│ <span class="pl-k">&lt;</span> <span class="pl-c1">0</span>
      │⠠⠈⠈⠀⠌⠠⠀⠅⠀⠩⠉│
      │⠠⣨⠴⠰⠪⠠⠄⠀⠸⠉⣐│
      │⢀⠲⠈⢠⠠⠀⠀⠂⠀⠲⠁│
   <span class="pl-c1">21</span> │⠀⠐⠀⠀⠠⠠⠀⠀⠀⠔⠀│
      └───────────┘
      <span class="pl-c1">1</span>          <span class="pl-c1">21</span>
        nz <span class="pl-k">=</span> <span class="pl-c1">70</span>σ² <span class="pl-k">=</span> [<span class="pl-c1">1.9727697778060356</span>, <span class="pl-c1">1.1224733663047743</span>, <span class="pl-c1">1.1798805640594814</span>, <span class="pl-c1">1.2625825149076064</span>, <span class="pl-c1">0.8503782631176267</span>, <span class="pl-c1">0.5262963446298372</span>, <span class="pl-c1">1.3835334059064883</span>, <span class="pl-c1">1.788996301274282</span>, <span class="pl-c1">1.759286517329432</span>, <span class="pl-c1">0.842571682652995</span>, <span class="pl-c1">1.713382150423666</span>, <span class="pl-c1">1.4524484793202235</span>, <span class="pl-c1">1.9464648511794784</span>, <span class="pl-c1">1.7729995603828317</span>, <span class="pl-c1">0.7110857327642559</span>, <span class="pl-c1">1.6837378902964577</span>, <span class="pl-c1">1.085405687408806</span>, <span class="pl-c1">1.3069888003095986</span>, <span class="pl-c1">1.3933773717634643</span>, <span class="pl-c1">1.0571823834646068</span>, <span class="pl-c1">1.9187793877731028</span>]</pre></div>
<p>Suppose we want to infer the direct causes for the last variables, i.e., 9, 11 and 18.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; causes(sem_obs, 21)
3-element Array{Int64,1}:
  9
 11
 18
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">causes</span>(sem_obs, <span class="pl-c1">21</span>)
<span class="pl-c1">3</span><span class="pl-k">-</span>element Array{Int64,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
  <span class="pl-c1">9</span>
 <span class="pl-c1">11</span>
 <span class="pl-c1">18</span></pre></div>
<p>Firstly, let us generate some observational data and call it <strong>environment 1</strong>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; X1 = simulate(sem_obs, 1000)
"><pre>julia<span class="pl-k">&gt;</span> X1 <span class="pl-k">=</span> <span class="pl-c1">simulate</span>(sem_obs, <span class="pl-c1">1000</span>)</pre></div>
<p>Then, we simulate from <strong>environment 2</strong> by performing <strong>do-intervention</strong> on variables 3, 4, 5, 6. Here we set them to fixed random values.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; X2 = simulate(sem_obs, [3,4,5,6], randn(4), 1000)
"><pre>julia<span class="pl-k">&gt;</span> X2 <span class="pl-k">=</span> <span class="pl-c1">simulate</span>(sem_obs, [<span class="pl-c1">3</span>,<span class="pl-c1">4</span>,<span class="pl-c1">5</span>,<span class="pl-c1">6</span>], <span class="pl-c1">randn</span>(<span class="pl-c1">4</span>), <span class="pl-c1">1000</span>)</pre></div>
<p>We run the algorithm on <strong>environments 1 and 2</strong>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; causalSearch(vcat(X1, X2)[:,1:20], vcat(X1, X2)[:,21], repeat([1,2], inner=1000))

8 variables are screened out from 20 variables with lasso: [5, 7, 8, 9, 11, 12, 15, 17]
Causal invariance search across 2 environments with at α=0.01 (|S| = 8, method = chow, model = linear)

S = []                                      : p-value = 0.0000 [ ] ⋂ = [5, 7, 8, 9, 11, 12, 15, 17]
S = [5]                                     : p-value = 0.0000 [ ] ⋂ = [5, 7, 8, 9, 11, 12, 15, 17]
S = [17]                                    : p-value = 0.0000 [ ] ⋂ = [5, 7, 8, 9, 11, 12, 15, 17]
S = [15]                                    : p-value = 0.0000 [ ] ⋂ = [5, 7, 8, 9, 11, 12, 15, 17]
S = [12]                                    : p-value = 0.0000 [ ] ⋂ = [5, 7, 8, 9, 11, 12, 15, 17]
S = [11]                                    : p-value = 0.0144 [*] ⋂ = [11]
S = [9]                                     : p-value = 0.0000 [ ] ⋂ = [11]
S = [8]                                     : p-value = 0.0000 [ ] ⋂ = [11]
S = [7]                                     : p-value = 0.0000 [ ] ⋂ = [11]
S = [11, 5]                                 : p-value = 0.0000 [ ] ⋂ = [11]
S = [11, 12]                                : p-value = 0.0000 [ ] ⋂ = [11]
S = [11, 15]                                : p-value = 0.0007 [ ] ⋂ = [11]
S = [7, 11]                                 : p-value = 0.0082 [ ] ⋂ = [11]
S = [11, 8]                                 : p-value = 0.0000 [ ] ⋂ = [11]
S = [9, 11]                                 : p-value = 0.0512 [*] ⋂ = [11]
S = [17, 11]                                : p-value = 0.0000 [ ] ⋂ = [11]
S = [9, 12]                                 : p-value = 0.0000 [ ] ⋂ = [11]
S = [9, 15]                                 : p-value = 0.0064 [ ] ⋂ = [11]
S = [7, 9]                                  : p-value = 0.0000 [ ] ⋂ = [11]
S = [9, 8]                                  : p-value = 0.0000 [ ] ⋂ = [11]
S = [9, 5]                                  : p-value = 0.7475 [*] ⋂ = Int64[]

Tested 21 sets: 3 sets are accepted.

 * Found no causal variable (empty intersection).

 ⋅ Variables considered include [5, 7, 8, 9, 11, 12, 15, 17]
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">causalSearch</span>(<span class="pl-c1">vcat</span>(X1, X2)[:,<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">20</span>], <span class="pl-c1">vcat</span>(X1, X2)[:,<span class="pl-c1">21</span>], <span class="pl-c1">repeat</span>([<span class="pl-c1">1</span>,<span class="pl-c1">2</span>], inner<span class="pl-k">=</span><span class="pl-c1">1000</span>))

<span class="pl-c1">8</span> variables are screened out from <span class="pl-c1">20</span> variables with lasso<span class="pl-k">:</span> [<span class="pl-c1">5</span>, <span class="pl-c1">7</span>, <span class="pl-c1">8</span>, <span class="pl-c1">9</span>, <span class="pl-c1">11</span>, <span class="pl-c1">12</span>, <span class="pl-c1">15</span>, <span class="pl-c1">17</span>]
Causal invariance search across <span class="pl-c1">2</span> environments with at α<span class="pl-k">=</span><span class="pl-c1">0.01</span> (<span class="pl-k">|</span>S<span class="pl-k">|</span> <span class="pl-k">=</span> <span class="pl-c1">8</span>, method <span class="pl-k">=</span> chow, model <span class="pl-k">=</span> linear)

S <span class="pl-k">=</span> []                                      <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">5</span>, <span class="pl-c1">7</span>, <span class="pl-c1">8</span>, <span class="pl-c1">9</span>, <span class="pl-c1">11</span>, <span class="pl-c1">12</span>, <span class="pl-c1">15</span>, <span class="pl-c1">17</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">5</span>]                                     <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">5</span>, <span class="pl-c1">7</span>, <span class="pl-c1">8</span>, <span class="pl-c1">9</span>, <span class="pl-c1">11</span>, <span class="pl-c1">12</span>, <span class="pl-c1">15</span>, <span class="pl-c1">17</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">17</span>]                                    <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">5</span>, <span class="pl-c1">7</span>, <span class="pl-c1">8</span>, <span class="pl-c1">9</span>, <span class="pl-c1">11</span>, <span class="pl-c1">12</span>, <span class="pl-c1">15</span>, <span class="pl-c1">17</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">15</span>]                                    <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">5</span>, <span class="pl-c1">7</span>, <span class="pl-c1">8</span>, <span class="pl-c1">9</span>, <span class="pl-c1">11</span>, <span class="pl-c1">12</span>, <span class="pl-c1">15</span>, <span class="pl-c1">17</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">12</span>]                                    <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">5</span>, <span class="pl-c1">7</span>, <span class="pl-c1">8</span>, <span class="pl-c1">9</span>, <span class="pl-c1">11</span>, <span class="pl-c1">12</span>, <span class="pl-c1">15</span>, <span class="pl-c1">17</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">11</span>]                                    <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0144</span> [<span class="pl-k">*</span>] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">9</span>]                                     <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">8</span>]                                     <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">7</span>]                                     <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">11</span>, <span class="pl-c1">5</span>]                                 <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">11</span>, <span class="pl-c1">12</span>]                                <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">11</span>, <span class="pl-c1">15</span>]                                <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0007</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">7</span>, <span class="pl-c1">11</span>]                                 <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0082</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">11</span>, <span class="pl-c1">8</span>]                                 <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">9</span>, <span class="pl-c1">11</span>]                                 <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0512</span> [<span class="pl-k">*</span>] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">17</span>, <span class="pl-c1">11</span>]                                <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">9</span>, <span class="pl-c1">12</span>]                                 <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">9</span>, <span class="pl-c1">15</span>]                                 <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0064</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">7</span>, <span class="pl-c1">9</span>]                                  <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">9</span>, <span class="pl-c1">8</span>]                                  <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.0000</span> [ ] ⋂ <span class="pl-k">=</span> [<span class="pl-c1">11</span>]
S <span class="pl-k">=</span> [<span class="pl-c1">9</span>, <span class="pl-c1">5</span>]                                  <span class="pl-k">:</span> p<span class="pl-k">-</span>value <span class="pl-k">=</span> <span class="pl-c1">0.7475</span> [<span class="pl-k">*</span>] ⋂ <span class="pl-k">=</span> Int64[]

Tested <span class="pl-c1">21</span> sets<span class="pl-k">:</span> <span class="pl-c1">3</span> sets are accepted.

 <span class="pl-k">*</span> Found no causal variable (empty intersection).

 <span class="pl-k">⋅</span> Variables considered include [<span class="pl-c1">5</span>, <span class="pl-c1">7</span>, <span class="pl-c1">8</span>, <span class="pl-c1">9</span>, <span class="pl-c1">11</span>, <span class="pl-c1">12</span>, <span class="pl-c1">15</span>, <span class="pl-c1">17</span>]</pre></div>
<p>The algorithm <strong>cannot find any</strong> direct causal variables (parents) of variable 21 due to <strong>insufficient power</strong> of two environments. The algorithm tends to <strong>discover more</strong> with <strong>more environments</strong>. Let us define a new environment where we perform a <strong>noise (soft) intervention</strong> that changes the equations for 5 variables other than the target. Note it is important that the <strong>target</strong> is left <strong>untouched</strong>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; sem_noise, variables_intervened = random_noise_intervened_SEM(sem_obs, p_intervened=5, avoid=[21])

(Gaussian SEM with 21 variables:
B =
      Sparsity Pattern
      ┌───────────┐
    1 │⠀⠠⠀⠀⢐⠀⠀⠄⠀⢔⠀│ &gt; 0
      │⠠⠀⠠⠨⠁⠀⠄⠀⠀⠸⠀│ &lt; 0
      │⠠⠈⠈⠀⠌⠠⠀⠅⠀⠩⠉│
      │⠠⣨⠴⠰⠪⠠⠄⠀⠸⠉⣐│
      │⢀⠲⠈⢠⠠⠀⠀⠂⠀⠲⠁│
   21 │⠀⠐⠀⠀⠠⠠⠀⠀⠀⠔⠀│
      └───────────┘
      1          21
        nz = 70σ² = [1.9727697778060356, 1.1224733663047743, 1.1798805640594814, 1.2625825149076064, 0.8503782631176267, 0.5262963446298372, 1.3835334059064883, 1.788996301274282, 1.759286517329432, 0.5837984015051159, 3.01957479564807, 0.9492838187140921, 1.9398913901673531, 1.7729995603828317, 0.7110857327642559, 1.6837378902964577, 1.2089053651343495, 1.3069888003095986, 1.3933773717634643, 1.0571823834646068, 1.9187793877731028], [17, 13, 10, 11, 12])
"><pre>julia<span class="pl-k">&gt;</span> sem_noise, variables_intervened <span class="pl-k">=</span> <span class="pl-c1">random_noise_intervened_SEM</span>(sem_obs, p_intervened<span class="pl-k">=</span><span class="pl-c1">5</span>, avoid<span class="pl-k">=</span>[<span class="pl-c1">21</span>])

(Gaussian SEM with <span class="pl-c1">21</span> variables<span class="pl-k">:</span>
B <span class="pl-k">=</span>
      Sparsity Pattern
      ┌───────────┐
    <span class="pl-c1">1</span> │⠀⠠⠀⠀⢐⠀⠀⠄⠀⢔⠀│ <span class="pl-k">&gt;</span> <span class="pl-c1">0</span>
      │⠠⠀⠠⠨⠁⠀⠄⠀⠀⠸⠀│ <span class="pl-k">&lt;</span> <span class="pl-c1">0</span>
      │⠠⠈⠈⠀⠌⠠⠀⠅⠀⠩⠉│
      │⠠⣨⠴⠰⠪⠠⠄⠀⠸⠉⣐│
      │⢀⠲⠈⢠⠠⠀⠀⠂⠀⠲⠁│
   <span class="pl-c1">21</span> │⠀⠐⠀⠀⠠⠠⠀⠀⠀⠔⠀│
      └───────────┘
      <span class="pl-c1">1</span>          <span class="pl-c1">21</span>
        nz <span class="pl-k">=</span> <span class="pl-c1">70</span>σ² <span class="pl-k">=</span> [<span class="pl-c1">1.9727697778060356</span>, <span class="pl-c1">1.1224733663047743</span>, <span class="pl-c1">1.1798805640594814</span>, <span class="pl-c1">1.2625825149076064</span>, <span class="pl-c1">0.8503782631176267</span>, <span class="pl-c1">0.5262963446298372</span>, <span class="pl-c1">1.3835334059064883</span>, <span class="pl-c1">1.788996301274282</span>, <span class="pl-c1">1.759286517329432</span>, <span class="pl-c1">0.5837984015051159</span>, <span class="pl-c1">3.01957479564807</span>, <span class="pl-c1">0.9492838187140921</span>, <span class="pl-c1">1.9398913901673531</span>, <span class="pl-c1">1.7729995603828317</span>, <span class="pl-c1">0.7110857327642559</span>, <span class="pl-c1">1.6837378902964577</span>, <span class="pl-c1">1.2089053651343495</span>, <span class="pl-c1">1.3069888003095986</span>, <span class="pl-c1">1.3933773717634643</span>, <span class="pl-c1">1.0571823834646068</span>, <span class="pl-c1">1.9187793877731028</span>], [<span class="pl-c1">17</span>, <span class="pl-c1">13</span>, <span class="pl-c1">10</span>, <span class="pl-c1">11</span>, <span class="pl-c1">12</span>])</pre></div>
<p>Here the equations for variables 17, 13, 10, 11, 12 have been changed. Now we simulate from this modified SEM and call it <strong>environment 3</strong>. We run the algorithm on all <strong>3 environments</strong>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; X3 = simulate(sem_noise, 1000)
julia&gt; causalSearch(vcat(X1, X2, X3)[:,1:20], vcat(X1, X2, X3)[:,21], repeat([1,2,3], inner=1000))
"><pre>julia<span class="pl-k">&gt;</span> X3 <span class="pl-k">=</span> <span class="pl-c1">simulate</span>(sem_noise, <span class="pl-c1">1000</span>)
julia<span class="pl-k">&gt;</span> <span class="pl-c1">causalSearch</span>(<span class="pl-c1">vcat</span>(X1, X2, X3)[:,<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">20</span>], <span class="pl-c1">vcat</span>(X1, X2, X3)[:,<span class="pl-c1">21</span>], <span class="pl-c1">repeat</span>([<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>], inner<span class="pl-k">=</span><span class="pl-c1">1000</span>))</pre></div>
<p>The algorithm searches over subsets for a while and successfully <strong>discovers</strong> variables 11. The other two causes, 9 and 18, can hopefully be discovered given even more environments.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="causalSearch(vcat(X1, X2, X3)[:,1:20], vcat(X1, X2, X3)[:,21], repeat([1,2,3], inner=1000))
8 variables are screened out from 20 variables with lasso: [4, 5, 7, 8, 9, 11, 12, 16]
Causal invariance search across 3 environments with at α=0.01 (|S| = 8, method = chow, model = linear)

S = []                                      : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [4]                                     : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [16]                                    : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [12]                                    : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [11]                                    : p-value = 0.0084 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [9]                                     : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [8]                                     : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [7]                                     : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [5]                                     : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [4, 11]                                 : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [11, 5]                                 : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [11, 8]                                 : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [7, 11]                                 : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [9, 11]                                 : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [16, 11]                                : p-value = 0.0709 [*] ⋂ = [11, 16]
S = [11, 12]                                : p-value = 0.0000 [ ] ⋂ = [11, 16]
																			...
S = [7, 9, 4, 16, 11, 5, 12]                : p-value = 0.0000 [ ] ⋂ = [11]
S = [7, 9, 4, 16, 11, 8, 12]                : p-value = 0.0001 [ ] ⋂ = [11]
S = [7, 4, 9, 16, 11, 5, 8, 12]             : p-value = 0.0002 [ ] ⋂ = [11]

Tested 256 sets: 6 sets are accepted.

 * Causal variables include: [11]

   variable   	 1.0 % 		 99.0 %
   11         	 0.1123 	 1.1017

 ⋅ Variables considered include [4, 5, 7, 8, 9, 11, 12, 16]
"><pre><code>causalSearch(vcat(X1, X2, X3)[:,1:20], vcat(X1, X2, X3)[:,21], repeat([1,2,3], inner=1000))
8 variables are screened out from 20 variables with lasso: [4, 5, 7, 8, 9, 11, 12, 16]
Causal invariance search across 3 environments with at α=0.01 (|S| = 8, method = chow, model = linear)

S = []                                      : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [4]                                     : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [16]                                    : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [12]                                    : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [11]                                    : p-value = 0.0084 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [9]                                     : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [8]                                     : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [7]                                     : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [5]                                     : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [4, 11]                                 : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [11, 5]                                 : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [11, 8]                                 : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [7, 11]                                 : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [9, 11]                                 : p-value = 0.0000 [ ] ⋂ = [4, 5, 7, 8, 9, 11, 12, 16]
S = [16, 11]                                : p-value = 0.0709 [*] ⋂ = [11, 16]
S = [11, 12]                                : p-value = 0.0000 [ ] ⋂ = [11, 16]
																			...
S = [7, 9, 4, 16, 11, 5, 12]                : p-value = 0.0000 [ ] ⋂ = [11]
S = [7, 9, 4, 16, 11, 8, 12]                : p-value = 0.0001 [ ] ⋂ = [11]
S = [7, 4, 9, 16, 11, 5, 8, 12]             : p-value = 0.0002 [ ] ⋂ = [11]

Tested 256 sets: 6 sets are accepted.

 * Causal variables include: [11]

   variable   	 1.0 % 		 99.0 %
   11         	 0.1123 	 1.1017

 ⋅ Variables considered include [4, 5, 7, 8, 9, 11, 12, 16]
</code></pre></div>
<h3><a id="user-content-functionalities" class="anchor" aria-hidden="true" href="#functionalities"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Functionalities</h3>
<ul>
<li>The main algorithm <code>causalSearch(X, y, env, [S]; α=0.01, method="chow", screen="auto", p_max=8, verbose=true, selection_only=false, n_max_for_exact=5000)</code>
<ul>
<li>Performs screening if number of covariates exceeds <code>p_max</code>
<ul>
<li><code>screen="auto"</code>: <code>"HOLP"</code> when p &gt; n, <code>"lasso"</code> otherwise</li>
<li><code>screen="HOLP"</code>: <a href="https://doi.org/10.1111/rssb.12127" rel="nofollow">High dimensional ordinary least squares projection for screening variables</a> when p ≧ n</li>
<li><code>screen="lasso"</code>: lasso solution path from <code>glmnet</code></li>
</ul>
</li>
<li>Skips supersets of an accepted set under <code>selection_only = true</code>, but confidence intervals are not reported</li>
<li>When sample size exceeds <code>n_max_for_exact</code>, sub-sampling is used for Chow test</li>
</ul>
</li>
<li>Methods
<ul>
<li><code>method="chow"</code>: Chow test for linear regression</li>
<li><code>method="logistic-LR"</code>: likelihood-ratio test for logistic regression</li>
<li><code>method="logistic-SF"</code>: <a href="http://www.jstor.org/stable/2286870" rel="nofollow">Sukhatme-Fisher test</a> for testing equal mean and variance of logistic prediction residuals</li>
</ul>
</li>
<li>SEM utilities: <code>random_gaussian_SEM</code>, <code>random_noise_intervened_SEM</code>, <code>simulate</code>, <code>causes</code> and <code>cov</code> for generating random SEM (Erdos-Renyi), simulation and interventions.</li>
<li>Variables screening:
<ul>
<li>Lasso (with <code>glmnet</code>): <code>screen_lasso(X, y, pmax)</code></li>
</ul>
</li>
</ul>
<h3><a id="user-content-features" class="anchor" aria-hidden="true" href="#features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Features</h3>
<ul>
<li>High performance implementation in Julia v1.x</li>
<li>Faster search:
<ul>
<li>skipping testing supersets of A if A is accepted ( under  <code>selection_only</code> mode)</li>
<li>Priority queue to prioritize testing sets likely to be invariant</li>
</ul>
</li>
</ul>
</article></div>