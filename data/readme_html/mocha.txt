<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p><strong>Update Dec. 2018</strong>: Mocha.jl is now deprecated. The latest version works with Julia v0.6. If you have existing legacy codebase with Mocha that you want to updates for Julia v1.0, the pull request <a href="https://github.com/pluskid/Mocha.jl/pull/255">255</a> contains fixes for CPU backend only that have all the unit tests passed under Julia v1.0.</p>
<p>The development of Mocha.jl happens in relative early days of Julia. Now that both Julia and the ecosystem has evolved significantly, and with some exciting new tech such as writing GPU kernels directly in Julia and general auto-differentiation supports, the Mocha codebase becomes excessively old and primitive. Reworking Mocha with new technologies requires some non-trivial efforts, and new exciting solutions already exist nowadays, it is a good time for the retirement of Mocha.jl.</p>
<p>If you are interested in doing deep learning with Julia, please check out some alternative packages that are more up-to-date and actively maintained. In particular, there are <a href="https://github.com/denizyuret/Knet.jl">Knet.jl</a> and <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> for pure-Julia solutions, and <a href="https://github.com/dmlc/MXNet.jl">MXNet.jl</a> and <a href="https://github.com/malmaud/TensorFlow.jl">Tensorflow.jl</a> for wrapper to existing deep learning systems.</p>
<h1><a id="user-content-mocha" class="anchor" aria-hidden="true" href="#mocha"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Mocha</h1>
<p><a href="https://travis-ci.org/pluskid/Mocha.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/4276834aa062adc23bc7e4278dbe8054c3697937/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f706c75736b69642f4d6f6368612e6a6c2e7376673f7374796c653d666c6174266272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://img.shields.io/travis/pluskid/Mocha.jl.svg?style=flat&amp;branch=master" style="max-width:100%;"></a>
<a href="http://mochajl.readthedocs.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/1cab75e9b6a004cdaa5eab4a074525c3208c28b6/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6d6f6368616a6c2f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/mochajl/badge/?version=latest" style="max-width:100%;"></a>
<a href="http://pkg.julialang.org/?pkg=Mocha&amp;ver=0.6" rel="nofollow"><img src="https://camo.githubusercontent.com/ab08571045944618047a7c95078b352513135a5c/687474703a2f2f706b672e6a756c69616c616e672e6f72672f6261646765732f4d6f6368615f302e362e737667" alt="Mocha" data-canonical-src="http://pkg.julialang.org/badges/Mocha_0.6.svg" style="max-width:100%;"></a>
<a href="https://coveralls.io/r/pluskid/Mocha.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/b5ba4c6da2844d806d7a1457ed348571dd240c11/68747470733a2f2f696d672e736869656c64732e696f2f636f766572616c6c732f706c75736b69642f4d6f6368612e6a6c2e7376673f7374796c653d666c6174" alt="Coverage Status" data-canonical-src="https://img.shields.io/coveralls/pluskid/Mocha.jl.svg?style=flat" style="max-width:100%;"></a>
<a href="LICENSE.md"><img src="https://camo.githubusercontent.com/4440d5deb3a53c4f8661ee765378e6071e7878e8/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c6174" alt="License" data-canonical-src="http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" style="max-width:100%;"></a></p>

<p><a href="http://mochajl.readthedocs.org/en/latest/#tutorials" rel="nofollow">Tutorials</a> | <a href="http://mochajl.readthedocs.org/" rel="nofollow">Documentation</a> | <a href="NEWS.md">Release Notes</a> | <a href="https://github.com/pluskid/Mocha.jl/issues/22">Roadmap</a> | <a href="https://github.com/pluskid/Mocha.jl/issues">Issues</a></p>
<p>Mocha is a Deep Learning framework for <a href="http://julialang.org/" rel="nofollow">Julia</a>, inspired by the C++ framework <a href="http://caffe.berkeleyvision.org/" rel="nofollow">Caffe</a>. Efficient implementations of general stochastic gradient solvers and common layers in Mocha can be used to train deep / shallow (convolutional) neural networks, with (optional) unsupervised pre-training via (stacked) auto-encoders. Some highlights:</p>
<ul>
<li><strong>Modular Architecture</strong>: Mocha has a clean architecture with isolated components like network layers, activation functions, solvers, regularizers, initializers, etc. Built-in components are sufficient for typical deep (convolutional) neural network applications and more are being added in each release. All of them can be easily extended by adding custom sub-types.</li>
<li><strong>High-level Interface</strong>: Mocha is written in <a href="http://julialang.org/" rel="nofollow">Julia</a>, a high-level dynamic programming language designed for scientific computing. Combining with the expressive power of Julia and its package eco-system, playing with deep neural networks in Mocha is easy and intuitive. See for example our IJulia Notebook example of <a href="http://nbviewer.ipython.org/github/pluskid/Mocha.jl/blob/master/examples/ijulia/ilsvrc12/imagenet-classifier.ipynb" rel="nofollow">using a pre-trained imagenet model to do image classification</a>.</li>
<li><strong>Portability and Speed</strong>: Mocha comes with multiple backends that can be switched transparently.
<ul>
<li>The <em>pure Julia backend</em> is portable -- it runs on any platform that supports Julia. This is reasonably fast on small models thanks to Julia's LLVM-based just-in-time (JIT) compiler and <a href="http://julia.readthedocs.org/en/latest/manual/performance-tips/#performance-annotations" rel="nofollow">Performance Annotations</a>, and can be very useful for prototyping.</li>
<li>The <em>native extension backend</em> can be turned on when a C++ compiler is available. It runs 2~3 times faster than the pure Julia backend.</li>
<li>The <em>GPU backend</em> uses NVidiaÂ® <a href="https://developer.nvidia.com/cuDNN" rel="nofollow">cuDNN</a>, cuBLAS and customized CUDA kernels to provide highly efficient computation. 20~30 times or even more speedup could be observed on a modern GPU device, especially on larger models.</li>
</ul>
</li>
<li><strong>Compatibility</strong>: Mocha uses the widely adopted HDF5 format to store both datasets and model snapshots, making it easy to inter-operate with Matlab, Python (numpy) and other existing computational tools. Mocha also provides tools to import trained model snapshots from Caffe.</li>
<li><strong>Correctness</strong>: the computational components in Mocha in all backends are extensively covered by unit-tests.</li>
<li><strong>Open Source</strong>: Mocha is licensed under <a href="LICENSE.md">the MIT "Expat" License</a>.</li>
</ul>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>To install the release version, simply run</p>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>Mocha<span class="pl-pds">"</span></span>)</pre></div>
<p>on the Julia console. To install the latest development version, run the following command instead:</p>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">clone</span>(<span class="pl-s"><span class="pl-pds">"</span>https://github.com/pluskid/Mocha.jl.git<span class="pl-pds">"</span></span>)</pre></div>
<p>Then you can run the built-in unit tests with</p>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">test</span>(<span class="pl-s"><span class="pl-pds">"</span>Mocha<span class="pl-pds">"</span></span>)</pre></div>
<p>to verify that everything is functioning properly on your machine.</p>
<h2><a id="user-content-hello-world" class="anchor" aria-hidden="true" href="#hello-world"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Hello World</h2>
<p>Please refer to <a href="http://mochajl.readthedocs.org/en/latest/tutorial/mnist.html" rel="nofollow">the MNIST tutorial</a> on how to prepare the MNIST dataset for the following example. The complete code for this example is located at <a href="examples/mnist/mnist.jl"><code>examples/mnist/mnist.jl</code></a>. See below for detailed documentation of other tutorials and user guide.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Mocha

data  <span class="pl-k">=</span> <span class="pl-c1">HDF5DataLayer</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>train-data<span class="pl-pds">"</span></span>,source<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>train-data-list.txt<span class="pl-pds">"</span></span>,batch_size<span class="pl-k">=</span><span class="pl-c1">64</span>)
conv  <span class="pl-k">=</span> <span class="pl-c1">ConvolutionLayer</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>conv1<span class="pl-pds">"</span></span>,n_filter<span class="pl-k">=</span><span class="pl-c1">20</span>,kernel<span class="pl-k">=</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>),bottoms<span class="pl-k">=</span>[<span class="pl-c1">:data</span>],tops<span class="pl-k">=</span>[<span class="pl-c1">:conv</span>])
pool  <span class="pl-k">=</span> <span class="pl-c1">PoolingLayer</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>pool1<span class="pl-pds">"</span></span>,kernel<span class="pl-k">=</span>(<span class="pl-c1">2</span>,<span class="pl-c1">2</span>),stride<span class="pl-k">=</span>(<span class="pl-c1">2</span>,<span class="pl-c1">2</span>),bottoms<span class="pl-k">=</span>[<span class="pl-c1">:conv</span>],tops<span class="pl-k">=</span>[<span class="pl-c1">:pool</span>])
conv2 <span class="pl-k">=</span> <span class="pl-c1">ConvolutionLayer</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>conv2<span class="pl-pds">"</span></span>,n_filter<span class="pl-k">=</span><span class="pl-c1">50</span>,kernel<span class="pl-k">=</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>),bottoms<span class="pl-k">=</span>[<span class="pl-c1">:pool</span>],tops<span class="pl-k">=</span>[<span class="pl-c1">:conv2</span>])
pool2 <span class="pl-k">=</span> <span class="pl-c1">PoolingLayer</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>pool2<span class="pl-pds">"</span></span>,kernel<span class="pl-k">=</span>(<span class="pl-c1">2</span>,<span class="pl-c1">2</span>),stride<span class="pl-k">=</span>(<span class="pl-c1">2</span>,<span class="pl-c1">2</span>),bottoms<span class="pl-k">=</span>[<span class="pl-c1">:conv2</span>],tops<span class="pl-k">=</span>[<span class="pl-c1">:pool2</span>])
fc1   <span class="pl-k">=</span> <span class="pl-c1">InnerProductLayer</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>ip1<span class="pl-pds">"</span></span>,output_dim<span class="pl-k">=</span><span class="pl-c1">500</span>,neuron<span class="pl-k">=</span>Neurons<span class="pl-k">.</span><span class="pl-c1">ReLU</span>(),bottoms<span class="pl-k">=</span>[<span class="pl-c1">:pool2</span>],
                          tops<span class="pl-k">=</span>[<span class="pl-c1">:ip1</span>])
fc2   <span class="pl-k">=</span> <span class="pl-c1">InnerProductLayer</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>ip2<span class="pl-pds">"</span></span>,output_dim<span class="pl-k">=</span><span class="pl-c1">10</span>,bottoms<span class="pl-k">=</span>[<span class="pl-c1">:ip1</span>],tops<span class="pl-k">=</span>[<span class="pl-c1">:ip2</span>])
loss  <span class="pl-k">=</span> <span class="pl-c1">SoftmaxLossLayer</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>loss<span class="pl-pds">"</span></span>,bottoms<span class="pl-k">=</span>[<span class="pl-c1">:ip2</span>,<span class="pl-c1">:label</span>])

backend <span class="pl-k">=</span> <span class="pl-c1">DefaultBackend</span>()
<span class="pl-c1">init</span>(backend)

common_layers <span class="pl-k">=</span> [conv, pool, conv2, pool2, fc1, fc2]
net <span class="pl-k">=</span> <span class="pl-c1">Net</span>(<span class="pl-s"><span class="pl-pds">"</span>MNIST-train<span class="pl-pds">"</span></span>, backend, [data, common_layers<span class="pl-k">...</span>, loss])

exp_dir <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>snapshots<span class="pl-pds">"</span></span>
solver_method <span class="pl-k">=</span> <span class="pl-c1">SGD</span>()
params <span class="pl-k">=</span> <span class="pl-c1">make_solver_parameters</span>(solver_method, max_iter<span class="pl-k">=</span><span class="pl-c1">10000</span>, regu_coef<span class="pl-k">=</span><span class="pl-c1">0.0005</span>,
    mom_policy<span class="pl-k">=</span>MomPolicy<span class="pl-k">.</span><span class="pl-c1">Fixed</span>(<span class="pl-c1">0.9</span>),
    lr_policy<span class="pl-k">=</span>LRPolicy<span class="pl-k">.</span><span class="pl-c1">Inv</span>(<span class="pl-c1">0.01</span>, <span class="pl-c1">0.0001</span>, <span class="pl-c1">0.75</span>),
    load_from<span class="pl-k">=</span>exp_dir)
solver <span class="pl-k">=</span> <span class="pl-c1">Solver</span>(solver_method, params)

<span class="pl-c1">setup_coffee_lounge</span>(solver, save_into<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-v">$exp_dir</span>/statistics.jld<span class="pl-pds">"</span></span>, every_n_iter<span class="pl-k">=</span><span class="pl-c1">1000</span>)

<span class="pl-c"><span class="pl-c">#</span> report training progress every 100 iterations</span>
<span class="pl-c1">add_coffee_break</span>(solver, <span class="pl-c1">TrainingSummary</span>(), every_n_iter<span class="pl-k">=</span><span class="pl-c1">100</span>)

<span class="pl-c"><span class="pl-c">#</span> save snapshots every 5000 iterations</span>
<span class="pl-c1">add_coffee_break</span>(solver, <span class="pl-c1">Snapshot</span>(exp_dir), every_n_iter<span class="pl-k">=</span><span class="pl-c1">5000</span>)

<span class="pl-c"><span class="pl-c">#</span> show performance on test data every 1000 iterations</span>
data_test <span class="pl-k">=</span> <span class="pl-c1">HDF5DataLayer</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>test-data<span class="pl-pds">"</span></span>,source<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>test-data-list.txt<span class="pl-pds">"</span></span>,batch_size<span class="pl-k">=</span><span class="pl-c1">100</span>)
accuracy <span class="pl-k">=</span> <span class="pl-c1">AccuracyLayer</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>test-accuracy<span class="pl-pds">"</span></span>,bottoms<span class="pl-k">=</span>[<span class="pl-c1">:ip2</span>, <span class="pl-c1">:label</span>])
test_net <span class="pl-k">=</span> <span class="pl-c1">Net</span>(<span class="pl-s"><span class="pl-pds">"</span>MNIST-test<span class="pl-pds">"</span></span>, backend, [data_test, common_layers<span class="pl-k">...</span>, accuracy])
<span class="pl-c1">add_coffee_break</span>(solver, <span class="pl-c1">ValidationPerformance</span>(test_net), every_n_iter<span class="pl-k">=</span><span class="pl-c1">1000</span>)

<span class="pl-c1">solve</span>(solver, net)

<span class="pl-c1">destroy</span>(net)
<span class="pl-c1">destroy</span>(test_net)
<span class="pl-c1">shutdown</span>(backend)</pre></div>
<h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Documentation</h2>
<p>The Mocha documentation is hosted at <a href="http://mochajl.readthedocs.org/" rel="nofollow">readthedocs.org</a>.</p>
</article></div>