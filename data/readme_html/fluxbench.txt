<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-fluxbenchjl" class="anchor" aria-hidden="true" href="#fluxbenchjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>FluxBench.jl</h1>
<p dir="auto"><a href="https://buildkite.com/julialang/fluxbench-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/5f2e8af08dd52cd8e9e19a673e334c8704639482ba317e1d87c57441346df5df/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f35363034363030343366333364633661323362346263373337396537646431323061326463313062333530643730323163612e737667" alt="" data-canonical-src="https://badge.buildkite.com/560460043f33dc6a23b4bc7379e7dd120a2dc10b350d7021ca.svg" style="max-width: 100%;"></a> <a href="https://speed.fluxml.ai" rel="nofollow"><img src="https://camo.githubusercontent.com/1073992785871ecf3293a215700dd1f27ec48779ab2580db1216675cee683441/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f42656e63686d61726b732d73706565642e666c75786d6c2e61692d626c7565" alt="bench-img" data-canonical-src="https://img.shields.io/badge/Benchmarks-speed.fluxml.ai-blue" style="max-width: 100%;"></a></p>
<p dir="auto">This is a repository that backs the results generated for <a href="https://speed.fluxml.ai" rel="nofollow">https://speed.fluxml.ai</a></p>
<p dir="auto">It is a collection of benchmarking runs for a subset of modeling done in the FluxML ecosystem and also serves as a means of tracking progress.</p>
<h3 dir="auto"><a id="user-content-running-locally" class="anchor" aria-hidden="true" href="#running-locally"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Running Locally</h3>
<p dir="auto">To run the benchmarks locally:</p>
<ul dir="auto">
<li>clone this repository</li>
<li><code>cd</code> in to the local copy via <code>cd FluxBench.jl</code></li>
<li>open Julia and call <code>] instantiate</code></li>
</ul>
<p dir="auto">And finally:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using FluxBench

julia&gt; FluxBench.bench()"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> FluxBench

julia<span class="pl-k">&gt;</span> FluxBench<span class="pl-k">.</span><span class="pl-c1">bench</span>()</pre></div>
<h2 dir="auto"><a id="user-content-adding-benchmarks" class="anchor" aria-hidden="true" href="#adding-benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Adding Benchmarks</h2>
<p dir="auto">To contribute benchmarks one needs to:</p>
<ul dir="auto">
<li>add in the script(s) to the <code>src/packages</code> directory with the required dependencies and code needed to run the benchmarks
<ul dir="auto">
<li>Note: remember to add a <code>group</code> to the <code>SUITE</code> variable via the <code>addgroup!(SUITE, "name/of/benchmark/group")</code></li>
<li>Treat <code>group</code> as a dictionary and new benchmarks can be added via assigning results to group as: <code>group["name_of_benchmark"] = @benchmarkable ...</code></li>
<li>Please use the macro <code>@benchmarkable</code> to set up the benchmarks (see BenchmarkTools.jl for a reference)</li>
<li>Please follow the performance, profiling and benchmarking guides of the different packages used in the benchmark. Examples include - <a href="https://docs.julialang.org/en/v1/manual/performance-tips/" rel="nofollow">Julia's</a>, <a href="https://fluxml.ai/Flux.jl/stable/performance/" rel="nofollow">Flux's</a>, <a href="https://cuda.juliagpu.org/stable/development/profiling/" rel="nofollow">CUDA's</a>, <a href="https://juliaci.github.io/BenchmarkTools.jl/stable/manual/" rel="nofollow">BenchmarkTools</a></li>
</ul>
</li>
<li>include the benchmarks in the top level file <code>src/FluxBench.jl</code></li>
<li>call the benchmarks in the <code>bench</code> function located in file <code>src/bench.jl</code></li>
</ul>
</article></div>