<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-parallelneighborsjl" class="anchor" aria-hidden="true" href="#parallelneighborsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ParallelNeighbors.jl</h1>
<p dir="auto"><a href="https://codecov.io/gh/davnn/ParallelNeighbors.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/ac7584c64ae0aec4a81c31225eaa3d1447ba89118bb41bac80ad7c61647f4472/68747470733a2f2f636f6465636f762e696f2f67682f6461766e6e2f506172616c6c656c4e65696768626f72732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/davnn/ParallelNeighbors.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><code>ParallelNeighbors.jl</code> is a Julia package to perform high-performance exact nearest neighbor searches in high-dimensionsal spaces. Unlike <a href="https://github.com/KristofferC/NearestNeighbors.jl">NearestNeighbors.jl</a>, this package solely focuses on massively-parallel brute-force search, which becomes necessary once the data dimensionality becomes large.</p>
<p dir="auto">Currently, the package is <em>experimental</em>, but it should already be usable for most cases. Things that are not yet supported are distance functions other than <code>Euclidean</code> and <code>SqEuclidean</code>.</p>
<p dir="auto">The package only supports <a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a> at the moment, but support for packages like <a href="https://github.com/JuliaGPU/AMDGPU.jl">AMDGPU.jl</a> could be implemented in the future.</p>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">It is recommended to use <a href="https://julialang.github.io/Pkg.jl" rel="nofollow">Pkg.jl</a> for installation. Follow the command below to install the latest official release or use <code>] add ParallelNeighbors</code> in the Julia REPL.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import Pkg;
Pkg.add(&quot;ParallelNeighbors&quot;)"><pre><span class="pl-k">import</span> Pkg;
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>ParallelNeighbors<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">If you would like to modify the package locally, you can use <code>Pkg.develop("ParallelNeighbors")</code> or <code>] dev ParallelNeighbors</code> in the Julia REPL. This fetches a full clone of the package to <code>~/.julia/dev/</code> (the path can be changed by setting the environment variable <code>JULIA_PKG_DEVDIR</code>).</p>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">As the name implies, <code>ParallelNeighbors</code> is all about parallelization of your nearest neighbors searches. It provides a simple interface to perform massively-parallel nearest neighbors searches: <code>knn(Xtrain, Xtest, k, batch_size; metric, algorithm)</code>. The interface is similar to the one provided by <a href="https://github.com/KristofferC/NearestNeighbors.jl">NearestNeighbors.jl</a>, yielding two vectors containing the indices and distances of the nearest neighbors.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ParallelNeighbors

k = 5; # number of neighbors to search
Xtrain = rand(Float32, 1000, 1000);
Xtest = rand(Float32, 1000, 100);

# using CPU-only in the following example
idxs, dists = knn(Xtrain, Xtest, k)"><pre><span class="pl-k">using</span> ParallelNeighbors

k <span class="pl-k">=</span> <span class="pl-c1">5</span>; <span class="pl-c"><span class="pl-c">#</span> number of neighbors to search</span>
Xtrain <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float32, <span class="pl-c1">1000</span>, <span class="pl-c1">1000</span>);
Xtest <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float32, <span class="pl-c1">1000</span>, <span class="pl-c1">100</span>);

<span class="pl-c"><span class="pl-c">#</span> using CPU-only in the following example</span>
idxs, dists <span class="pl-k">=</span> <span class="pl-c1">knn</span>(Xtrain, Xtest, k)</pre></div>
<p dir="auto">Assuming that you have a CUDA-compatible device available, you would use the package as follows (if <code>Xtrain</code> and <code>Xtest</code> is not already a <code>CuMatrix</code>). Note, that different algorithm are available depending on your requirements.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using CUDA

# copy batches of train and test data to the GPU
idxs, dists = knn(Xtrain, Xtest, k; algorithm=:hybrid_batch_all)

# copy the full train data and batches of the test data to the GPU
idxs, dists = knn(Xtrain, Xtest, k; algorithm=:hybrid_batch_test)

# copy the full train and test data to the GPU
idxs, dists = knn(Xtrain, Xtest, k; algorithm=:full)"><pre><span class="pl-k">using</span> CUDA

<span class="pl-c"><span class="pl-c">#</span> copy batches of train and test data to the GPU</span>
idxs, dists <span class="pl-k">=</span> <span class="pl-c1">knn</span>(Xtrain, Xtest, k; algorithm<span class="pl-k">=</span><span class="pl-c1">:hybrid_batch_all</span>)

<span class="pl-c"><span class="pl-c">#</span> copy the full train data and batches of the test data to the GPU</span>
idxs, dists <span class="pl-k">=</span> <span class="pl-c1">knn</span>(Xtrain, Xtest, k; algorithm<span class="pl-k">=</span><span class="pl-c1">:hybrid_batch_test</span>)

<span class="pl-c"><span class="pl-c">#</span> copy the full train and test data to the GPU</span>
idxs, dists <span class="pl-k">=</span> <span class="pl-c1">knn</span>(Xtrain, Xtest, k; algorithm<span class="pl-k">=</span><span class="pl-c1">:full</span>)</pre></div>
<p dir="auto">The difference between the algorithms is:</p>
<ul dir="auto">
<li><code>full</code> calculates the full distance matrix, then ranks the nearest neighbors, which is currently the slowest method, but might become useful once better specialized GPU kernels are available. In this case all calculations happen on the same device (CPU or GPU).</li>
<li><code>hybrid_batch_test</code> calculates the distance matrix for a batch of test points to all train points, and sorts the batch <em>(n - 1)</em> in parallel (CPU) while the distance for batch <em>n</em> is calculated (GPU).</li>
<li><code>hybrid_batch_all</code> is the most versatile function, batching distance calculation for the train and test points (GPU), again sorting in parallel (CPU).</li>
</ul>
<h2 dir="auto"><a id="user-content-performance" class="anchor" aria-hidden="true" href="#performance"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Performance</h2>
<p dir="auto">The default algorithm is <code>hybrid_batch_all</code> with a default batch size of <code>max(trunc(Int, n^(1 / sqrt(2))), k)</code> and should be the method of choice for most use cases. You can tune the <code>batch_size</code> argument such that it perfectly fits your use case. You should always try to fit all the data on the GPU beforehand as in the following example (reusing the data from above example).</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using BenchmarkTools: @benchmark

batch_size = 500
Xtrain_cu, Xtest_cu = cu(Xtrain), cu(Xtest)

# with data copied to the GPU beforehand (fastest)
@benchmark knn($Xtrain_cu, $Xtest_cu, $k, $batch_size)"><pre><span class="pl-k">using</span> BenchmarkTools<span class="pl-k">:</span> <span class="pl-c1">@benchmark</span>

batch_size <span class="pl-k">=</span> <span class="pl-c1">500</span>
Xtrain_cu, Xtest_cu <span class="pl-k">=</span> <span class="pl-c1">cu</span>(Xtrain), <span class="pl-c1">cu</span>(Xtest)

<span class="pl-c"><span class="pl-c">#</span> with data copied to the GPU beforehand (fastest)</span>
<span class="pl-c1">@benchmark</span> <span class="pl-c1">knn</span>(<span class="pl-k">$</span>Xtrain_cu, <span class="pl-k">$</span>Xtest_cu, <span class="pl-k">$</span>k, <span class="pl-k">$</span>batch_size)</pre></div>
<h2 dir="auto"><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributing</h2>
<p dir="auto"><code>ParallelNeighbors.jl</code> is a community effort and your help is extremely welcome! Please open an issue or pull request if you find a bug or would like to contribute to the project.</p>
</article></div>