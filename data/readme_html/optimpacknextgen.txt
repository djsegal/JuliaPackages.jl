<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-optimpacknextgenjl" class="anchor" aria-hidden="true" href="#optimpacknextgenjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>OptimPackNextGen.jl</h1>
<p dir="auto"><a href="./LICENSE.md"><img src="https://camo.githubusercontent.com/bbf49a2eb96e6f718803f2493bd7aa3baae61abb09b7f8fc185a94e08c504dc6/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c6174" alt="License" data-canonical-src="http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" style="max-width: 100%;"></a>
<a href="https://travis-ci.org/emmt/OptimPackNextGen.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/69c3085ccfdbf311ac5b7f061ca27fa3e7ae34204a61e1b7e4a0cb234f0520d6/68747470733a2f2f7472617669732d63692e6f72672f656d6d742f4f7074696d5061636b4e65787447656e2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/emmt/OptimPackNextGen.jl.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://ci.appveyor.com/project/emmt/OptimPackNextGen-jl/branch/master" rel="nofollow"><img src="https://camo.githubusercontent.com/2451e80621e2546d6e3a28ae193aa0c899faa3702a41dc121532882d29c422d9/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f656d6d742f4f7074696d5061636b4e65787447656e2e6a6c3f6272616e63683d6d6173746572" alt="Appveyor" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/emmt/OptimPackNextGen.jl?branch=master" style="max-width: 100%;"></a>
<a href="https://coveralls.io/github/emmt/OptimPackNextGen.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/aba8296364f794a48eb815eff2ed18b45cec43a1d2fe0d9d1bc64820cc16fdde/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f656d6d742f4f7074696d5061636b4e65787447656e2e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562" alt="Coveralls" data-canonical-src="https://coveralls.io/repos/emmt/OptimPackNextGen.jl/badge.svg?branch=master&amp;service=github" style="max-width: 100%;"></a>
<a href="http://codecov.io/github/emmt/OptimPackNextGen.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/221919ee88d015e0e106b43a5fd1c10dae881815bd6d0941570c7d682211dfa6/687474703a2f2f636f6465636f762e696f2f6769746875622f656d6d742f4f7074696d5061636b4e65787447656e2e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="Codecov.io" data-canonical-src="http://codecov.io/github/emmt/OptimPackNextGen.jl/coverage.svg?branch=master" style="max-width: 100%;"></a></p>
<p dir="auto"><code>OptimPackNextGen</code> is a <a href="http://julialang.org/" rel="nofollow">Julia</a> package for numerical
optimization with particular focus on large scale problems.</p>
<h2 dir="auto"><a id="user-content-large-scale-problems" class="anchor" aria-hidden="true" href="#large-scale-problems"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Large scale problems</h2>
<ul dir="auto">
<li>
<p dir="auto"><a href="doc/quasinewton.md">Quasi-Newton methods</a> can be used to solve nonlinear
large scale optimization problems. Optionally, bounds on the variables can be
taken into account. The objective function must be differentiable and the
caller must provide means to compute the objective function and its gradient.
If the <a href="https://github.com/FluxML/Zygote.jl"><code>Zygote</code></a> is loaded, the
gradient of the objective function may be computed by means of
automatic-differentiation.</p>
</li>
<li>
<p dir="auto"><em>Spectral Projected Gradient</em> (SPG) method is provided for large-scale
optimization problems with a differentiable objective function and convex
constraints. The caller of <code>spg</code> (or <code>spg!</code>) shall provide a couple of
functions to compute the objective function and its gradient and to project
the variables on the feasible set. If the
<a href="https://github.com/FluxML/Zygote.jl"><code>Zygote</code></a> is loaded, the gradient of
the objective function may be computed by means of automatic-differentiation.</p>
</li>
<li>
<p dir="auto"><a href="doc/linesearches.md">Line searches methods</a> are used to approximately
minimize the objective function along a given search direction.</p>
</li>
<li>
<p dir="auto"><a href="doc/algebra.md">Algebra</a> describes operations on "vectors" (that is to say
the "variables" of the problem to solve).</p>
</li>
</ul>
<h2 dir="auto"><a id="user-content-small-to-moderate-size-problems" class="anchor" aria-hidden="true" href="#small-to-moderate-size-problems"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Small to moderate size problems</h2>
<p dir="auto">For problems of small to moderate size, <code>OptimPackNextGen</code> provides:</p>
<ul dir="auto">
<li>
<p dir="auto">Mike Powell's <code>COBYLA</code> (Powell, 1994), <code>NEWUOA</code> (Powell, 2006), and <code>BOBYQA</code>
(Powell, 2009) algorithms for minimizing a function of many variables. These
methods are <em>derivatives free</em> (only the function values are needed).
<code>NEWUOA</code> is for unconstrained optimization. <code>COBYLA</code> accounts for general
inequality constraints. <code>BOBYQA</code> accounts for bound constraints on the
variables.</p>
</li>
<li>
<p dir="auto"><code>nllsq</code> implements non-linear (weighted) least squares fit. Powell's NEWUOA
method is exploited to find the best fit parameters of given data by a user
defined model function.</p>
</li>
</ul>
<h2 dir="auto"><a id="user-content-univariate-functions" class="anchor" aria-hidden="true" href="#univariate-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Univariate functions</h2>
<p dir="auto">The following methods are provided for univariate functions:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>Brent.fzero</code> implements van Wijngaarden–Dekker–Brent method for finding a
zero of a function (Brent, 1973).</p>
</li>
<li>
<p dir="auto"><code>Brent.fmin</code> implements Brent's method for finding a minimum of a function
(Brent, 1973).</p>
</li>
<li>
<p dir="auto"><code>Bradi.minimize</code> (resp. <code>Bradi.maximize</code>) implements the BRADI ("Bracket"
then "Dig"; Soulez <em>et al.</em>, 2014) method for finding the global minimum
(resp. maximum) of a function on an interval.</p>
</li>
<li>
<p dir="auto"><code>Step.minimize</code> (resp. <code>Step.maximize</code>) implements the STEP method (Swarzberg
<em>et al.</em>, 1994) for finding the global minimum (resp. maximum) of a function
on an interval. The objective function <code>f(x)</code> and the variable <code>x</code> may have
units.</p>
</li>
</ul>
<h2 dir="auto"><a id="user-content-trust-region" class="anchor" aria-hidden="true" href="#trust-region"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Trust region</h2>
<ul dir="auto">
<li>Methods <code>gqtpar</code> and <code>gqtpar!</code> implement Moré &amp; Sorensen algorithm for
computing a trust region step (Moré &amp; D.C. Sorensen, 1983).</li>
</ul>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">The easiest way to install <code>OptimPackNextGen</code> is via Julia registry
<a href="https://github.com/emmt/EmmtRegistry"><code>EmmtRegistry</code></a>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Pkg
pkg&quot;registry add General&quot;  # if not yet any registries
pkg&quot;registry add https://github.com/emmt/EmmtRegistry&quot;
pkg&quot;add OptimPackNextGen&quot;"><pre><span class="pl-k">using</span> Pkg
<span class="pl-s"><span class="pl-pds"><span class="pl-c1">pkg</span>"</span>registry add General<span class="pl-pds">"</span></span>  <span class="pl-c"><span class="pl-c">#</span> if not yet any registries</span>
<span class="pl-s"><span class="pl-pds"><span class="pl-c1">pkg</span>"</span>registry add https://github.com/emmt/EmmtRegistry<span class="pl-pds">"</span></span>
<span class="pl-s"><span class="pl-pds"><span class="pl-c1">pkg</span>"</span>add OptimPackNextGen<span class="pl-pds">"</span></span></pre></div>
<h2 dir="auto"><a id="user-content-rationale-and-related-software" class="anchor" aria-hidden="true" href="#rationale-and-related-software"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Rationale and related software</h2>
<p dir="auto">Related software are the <a href="https://github.com/emmt/OptimPack"><code>OptimPack</code></a>
library which implements the C version of the algorithms and the
<a href="https://github.com/emmt/OptimPack.jl"><code>OptimPack.jl</code></a> Julia package which is a
wrapper of this library for Julia. Compared to <code>OptimPack.jl</code>, the new
<code>OptimPackNextGen.jl</code> implements in pure Julia the algorithms dedicated to
large scale problems but still relies on the C libraries for a few algorithms
(notably the Powell methods). Precompiled versions of these libraries are
provided by
<a href="https://github.com/JuliaBinaryWrappers/OptimPack_jll.jl">OptimPack_jll</a>
package. The rationale is to facilitate the integration of exotic types of
variables for optimization problems in Julia. Eventually, <code>OptimPackNextGen.jl</code>
will become the next version of <code>OptimPack.jl</code> but, until then, it is more
flexible to have two separate modules and avoid coping with compatibility and
design issues.</p>
<h2 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<ul dir="auto">
<li>
<p dir="auto">S.J. Benson &amp; J.J. Moré, "<em>A limited memory variable metric method in
subspaces and bound constrained optimization problems</em>", in Subspaces and
Bound Constrained Optimization Problems, (2001).</p>
</li>
<li>
<p dir="auto">E.G. Birgin, J.M. Martínez &amp; M. Raydan, "<em>Nonmonotone Spectral Projected
Gradient Methods on Convex Sets</em>," SIAM J. Optim. <strong>10</strong>, 1196-1211 (2000).</p>
</li>
<li>
<p dir="auto">R.P. Brent, "<em>Algorithms for Minimization without Derivatives</em>,"
Prentice-Hall, Inc. (1973).</p>
</li>
<li>
<p dir="auto">W.W. Hager &amp; H. Zhang, "<em>A New Conjugate Gradient Method with Guaranteed
Descent and an Efficient Line Search</em>," SIAM J. Optim., Vol. 16, pp. 170-192
(2005).</p>
</li>
<li>
<p dir="auto">W.W. Hager &amp; H. Zhang, "<em>A survey of nonlinear conjugate gradient methods</em>,"
Pacific Journal of Optimization, Vol. 2, pp. 35-58 (2006).</p>
</li>
<li>
<p dir="auto">M.R. Hestenes &amp; E. Stiefel, "<em>Methods of Conjugate Gradients for Solving
Linear Systems</em>," Journal of Research of the National Bureau of Standards 49,
pp. 409-436 (1952).</p>
</li>
<li>
<p dir="auto">D. Liu and J. Nocedal, "<em>On the limited memory BFGS method for large scale
optimization</em>", Mathematical Programming B <strong>45</strong>, 503-528 (1989).</p>
</li>
<li>
<p dir="auto">J.J. Moré &amp; D.C. Sorensen, "<em>Computing a Trust Region Step</em>," SIAM J. Sci.
Stat. Comp. <strong>4</strong>, 553-572 (1983).</p>
</li>
<li>
<p dir="auto">J.J. Moré and D.J. Thuente, "<em>Line search algorithms with guaranteed
sufficient decrease</em>" in ACM Transactions on Mathematical Software (TOMS)
Volume 20, Issue 3, Pages 286-307 (1994).</p>
</li>
<li>
<p dir="auto">M.J.D. Powell, "<em>A direct search optimization method that models the
objective and constraint functions by linear interpolation</em>" in Advances in
Optimization and Numerical Analysis Mathematics and Its Applications, vol.
<strong>275</strong> (eds. Susana Gomez and Jean-Pierre Hennart), Kluwer Academic
Publishers, pp. 51-67 (1994).</p>
</li>
<li>
<p dir="auto">M.J.D. Powell, "<em>The NEWUOA software for unconstrained minimization without
derivatives</em>" in Large-Scale Nonlinear Optimization, editors G. Di Pillo and
M. Roma, Springer, pp. 255-297 (2006).</p>
</li>
<li>
<p dir="auto">M.J.D. Powell, "<em>The BOBYQA Algorithm for Bound Constrained Optimization
Without Derivatives</em>", Technical report, Department of Applied Mathematics
and Theoretical Physics, University of Cambridge (2009).</p>
</li>
<li>
<p dir="auto">F. Soulez, É. Thiébaut, M. Tallon, I. Tallon-Bosc &amp; P. Garcia, "<em>Optimal a
posteriori fringe tracking in optical interferometry</em>" in Proc. SPIE 9146
"<em>Optical and Infrared Interferometry IV</em>", 91462Y (2014);
<a href="http://dx.doi.org/10.1117/12.2056590" rel="nofollow">doi:10.1117/12.2056590</a>.</p>
</li>
<li>
<p dir="auto">T. Steihaug, "<em>The conjugate gradient method and trust regions in large scale
optimization</em>", SIAM Journal on Numerical Analysis, vol. <strong>20</strong>, pp. 626-637
(1983).</p>
</li>
<li>
<p dir="auto">S. Swarzberg, G. Seront &amp; H. Bersini, "<em>S.T.E.P.: the easiest way to optimize
a function</em>" in IEEE World Congress on Computational Intelligence,
Proceedings of the First IEEE Conference on Evolutionary Computation, vol.
<strong>1</strong>, pp. 519-524 (1994).</p>
</li>
<li>
<p dir="auto">É. Thiébaut, "<em>Optimization issues in blind deconvolution algorithms</em>," in
Astronomical Data Analysis II, SPIE Proc. <strong>4847</strong>, 174-183 (2002).</p>
</li>
</ul>
</article></div>