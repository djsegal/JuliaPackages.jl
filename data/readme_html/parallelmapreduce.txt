<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-parallelmapreducejl" class="anchor" aria-hidden="true" href="#parallelmapreducejl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ParallelMapReduce.jl</h1>
<p dir="auto">This package provides the function <code>pmapreduce</code>. This function is essentially</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="function pmapreduce(f, op, itrs)
    @distributed op for arg in itrs
        f(arg)
    end
end"><pre><span class="pl-k">function</span> <span class="pl-en">pmapreduce</span>(f, op, itrs)
    <span class="pl-c1">@distributed</span> op <span class="pl-k">for</span> arg <span class="pl-k">in</span> itrs
        <span class="pl-c1">f</span>(arg)
    <span class="pl-k">end</span>
<span class="pl-k">end</span></pre></div>
<p dir="auto">However, since <code>@distributed</code> partitions <code>itrs</code> evenly across nodes, some nodes
may be idle if the nodes are different in computational speed, or equivalently
if <code>f</code> takes different time to compute depending on the input. With the added option
<code>pmapreduce(f, op, itrs...; algorithm = :reduction_local)</code>, computations are
dynamically load balanced, that is, the elements in <code>itrs</code> are only distributed
to a worker which is free. The result of each computation of <code>f</code> is stored
and reduced locally, until <code>itrs</code> is exhausted, and then sent back to the master
process, where the results from the nodes are further reduced, thus saving
communication bandwidth.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="addprocs(2)

function test()
    @everywhere function f(n)
        sleep(n)
        n
    end

    args = [5, ones(Int, 9)...]

    val_even = @time pmapreduce(f, +, args)
    val_uneven  = @time pmapreduce(f, +, args; algorithm = :reduction_local)

    println(val_even, &quot; &quot;, val_uneven)
end

julia&gt; test()
  9.039506 seconds (150 allocations: 6.562 KiB)
  7.048571 seconds (1.91 k allocations: 81.703 KiB)
14 14"><pre><span class="pl-c1">addprocs</span>(<span class="pl-c1">2</span>)

<span class="pl-k">function</span> <span class="pl-en">test</span>()
    <span class="pl-c1">@everywhere</span> <span class="pl-k">function</span> <span class="pl-en">f</span>(n)
        <span class="pl-c1">sleep</span>(n)
        n
    <span class="pl-k">end</span>

    args <span class="pl-k">=</span> [<span class="pl-c1">5</span>, <span class="pl-c1">ones</span>(Int, <span class="pl-c1">9</span>)<span class="pl-k">...</span>]

    val_even <span class="pl-k">=</span> <span class="pl-c1">@time</span> <span class="pl-c1">pmapreduce</span>(f, <span class="pl-k">+</span>, args)
    val_uneven  <span class="pl-k">=</span> <span class="pl-c1">@time</span> <span class="pl-c1">pmapreduce</span>(f, <span class="pl-k">+</span>, args; algorithm <span class="pl-k">=</span> <span class="pl-c1">:reduction_local</span>)

    <span class="pl-c1">println</span>(val_even, <span class="pl-s"><span class="pl-pds">"</span> <span class="pl-pds">"</span></span>, val_uneven)
<span class="pl-k">end</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">test</span>()
  <span class="pl-c1">9.039506</span> seconds (<span class="pl-c1">150</span> allocations<span class="pl-k">:</span> <span class="pl-c1">6.562</span> KiB)
  <span class="pl-c1">7.048571</span> seconds (<span class="pl-c1">1.91</span> k allocations<span class="pl-k">:</span> <span class="pl-c1">81.703</span> KiB)
<span class="pl-c1">14</span> <span class="pl-c1">14</span></pre></div>
<p dir="auto">The option <code>:reduction_master</code> is also available, where the result of every
<code>f</code> computation is sent back to the master, where the reduction is performed.</p>
</article></div>