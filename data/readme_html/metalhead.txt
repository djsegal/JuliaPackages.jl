<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-metalhead" class="anchor" aria-hidden="true" href="#metalhead"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Metalhead</h1>
<p><a href="https://travis-ci.org/FluxML/Metalhead.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/f0be7ee4da034b1eaa0c6b1712138820950be685af40eb5643eb5eec03535956/68747470733a2f2f7472617669732d63692e6f72672f466c75784d4c2f4d6574616c686561642e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/FluxML/Metalhead.jl.svg?branch=master" style="max-width:100%;"></a> <a href="https://codecov.io/gh/FluxML/Metalhead.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/a7cb915041d0fea39b31967216ce3bfd407b3c0ff59e43803e2b507f299a5606/68747470733a2f2f636f6465636f762e696f2f67682f466c75784d4c2f4d6574616c686561642e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/FluxML/Metalhead.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="Pkg.add(&quot;Metalhead&quot;)
"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>Metalhead<span class="pl-pds">"</span></span>)</pre></div>
<p>This package provides computer vision models that run on top of the <a href="http://fluxml.github.io/" rel="nofollow">Flux</a> machine learning library.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/7a8773e570496e7c9fc562933d7a7e934fdc3564a8a29f406ab5819fa842862c/68747470733a2f2f692e696d6775722e636f6d2f73704273617a372e706e67"><img src="https://camo.githubusercontent.com/7a8773e570496e7c9fc562933d7a7e934fdc3564a8a29f406ab5819fa842862c/68747470733a2f2f692e696d6775722e636f6d2f73704273617a372e706e67" alt="IJulia Screenshot" data-canonical-src="https://i.imgur.com/spBsaz7.png" style="max-width:100%;"></a></p>
<p>Each model (like <code>VGG19</code>) is a Flux layer, so you can do anything you would normally do with a model; like moving it to the GPU, training or freezing components, and extending it to carry out other tasks (such as neural style transfer).</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="# Run with dummy image data
julia&gt; x = rand(Float32, 224, 224, 3, 1)
224×224×3×1 Array{Float32,4}:
[:, :, 1, 1] =
 0.353337   0.252493    0.444695   0.767193    …  0.107599   0.424298   0.218889    0.377959
 0.247294   0.039822    0.829367   0.832303       0.582103   0.359319   0.259342    0.12293
  ⋮

julia&gt; vgg(x)
1000×1 Array{Float32,2}:
 0.000851723
 0.00079913
  ⋮

# See the underlying model structure
julia&gt; vgg.layers
Chain(Conv2D((3, 3), 3=&gt;64, NNlib.relu), Conv2D((3, 3), 64=&gt;64, NNlib.relu), Metalhead.#3, Conv2D((3, 3), 64=&gt;128, NNlib.relu), Conv2D((3, 3), 128=&gt;128, NNlib.relu), Metalhead.#4, Conv2D((3, 3), 128=&gt;256, NNlib.relu), Conv2D((3, 3), 256=&gt;256, NNlib.relu), Conv2D((3, 3), 256=&gt;256, NNlib.relu), Conv2D((3, 3), 256=&gt;256, NNlib.relu), Metalhead.#5, Conv2D((3, 3), 256=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Metalhead.#6, Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Metalhead.#7, Metalhead.#8, Dense(25088, 4096, NNlib.relu), Flux.Dropout{Float32}(0.5f0, false), Dense(4096, 4096, NNlib.relu), Flux.Dropout{Float32}(0.5f0, false), Dense(4096, 1000), NNlib.softmax)

# Run the model up to the last convolution/pooling layer
julia&gt; vgg.layers[1:21](x)
7×7×512×1 Array{Float32,4}:
[:, :, 1, 1] =
 0.657502  0.598338  0.594517  0.594425  0.594522  0.597183  0.59534
 0.663341  0.600874  0.596379  0.596292  0.596385  0.598204  0.590494
  ⋮
"><pre><span class="pl-c"><span class="pl-c">#</span> Run with dummy image data</span>
julia<span class="pl-k">&gt;</span> x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float32, <span class="pl-c1">224</span>, <span class="pl-c1">224</span>, <span class="pl-c1">3</span>, <span class="pl-c1">1</span>)
<span class="pl-c1">224</span><span class="pl-k">×</span><span class="pl-c1">224</span><span class="pl-k">×</span><span class="pl-c1">3</span><span class="pl-k">×</span><span class="pl-c1">1</span> Array{Float32,<span class="pl-c1">4</span>}<span class="pl-k">:</span>
[:, :, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>] <span class="pl-k">=</span>
 <span class="pl-c1">0.353337</span>   <span class="pl-c1">0.252493</span>    <span class="pl-c1">0.444695</span>   <span class="pl-c1">0.767193</span>    …  <span class="pl-c1">0.107599</span>   <span class="pl-c1">0.424298</span>   <span class="pl-c1">0.218889</span>    <span class="pl-c1">0.377959</span>
 <span class="pl-c1">0.247294</span>   <span class="pl-c1">0.039822</span>    <span class="pl-c1">0.829367</span>   <span class="pl-c1">0.832303</span>       <span class="pl-c1">0.582103</span>   <span class="pl-c1">0.359319</span>   <span class="pl-c1">0.259342</span>    <span class="pl-c1">0.12293</span>
  ⋮

julia<span class="pl-k">&gt;</span> <span class="pl-c1">vgg</span>(x)
<span class="pl-c1">1000</span><span class="pl-k">×</span><span class="pl-c1">1</span> Array{Float32,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-c1">0.000851723</span>
 <span class="pl-c1">0.00079913</span>
  ⋮

<span class="pl-c"><span class="pl-c">#</span> See the underlying model structure</span>
julia<span class="pl-k">&gt;</span> vgg<span class="pl-k">.</span>layers
<span class="pl-c1">Chain</span>(<span class="pl-c1">Conv2D</span>((<span class="pl-c1">3</span>, <span class="pl-c1">3</span>), <span class="pl-c1">3</span><span class="pl-k">=&gt;</span><span class="pl-c1">64</span>, NNlib<span class="pl-k">.</span>relu), <span class="pl-c1">Conv2D</span>((<span class="pl-c1">3</span>, <span class="pl-c1">3</span>), <span class="pl-c1">64</span><span class="pl-k">=&gt;</span><span class="pl-c1">64</span>, NNlib<span class="pl-k">.</span>relu), Metalhead.<span class="pl-c"><span class="pl-c">#</span>3, Conv2D((3, 3), 64=&gt;128, NNlib.relu), Conv2D((3, 3), 128=&gt;128, NNlib.relu), Metalhead.#4, Conv2D((3, 3), 128=&gt;256, NNlib.relu), Conv2D((3, 3), 256=&gt;256, NNlib.relu), Conv2D((3, 3), 256=&gt;256, NNlib.relu), Conv2D((3, 3), 256=&gt;256, NNlib.relu), Metalhead.#5, Conv2D((3, 3), 256=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Metalhead.#6, Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Metalhead.#7, Metalhead.#8, Dense(25088, 4096, NNlib.relu), Flux.Dropout{Float32}(0.5f0, false), Dense(4096, 4096, NNlib.relu), Flux.Dropout{Float32}(0.5f0, false), Dense(4096, 1000), NNlib.softmax)</span>

<span class="pl-c"><span class="pl-c">#</span> Run the model up to the last convolution/pooling layer</span>
julia<span class="pl-k">&gt;</span> vgg<span class="pl-k">.</span>layers[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">21</span>](x)
<span class="pl-c1">7</span><span class="pl-k">×</span><span class="pl-c1">7</span><span class="pl-k">×</span><span class="pl-c1">512</span><span class="pl-k">×</span><span class="pl-c1">1</span> Array{Float32,<span class="pl-c1">4</span>}<span class="pl-k">:</span>
[:, :, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>] <span class="pl-k">=</span>
 <span class="pl-c1">0.657502</span>  <span class="pl-c1">0.598338</span>  <span class="pl-c1">0.594517</span>  <span class="pl-c1">0.594425</span>  <span class="pl-c1">0.594522</span>  <span class="pl-c1">0.597183</span>  <span class="pl-c1">0.59534</span>
 <span class="pl-c1">0.663341</span>  <span class="pl-c1">0.600874</span>  <span class="pl-c1">0.596379</span>  <span class="pl-c1">0.596292</span>  <span class="pl-c1">0.596385</span>  <span class="pl-c1">0.598204</span>  <span class="pl-c1">0.590494</span>
  ⋮</pre></div>
<h1><a id="user-content-working-with-common-datasets" class="anchor" aria-hidden="true" href="#working-with-common-datasets"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Working with common datasets</h1>
<p>Metalhead includes support for working with several common object recognition datasets.
The <code>datasets()</code> function will attempt to auto-detect any common dataset placed in
the <code>datasets/</code>. The <code>Metalhead.download</code> function can be used to download these datasets
(where such automatic download is possible - for other data sets, see <code>datasets/README.md</code>),
e.g.:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Metalhead.download(CIFAR10)
"><pre><code>Metalhead.download(CIFAR10)
</code></pre></div>
<p>Once a dataset is loaded, it's training, validation, and test images are available using the
<code>trainimgs</code>, <code>valimgs</code>, and <code>testimgs</code> functions. E.g.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="julia&gt; valimgs(dataset(ImageNet))[rand(1:50000, 10)]
"><pre><code>julia&gt; valimgs(dataset(ImageNet))[rand(1:50000, 10)]
</code></pre></div>
<p>will fetch 10 random validation images from the ImageNet data set.</p>
<h1><a id="user-content-inline-images-at-the-repl" class="anchor" aria-hidden="true" href="#inline-images-at-the-repl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Inline Images at the REPL</h1>
<p>If you are using OS X, it is recommended that you use iTerm2 and install the
<code>TerminalExtensions.jl</code> package. This will allow you to see inference results
as well as the corresponding images directly in your terminal:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/00bbef37dc694555a9d6259f79dae3ee8c7764fe2f5b64a60d1beab84e0c07e5/68747470733a2f2f692e696d6775722e636f6d2f72754a6e4677722e706e67"><img src="https://camo.githubusercontent.com/00bbef37dc694555a9d6259f79dae3ee8c7764fe2f5b64a60d1beab84e0c07e5/68747470733a2f2f692e696d6775722e636f6d2f72754a6e4677722e706e67" alt="REPL Screenshot" data-canonical-src="https://i.imgur.com/ruJnFwr.png" style="max-width:100%;"></a></p>
</article></div>