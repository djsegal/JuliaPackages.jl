<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-lyceumai" class="anchor" aria-hidden="true" href="#lyceumai"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LyceumAI</h1>
<p><a href="https://github.com/Lyceum/LyceumAI.jl/actions"><img src="https://github.com/Lyceum/LyceumAI.jl/workflows/CI/badge.svg" alt="" style="max-width:100%;"></a></p>
<p>LyceumAI is a component package of the Lyceum ecosystem. It provides tools and frameworks to
support algorithm development for continous control problems, such as trajectory optimization and
reinforcement learning. Checkout the <a href="https://docs.lyceum.ml/dev/" rel="nofollow">documentation</a> for more
information about Lyceum and LyceumAI.jl.</p>
<h1><a id="user-content-algorithms" class="anchor" aria-hidden="true" href="#algorithms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Algorithms</h1>
<p>LyceumAI currently comes with Natural Policy Gradient, an on-policy Policy Gradient method
referenced in <a href="https://arxiv.org/pdf/1703.02660.pdf" rel="nofollow">Towards Generalization and Simplicity in Continuous Control</a>,
as well a <a href="https://www.cc.gatech.edu/~bboots3/files/InformationTheoreticMPC.pdf" rel="nofollow">Model Predictive Path Integral</a>,
an indirect shooting method for trajectory optimization and model predictive control.</p>
</article></div>