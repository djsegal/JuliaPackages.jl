<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-bitfloats" class="anchor" aria-hidden="true" href="#bitfloats"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>BitFloats</h1>
<p dir="auto"><a href="https://travis-ci.org/rfourquet/BitFloats.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/d3942de18736bb9de80c4c1f4f68175719c0dd62c02dfb23e7fb18f84e2f0751/68747470733a2f2f7472617669732d63692e6f72672f72666f7572717565742f426974466c6f6174732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/rfourquet/BitFloats.jl.svg?branch=master" style="max-width: 100%;"></a></p>
<p dir="auto">This package is a wrapper around LLVM's builtin floating-point types with 80 and 128 bits, here called <code>Float80</code> and <code>Float128</code>.</p>
<p dir="auto">This is very experimental:</p>
<ul dir="auto">
<li>I heard that support for <code>Float80</code> exists mainly only on x86 CPUs;</li>
<li>LLVM support for <code>Float128</code> operations (e.g. <code>log</code>, <code>cos</code>, etc.) is bad on my machine, except for
the most simple arithmetic, so conversion to/from <code>BigFloat</code> is done before/after computation;</li>
<li>conversions to/from other types is mostly done without consideration for rounding modes;</li>
<li>there can be unexpected segfaults (which I don't understand);</li>
<li>this is tested only on Linux; some tests pass on MacOS, but I don't have a machine at hand
to check what doesn't work;</li>
<li>this uses the <a href="https://github.com/rfourquet/BitIntegers.jl">BitIntegers.jl</a> package,
so the problem of slow REPL experience after <code>using BitFloats</code> carries over here;</li>
<li>arrays of <code>Float80</code> are prone to segfaults.</li>
</ul>
<p dir="auto">An issue is open for last two items in the Julia repository, so these will hopefully be fixed eventually.
It would be desirable to use a proper library for handling <code>Float128</code> computations, but I had no luck
with libquadmath for example, results were simply incorrect.</p>
<p dir="auto">I'm way out of my areas of expertise, both in terms of "talking with LLVM",
and in terms of floating-point tricks, so there are bugs along those two dimensions.
This package is currently just a starting point, and will need other contributors to stand a chance
of becoming reliable.</p>
<p dir="auto">Note also that there has already been some discussions regarding including a <code>Float128</code> type in <code>Base</code>,
for example <a href="https://github.com/JuliaLang/julia/issues/757" data-hovercard-type="issue" data-hovercard-url="/JuliaLang/julia/issues/757/hovercard">here</a>.</p>
</article></div>