<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content---implicitglobalgridjl-" class="anchor" aria-hidden="true" href="#--implicitglobalgridjl-"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a> <a target="_blank" rel="noopener noreferrer" href="docs/logo/logo_ImplicitGlobalGrid.png"><img src="docs/logo/logo_ImplicitGlobalGrid.png" alt="ImplicitGlobalGrid.jl" width="50" style="max-width: 100%;"></a> ImplicitGlobalGrid.jl </h1>
<p dir="auto"><a href="https://github.com/eth-cscs/ImplicitGlobalGrid.jl/actions"><img src="https://github.com/eth-cscs/ImplicitGlobalGrid.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a></p>
<p dir="auto">ImplicitGlobalGrid is an outcome of a collaboration of the Swiss National Supercomputing Centre, ETH Zurich (Dr. Samuel Omlin) with Stanford University (Dr. Ludovic RÃ¤ss) and the Swiss Geocomputing Centre (Prof. Yuri Podladchikov). It renders the distributed parallelization of stencil-based GPU and CPU applications on a regular staggered grid almost trivial and enables close to ideal weak scaling of real-world applications on thousands of GPUs [<a href="https://pretalx.com/juliacon2019/talk/LGHLC3/" rel="nofollow">1</a>, <a href="https://pasc19.pasc-conference.org/program/schedule/presentation/?id=msa218&amp;sess=sess144" rel="nofollow">2</a>, <a href="https://www.youtube.com/watch?v=vPsfZUqI4_0" rel="nofollow">3</a>]:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="docs/images/fig_parEff_HM3D_Julia_CUDA_all_Daint_extrapol.png"><img src="docs/images/fig_parEff_HM3D_Julia_CUDA_all_Daint_extrapol.png" alt="Weak scaling Piz Daint" style="max-width: 100%;"></a></p>
<p dir="auto">ImplicitGlobalGrid relies on the Julia MPI wrapper (<a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a>) to perform halo updates close to hardware limit and leverages CUDA-aware or ROCm-aware MPI for GPU-applications. The communication can straightforwardly be hidden behind computation [<a href="https://pretalx.com/juliacon2019/talk/LGHLC3/" rel="nofollow">1</a>, <a href="https://www.youtube.com/watch?v=vPsfZUqI4_0" rel="nofollow">3</a>] (how this can be done automatically when using ParallelStencil.jl is shown in [<a href="https://www.youtube.com/watch?v=vPsfZUqI4_0" rel="nofollow">3</a>]; a general approach particularly suited for CUDA C applications is explained in [<a href="https://on-demand.gputechconf.com/gtc/2019/video/_/S9368/" rel="nofollow">4</a>]).</p>
<p dir="auto">A particularity of ImplicitGlobalGrid is the automatic <em>implicit creation of the global computational grid</em> based on the number of processes the application is run with (and based on the process topology, which can be explicitly chosen by the user or automatically defined). As a consequence, the user only needs to write a code to solve his problem on one GPU/CPU (<em>local grid</em>); then, <strong>as little as three functions can be enough to transform a single GPU/CPU application into a massively scaling Multi-GPU/CPU application</strong>. See the <a href="#multi-gpu-with-three-functions">example</a> below. 1-D, 2-D and 3-D grids are supported. Here is a sketch of the global grid that results from running a 2-D solver with 4 processes (P1-P4) (a 2x2 process topology is created by default in this case):</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="docs/images/implicit_global_grid.png"><img src="docs/images/implicit_global_grid.png" alt="Implicit global grid" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contents</h2>
<ul dir="auto">
<li><a href="#multi-gpu-with-three-functions">Multi-GPU with three functions</a></li>
<li><a href="#50-lines-multi-gpu-example">50-lines Multi-GPU example</a></li>
<li><a href="#straightforward-in-situ-visualization--monitoring">Straightforward in-situ visualization / monitoring</a></li>
<li><a href="#seamless-interoperability-with-mpijl">Seamless interoperability with MPI.jl</a></li>
<li><a href="#cuda-awarerocm-aware-mpi-support">CUDA-aware/ROCm-aware MPI support</a></li>
<li><a href="#module-documentation-callable-from-the-julia-repl--ijulia">Module documentation callable from the Julia REPL / IJulia</a></li>
<li><a href="#dependencies">Dependencies</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#references">References</a></li>
</ul>
<h2 dir="auto"><a id="user-content-multi-gpu-with-three-functions" class="anchor" aria-hidden="true" href="#multi-gpu-with-three-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Multi-GPU with three functions</h2>
<p dir="auto">Only three functions are required to perform halo updates close to hardware limit:</p>
<ul dir="auto">
<li><code>init_global_grid</code></li>
<li><code>update_halo!</code></li>
<li><code>finalize_global_grid</code></li>
</ul>
<p dir="auto">Three additional functions are provided to query Cartesian coordinates with respect to the global computational grid if required:</p>
<ul dir="auto">
<li><code>x_g</code></li>
<li><code>y_g</code></li>
<li><code>z_g</code></li>
</ul>
<p dir="auto">Moreover, the following three functions allow to query the size of the global grid:</p>
<ul dir="auto">
<li><code>nx_g</code></li>
<li><code>ny_g</code></li>
<li><code>nz_g</code></li>
</ul>
<p dir="auto">The following Multi-GPU 3-D heat diffusion solver illustrates how these functions enable the creation of massively parallel applications.</p>
<h2 dir="auto"><a id="user-content-50-lines-multi-gpu-example" class="anchor" aria-hidden="true" href="#50-lines-multi-gpu-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>50-lines Multi-GPU example</h2>
<p dir="auto">This simple Multi-GPU 3-D heat diffusion solver uses ImplicitGlobalGrid. It relies fully on the broadcasting capabilities of <a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a>'s <code>CuArray</code> type to perform the stencil-computations with maximal simplicity (<a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a> enables also writing explicit GPU kernels which can lead to significantly better performance for these computations).</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ImplicitGlobalGrid, CUDA

@views d_xa(A) = A[2:end  , :     , :     ] .- A[1:end-1, :     , :     ];
@views d_xi(A) = A[2:end  ,2:end-1,2:end-1] .- A[1:end-1,2:end-1,2:end-1];
@views d_ya(A) = A[ :     ,2:end  , :     ] .- A[ :     ,1:end-1, :     ];
@views d_yi(A) = A[2:end-1,2:end  ,2:end-1] .- A[2:end-1,1:end-1,2:end-1];
@views d_za(A) = A[ :     , :     ,2:end  ] .- A[ :     , :     ,1:end-1];
@views d_zi(A) = A[2:end-1,2:end-1,2:end  ] .- A[2:end-1,2:end-1,1:end-1];
@views  inn(A) = A[2:end-1,2:end-1,2:end-1]

@views function diffusion3D()
    # Physics
    lam        = 1.0;                                       # Thermal conductivity
    cp_min     = 1.0;                                       # Minimal heat capacity
    lx, ly, lz = 10.0, 10.0, 10.0;                          # Length of domain in dimensions x, y and z

    # Numerics
    nx, ny, nz = 256, 256, 256;                             # Number of gridpoints dimensions x, y and z
    nt         = 100000;                                    # Number of time steps
    init_global_grid(nx, ny, nz);                           # Initialize the implicit global grid
    dx         = lx/(nx_g()-1);                             # Space step in dimension x
    dy         = ly/(ny_g()-1);                             # ...        in dimension y
    dz         = lz/(nz_g()-1);                             # ...        in dimension z

    # Array initializations
    T     = CUDA.zeros(Float64, nx,   ny,   nz  );
    Cp    = CUDA.zeros(Float64, nx,   ny,   nz  );
    dTedt = CUDA.zeros(Float64, nx-2, ny-2, nz-2);
    qx    = CUDA.zeros(Float64, nx-1, ny-2, nz-2);
    qy    = CUDA.zeros(Float64, nx-2, ny-1, nz-2);
    qz    = CUDA.zeros(Float64, nx-2, ny-2, nz-1);

    # Initial conditions (heat capacity and temperature with two Gaussian anomalies each)
    Cp .= cp_min .+ CuArray([5*exp(-((x_g(ix,dx,Cp)-lx/1.5))^2-((y_g(iy,dy,Cp)-ly/2))^2-((z_g(iz,dz,Cp)-lz/1.5))^2) +
                             5*exp(-((x_g(ix,dx,Cp)-lx/3.0))^2-((y_g(iy,dy,Cp)-ly/2))^2-((z_g(iz,dz,Cp)-lz/1.5))^2) for ix=1:size(T,1), iy=1:size(T,2), iz=1:size(T,3)])
    T  .= CuArray([100*exp(-((x_g(ix,dx,T)-lx/2)/2)^2-((y_g(iy,dy,T)-ly/2)/2)^2-((z_g(iz,dz,T)-lz/3.0)/2)^2) +
                    50*exp(-((x_g(ix,dx,T)-lx/2)/2)^2-((y_g(iy,dy,T)-ly/2)/2)^2-((z_g(iz,dz,T)-lz/1.5)/2)^2) for ix=1:size(T,1), iy=1:size(T,2), iz=1:size(T,3)])

    # Time loop
    dt = min(dx*dx,dy*dy,dz*dz)*cp_min/lam/8.1;                                               # Time step for the 3D Heat diffusion
    for it = 1:nt
        qx    .= -lam.*d_xi(T)./dx;                                                           # Fourier's law of heat conduction: q_x   = -Î» Î´T/Î´x
        qy    .= -lam.*d_yi(T)./dy;                                                           # ...                               q_y   = -Î» Î´T/Î´y
        qz    .= -lam.*d_zi(T)./dz;                                                           # ...                               q_z   = -Î» Î´T/Î´z
        dTedt .= 1.0./inn(Cp).*(-d_xa(qx)./dx .- d_ya(qy)./dy .- d_za(qz)./dz);               # Conservation of energy:           Î´T/Î´t = 1/câ (-Î´q_x/Î´x - Î´q_y/dy - Î´q_z/dz)
        T[2:end-1,2:end-1,2:end-1] .= inn(T) .+ dt.*dTedt;                                    # Update of temperature             T_new = T_old + Î´T/Î´t
        update_halo!(T);                                                                      # Update the halo of T
    end

    finalize_global_grid();                                                                   # Finalize the implicit global grid
end

diffusion3D()"><pre><span class="pl-k">using</span> ImplicitGlobalGrid, CUDA

<span class="pl-c1">@views</span> <span class="pl-en">d_xa</span>(A) <span class="pl-k">=</span> A[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>  , <span class="pl-k">:</span>     , <span class="pl-k">:</span>     ] <span class="pl-k">.-</span> A[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>, <span class="pl-k">:</span>     , <span class="pl-k">:</span>     ];
<span class="pl-c1">@views</span> <span class="pl-en">d_xi</span>(A) <span class="pl-k">=</span> A[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>  ,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-k">.-</span> A[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>];
<span class="pl-c1">@views</span> <span class="pl-en">d_ya</span>(A) <span class="pl-k">=</span> A[ <span class="pl-k">:</span>     ,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>  , <span class="pl-k">:</span>     ] <span class="pl-k">.-</span> A[ <span class="pl-k">:</span>     ,<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>, <span class="pl-k">:</span>     ];
<span class="pl-c1">@views</span> <span class="pl-en">d_yi</span>(A) <span class="pl-k">=</span> A[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>  ,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-k">.-</span> A[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>];
<span class="pl-c1">@views</span> <span class="pl-en">d_za</span>(A) <span class="pl-k">=</span> A[ <span class="pl-k">:</span>     , <span class="pl-k">:</span>     ,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>  ] <span class="pl-k">.-</span> A[ <span class="pl-k">:</span>     , <span class="pl-k">:</span>     ,<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>];
<span class="pl-c1">@views</span> <span class="pl-en">d_zi</span>(A) <span class="pl-k">=</span> A[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>  ] <span class="pl-k">.-</span> A[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>];
<span class="pl-c1">@views</span>  <span class="pl-en">inn</span>(A) <span class="pl-k">=</span> A[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>]

<span class="pl-c1">@views</span> <span class="pl-k">function</span> <span class="pl-en">diffusion3D</span>()
    <span class="pl-c"><span class="pl-c">#</span> Physics</span>
    lam        <span class="pl-k">=</span> <span class="pl-c1">1.0</span>;                                       <span class="pl-c"><span class="pl-c">#</span> Thermal conductivity</span>
    cp_min     <span class="pl-k">=</span> <span class="pl-c1">1.0</span>;                                       <span class="pl-c"><span class="pl-c">#</span> Minimal heat capacity</span>
    lx, ly, lz <span class="pl-k">=</span> <span class="pl-c1">10.0</span>, <span class="pl-c1">10.0</span>, <span class="pl-c1">10.0</span>;                          <span class="pl-c"><span class="pl-c">#</span> Length of domain in dimensions x, y and z</span>

    <span class="pl-c"><span class="pl-c">#</span> Numerics</span>
    nx, ny, nz <span class="pl-k">=</span> <span class="pl-c1">256</span>, <span class="pl-c1">256</span>, <span class="pl-c1">256</span>;                             <span class="pl-c"><span class="pl-c">#</span> Number of gridpoints dimensions x, y and z</span>
    nt         <span class="pl-k">=</span> <span class="pl-c1">100000</span>;                                    <span class="pl-c"><span class="pl-c">#</span> Number of time steps</span>
    <span class="pl-c1">init_global_grid</span>(nx, ny, nz);                           <span class="pl-c"><span class="pl-c">#</span> Initialize the implicit global grid</span>
    dx         <span class="pl-k">=</span> lx<span class="pl-k">/</span>(<span class="pl-c1">nx_g</span>()<span class="pl-k">-</span><span class="pl-c1">1</span>);                             <span class="pl-c"><span class="pl-c">#</span> Space step in dimension x</span>
    dy         <span class="pl-k">=</span> ly<span class="pl-k">/</span>(<span class="pl-c1">ny_g</span>()<span class="pl-k">-</span><span class="pl-c1">1</span>);                             <span class="pl-c"><span class="pl-c">#</span> ...        in dimension y</span>
    dz         <span class="pl-k">=</span> lz<span class="pl-k">/</span>(<span class="pl-c1">nz_g</span>()<span class="pl-k">-</span><span class="pl-c1">1</span>);                             <span class="pl-c"><span class="pl-c">#</span> ...        in dimension z</span>

    <span class="pl-c"><span class="pl-c">#</span> Array initializations</span>
    T     <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">zeros</span>(Float64, nx,   ny,   nz  );
    Cp    <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">zeros</span>(Float64, nx,   ny,   nz  );
    dTedt <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">zeros</span>(Float64, nx<span class="pl-k">-</span><span class="pl-c1">2</span>, ny<span class="pl-k">-</span><span class="pl-c1">2</span>, nz<span class="pl-k">-</span><span class="pl-c1">2</span>);
    qx    <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">zeros</span>(Float64, nx<span class="pl-k">-</span><span class="pl-c1">1</span>, ny<span class="pl-k">-</span><span class="pl-c1">2</span>, nz<span class="pl-k">-</span><span class="pl-c1">2</span>);
    qy    <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">zeros</span>(Float64, nx<span class="pl-k">-</span><span class="pl-c1">2</span>, ny<span class="pl-k">-</span><span class="pl-c1">1</span>, nz<span class="pl-k">-</span><span class="pl-c1">2</span>);
    qz    <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">zeros</span>(Float64, nx<span class="pl-k">-</span><span class="pl-c1">2</span>, ny<span class="pl-k">-</span><span class="pl-c1">2</span>, nz<span class="pl-k">-</span><span class="pl-c1">1</span>);

    <span class="pl-c"><span class="pl-c">#</span> Initial conditions (heat capacity and temperature with two Gaussian anomalies each)</span>
    Cp <span class="pl-k">.=</span> cp_min <span class="pl-k">.+</span> <span class="pl-c1">CuArray</span>([<span class="pl-c1">5</span><span class="pl-k">*</span><span class="pl-c1">exp</span>(<span class="pl-k">-</span>((<span class="pl-c1">x_g</span>(ix,dx,Cp)<span class="pl-k">-</span>lx<span class="pl-k">/</span><span class="pl-c1">1.5</span>))<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">-</span>((<span class="pl-c1">y_g</span>(iy,dy,Cp)<span class="pl-k">-</span>ly<span class="pl-k">/</span><span class="pl-c1">2</span>))<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">-</span>((<span class="pl-c1">z_g</span>(iz,dz,Cp)<span class="pl-k">-</span>lz<span class="pl-k">/</span><span class="pl-c1">1.5</span>))<span class="pl-k">^</span><span class="pl-c1">2</span>) <span class="pl-k">+</span>
                             <span class="pl-c1">5</span><span class="pl-k">*</span><span class="pl-c1">exp</span>(<span class="pl-k">-</span>((<span class="pl-c1">x_g</span>(ix,dx,Cp)<span class="pl-k">-</span>lx<span class="pl-k">/</span><span class="pl-c1">3.0</span>))<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">-</span>((<span class="pl-c1">y_g</span>(iy,dy,Cp)<span class="pl-k">-</span>ly<span class="pl-k">/</span><span class="pl-c1">2</span>))<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">-</span>((<span class="pl-c1">z_g</span>(iz,dz,Cp)<span class="pl-k">-</span>lz<span class="pl-k">/</span><span class="pl-c1">1.5</span>))<span class="pl-k">^</span><span class="pl-c1">2</span>) <span class="pl-k">for</span> ix<span class="pl-k">=</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">size</span>(T,<span class="pl-c1">1</span>), iy<span class="pl-k">=</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">size</span>(T,<span class="pl-c1">2</span>), iz<span class="pl-k">=</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">size</span>(T,<span class="pl-c1">3</span>)])
    T  <span class="pl-k">.=</span> <span class="pl-c1">CuArray</span>([<span class="pl-c1">100</span><span class="pl-k">*</span><span class="pl-c1">exp</span>(<span class="pl-k">-</span>((<span class="pl-c1">x_g</span>(ix,dx,T)<span class="pl-k">-</span>lx<span class="pl-k">/</span><span class="pl-c1">2</span>)<span class="pl-k">/</span><span class="pl-c1">2</span>)<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">-</span>((<span class="pl-c1">y_g</span>(iy,dy,T)<span class="pl-k">-</span>ly<span class="pl-k">/</span><span class="pl-c1">2</span>)<span class="pl-k">/</span><span class="pl-c1">2</span>)<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">-</span>((<span class="pl-c1">z_g</span>(iz,dz,T)<span class="pl-k">-</span>lz<span class="pl-k">/</span><span class="pl-c1">3.0</span>)<span class="pl-k">/</span><span class="pl-c1">2</span>)<span class="pl-k">^</span><span class="pl-c1">2</span>) <span class="pl-k">+</span>
                    <span class="pl-c1">50</span><span class="pl-k">*</span><span class="pl-c1">exp</span>(<span class="pl-k">-</span>((<span class="pl-c1">x_g</span>(ix,dx,T)<span class="pl-k">-</span>lx<span class="pl-k">/</span><span class="pl-c1">2</span>)<span class="pl-k">/</span><span class="pl-c1">2</span>)<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">-</span>((<span class="pl-c1">y_g</span>(iy,dy,T)<span class="pl-k">-</span>ly<span class="pl-k">/</span><span class="pl-c1">2</span>)<span class="pl-k">/</span><span class="pl-c1">2</span>)<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">-</span>((<span class="pl-c1">z_g</span>(iz,dz,T)<span class="pl-k">-</span>lz<span class="pl-k">/</span><span class="pl-c1">1.5</span>)<span class="pl-k">/</span><span class="pl-c1">2</span>)<span class="pl-k">^</span><span class="pl-c1">2</span>) <span class="pl-k">for</span> ix<span class="pl-k">=</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">size</span>(T,<span class="pl-c1">1</span>), iy<span class="pl-k">=</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">size</span>(T,<span class="pl-c1">2</span>), iz<span class="pl-k">=</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">size</span>(T,<span class="pl-c1">3</span>)])

    <span class="pl-c"><span class="pl-c">#</span> Time loop</span>
    dt <span class="pl-k">=</span> <span class="pl-c1">min</span>(dx<span class="pl-k">*</span>dx,dy<span class="pl-k">*</span>dy,dz<span class="pl-k">*</span>dz)<span class="pl-k">*</span>cp_min<span class="pl-k">/</span>lam<span class="pl-k">/</span><span class="pl-c1">8.1</span>;                                               <span class="pl-c"><span class="pl-c">#</span> Time step for the 3D Heat diffusion</span>
    <span class="pl-k">for</span> it <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">:</span>nt
        qx    <span class="pl-k">.=</span> <span class="pl-k">-</span>lam<span class="pl-k">.*</span><span class="pl-c1">d_xi</span>(T)<span class="pl-k">./</span>dx;                                                           <span class="pl-c"><span class="pl-c">#</span> Fourier's law of heat conduction: q_x   = -Î» Î´T/Î´x</span>
        qy    <span class="pl-k">.=</span> <span class="pl-k">-</span>lam<span class="pl-k">.*</span><span class="pl-c1">d_yi</span>(T)<span class="pl-k">./</span>dy;                                                           <span class="pl-c"><span class="pl-c">#</span> ...                               q_y   = -Î» Î´T/Î´y</span>
        qz    <span class="pl-k">.=</span> <span class="pl-k">-</span>lam<span class="pl-k">.*</span><span class="pl-c1">d_zi</span>(T)<span class="pl-k">./</span>dz;                                                           <span class="pl-c"><span class="pl-c">#</span> ...                               q_z   = -Î» Î´T/Î´z</span>
        dTedt <span class="pl-k">.=</span> <span class="pl-c1">1.0</span><span class="pl-k">./</span><span class="pl-c1">inn</span>(Cp)<span class="pl-k">.*</span>(<span class="pl-k">-</span><span class="pl-c1">d_xa</span>(qx)<span class="pl-k">./</span>dx <span class="pl-k">.-</span> <span class="pl-c1">d_ya</span>(qy)<span class="pl-k">./</span>dy <span class="pl-k">.-</span> <span class="pl-c1">d_za</span>(qz)<span class="pl-k">./</span>dz);               <span class="pl-c"><span class="pl-c">#</span> Conservation of energy:           Î´T/Î´t = 1/câ (-Î´q_x/Î´x - Î´q_y/dy - Î´q_z/dz)</span>
        T[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-k">.=</span> <span class="pl-c1">inn</span>(T) <span class="pl-k">.+</span> dt<span class="pl-k">.*</span>dTedt;                                    <span class="pl-c"><span class="pl-c">#</span> Update of temperature             T_new = T_old + Î´T/Î´t</span>
        <span class="pl-c1">update_halo!</span>(T);                                                                      <span class="pl-c"><span class="pl-c">#</span> Update the halo of T</span>
    <span class="pl-k">end</span>

    <span class="pl-c1">finalize_global_grid</span>();                                                                   <span class="pl-c"><span class="pl-c">#</span> Finalize the implicit global grid</span>
<span class="pl-k">end</span>

<span class="pl-c1">diffusion3D</span>()</pre></div>
<p dir="auto">The corresponding file can be found <a href="docs/examples/diffusion3D_multigpu_CuArrays_novis.jl">here</a>. A basic cpu-only example is available <a href="docs/examples/diffusion3D_multicpu_novis.jl">here</a> (no usage of multi-threading).</p>
<h2 dir="auto"><a id="user-content-straightforward-in-situ-visualization--monitoring" class="anchor" aria-hidden="true" href="#straightforward-in-situ-visualization--monitoring"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Straightforward in-situ visualization / monitoring</h2>
<p dir="auto">ImplicitGlobalGrid provides a function to gather an array from each process into a one large array on a single process, assembled according to the global grid:</p>
<ul dir="auto">
<li><code>gather!</code></li>
</ul>
<p dir="auto">This enables straightforward in-situ visualization or monitoring of Multi-GPU/CPU applications using e.g. the <a href="https://github.com/JuliaPlots/Plots.jl">Julia Plots package</a> as shown in the following (the GR backend is used as it is particularly fast according to the <a href="http://docs.juliaplots.org/latest/backends/" rel="nofollow">Julia Plots documentation</a>). It is enough to add a couple of lines to the previous example (omitted unmodified lines are represented with <code>#(...)</code>):</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ImplicitGlobalGrid, CUDA, Plots
#(...)

@views function diffusion3D()
    # Physics
    #(...)

    # Numerics
    #(...)
    me, dims   = init_global_grid(nx, ny, nz);              # Initialize the implicit global grid
    #(...)

    # Array initializations
    #(...)

    # Initial conditions (heat capacity and temperature with two Gaussian anomalies each)
    #(...)

    # Preparation of visualisation
    gr()
    ENV[&quot;GKSwstype&quot;]=&quot;nul&quot;
    anim = Animation();
    nx_v = (nx-2)*dims[1];
    ny_v = (ny-2)*dims[2];
    nz_v = (nz-2)*dims[3];
    T_v  = zeros(nx_v, ny_v, nz_v);
    T_nohalo = zeros(nx-2, ny-2, nz-2);

    # Time loop
    #(...)
    for it = 1:nt
        if mod(it, 1000) == 1                                                                 # Visualize only every 1000th time step
            T_nohalo .= Array(T[2:end-1,2:end-1,2:end-1]);                                    # Copy data to CPU removing the halo
            gather!(T_nohalo, T_v)                                                            # Gather data on process 0 (could be interpolated/sampled first)
            if (me==0) heatmap(transpose(T_v[:,ny_vÃ·2,:]), aspect_ratio=1); frame(anim); end  # Visualize it on process 0
        end
        #(...)
    end

    # Postprocessing
    if (me==0) gif(anim, &quot;diffusion3D.gif&quot;, fps = 15) end                                     # Create a gif movie on process 0
    if (me==0) mp4(anim, &quot;diffusion3D.mp4&quot;, fps = 15) end                                     # Create a mp4 movie on process 0
    finalize_global_grid();                                                                   # Finalize the implicit global grid
end

diffusion3D()"><pre><span class="pl-k">using</span> ImplicitGlobalGrid, CUDA, Plots
<span class="pl-c"><span class="pl-c">#</span>(...)</span>

<span class="pl-c1">@views</span> <span class="pl-k">function</span> <span class="pl-en">diffusion3D</span>()
    <span class="pl-c"><span class="pl-c">#</span> Physics</span>
    <span class="pl-c"><span class="pl-c">#</span>(...)</span>

    <span class="pl-c"><span class="pl-c">#</span> Numerics</span>
    <span class="pl-c"><span class="pl-c">#</span>(...)</span>
    me, dims   <span class="pl-k">=</span> <span class="pl-c1">init_global_grid</span>(nx, ny, nz);              <span class="pl-c"><span class="pl-c">#</span> Initialize the implicit global grid</span>
    <span class="pl-c"><span class="pl-c">#</span>(...)</span>

    <span class="pl-c"><span class="pl-c">#</span> Array initializations</span>
    <span class="pl-c"><span class="pl-c">#</span>(...)</span>

    <span class="pl-c"><span class="pl-c">#</span> Initial conditions (heat capacity and temperature with two Gaussian anomalies each)</span>
    <span class="pl-c"><span class="pl-c">#</span>(...)</span>

    <span class="pl-c"><span class="pl-c">#</span> Preparation of visualisation</span>
    <span class="pl-c1">gr</span>()
    <span class="pl-c1">ENV</span>[<span class="pl-s"><span class="pl-pds">"</span>GKSwstype<span class="pl-pds">"</span></span>]<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>nul<span class="pl-pds">"</span></span>
    anim <span class="pl-k">=</span> <span class="pl-c1">Animation</span>();
    nx_v <span class="pl-k">=</span> (nx<span class="pl-k">-</span><span class="pl-c1">2</span>)<span class="pl-k">*</span>dims[<span class="pl-c1">1</span>];
    ny_v <span class="pl-k">=</span> (ny<span class="pl-k">-</span><span class="pl-c1">2</span>)<span class="pl-k">*</span>dims[<span class="pl-c1">2</span>];
    nz_v <span class="pl-k">=</span> (nz<span class="pl-k">-</span><span class="pl-c1">2</span>)<span class="pl-k">*</span>dims[<span class="pl-c1">3</span>];
    T_v  <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(nx_v, ny_v, nz_v);
    T_nohalo <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(nx<span class="pl-k">-</span><span class="pl-c1">2</span>, ny<span class="pl-k">-</span><span class="pl-c1">2</span>, nz<span class="pl-k">-</span><span class="pl-c1">2</span>);

    <span class="pl-c"><span class="pl-c">#</span> Time loop</span>
    <span class="pl-c"><span class="pl-c">#</span>(...)</span>
    <span class="pl-k">for</span> it <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">:</span>nt
        <span class="pl-k">if</span> <span class="pl-c1">mod</span>(it, <span class="pl-c1">1000</span>) <span class="pl-k">==</span> <span class="pl-c1">1</span>                                                                 <span class="pl-c"><span class="pl-c">#</span> Visualize only every 1000th time step</span>
            T_nohalo <span class="pl-k">.=</span> <span class="pl-c1">Array</span>(T[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>]);                                    <span class="pl-c"><span class="pl-c">#</span> Copy data to CPU removing the halo</span>
            <span class="pl-c1">gather!</span>(T_nohalo, T_v)                                                            <span class="pl-c"><span class="pl-c">#</span> Gather data on process 0 (could be interpolated/sampled first)</span>
            <span class="pl-k">if</span> (me<span class="pl-k">==</span><span class="pl-c1">0</span>) <span class="pl-c1">heatmap</span>(<span class="pl-c1">transpose</span>(T_v[:,ny_v<span class="pl-k">Ã·</span><span class="pl-c1">2</span>,:]), aspect_ratio<span class="pl-k">=</span><span class="pl-c1">1</span>); <span class="pl-c1">frame</span>(anim); <span class="pl-k">end</span>  <span class="pl-c"><span class="pl-c">#</span> Visualize it on process 0</span>
        <span class="pl-k">end</span>
        <span class="pl-c"><span class="pl-c">#</span>(...)</span>
    <span class="pl-k">end</span>

    <span class="pl-c"><span class="pl-c">#</span> Postprocessing</span>
    <span class="pl-k">if</span> (me<span class="pl-k">==</span><span class="pl-c1">0</span>) <span class="pl-c1">gif</span>(anim, <span class="pl-s"><span class="pl-pds">"</span>diffusion3D.gif<span class="pl-pds">"</span></span>, fps <span class="pl-k">=</span> <span class="pl-c1">15</span>) <span class="pl-k">end</span>                                     <span class="pl-c"><span class="pl-c">#</span> Create a gif movie on process 0</span>
    <span class="pl-k">if</span> (me<span class="pl-k">==</span><span class="pl-c1">0</span>) <span class="pl-c1">mp4</span>(anim, <span class="pl-s"><span class="pl-pds">"</span>diffusion3D.mp4<span class="pl-pds">"</span></span>, fps <span class="pl-k">=</span> <span class="pl-c1">15</span>) <span class="pl-k">end</span>                                     <span class="pl-c"><span class="pl-c">#</span> Create a mp4 movie on process 0</span>
    <span class="pl-c1">finalize_global_grid</span>();                                                                   <span class="pl-c"><span class="pl-c">#</span> Finalize the implicit global grid</span>
<span class="pl-k">end</span>

<span class="pl-c1">diffusion3D</span>()</pre></div>
<p dir="auto">Here is the resulting movie when running the application on 8 GPUs, solving 3-D heat diffusion with heterogeneous heat capacity (two Gaussian anomalies) on a global computational grid of size 510x510x510 grid points. It shows the x-z-dimension plane in the middle of the dimension y:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="docs/movies/diffusion3D_8gpus.gif"><img src="docs/movies/diffusion3D_8gpus.gif" alt="Implicit global grid" data-animated-image="" style="max-width: 100%;"></a></p>
<p dir="auto">The simulation producing this movie - <em>including the in-situ visualization</em> - took 29 minutes on 8 NVIDIAÂ® TeslaÂ® P100 GPUs on Piz Daint (an optimized solution using <a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a>'s native kernel programming capabilities can be more than 10 times faster).
The complete example can be found <a href="docs/examples/diffusion3D_multigpu_CuArrays.jl">here</a>. A corresponding basic cpu-only example is available <a href="docs/examples/diffusion3D_multicpu.jl">here</a> (no usage of multi-threading) and a movie of a simulation with 254x254x254 grid points which it produced within 34 minutes using 8 IntelÂ® XeonÂ® E5-2690 v3 is found <a href="docs/movies/diffusion3D_8cpus.gif">here</a> (with 8 processes, no multi-threading).</p>
<h2 dir="auto"><a id="user-content-seamless-interoperability-with-mpijl" class="anchor" aria-hidden="true" href="#seamless-interoperability-with-mpijl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Seamless interoperability with MPI.jl</h2>
<p dir="auto">ImplicitGlobalGrid is seamlessly interoperable with <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a>. The Cartesian MPI communicator it uses is created by default when calling <code>init_global_grid</code> and can then be obtained as follows (variable <code>comm_cart</code>):</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="me, dims, nprocs, coords, comm_cart = init_global_grid(nx, ny, nz);"><pre>me, dims, nprocs, coords, comm_cart <span class="pl-k">=</span> <span class="pl-c1">init_global_grid</span>(nx, ny, nz);</pre></div>
<p dir="auto">Moreover, the automatic initialization and finalization of MPI can be deactivated in order to replace them with direct calls to <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="init_global_grid(nx, ny, nz; init_MPI=false);"><pre><span class="pl-c1">init_global_grid</span>(nx, ny, nz; init_MPI<span class="pl-k">=</span><span class="pl-c1">false</span>);</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="finalize_global_grid(;finalize_MPI=false)"><pre><span class="pl-c1">finalize_global_grid</span>(;finalize_MPI<span class="pl-k">=</span><span class="pl-c1">false</span>)</pre></div>
<p dir="auto">Besides, <code>init_global_grid</code> makes every argument it passes to an <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a> function customizable via its keyword arguments.</p>
<h2 dir="auto"><a id="user-content-cuda-awarerocm-aware-mpi-support" class="anchor" aria-hidden="true" href="#cuda-awarerocm-aware-mpi-support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>CUDA-aware/ROCm-aware MPI support</h2>
<p dir="auto">If the system supports CUDA-aware/ROCm-aware MPI, it may be activated for ImplicitGlobalGrid by setting an environment variable as specified in the module documentation callable from the <a href="https://docs.julialang.org/en/v1/stdlib/REPL/" rel="nofollow">Julia REPL</a> or in <a href="https://github.com/JuliaLang/IJulia.jl">IJulia</a> (see next section).</p>
<h2 dir="auto"><a id="user-content-module-documentation-callable-from-the-julia-repl--ijulia" class="anchor" aria-hidden="true" href="#module-documentation-callable-from-the-julia-repl--ijulia"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Module documentation callable from the Julia REPL / IJulia</h2>
<p dir="auto">The module documentation can be called from the <a href="https://docs.julialang.org/en/v1/stdlib/REPL/" rel="nofollow">Julia REPL</a> or in <a href="https://github.com/JuliaLang/IJulia.jl">IJulia</a>:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="julia&gt; using ImplicitGlobalGrid
julia&gt;?
help?&gt; ImplicitGlobalGrid
search: ImplicitGlobalGrid

  Module ImplicitGlobalGrid

  Renders the distributed parallelization of stencil-based GPU and CPU applications on a
  regular staggered grid almost trivial and enables close to ideal weak scaling of
  real-world applications on thousands of GPUs.

  General overview and examples
  â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡

  https://github.com/eth-cscs/ImplicitGlobalGrid.jl

  Functions
  â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡

    â¢    init_global_grid

    â¢    finalize_global_grid

    â¢    update_halo!

    â¢    gather!

    â¢    select_device

    â¢    nx_g

    â¢    ny_g

    â¢    nz_g

    â¢    x_g

    â¢    y_g

    â¢    z_g

    â¢    tic

    â¢    toc

  To see a description of a function type ?&lt;functionname&gt;.

  â Performance note
  â
  â  If the system supports CUDA-aware MPI (for Nvidia GPUs) or
  â  ROCm-aware MPI (for AMD GPUs), it may be activated for
  â  ImplicitGlobalGrid by setting one of the following environment
  â  variables (at latest before the call to init_global_grid):
  â
  â  shell&gt; export IGG_CUDAAWARE_MPI=1
  â
  â  shell&gt; export IGG_ROCMAWARE_MPI=1

julia&gt;"><pre lang="julia-repl" class="notranslate"><code>julia&gt; using ImplicitGlobalGrid
julia&gt;?
help?&gt; ImplicitGlobalGrid
search: ImplicitGlobalGrid

  Module ImplicitGlobalGrid

  Renders the distributed parallelization of stencil-based GPU and CPU applications on a
  regular staggered grid almost trivial and enables close to ideal weak scaling of
  real-world applications on thousands of GPUs.

  General overview and examples
  â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡

  https://github.com/eth-cscs/ImplicitGlobalGrid.jl

  Functions
  â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡â¡

    â¢    init_global_grid

    â¢    finalize_global_grid

    â¢    update_halo!

    â¢    gather!

    â¢    select_device

    â¢    nx_g

    â¢    ny_g

    â¢    nz_g

    â¢    x_g

    â¢    y_g

    â¢    z_g

    â¢    tic

    â¢    toc

  To see a description of a function type ?&lt;functionname&gt;.

  â Performance note
  â
  â  If the system supports CUDA-aware MPI (for Nvidia GPUs) or
  â  ROCm-aware MPI (for AMD GPUs), it may be activated for
  â  ImplicitGlobalGrid by setting one of the following environment
  â  variables (at latest before the call to init_global_grid):
  â
  â  shell&gt; export IGG_CUDAAWARE_MPI=1
  â
  â  shell&gt; export IGG_ROCMAWARE_MPI=1

julia&gt;
</code></pre></div>
<h2 dir="auto"><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Dependencies</h2>
<p dir="auto">ImplicitGlobalGrid relies on the Julia MPI wrapper (<a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a>), the Julia CUDA package (<a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a> [<a href="https://doi.org/10.1109/TPDS.2018.2872064" rel="nofollow">5</a>, <a href="https://doi.org/10.1016/j.advengsoft.2019.02.002" rel="nofollow">6</a>]) and the Julia AMDGPU package (<a href="https://github.com/JuliaGPU/AMDGPU.jl">AMDGPU.jl</a>).</p>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">ImplicitGlobalGrid may be installed directly with the <a href="https://docs.julialang.org/en/v1/stdlib/Pkg/index.html" rel="nofollow">Julia package manager</a> from the REPL:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="julia&gt;]
  pkg&gt; add ImplicitGlobalGrid
  pkg&gt; test ImplicitGlobalGrid"><pre lang="julia-repl" class="notranslate"><code>julia&gt;]
  pkg&gt; add ImplicitGlobalGrid
  pkg&gt; test ImplicitGlobalGrid
</code></pre></div>
<h2 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<p dir="auto">[1] <a href="https://pretalx.com/juliacon2019/talk/LGHLC3/" rel="nofollow">RÃ¤ss, L., Omlin, S., &amp; Podladchikov, Y. Y. (2019). Porting a Massively Parallel Multi-GPU Application to Julia: a 3-D Nonlinear Multi-Physics Flow Solver. JuliaCon Conference, Baltimore, USA.</a></p>
<p dir="auto">[2] <a href="https://pasc19.pasc-conference.org/program/schedule/presentation/?id=msa218&amp;sess=sess144" rel="nofollow">RÃ¤ss, L., Omlin, S., &amp; Podladchikov, Y. Y. (2019). A Nonlinear Multi-Physics 3-D Solver: From CUDA C + MPI to Julia. PASC19 Conference, Zurich, Switzerland.</a></p>
<p dir="auto">[3] <a href="https://www.youtube.com/watch?v=vPsfZUqI4_0" rel="nofollow">Omlin, S., RÃ¤ss, L., Kwasniewski, G., Malvoisin, B., &amp; Podladchikov, Y. Y. (2020). Solving Nonlinear Multi-Physics on GPU Supercomputers with Julia. JuliaCon Conference, virtual.</a></p>
<p dir="auto">[4] <a href="https://on-demand.gputechconf.com/gtc/2019/video/_/S9368/" rel="nofollow">RÃ¤ss, L., Omlin, S., &amp; Podladchikov, Y. Y. (2019). Resolving Spontaneous Nonlinear Multi-Physics Flow Localisation in 3-D: Tackling Hardware Limit. GPU Technology Conference 2019, San Jose, Silicon Valley, CA, USA.</a></p>
<p dir="auto">[5] <a href="https://doi.org/10.1109/TPDS.2018.2872064" rel="nofollow">Besard, T., Foket, C., &amp; De Sutter, B. (2018). Effective Extensible Programming: Unleashing Julia on GPUs. IEEE Transactions on Parallel and Distributed Systems, 30(4), 827-841. doi: 10.1109/TPDS.2018.2872064</a></p>
<p dir="auto">[6] <a href="https://doi.org/10.1016/j.advengsoft.2019.02.002" rel="nofollow">Besard, T., Churavy, V., Edelman, A., &amp; De Sutter B. (2019). Rapid software prototyping for heterogeneous and distributed platforms. Advances in Engineering Software, 132, 29-46. doi: 10.1016/j.advengsoft.2019.02.002</a></p>
</article></div>