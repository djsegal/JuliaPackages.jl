<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-steindiscrepancyjl" class="anchor" aria-hidden="true" href="#steindiscrepancyjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>SteinDiscrepancy.jl</h1>
<h2><a id="user-content-whats-a-stein-discrepancy" class="anchor" aria-hidden="true" href="#whats-a-stein-discrepancy"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What's a Stein discrepancy?</h2>
<p>To improve the efficiency of Monte Carlo estimation, practitioners are
turning to biased Markov chain Monte Carlo procedures that trade off
asymptotic exactness for computational speed. The reasoning is sound: a
reduction in variance due to more rapid sampling can outweigh the bias
introduced. However, the inexactness creates new challenges for sampler and
parameter selection, since standard measures of sample quality like
effective sample size do not account for asymptotic bias. To address these
challenges, we introduced new computable quality measures, based on Stein's
method, that quantify the maximum discrepancy between sample and target
expectations over large classes of test functions. We call these measures
Stein discrepancies.</p>
<p>For a more detailed explanation, take a peek at the latest papers:</p>
<p><a href="https://arxiv.org/abs/1611.06972" rel="nofollow">Measuring Sample Quality with Diffusions</a>,
<a href="https://arxiv.org/abs/1703.01717" rel="nofollow">Measuring Sample Quality with Kernels</a>.</p>
<p>These build on previous work from</p>
<p><a href="http://arxiv.org/abs/1506.03039" rel="nofollow">Measuring Sample Quality with Stein's Method</a></p>
<p>and its companion paper</p>
<p><a href="http://arxiv.org/abs/1512.07392" rel="nofollow">Multivariate Stein Factors for a Class of Strongly Log-concave
Distributions</a>.</p>
<p>These latter two papers are a more gentle introduction describing how the
Stein discrepancy bounds standard probability metrics like the
<a href="https://en.wikipedia.org/wiki/Wasserstein_metric" rel="nofollow">Wasserstein distance</a>.</p>
<p>Code built on <code>SteinDiscrepancy.jl</code> recreating all experiments in the above
papers can be found at the repo
<a href="https://github.com/jgorham/stein_discrepancy">stein_discrepancy</a>.
Please note that experiments in aforementioned repo all run on v0.0.2 of
this package with Julia v0.5.</p>
<h2><a id="user-content-where-has-it-been-used" class="anchor" aria-hidden="true" href="#where-has-it-been-used"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Where has it been used?</h2>
<p>Since its introduction in <a href="http://arxiv.org/abs/1506.03039" rel="nofollow">Measuring Sample Quality with Stein's
Method</a>, the Stein discrepancy has been
incorporated into a variety of applications including:</p>
<ol>
<li>Hypothesis testing
<ul>
<li><a href="https://arxiv.org/abs/1602.03253" rel="nofollow">A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation</a></li>
<li><a href="https://arxiv.org/abs/1602.02964" rel="nofollow">A Kernel Test of Goodness of Fit</a></li>
</ul>
</li>
<li>Variational inference
<ul>
<li><a href="https://arxiv.org/abs/1610.09033" rel="nofollow">Operator Variational Inference</a></li>
<li><a href="https://arxiv.org/abs/1612.00081" rel="nofollow">Two Methods For Wild Variational Inference</a></li>
<li><a href="https://arxiv.org/abs/1702.08343" rel="nofollow">Approximate Inference with Amortised MCMC</a></li>
<li><a href="https://arxiv.org/abs/1608.04471" rel="nofollow">Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm</a></li>
</ul>
</li>
<li>Importance sampling
<ul>
<li><a href="https://arxiv.org/abs/1610.05247" rel="nofollow">Black-box Importance Sampling</a></li>
<li><a href="https://arxiv.org/abs/1704.05201" rel="nofollow">Stein Variational Adaptive Importance Sampling</a></li>
</ul>
</li>
<li>Training generative adversarial networks (GANs)
<ul>
<li><a href="https://arxiv.org/abs/1611.01722" rel="nofollow">Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning</a></li>
</ul>
</li>
<li>Training variational autoencoders (VAEs)
<ul>
<li><a href="https://arxiv.org/abs/1704.05155" rel="nofollow">Stein Variational Autoencoder</a></li>
</ul>
</li>
<li>Sample quality measurement
<ul>
<li><a href="http://arxiv.org/abs/1506.03039" rel="nofollow">Measuring Sample Quality with Stein's Method</a></li>
<li><a href="https://arxiv.org/abs/1611.06972" rel="nofollow">Measuring Sample Quality with Diffusions</a></li>
<li><a href="https://arxiv.org/abs/1703.01717" rel="nofollow">Measuring Sample Quality with Kernels</a></li>
</ul>
</li>
</ol>
<h2><a id="user-content-so-how-do-i-use-it" class="anchor" aria-hidden="true" href="#so-how-do-i-use-it"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>So how do I use it?</h2>
<p>This software has been tested on Julia v0.6. This release implements two
classes of Stein discrepancies: graph Stein discrepancies and kernel Stein
discrepancies.</p>
<h3><a id="user-content-graph-stein-discrepancies" class="anchor" aria-hidden="true" href="#graph-stein-discrepancies"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Graph Stein discrepancies</h3>
<p>Computing the graph Stein discrepancy requires solving a linear program
(LP), and thus you'll need some kind of LP solver installed to use this
software. We use JuMP (<a href="https://jump.readthedocs.org/en/latest/" rel="nofollow">Julia for Mathematical
Programming</a>) to interface with
these solvers; any of the supported JuMP LP solvers with do just fine.</p>
<p>Once you have an LP solver installed, computing our measure is easy.
Below we'll first show how to compute the Langevin graph Stein discrepancy
for a univariate Gaussian target:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span> import the gsd function (graph Stein discrepancy)</span>
<span class="pl-k">using</span> SteinDiscrepancy<span class="pl-k">:</span> gsd
<span class="pl-c"><span class="pl-c">#</span> define the grad log density of univariate Gaussian (we always expect vector inputs!)</span>
<span class="pl-k">function</span> <span class="pl-en">gradlogp</span>(x<span class="pl-k">::</span><span class="pl-c1">Array{Float64,1}</span>)
    <span class="pl-k">-</span>x
<span class="pl-k">end</span>
<span class="pl-c"><span class="pl-c">#</span> generates 100 points from N(0,1)</span>
X <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">100</span>)
<span class="pl-c"><span class="pl-c">#</span> use a solver covered by JuMP</span>
<span class="pl-k">using</span> Clp
solver <span class="pl-k">=</span> Clp<span class="pl-k">.</span><span class="pl-c1">ClpSolver</span>(LogLevel<span class="pl-k">=</span><span class="pl-c1">4</span>)
result <span class="pl-k">=</span> <span class="pl-c1">gsd</span>(points<span class="pl-k">=</span>X, gradlogdensity<span class="pl-k">=</span>gradlogp, solver<span class="pl-k">=</span>solver)
graph_stein_discrepancy <span class="pl-k">=</span> result<span class="pl-k">.</span>objectivevalue[<span class="pl-c1">1</span>]</pre></div>
<p>Here's another example that will compute the Langevin graph Stein
discrepancy for a bivariate uniform sample (notice this target distribution
has a bounded support so these bounds become part of the input parameters):</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span> do the necessary imports</span>
<span class="pl-k">using</span> SteinDiscrepancy<span class="pl-k">:</span> gsd
<span class="pl-c"><span class="pl-c">#</span> define the grad log density of bivariate uniform target</span>
<span class="pl-k">function</span> <span class="pl-en">gradlogp</span>(x<span class="pl-k">::</span><span class="pl-c1">Array{Float64,1}</span>)
    <span class="pl-c1">zeros</span>(<span class="pl-c1">size</span>(x))
<span class="pl-k">end</span>
<span class="pl-c"><span class="pl-c">#</span> generates 100 points from Unif([0,1]^2)</span>
X <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">100</span>,<span class="pl-c1">2</span>)
<span class="pl-c"><span class="pl-c">#</span> use a solver covered by JuMP</span>
<span class="pl-k">using</span> Clp
solver <span class="pl-k">=</span> Clp<span class="pl-k">.</span><span class="pl-c1">ClpSolver</span>(LogLevel<span class="pl-k">=</span><span class="pl-c1">4</span>)
result <span class="pl-k">=</span> <span class="pl-c1">gsd</span>(points<span class="pl-k">=</span>X,
             gradlogdensity<span class="pl-k">=</span>gradlogp,
             solver<span class="pl-k">=</span>solver,
             supportlowerbounds<span class="pl-k">=</span><span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>),
             supportupperbounds<span class="pl-k">=</span><span class="pl-c1">ones</span>(<span class="pl-c1">2</span>))
discrepancy <span class="pl-k">=</span> <span class="pl-c1">vec</span>(result<span class="pl-k">.</span>objectivevalue)</pre></div>
<p>The variable <code>discrepancy</code> here will encode the Stein discrepancy along each
dimension. The final discrepancy is just the sum of this vector.</p>
<h3><a id="user-content-kernel-stein-discrepancies" class="anchor" aria-hidden="true" href="#kernel-stein-discrepancies"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Kernel Stein discrepancies</h3>
<p>Computing the kernel Stein discrepancies does not require a LP solver. In
lieu of a solver, you will need to specify a kernel function. Many common
kernels are already implemented in <code>src/kernels</code>, but if yours is not there
for some reason, feel free to inherit from the <code>SteinKernel</code> type and roll
your own.</p>
<p>With a kernel in hand, computing the kernel Stein discrepancy is easy:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span> import the kernel stein discrepancy function and kernel to use</span>
<span class="pl-k">using</span> SteinDiscrepancy<span class="pl-k">:</span> SteinInverseMultiquadricKernel, ksd
<span class="pl-c"><span class="pl-c">#</span> define the grad log density of standard normal target</span>
<span class="pl-k">function</span> <span class="pl-en">gradlogp</span>(x<span class="pl-k">::</span><span class="pl-c1">Array{Float64,1}</span>)
    <span class="pl-k">-</span>x
<span class="pl-k">end</span>
<span class="pl-c"><span class="pl-c">#</span> grab sample</span>
X <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">500</span>, <span class="pl-c1">3</span>)
<span class="pl-c"><span class="pl-c">#</span> create the kernel instance</span>
kernel <span class="pl-k">=</span> <span class="pl-c1">SteinInverseMultiquadricKernel</span>()
<span class="pl-c"><span class="pl-c">#</span> compute the KSD2</span>
result <span class="pl-k">=</span> <span class="pl-c1">ksd</span>(points<span class="pl-k">=</span>X, gradlogdensity<span class="pl-k">=</span>gradlogp, kernel<span class="pl-k">=</span>kernel)
<span class="pl-c"><span class="pl-c">#</span> get the final ksd</span>
kernel_stein_discrepancy <span class="pl-k">=</span> <span class="pl-c1">sqrt</span>(result<span class="pl-k">.</span>discrepancy2)</pre></div>
<p>If your target has constrained support, you should simply use a kernel that
respects these constraints (no <code>supportlowerbounds</code> and <code>supportupperbounds</code>
arguments are needed). In the case you have a rectangular domain, the
<code>SteinRectangularDomainMetaKernel</code> should be useful. Here's an example
for a bivariate uniform target:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> SteinDiscrepancy<span class="pl-k">:</span>
    SteinRectangularDomainMetaKernel,
    SteinInverseMultiquadricKernel,
    ksd
<span class="pl-c"><span class="pl-c">#</span> define the grad log density of standard normal target</span>
<span class="pl-k">function</span> <span class="pl-en">gradlogp</span>(x<span class="pl-k">::</span><span class="pl-c1">Array{Float64,1}</span>)
    <span class="pl-c1">zeros</span>(<span class="pl-c1">length</span>(d))
<span class="pl-k">end</span>
<span class="pl-c"><span class="pl-c">#</span> grab sample</span>
X <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">500</span>, <span class="pl-c1">2</span>)
<span class="pl-c"><span class="pl-c">#</span> create the base kernel instance</span>
imqkernel <span class="pl-k">=</span> <span class="pl-c1">SteinInverseMultiquadricKernel</span>()
<span class="pl-c"><span class="pl-c">#</span> clip the kernel to have the target distribution's domain</span>
imqrectkernel <span class="pl-k">=</span> <span class="pl-c1">SteinRectangularDomainMetaKernel</span>(imqkernel, [<span class="pl-c1">0.</span>, <span class="pl-c1">0.</span>], [<span class="pl-c1">1.</span>, <span class="pl-c1">1.</span>])
<span class="pl-c"><span class="pl-c">#</span> compute the KSD2</span>
result <span class="pl-k">=</span> <span class="pl-c1">ksd</span>(points<span class="pl-k">=</span>X, gradlogdensity<span class="pl-k">=</span>gradlogp, kernel<span class="pl-k">=</span>imqrectkernel)
<span class="pl-c"><span class="pl-c">#</span> get the final ksd</span>
kernel_stein_discrepancy <span class="pl-k">=</span> <span class="pl-c1">sqrt</span>(result<span class="pl-k">.</span>discrepancy2)</pre></div>
<h2><a id="user-content-summary-of-the-code" class="anchor" aria-hidden="true" href="#summary-of-the-code"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Summary of the Code</h2>
<p>All code is available in the src directory of the repo. Many examples for
computing the stein_discrepancy are in the test directory.</p>
<h3><a id="user-content-contents-of-src" class="anchor" aria-hidden="true" href="#contents-of-src"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Contents of src</h3>
<ul>
<li>discrepancy - Code for computing Stein discrepancy</li>
<li>kernels - Commonly used kernels</li>
</ul>
<h3><a id="user-content-compiling-code-in-discrepancyspanner-directory" class="anchor" aria-hidden="true" href="#compiling-code-in-discrepancyspanner-directory"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Compiling Code in discrepancy/spanner directory</h3>
<p><strong>Our C++ code should be compiled automatically when the package is
built</strong>. However, if this doesn't work for some reason, you can issue the
following commands to compile the code in <code>src/discrepancy/spanner</code>:</p>
<pre><code>cd &lt;PACKAGE_DIR&gt;/src/discrepancy/spanner
make
make clean
</code></pre>
<p>The last step isn't necessary, but it will remove some superfluous
files. If you want to kill everything made in the build process, just run</p>
<pre><code>make distclean
</code></pre>
</article></div>