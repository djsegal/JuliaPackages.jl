<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-ntfk-nonnegative-tensor-factorization-using-k-means-clustering" class="anchor" aria-hidden="true" href="#ntfk-nonnegative-tensor-factorization-using-k-means-clustering"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>NTFk: Nonnegative Tensor Factorization using k-means clustering</h1>
<div>
    <a target="_blank" rel="noopener noreferrer" href="logo/ntfk-logo.png"><img src="logo/ntfk-logo.png" alt="ntfk" width="25%" style="max-width:100%;"></a>
</div>
<p><strong>NTFk</strong> performs a novel unsupervised Machine Learning (ML) method based on Tensor Decomposition coupled with sparsity and nonnegativity constraints.
<strong>NTFk</strong> methodology allows for automatic identification of the optimal number of features (signals) present in multi-dimensional data arrays (tensors).
The number of features (tensor "rank") along different dimensions can be estimated jointly and independently.</p>
<p><strong>NMFk</strong> can be applied to perform various types of analyses of multi-dimensional data:</p>
<ul>
<li>Feature extraction (<strong>FE</strong>)</li>
<li>Blind source separation (<strong>BSS</strong>)</li>
<li>Detection of disruptions / anomalies</li>
<li>Image recognition</li>
<li>Separation of (physics) processes</li>
<li>Discovery of unknown dependencies and phenomena</li>
<li>Development reduced-order/surrogate models</li>
<li>Identification of dependencies between model inputs and outputs</li>
<li>Guiding development of physics models representing the ML analyzed data</li>
<li>Data classification</li>
<li>Blind predictions</li>
<li>Optimization of data acquisition (optimal experimental design)</li>
<li>Labeling of datasets for supervised ML analyses</li>
</ul>
<p><strong>NTFk</strong> provides high-performance computing capabilities to solve problems with Shared and Distributed Arrays in parallel.
The parallelization allows for utilization of multi-core / multi-processor environments.
GPU and TPU accelerations are also available through existing Julia packages.</p>
<p><strong>NTFk</strong> can be employed to perform tensor decomposition using CP (Candecomp/Parafac) and Tucker methods.</p>
<p><strong>NTFk</strong> provides options to access to tensor decomposition methods available in MATLAB modules (MATLAB installation required): Tamara Kolda's <a href="https://www.tensortoolbox.org" rel="nofollow">TensorToolbox</a>, Ivan Oseledets' <a href="https://www.mathworks.com/matlabcentral/fileexchange/46312-oseledets-tt-toolbox" rel="nofollow">TT-Toolbox</a>, Wotao Yin's <a href="https://www.math.ucla.edu/~wotaoyin/papers/bcu/matlab.html" rel="nofollow">BCU</a>, and <a href="https://www.tensorlab.net" rel="nofollow">TensorLab</a>.</p>
<p><strong>NTFk</strong> provides also interface to Jean Kossaifi's <a href="http://tensorly.org/stable/index.html" rel="nofollow">Python TensorLy</a>.</p>
<p><strong>NTFk</strong> can perform high-performance computing tensor decomposition analyses using TensorFlow, PyTorch and MXNET.</p>
<p><strong>NTFk</strong> methodology and applications are discussed in the the papers and presentations listed below.</p>
<p>Tensor network decompositions can be be performed using our <a href="https://github.com/TensorDecompositions/NTNk.jl"><strong>NTNk</strong></a> package.</p>
<h3><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h3>
<p>After starting Julia, execute:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>NTFk<span class="pl-pds">"</span></span>)</pre></div>
<p>to access the latest released version.
To utilize the latest updates (commits) use:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(Pkg<span class="pl-k">.</span><span class="pl-c1">PackageSpec</span>(name<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>NTFk<span class="pl-pds">"</span></span>, rev<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>master<span class="pl-pds">"</span></span>))</pre></div>
<h2><a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Docker</h2>
<div class="highlight highlight-source-shell"><pre>docker run --interactive --tty montyvesselinov/tensors</pre></div>
<p>The docker image provides access to all <strong>TensorDecomposition</strong> packages.</p>
<h3><a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Testing</h3>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">test</span>(<span class="pl-s"><span class="pl-pds">"</span>NTFk<span class="pl-pds">"</span></span>)</pre></div>
<h3><a id="user-content-tensor-decomposition" class="anchor" aria-hidden="true" href="#tensor-decomposition"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tensor Decomposition</h3>
<p><strong>NTFk</strong> performs a novel unsupervised Machine Learning (ML) method based on Tensor Decomposition coupled with sparsity and nonnegativity constraints.</p>
<p><strong>NTFk</strong> has been applied to extract the temporal and spatial footprints of the features in multi-dimensional datasets in the form of multi-way arrays or tensors.</p>
<p><strong>NTFk</strong> executes the decomposition (factorization) of a given tensor <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fc0f4e2397cdf2612a306e6f174e99e557130145/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b58"><img src="https://camo.githubusercontent.com/fc0f4e2397cdf2612a306e6f174e99e557130145/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b58" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;X" style="max-width:100%;"></a> by minimization of the Frobenius norm:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e23a003df5ace732dc027fcccd762d597068a239/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b5c667261637b317d7b327d253743253743253230582d475c6f74696d65735f31415f315c6f74696d65735f32415f325c6c646f74735c6f74696d65735f6e415f6e2537432537435f465e32"><img src="https://camo.githubusercontent.com/e23a003df5ace732dc027fcccd762d597068a239/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b5c667261637b317d7b327d253743253743253230582d475c6f74696d65735f31415f315c6f74696d65735f32415f325c6c646f74735c6f74696d65735f6e415f6e2537432537435f465e32" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;\frac{1}{2}%7C%7C%20X-G\otimes_1A_1\otimes_2A_2\ldots\otimes_nA_n%7C%7C_F^2" style="max-width:100%;"></a></p>

<p>where:</p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4c1c65596ded972e2f13f71fce1101e47456fc78/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b6e"><img src="https://camo.githubusercontent.com/4c1c65596ded972e2f13f71fce1101e47456fc78/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b6e" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;n" style="max-width:100%;"></a> is the dimensionality of the tensor <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fc0f4e2397cdf2612a306e6f174e99e557130145/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b58"><img src="https://camo.githubusercontent.com/fc0f4e2397cdf2612a306e6f174e99e557130145/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b58" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;X" style="max-width:100%;"></a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2bdce837b77ab71e8fe6f252e34d81a4d17596c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b47"><img src="https://camo.githubusercontent.com/2bdce837b77ab71e8fe6f252e34d81a4d17596c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b47" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;G" style="max-width:100%;"></a> is a "mixing" core tensor</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d4bd93f69cd749ea6eeee439268920cd1a731d82/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f312c415f322c5c6c646f74732c415f6e"><img src="https://camo.githubusercontent.com/d4bd93f69cd749ea6eeee439268920cd1a731d82/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f312c415f322c5c6c646f74732c415f6e" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;A_1,A_2,\ldots,A_n" style="max-width:100%;"></a> are "feature” factors (in the form of vectors or matrices)</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f2470cf84840caf58a80a51efb8a2e13372af91a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b5c6f74696d6573"><img src="https://camo.githubusercontent.com/f2470cf84840caf58a80a51efb8a2e13372af91a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b5c6f74696d6573" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;\otimes" style="max-width:100%;"></a> is a tensor product applied to fold-in factors <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d4bd93f69cd749ea6eeee439268920cd1a731d82/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f312c415f322c5c6c646f74732c415f6e"><img src="https://camo.githubusercontent.com/d4bd93f69cd749ea6eeee439268920cd1a731d82/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f312c415f322c5c6c646f74732c415f6e" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;A_1,A_2,\ldots,A_n" style="max-width:100%;"></a>  in each of the tensor dimensions</li>
</ul>
<div>
    <a target="_blank" rel="noopener noreferrer" href="figures/tucker-paper.png"><img src="figures/tucker-paper.png" alt="tucker" width="auto/" style="max-width:100%;"></a>
</div>
<p>The product <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5e9225a56bc9896f296b11eaa9312b24108824ab/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b475c6f74696d65735f31415f315c6f74696d65735f32415f325c6c646f74735c6f74696d65735f6e415f6e"><img src="https://camo.githubusercontent.com/5e9225a56bc9896f296b11eaa9312b24108824ab/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b475c6f74696d65735f31415f315c6f74696d65735f32415f325c6c646f74735c6f74696d65735f6e415f6e" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;G\otimes_1A_1\otimes_2A_2\ldots\otimes_nA_n" style="max-width:100%;"></a> is an estimate of <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fc0f4e2397cdf2612a306e6f174e99e557130145/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b58"><img src="https://camo.githubusercontent.com/fc0f4e2397cdf2612a306e6f174e99e557130145/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b58" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;X" style="max-width:100%;"></a> (<a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/00c989d6d5130bc537ddde5a49d67b5810720408/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b585f7b6573747d"><img src="https://camo.githubusercontent.com/00c989d6d5130bc537ddde5a49d67b5810720408/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b585f7b6573747d" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;X_{est}" style="max-width:100%;"></a>).</p>
<p>The reconstruction error <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ffa386394a1d2cfdaf26f9001dae9828048c4160/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b582d585f7b6573747d"><img src="https://camo.githubusercontent.com/ffa386394a1d2cfdaf26f9001dae9828048c4160/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b582d585f7b6573747d" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;X-X_{est}" style="max-width:100%;"></a> is expected to be random uncorrelated noise.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2bdce837b77ab71e8fe6f252e34d81a4d17596c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b47"><img src="https://camo.githubusercontent.com/2bdce837b77ab71e8fe6f252e34d81a4d17596c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b47" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;G" style="max-width:100%;"></a> is a <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4c1c65596ded972e2f13f71fce1101e47456fc78/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b6e"><img src="https://camo.githubusercontent.com/4c1c65596ded972e2f13f71fce1101e47456fc78/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b6e" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;n" style="max-width:100%;"></a>-dimensional tensor with a size and a rank lower than the size and the rank of <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fc0f4e2397cdf2612a306e6f174e99e557130145/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b58"><img src="https://camo.githubusercontent.com/fc0f4e2397cdf2612a306e6f174e99e557130145/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b58" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;X" style="max-width:100%;"></a>.
The size of tensor <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2bdce837b77ab71e8fe6f252e34d81a4d17596c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b47"><img src="https://camo.githubusercontent.com/2bdce837b77ab71e8fe6f252e34d81a4d17596c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b47" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;G" style="max-width:100%;"></a> defines the number of extracted features (signals) in each of the tensor dimensions.</p>
<p>The factor matrices <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d4bd93f69cd749ea6eeee439268920cd1a731d82/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f312c415f322c5c6c646f74732c415f6e"><img src="https://camo.githubusercontent.com/d4bd93f69cd749ea6eeee439268920cd1a731d82/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f312c415f322c5c6c646f74732c415f6e" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;A_1,A_2,\ldots,A_n" style="max-width:100%;"></a> represent the extracted features (signals) in each of the tensor dimensions.
The number of matrix columns equals the number of features in the respective tensor dimensions (if there is only 1 column, the particular factor is a vector).
The number of matrix rows in each factor (matrix) <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/77d947a1f7455a2c0062713b915b8b3e157d7141/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f69"><img src="https://camo.githubusercontent.com/77d947a1f7455a2c0062713b915b8b3e157d7141/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f69" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;A_i" style="max-width:100%;"></a> equals the size of tensor X in the respective dimensions.</p>
<p>The elements of tensor <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2bdce837b77ab71e8fe6f252e34d81a4d17596c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b47"><img src="https://camo.githubusercontent.com/2bdce837b77ab71e8fe6f252e34d81a4d17596c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b47" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;G" style="max-width:100%;"></a> define how the features along each dimension (<a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d4bd93f69cd749ea6eeee439268920cd1a731d82/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f312c415f322c5c6c646f74732c415f6e"><img src="https://camo.githubusercontent.com/d4bd93f69cd749ea6eeee439268920cd1a731d82/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f312c415f322c5c6c646f74732c415f6e" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;A_1,A_2,\ldots,A_n" style="max-width:100%;"></a>) are mixed to represent the original tensor <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fc0f4e2397cdf2612a306e6f174e99e557130145/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b58"><img src="https://camo.githubusercontent.com/fc0f4e2397cdf2612a306e6f174e99e557130145/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b58" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;X" style="max-width:100%;"></a>.</p>
<p><strong>NTFk</strong> can perform Tensor Decomposition using <a href="https://en.wikipedia.org/wiki/Tensor_rank_decomposition" rel="nofollow">Candecomp/Parafac (CP)</a> or <a href="https://en.wikipedia.org/wiki/Tucker_decomposition" rel="nofollow">Tucker</a> decomposition models.</p>
<p>Some of the decomposition models can theoretically lead to unique solutions under specific, albeit rarely satisfied, noiseless conditions.
When these conditions are not satisfied, additional minimization constraints can assist the factorization.
A popular approach is to add sparsity and nonnegative constraints.
Sparsity constraints on the elements of G reduce the number of features and their mixing (by having as many zero entries as possible).
Nonnegativity enforces parts-based representation of the original data which also allows the Tensor Decomposition results for <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2bdce837b77ab71e8fe6f252e34d81a4d17596c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b47"><img src="https://camo.githubusercontent.com/2bdce837b77ab71e8fe6f252e34d81a4d17596c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b47" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;G" style="max-width:100%;"></a> and <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d4bd93f69cd749ea6eeee439268920cd1a731d82/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f312c415f322c5c6c646f74732c415f6e"><img src="https://camo.githubusercontent.com/d4bd93f69cd749ea6eeee439268920cd1a731d82/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c4c617267652673706163653b415f312c415f322c5c6c646f74732c415f6e" data-canonical-src="https://latex.codecogs.com/svg.latex?\Large&amp;space;A_1,A_2,\ldots,A_n" style="max-width:100%;"></a> to be easily interrelated <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=KaxssMiWgswC&amp;oi=fnd&amp;pg=PR5&amp;ots=Lta2adM6LV&amp;sig=jNPDxjKlON1U3l46tZAYH92mvAE#v=onepage&amp;q&amp;f=false" rel="nofollow">Cichocki et al, 2009</a>.</p>
<h3><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples</h3>
<p>A simple problem demonstrating <strong>NTFk</strong> can be executed as follows.
First, generate a random Tucker tensor:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> NTFk
<span class="pl-k">import</span> TensorDecompositions

csize <span class="pl-k">=</span> (<span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">4</span>)
tsize <span class="pl-k">=</span> (<span class="pl-c1">5</span>, <span class="pl-c1">10</span>, <span class="pl-c1">15</span>)
tucker_orig <span class="pl-k">=</span> NTFk<span class="pl-k">.</span><span class="pl-c1">rand_tucker</span>(csize, tsize; factors_nonneg<span class="pl-k">=</span><span class="pl-c1">true</span>, core_nonneg<span class="pl-k">=</span><span class="pl-c1">true</span>)</pre></div>
<p>After that, we can compose a tensor based on this Tucker decomposition:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> TensorDecompositions

T_orig <span class="pl-k">=</span> TensorDecompositions<span class="pl-k">.</span><span class="pl-c1">compose</span>(tucker_orig)
T_orig <span class="pl-k">.*=</span> <span class="pl-c1">1000</span></pre></div>
<p>Applying <strong>NTFk</strong>, we can find the unknown core size of the tensor using the tensor by itself as an input only.
To do this, we explore a series of core sizes and we identify the optimal one:</p>
<div class="highlight highlight-source-julia"><pre>sizes <span class="pl-k">=</span> [csize, (<span class="pl-c1">1</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>), (<span class="pl-c1">3</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>), (<span class="pl-c1">2</span>,<span class="pl-c1">2</span>,<span class="pl-c1">4</span>), (<span class="pl-c1">2</span>,<span class="pl-c1">4</span>,<span class="pl-c1">4</span>), (<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">3</span>), (<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">5</span>)]
tucker_estimated, csize_estimated <span class="pl-k">=</span> NTFk<span class="pl-k">.</span><span class="pl-c1">analysis</span>(T_orig, sizes, <span class="pl-c1">3</span>; eigmethod<span class="pl-k">=</span>[<span class="pl-c1">false</span>,<span class="pl-c1">false</span>,<span class="pl-c1">false</span>], progressbar<span class="pl-k">=</span><span class="pl-c1">false</span>, tol<span class="pl-k">=</span><span class="pl-c1">1e-16</span>, max_iter<span class="pl-k">=</span><span class="pl-c1">100000</span>, lambda<span class="pl-k">=</span><span class="pl-c1">0.</span>);</pre></div>
<p><strong>NTFk</strong> execution will produce something like this:</p>
<pre><code>[ Info: Decompositions (clustering dimension: 1)
1 - (2, 3, 4): residual 5.46581369842339e-5 worst tensor correlations [0.999999907810158, 0.9999997403618763, 0.9999995616299466] rank (2, 3, 4) silhouette 0.9999999999999997
2 - (1, 3, 4): residual 0.035325052042119755 worst tensor correlations [0.9634250567157897, 0.9842244237924007, 0.9254792458530211] rank (1, 3, 3) silhouette 1.0
3 - (3, 3, 4): residual 0.00016980024483822563 worst tensor correlations [0.9999982865486768, 0.9999923375643894, 0.9999915188040427] rank (3, 3, 4) silhouette 0.9404124172744835
4 - (2, 2, 4): residual 0.008914390317042747 worst tensor correlations [0.99782068249921, 0.9954301522732436, 0.9849956624171726] rank (2, 2, 4) silhouette 1.0
5 - (2, 4, 4): residual 0.00016061795564929862 worst tensor correlations [0.9999980289931861, 0.999996821183636, 0.9999940994076768] rank (2, 4, 4) silhouette 0.9996306553034816
6 - (2, 3, 3): residual 0.004136013571334162 worst tensor correlations [0.999947037606024, 0.9989851398124378, 0.9974723120905729] rank (2, 3, 3) silhouette 0.9999999999999999
7 - (2, 3, 5): residual 7.773676978117656e-5 worst tensor correlations [0.9999997131266367, 0.999999385995213, 0.9999988336042696] rank (2, 3, 5) silhouette 0.9999359399113312
[ Info: Estimated true core size based on the reconstruction: (2, 3, 4)
</code></pre>
<p>The final <strong>NTFk</strong> result is the estimated core size <code>(2,3,4)</code> which as expected matches the original unknown core size.</p>
<p><strong>NTFk</strong> also produces a Tucker deconstruction of this tensor with core size <code>(2,3,4)</code> which is stored as <code>tucker_estimated[ibest]</code></p>
<h3><a id="user-content-notebooks" class="anchor" aria-hidden="true" href="#notebooks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Notebooks:</h3>
<p>A series of Jupyter notebooks demonstrating <strong>NMFk</strong> have been developed:</p>
<ul>
<li><a href="https://github.com/TensorDecompositions/NTFk.jl/blob/master/notebooks/simple_tensor_decomposition.ipynb">Simple Tucker tensor decomposition</a></li>
<li><a href="https://github.com/TensorDecompositions/NTFk.jl/blob/master/notebooks/simple_tensor_decomposition_cp.ipynb">Simple Candecomp/Parafac (CP) tensor decomposition</a></li>
</ul>
<h3><a id="user-content-applications" class="anchor" aria-hidden="true" href="#applications"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Applications:</h3>
<p><strong>NTFk</strong> has been applied in a wide range of real-world applications.
The analyzed datasets include model outputs, laboratory experimental data, and field tests:</p>
<ul>
<li>Climate modeling</li>
<li>Material characterization using X rays</li>
<li>Reactive mixing</li>
<li>Molecular dynamics</li>
<li>Contaminant transport</li>
<li>Induced seismicity</li>
<li>Phase separation of co-polymers</li>
<li>Oil / Gas extraction from unconventional reservoirs</li>
</ul>
<h3><a id="user-content-videos" class="anchor" aria-hidden="true" href="#videos"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Videos:</h3>
<p>(click on the images below to start the videos)</p>
<ul>
<li>Europe Climate Model: Water table fluctuations in 2003</li>
</ul>
<div>
    <a href="https://www.youtube.com/embed/18EHkbDt5-0" rel="nofollow"><img src="https://camo.githubusercontent.com/5832da34b9eb52a4926bb3a33748a595f23ef46b/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f313845486b624474352d302f302e6a7067" width="25%" data-canonical-src="https://img.youtube.com/vi/18EHkbDt5-0/0.jpg" style="max-width:100%;"></a>
</div>
<ul>
<li>Europe Climate Model: Deconstruction of water table fluctuations in 2003</li>
</ul>
<div>
    <a href="https://www.youtube.com/embed/s8socihoqTo" rel="nofollow"><img src="https://camo.githubusercontent.com/38389c6f561239deae8e482db99fdf86fb1a45a3/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f7338736f6369686f71546f2f302e6a7067" width="25%" data-canonical-src="https://img.youtube.com/vi/s8socihoqTo/0.jpg" style="max-width:100%;"></a>
</div>
<ul>
<li>Europe Climate Model: Air temperature fluctuations in 2003</li>
</ul>
<div>
    <a href="https://www.youtube.com/embed/ZAWBn3OsCCw" rel="nofollow"><img src="https://camo.githubusercontent.com/e478d432ba08fdabf7f9f13f6917527549d62cd2/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f5a4157426e334f734343772f302e6a7067" width="25%" data-canonical-src="https://img.youtube.com/vi/ZAWBn3OsCCw/0.jpg" style="max-width:100%;"></a>
</div>
<ul>
<li>Europe Climate Model: Deconstruction of Air temperature fluctuations in 2003</li>
</ul>
<div>
    <a href="https://www.youtube.com/embed/qUQvChqE8_4" rel="nofollow"><img src="https://camo.githubusercontent.com/7dd95797e29aa12619d63e0fb44ca74953a59ac3/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f7155517643687145385f342f302e6a7067" width="25%" data-canonical-src="https://img.youtube.com/vi/qUQvChqE8_4/0.jpg" style="max-width:100%;"></a>
</div>
<ul>
<li>Oklahoma seismic events</li>
</ul>
<div>
    <a href="https://www.youtube.com/embed/prP_OZFA3tE" rel="nofollow"><img src="https://camo.githubusercontent.com/a3fee537b2b25339b3517a441538130d6a6a7be9/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f7072505f4f5a46413374452f302e6a7067" width="25%" data-canonical-src="https://img.youtube.com/vi/prP_OZFA3tE/0.jpg" style="max-width:100%;"></a>
</div>
<ul>
<li>Deconstruction of Oklahoma seismic events</li>
</ul>
<div>
    <a href="https://www.youtube.com/embed/xIoWi0WjeoQ" rel="nofollow"><img src="https://camo.githubusercontent.com/601c71936f3f1121b91430d214414a5789f4547e/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f78496f576930576a656f512f302e6a7067" width="25%" data-canonical-src="https://img.youtube.com/vi/xIoWi0WjeoQ/0.jpg" style="max-width:100%;"></a>
</div>
<ul>
<li>Deconstruction of Oklahoma seismic events</li>
</ul>
<div>
    <a href="https://www.youtube.com/embed/xIoWi0WjeoQ" rel="nofollow"><img src="https://camo.githubusercontent.com/601c71936f3f1121b91430d214414a5789f4547e/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f78496f576930576a656f512f302e6a7067" width="25%" data-canonical-src="https://img.youtube.com/vi/xIoWi0WjeoQ/0.jpg" style="max-width:100%;"></a>
</div>
<p>Videos are available on <a href="https://www.youtube.com/watch?v=xPOkeLMJywE&amp;list=PLpVcrIWNlP22LfyIu5MSZ7WHp7q0MNjsj" rel="nofollow">YouTube</a></p>
<h3><a id="user-content-publications" class="anchor" aria-hidden="true" href="#publications"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Publications:</h3>
<ul>
<li>Vesselinov, V.V., Mudunuru, M., Karra, S., O'Malley, D., Alexandrov, B.S., Unsupervised Machine Learning Based on Non-Negative Tensor Factorization for Analyzing Reactive-Mixing, Journal of Computational Physics, 2018 (in review). <a href="http://monty.gitlab.io/papers/Vesselinov%20et%20al%202018%20Unsupervised%20Machine%20Learning%20Based%20on%20Non-Negative%20Tensor%20Factorization%20for%20Analyzing%20Reactive-Mixing.pdf" rel="nofollow">PDF</a></li>
<li>Vesselinov, V.V., Alexandrov, B.S., O'Malley, D., Nonnegative Tensor Factorization for Contaminant Source Identification, Journal of Contaminant Hydrology, 10.1016/j.jconhyd.2018.11.010, 2018. <a href="http://monty.gitlab.io/papers/Vesselinov%20et%20al%202018%20Nonnegative%20Tensor%20Factorization%20for%20Contaminant%20Source%20Identification.pdf" rel="nofollow">PDF</a></li>
</ul>
<p>Research papers are also available at <a href="http://scholar.google.com/citations?user=sIFHVvwAAAAJ&amp;hl=en" rel="nofollow">Google Scholar</a>, <a href="https://www.researchgate.net/profile/Velimir_Vesselinov" rel="nofollow">ResearchGate</a> and <a href="https://lanl.academia.edu/monty" rel="nofollow">Academia.edu</a></p>
<h3><a id="user-content-presentations" class="anchor" aria-hidden="true" href="#presentations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Presentations:</h3>
<ul>
<li>Vesselinov, V.V., Novel Machine Learning Methods for Extraction of Features Characterizing Datasets and Models, AGU Fall meeting, Washington D.C., 2018. <a href="http://monty.gitlab.io/presentations/Vesselinov%202018%20Novel%20Machine%20Learning%20Methods%20for%20Extraction%20of%20Features%20Characterizing%20Datasets%20and%20Models%20LA-UR-18-31366.pdf" rel="nofollow">PDF</a></li>
<li>Vesselinov, V.V., Novel Machine Learning Methods for Extraction of Features Characterizing Complex Datasets and Models, Recent Advances in Machine Learning and Computational Methods for Geoscience, Institute for Mathematics and its Applications, University of Minnesota, 2018. <a href="http://monty.gitlab.io/presentations/Vesselinov%202018%20Novel%20Machine%20Learning%20Methods%20for%20Extraction%20of%20Features%20Characterizing%20Complex%20Datasets%20and%20Models%20LA-UR-18-30987.pdf" rel="nofollow">PDF</a></li>
</ul>
<p>Presentations are also available at <a href="https://www.slideshare.net/VelimirmontyVesselin" rel="nofollow">slideshare.net</a>, <a href="https://www.researchgate.net/profile/Velimir_Vesselinov" rel="nofollow">ResearchGate</a> and <a href="https://lanl.academia.edu/monty" rel="nofollow">Academia.edu</a></p>
<h3><a id="user-content-lectures" class="anchor" aria-hidden="true" href="#lectures"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Lectures:</h3>
<ul>
<li><a href="https://youtu.be/xPOkeLMJywE" rel="nofollow">Vesselinov, V.V., Novel Machine Learning Methods for Extraction of Features Characterizing Complex Datasets and Models, Recent Advances in Machine Learning and Computational Methods for Geoscience, Institute for Mathematics and its Applications, University of Minnesota, 2018.</a></li>
</ul>
<p><a href="https://www.youtube.com/embed/xPOkeLMJywE" rel="nofollow"><img src="images/nma.png" alt="Watch the video" style="max-width:100%;"></a></p>
<h3><a id="user-content-extra-information" class="anchor" aria-hidden="true" href="#extra-information"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Extra information</h3>
<p>For more information, visit <a href="http://monty.gitlab.io" rel="nofollow">monty.gitlab.io</a>, [tensordecompositions.github.io],(<a href="https://tensordecompositions.github.io" rel="nofollow">https://tensordecompositions.github.io</a>), and <a href="http://tensors.lanl.gov" rel="nofollow">tensors.lanl.gov</a></p>
<h2><a id="user-content-installation-behind-a-firewall" class="anchor" aria-hidden="true" href="#installation-behind-a-firewall"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation behind a firewall</h2>
<p>Julia uses git for package management. Add in the <code>.gitconfig</code> file in your home directory:</p>
<pre><code>[url "git@github.com:"]
    insteadOf = https://github.com/
[url "git@gitlab.com:"]
    insteadOf = https://gitlab.com/
[url "https://"]
    insteadOf = git://
[url "http://"]
    insteadOf = git://
</code></pre>
<p>or execute:</p>
<pre><code>git config --global url."https://".insteadOf git://
git config --global url."http://".insteadOf git://
git config --global url."git@gitlab.com:".insteadOf https://gitlab.com/
git config --global url."git@github.com:".insteadOf https://github.com/
</code></pre>
<p>Set proxies:</p>
<pre><code>export ftp_proxy=http://proxyout.&lt;your_site&gt;:8080
export rsync_proxy=http://proxyout.&lt;your_site&gt;:8080
export http_proxy=http://proxyout.&lt;your_site&gt;:8080
export https_proxy=http://proxyout.&lt;your_site&gt;:8080
export no_proxy=.&lt;your_site&gt;
</code></pre>
<p>For example, if you are doing this at LANL, you will need to execute the
following lines in your bash command-line environment:</p>
<pre><code>export ftp_proxy=http://proxyout.lanl.gov:8080
export rsync_proxy=http://proxyout.lanl.gov:8080
export http_proxy=http://proxyout.lanl.gov:8080
export https_proxy=http://proxyout.lanl.gov:8080
export no_proxy=.lanl.gov
</code></pre>
<p>Proxies can be also set up directly in the Julia REPL as well:</p>
<div class="highlight highlight-source-julia"><pre>ENV[<span class="pl-s"><span class="pl-pds">"</span>ftp_proxy<span class="pl-pds">"</span></span>] <span class="pl-k">=</span>  <span class="pl-s"><span class="pl-pds">"</span>http://proxyout.lanl.gov:8080<span class="pl-pds">"</span></span>
ENV[<span class="pl-s"><span class="pl-pds">"</span>rsync_proxy<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>http://proxyout.lanl.gov:8080<span class="pl-pds">"</span></span>
ENV[<span class="pl-s"><span class="pl-pds">"</span>http_proxy<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>http://proxyout.lanl.gov:8080<span class="pl-pds">"</span></span>
ENV[<span class="pl-s"><span class="pl-pds">"</span>https_proxy<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>http://proxyout.lanl.gov:8080<span class="pl-pds">"</span></span>
ENV[<span class="pl-s"><span class="pl-pds">"</span>no_proxy<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>.lanl.gov<span class="pl-pds">"</span></span></pre></div>
</article></div>