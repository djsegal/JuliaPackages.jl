<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-multistochgrad" class="anchor" aria-hidden="true" href="#multistochgrad"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>MultiStochGrad</h1>
<h2><a id="user-content-this-package-provides-an-implementation-of-2-stochastic-gradient-algorithms-scsg-and-svrg" class="anchor" aria-hidden="true" href="#this-package-provides-an-implementation-of-2-stochastic-gradient-algorithms-scsg-and-svrg"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>This package provides an implementation of 2 stochastic gradient algorithms: SCSG and SVRG</h2>
<p>The algorithms implemented are described in the following papers:</p>
<ol>
<li>
<p>The so-called SCSG algorithm described and analyzed in the two papers by L. Lei and  M.I Jordan.</p>
<ul>
<li>
<p>"On the adaptativity of stochastic gradient based optimization" (2019)
<a href="https://arxiv.org/abs/1904.04480" rel="nofollow">SCSG-1</a></p>
</li>
<li>
<p>"Less than a single pass : stochastically controlled stochastic gradient" (2019)
<a href="https://arxiv.org/abs/1609.03261" rel="nofollow">SCSD-2</a></p>
</li>
</ul>
</li>
<li>
<p>The SVRG algorithm described in the paper by R. Johnson and T. Zhang
"Accelerating Stochastic Gradient Descent using Predictive Variance Reduction" (2013).<br>
<a href="https://papers.nips.cc/paper/4937-accelerating-stochastic-gradient-descent-using-predictive-variance-reduction.pdf" rel="nofollow">Advances in Neural Information Processing Systems, pages 315–323, 2013</a></p>
</li>
</ol>
<p>These algorithms minimize functions given by an expression:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="    f(x) = 1/n ∑ fᵢ(x) where fᵢ is a convex function.
"><pre><code>    f(x) = 1/n ∑ fᵢ(x) where fᵢ is a convex function.
</code></pre></div>
<p>All algorithms alternates some form of large batch computation (computing gradient of many terms of the sum)
and small or mini batches (computing a small number of terms, possibly just one, term of the gradient)
and updating position by combining these global and local gradients.</p>
<h2><a id="user-content-structure-of-the-package-and-documentation" class="anchor" aria-hidden="true" href="#structure-of-the-package-and-documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Structure of the package and documentation</h2>
<p>The user API relies mainly upon two structures defining the optimization problem (detailed in file <strong>evaluator.jl</strong>) specifying how to compute the value and gradient of each term of the sum at a given position:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="- struct TermFunction{F &lt;: Function}

- struct TermGradient{G &lt;: Function&gt;}
"><pre><code>- struct TermFunction{F &lt;: Function}

- struct TermGradient{G &lt;: Function&gt;}
</code></pre></div>
<p>The directory src/applis show examples of definitions of these 2 structures.</p>
<p>These two structures are grouped into a <strong>struct Evaluator{F,G}</strong> which can thus do all value and gradient computations needed during the iterations.<br>
Each algorithm SVRG or SCSG is described by its own structure and has its specific parameters and iteration strategy.
A minimize function taking as arguments a structure SCSG or SVRG, an evaluator structure, the maximum number of iterations and an initial position then returns the minimum value obtained and its correspond position.</p>
<p>Further documentation can be found in docs of the Julia package (run <strong>julia make.jl</strong>), some more in the doc of the equivalent Rust crate <a href="https://github.com/jean-pierreBoth/multistochgrad">multistochgrad.rs</a> and in the reference papers.</p>
<p>We compare below the performance of the Rust and the Julia versions.</p>
<h2><a id="user-content-examples-and-tests" class="anchor" aria-hidden="true" href="#examples-and-tests"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples and tests</h2>
<p>Small tests consist in a line fitting problem and logisitc regression.</p>
<p>The logistic regression test and example run on the training files of the digits MNIST database, as in the second paper on SCSG.</p>
<p>The data files can be downloaded from <a href="http://yann.lecun.com/exdb/mnist" rel="nofollow">MNIST</a>, then modify accordingly the paths
declared in file TestLogisiticRegression.jl.</p>
<p>The database has 60000 images of 784 pixels corresponding to
handwritten digits form 0 to 9.<br>
The logistic regression, with 10 classes,  is tested with the 2 algorithms and some comments are provided, comparing the results.
Times are obtained by launching twice the example to avoid the compilation time of the first pass.
Run times are those obtained on a 4 hyperthreaded i7-cores laptop at 2.7Ghz</p>
<h3><a id="user-content-scsg-logistic-regression" class="anchor" aria-hidden="true" href="#scsg-logistic-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>SCSG logistic regression</h3>
<p>The identifiability constraint was set on the class corresponding to the 0 digit. (Contrary to the Rust tests
where the 9-digit class was chosen, this explains the different initial error and the fact that the best step
was not the same).</p>
<p>For the signification of the parameters B_0 , b_O, see documentation of SCSG.
Here we give some results:</p>
<ul>
<li>initialization position : 9 images with <em>constant pixel = 0.5</em>,
error at initial position: 8.88</li>
</ul>
<table>
<thead>
<tr>
<th align="center">nb iter</th>
<th align="center">B_0</th>
<th align="center">m_0</th>
<th align="center">step_0</th>
<th>y value</th>
<th>time(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">50</td>
<td align="center">0.02</td>
<td align="center">0.004</td>
<td align="center">0.1</td>
<td>0.29</td>
<td>11.3</td>
</tr>
<tr>
<td align="center">50</td>
<td align="center">0.02</td>
<td align="center">0.006</td>
<td align="center">0.1</td>
<td>0.281</td>
<td>14.</td>
</tr>
<tr>
<td align="center">70</td>
<td align="center">0.02</td>
<td align="center">0.006</td>
<td align="center">0.1</td>
<td>0.272</td>
<td>19.5</td>
</tr>
<tr>
<td align="center">100</td>
<td align="center">0.02</td>
<td align="center">0.006</td>
<td align="center">0.1</td>
<td>0.265</td>
<td>27.</td>
</tr>
</tbody>
</table>
<ul>
<li>initialization position : 9 images with <em>constant pixel = 0.0</em>,
error at initial position: 2.3</li>
</ul>
<table>
<thead>
<tr>
<th>nb iter</th>
<th align="center">B_0</th>
<th>m_0</th>
<th>step_0</th>
<th>y value</th>
<th>time(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>50</td>
<td align="center">0.015</td>
<td>0.003</td>
<td>0.1</td>
<td>0.285</td>
<td>10.2</td>
</tr>
<tr>
<td>50</td>
<td align="center">0.02</td>
<td>0.004</td>
<td>0.1</td>
<td>0.28</td>
<td>11</td>
</tr>
<tr>
<td>50</td>
<td align="center">0.02</td>
<td>0.006</td>
<td>0.1</td>
<td>0.274</td>
<td>14</td>
</tr>
<tr>
<td>100</td>
<td align="center">0.02</td>
<td>0.004</td>
<td>0.1</td>
<td>0.266</td>
<td>22.</td>
</tr>
<tr>
<td>100</td>
<td align="center">0.02</td>
<td>0.006</td>
<td>0.1</td>
<td>0.262</td>
<td>27.5</td>
</tr>
</tbody>
</table>
<h3><a id="user-content-svrg-logistic-regression" class="anchor" aria-hidden="true" href="#svrg-logistic-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>SVRG logistic regression</h3>
<ul>
<li>initialization position : 9 images with <em>constant pixel = 0.5</em>,
error at initial position: 8.88</li>
</ul>
<table>
<thead>
<tr>
<th>nb iter</th>
<th align="center">nb mini batch</th>
<th>step</th>
<th>y value</th>
<th>time(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>50</td>
<td align="center">1000</td>
<td>0.05</td>
<td>0.269</td>
<td>25</td>
</tr>
<tr>
<td>50</td>
<td align="center">2000</td>
<td>0.05</td>
<td>0.255</td>
<td>27</td>
</tr>
</tbody>
</table>
<ul>
<li>initialization position : 9 images with <em>constant pixel = 0.0</em>,
error at initial position: 2.3</li>
</ul>
<table>
<thead>
<tr>
<th>nb iter</th>
<th align="center">nb mini batch</th>
<th>step</th>
<th>y value</th>
<th>time(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>50</td>
<td align="center">500</td>
<td>0.05</td>
<td>0.28</td>
<td>23.5</td>
</tr>
<tr>
<td>50</td>
<td align="center">1000</td>
<td>0.05</td>
<td>0.264</td>
<td>24.5</td>
</tr>
<tr>
<td>50</td>
<td align="center">2000</td>
<td>0.05</td>
<td>0.25</td>
<td>27</td>
</tr>
<tr>
<td>100</td>
<td align="center">1000</td>
<td>0.05</td>
<td>0.253</td>
<td>50</td>
</tr>
</tbody>
</table>
<h3><a id="user-content-some-comments-on-cpu-times" class="anchor" aria-hidden="true" href="#some-comments-on-cpu-times"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>some comments on cpu-times</h3>
<p>All times were obtained withe @time macro and julia running with JULIA_NUM_THREADS = 8.</p>
<p>We see that SCSG is fast to reach a minimum of 0.28, it is more difficult to reach 0.26-0.27
it nevertheless quite competitive compared to SVRG.<br>
The efficiency gain with respect to SVRG is not as important
as with the <em>Rust</em> version (see below) where we have a factor 1.8 in cpu-time <strong>due to a multithreading effect</strong>.
Our test uses 60000 observations and SCSG runs at most on 1/10 of the terms in a batch (i.e 6000 terms), on the constrary SVRG batches run on the full 60000 terms.<br>
<strong>Batch sizes on SCSG are not large enough to fully benefit of the multithreading.</strong>
This can be verified by setting JULIA_NUM_THREADS = 1 and compare how SCSG and SVRG timing benefit from
the threading:</p>
<p>We did 2  checks with initial conditions set to pixel = 0.5 and compared with previous results:</p>
<ul>
<li>
<p>For SCSG we ran the case with parameters (70, 0.02, 0.006, 0.1 )  corresponding to last line of first array of results. We had with 8 threads y=0.27 in 20s , and with one thread we obtain y=0.27 in 36.5s, so the threading gives us less than a factor 2.</p>
</li>
<li>
<p>For SVRG we ran the case with parameters (50,1000, 0.05) corresponding to the first line of first array of result for SVRG.
We had y=0.269 with 25s, and with one thread we need 72s. Here the threading
gives us a gain of 3.</p>
</li>
</ul>
<p>So SCSG  efficiency should be more evident on larger problems, note that the threading in Julia is still young.</p>
<p>The logistic regression needed the explicit use of BLAS interface to speed up vectorization.</p>
<p><em>Nevertheless the Julia version runs within a factor 1.5 or 1.8 of the Rust version which seems a good compromise.</em></p>
<h2><a id="user-content-rust-version-of-this-package" class="anchor" aria-hidden="true" href="#rust-version-of-this-package"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Rust version of this package</h2>
<p>There is also a Rust implementation of this package at <a href="https://github.com/jean-pierreBoth/multistochgrad">multigrad.rs</a>.</p>
<p>The Rust version has also an implementation of the SAG algorithm:</p>
<p>The Stochastic Averaged Gradient Descent as described in the paper:
<strong>"Minimizing Finite Sums with the Stochastic Average Gradient" (2013, 2016)</strong>
M.Schmidt, N.LeRoux, F.Bach.</p>
<h2><a id="user-content-note" class="anchor" aria-hidden="true" href="#note"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Note</h2>
<ul>
<li>version 0.1.2 runs 10-15 % faster on SCSG due to some optimization
see  <a href="https://bkamins.github.io/julialang/2020/11/20/rand.html" rel="nofollow">The need for rand speed</a> or julia bloggers.</li>
</ul>
<h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>License</h2>
<p>Licensed under either of</p>
<ul>
<li>Apache License, Version 2.0, <a href="LICENSE-APACHE">LICENSE-APACHE</a> or <a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow">http://www.apache.org/licenses/LICENSE-2.0</a></li>
<li>MIT license <a href="LICENSE-MIT">LICENSE-MIT</a> or <a href="http://opensource.org/licenses/MIT" rel="nofollow">http://opensource.org/licenses/MIT</a></li>
</ul>
<p>at your option.</p>
<p>This software was written on my own while working at <a href="http://www.cea.fr/" rel="nofollow">CEA</a>, <a href="http://www-list.cea.fr/en/" rel="nofollow">CEA-LIST</a></p>
</article></div>