<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a href="https://travis-ci.com/BGU-CS-VIL/DPMMSubClusters.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/774be302cb1d7f4a3e0f48f12f79886a6eb2f5f6a7e32208f7c2c0e3e18448aa/68747470733a2f2f7472617669732d63692e636f6d2f4247552d43532d56494c2f44504d4d537562436c7573746572732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/BGU-CS-VIL/DPMMSubClusters.jl.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://coveralls.io/github/dinarior/DPMMSubClusters.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/b4ba92786e733ef6c1492ec16209a35c1dc0999bbbccfe8fbad0bb97a8f5f87e/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f64696e6172696f722f44504d4d537562436c7573746572732e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/dinarior/DPMMSubClusters.jl/badge.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://bgu-cs-vil.github.io/DPMMSubClusters.jl/latest/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a></p>
<h1 dir="auto"><a id="user-content-dpmmsubclustersjl" class="anchor" aria-hidden="true" href="#dpmmsubclustersjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DPMMSubClusters.jl</h1>
<p dir="auto">This is the code repository for the <em>Julia</em> package (with an optional <a href="https://github.com/BGU-CS-VIL/dpmmpython">Python wrapper</a>) that corresponds to our paper, <a href="https://www.cs.bgu.ac.il/~dinari/papers/dpmm_hpml2019.pdf" rel="nofollow">Distributed MCMC Inference in Dirichlet Process Mixture Models Using Julia</a>, which was presented at CCGrid2019 High Performance Computing Maching Learning workshop (HPML).</p>
<p dir="auto">Note that due to improvements in the code we have made since the time of the pulication of the paper, this package is now faster than what we reported there.
This is a CPU-based package, which supports multiple cores and multiple machines. However, please also check out its even-faster <a href="https://github.com/BGU-CS-VIL/DPMMSubClusters_GPU">GPU counterpart</a>.</p>
<br>
<p align="center" dir="auto">
<a target="_blank" rel="noopener noreferrer" href="clusters_low_slow.gif"><img src="clusters_low_slow.gif" alt="DPGMM SubClusters 2d example" data-animated-image="" style="max-width: 100%;"></a>
</p>
<p dir="auto"><a href="https://bgu-cs-vil.github.io/DPMMSubClusters.jl/stable/" rel="nofollow">Docs are now available</a>.<br></p>
<h2 dir="auto"><a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Requirements</h2>
<p dir="auto">This package was developed and tested on <em>Julia 1.0.3</em>, prior versions will not work.
The following dependencies are required:</p>
<ul dir="auto">
<li>Distributed</li>
<li>DistributedArrays</li>
<li>Distributions</li>
<li>JLD2</li>
<li>LinearAlgebra</li>
<li>NPZ</li>
<li>Random</li>
<li>SpecialFunctions</li>
<li>StatsBase</li>
</ul>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">Use Julia's package manager:
<code>(v1.0) pkg&gt; add DPMMSubClusters</code></p>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">This package is aimed for distributed parallel computing, while working with no workers is possible. Adding more workers, distributed across different machines, are encouraged for increased performance.</p>
<p dir="auto">It is recommended to use <code>BLAS.set_num_threads(1)</code>, when working with larger datasets increasing the amount of workers will do the trick, <code>BLAS</code> multi threading might disturb the multiprocessing, resulting in slower inference.</p>
<p dir="auto">For all the workers to recognize the package, you must start with <code>@everywhere using DPMMSubClusters</code>. If you require to set the seed (using the <code>seed</code> kwarg), add <code>@everywhere using Random</code> as well.</p>
<p dir="auto">The package currently contains priors for handling <em>Multinomial</em> or <em>Gaussian</em> mixture models.</p>
<p dir="auto">While being very verstile in the setting and configuration, there are 2 modes which you can work with, either the <em>Basic</em>, which will use mostly predefined configuration, and will take the data as an argument, or <em>Advanced</em> use, which allows more configuration, loading data from file, and saving the model, or running from a saved checkpoint.</p>
<h3 dir="auto"><a id="user-content-basic" class="anchor" aria-hidden="true" href="#basic"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basic</h3>
<p dir="auto">In order to run in the basic mode, use the function:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="labels, clusters, weights = fit(all_data::AbstractArray{Float32,2},local_hyper_params::distribution_hyper_params,α_param::Float32;
        iters::Int64 = 100, init_clusters::Int64 = 1,seed = nothing, verbose = true, save_model = false, burnout = 20, gt = nothing)"><pre class="notranslate"><code>labels, clusters, weights = fit(all_data::AbstractArray{Float32,2},local_hyper_params::distribution_hyper_params,α_param::Float32;
        iters::Int64 = 100, init_clusters::Int64 = 1,seed = nothing, verbose = true, save_model = false, burnout = 20, gt = nothing)
</code></pre></div>
<p dir="auto">Or, if opting for the default Gaussian weak prior:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="labels, clusters, weights = fit(all_data::AbstractArray{Float32,2},α_param::Float32;
        iters::Int64 = 100, init_clusters::Int64 = 1,seed = nothing, verbose = true, save_model = false,burnout = 20, gt = nothing)"><pre class="notranslate"><code>labels, clusters, weights = fit(all_data::AbstractArray{Float32,2},α_param::Float32;
        iters::Int64 = 100, init_clusters::Int64 = 1,seed = nothing, verbose = true, save_model = false,burnout = 20, gt = nothing)
</code></pre></div>
<p dir="auto">* note that while we dispatch on <code>Float32</code>, other numbers will work as well, and will be cast if needed.</p>
<h4 dir="auto"><a id="user-content-args-and-kwargs" class="anchor" aria-hidden="true" href="#args-and-kwargs"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Args and Kwargs:</h4>
<ul dir="auto">
<li>all_data - The data, should be <code>DxN</code>.</li>
<li>local_hyper_params - The prior you plan to use, can be either Multinomial, or <code>NIW</code> (example below on how to create one)</li>
<li>α_param - Concetration parameter</li>
<li>iters - Number of iterations</li>
<li>seed - Random seed, can also be set seperatly. note that if seting seperatly you must set it on all workers.</li>
<li>verbose - Printing status on every iteration.</li>
<li>save_model - If true, will save a checkpoint every 25 iterations, note that if you opt for saving, I recommend the advanced mode.</li>
<li>burnout - How many iteration before allowing clusters to split/merge, reducing this number will result in faster inference, but with higher variance between the different runs.</li>
<li>gt - Ground Truth, if supplied will perform <code>NMI</code> and <code>VI</code> tests on every iteration.</li>
</ul>
<h4 dir="auto"><a id="user-content-return-values" class="anchor" aria-hidden="true" href="#return-values"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Return values:</h4>
<p dir="auto"><code>fit</code> will return the following:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="labels, cluster_params, weights, iteration_time_history, nmi_score_history,likelihood_history, cluster_count_history"><pre class="notranslate"><code>labels, cluster_params, weights, iteration_time_history, nmi_score_history,likelihood_history, cluster_count_history
</code></pre></div>
<p dir="auto">Note that <code>weights</code> does not sum up to <code>1</code>, but to <code>1</code> minus the weight of the non-instanisated components.</p>
<p dir="auto">Examples:
<a href="https://nbviewer.jupyter.org/github/dinarior/DPMMSubClusters.jl/blob/master/examples/2d_gaussian/gaussian_2d.ipynb" rel="nofollow">2d Gaussian with plotting</a>.
<a href="https://nbviewer.jupyter.org/github/dinarior/DPMMSubClusters.jl/blob/master/examples/image_seg/dpgmm-superpixels.ipynb" rel="nofollow">Image Segmentation</a>.</p>
<p dir="auto">Reducing the <code>burnout</code> will increase the speed and reduce stability, increasing the variance in the results.</p>
<p dir="auto">When supplied with <code>gt</code> kwarg, it will perform <code>NMI</code> and <code>Variation of Information</code> analysis on each iteration.</p>
<p dir="auto">The return values for the <code>fit</code> methods is:</p>
<p dir="auto"><code>labels, clusters, weights, iteration_time, nmi_history, likelihood_history, cluster_count_history</code></p>
<h3 dir="auto"><a id="user-content-advanced" class="anchor" aria-hidden="true" href="#advanced"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Advanced</h3>
<p dir="auto">In this mode you are required to supply a params file, example for one is the file <code>global_params.jl</code>.
It includes all the configurable params. Running it is as simple as:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="dp = dp_parallel(model_params::String; verbose = true, save_model = true, burnout = 5, gt = nothing)"><pre class="notranslate"><code>dp = dp_parallel(model_params::String; verbose = true, save_model = true, burnout = 5, gt = nothing)
</code></pre></div>
<p dir="auto">Will return:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="dp, iteration_time_history , nmi_score_history, liklihood_history, cluster_count_history"><pre class="notranslate"><code>dp, iteration_time_history , nmi_score_history, liklihood_history, cluster_count_history
</code></pre></div>
<p dir="auto">The returned value <code>dp</code> is a data structure:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="mutable struct dp_parallel_sampling
    model_hyperparams::model_hyper_params
    group::local_group
end"><pre class="notranslate"><code>mutable struct dp_parallel_sampling
    model_hyperparams::model_hyper_params
    group::local_group
end
</code></pre></div>
<p dir="auto">In which contains the <code>local_group</code>, another structure:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="mutable struct local_group
    model_hyperparams::model_hyper_params
    points::AbstractArray{Float64,2}
    labels::AbstractArray{Int64,1}
    labels_subcluster::AbstractArray{Int64,1}
    local_clusters::Vector{local_cluster}
    weights::Vector{Float64}
end"><pre class="notranslate"><code>mutable struct local_group
    model_hyperparams::model_hyper_params
    points::AbstractArray{Float64,2}
    labels::AbstractArray{Int64,1}
    labels_subcluster::AbstractArray{Int64,1}
    local_clusters::Vector{local_cluster}
    weights::Vector{Float64}
end
</code></pre></div>
<p dir="auto">Note that for data loading the package use <code>NPZ</code> , which utilize python <em>numpy</em> files. Thus the data files must be <em>pythonic</em>, and be of the shape <code>NxD</code>.</p>
<p dir="auto"><a href="https://nbviewer.jupyter.org/github/dinarior/DPMMSubClusters.jl/blob/master/examples/save_load_model/save_load_example.ipynb" rel="nofollow">Example of running from a params file, including saving and loading, with a multinomial prior</a>.</p>
<h2 dir="auto"><a id="user-content-additional-functions" class="anchor" aria-hidden="true" href="#additional-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Additional Functions</h2>
<p dir="auto">Additional function exposed to the user include:</p>
<ul dir="auto">
<li><code>run_model_from_checkpoint(file_name)</code> : Used to restart a saved run, file_name must point to a valid checkpoint file created during a run of the model.  Note that the params files used for running the model initialy must still be available and in the same location, this is true for the data as well.</li>
<li><code>calculate_posterior(model)</code> : Calculate the posterior of a model, returned from <code>dp_parallel</code>.</li>
<li><code>generate_gaussian_data(N::Int64, D::Int64, K::Int64)</code>: Randomly generates gaussian data, <code>N</code> points, of dimension <code>D</code> from <code>K</code> clusters. return value is <code>points, labels, cluster_means, cluster_covariance</code>.</li>
<li><code>generate_mnmm_data(N::Int64, D::Int64, K::Int64, trials::Int64)</code>: Similar to above, just for multinomial data, the return value is <code>points, labels, clusters</code></li>
</ul>
<h3 dir="auto"><a id="user-content-misc" class="anchor" aria-hidden="true" href="#misc"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Misc</h3>
<p dir="auto">For any questions: <a href="mailto:dinari@post.bgu.ac.il">dinari@post.bgu.ac.il</a></p>
<p dir="auto">Contributions, feature requests, suggestion etc.. are welcomed.</p>
<p dir="auto">If you use this code for your work, please cite the following:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="@inproceedings{dinari2019distributed,
  title={Distributed MCMC Inference in Dirichlet Process Mixture Models Using Julia},
  author={Dinari, Or and Yu, Angel and Freifeld, Oren and Fisher III, John W},
  booktitle={2019 19th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)},
  pages={518--525},
  year={2019}
}"><pre class="notranslate"><code>@inproceedings{dinari2019distributed,
  title={Distributed MCMC Inference in Dirichlet Process Mixture Models Using Julia},
  author={Dinari, Or and Yu, Angel and Freifeld, Oren and Fisher III, John W},
  booktitle={2019 19th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)},
  pages={518--525},
  year={2019}
}
</code></pre></div>
</article></div>