<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-diffeqfluxjl" class="anchor" aria-hidden="true" href="#diffeqfluxjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DiffEqFlux.jl</h1>
<p><a href="https://gitter.im/JuliaDiffEq/Lobby?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge" rel="nofollow"><img src="https://camo.githubusercontent.com/833b89353967086ef3bf7e1d470c469fd93cc80696ae173ffc5fbcf401d2f5af/68747470733a2f2f6261646765732e6769747465722e696d2f4a756c69614469666645712f4c6f6262792e737667" alt="Join the chat at https://gitter.im/JuliaDiffEq/Lobby" data-canonical-src="https://badges.gitter.im/JuliaDiffEq/Lobby.svg" style="max-width:100%;"></a>
<a href="https://github.com/SciML/DiffEqFlux.jl/actions?query=workflow%3ACI"><img src="https://github.com/SciML/DiffEqFlux.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width:100%;"></a>
<a href="https://buildkite.com/julialang/diffeqflux-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/f2029cc13eef89259b48f3050b626354255d894242659737fd89e1e15ecb862c/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f61316665636638376230383562343532666530663364333936386464616362356331643535373038303638333465316435322e737667" alt="Build status" data-canonical-src="https://badge.buildkite.com/a1fecf87b085b452fe0f3d3968ddacb5c1d5570806834e1d52.svg" style="max-width:100%;"></a>
<a href="http://diffeqflux.sciml.ai/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a>
<a href="http://diffeqflux.sciml.ai/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a></p>
<p>DiffEqFlux.jl fuses the world of differential equations with machine learning
by helping users put diffeq solvers into neural networks. This package utilizes
<a href="http://diffeq.sciml.ai/dev/" rel="nofollow">DifferentialEquations.jl</a> and
<a href="https://fluxml.ai/" rel="nofollow">Flux.jl</a> as its building blocks to support research in
<a href="http://www.stochasticlifestyle.com/the-essential-tools-of-scientific-machine-learning-scientific-ml/" rel="nofollow">Scientific Machine Learning</a>,
specifically neural differential equations and universal differential equations,
to add physical information into traditional machine learning.</p>
<h2><a id="user-content-tutorials-and-documentation" class="anchor" aria-hidden="true" href="#tutorials-and-documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tutorials and Documentation</h2>
<p>For information on using the package,
<a href="https://diffeqflux.sciml.ai/stable/" rel="nofollow">see the stable documentation</a>. Use the
<a href="https://diffeqflux.sciml.ai/dev/" rel="nofollow">in-development documentation</a> for the version of
the documentation, which contains the unreleased features.</p>
<h2><a id="user-content-problem-domain" class="anchor" aria-hidden="true" href="#problem-domain"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Problem Domain</h2>
<p>DiffEqFlux.jl is not just for neural ordinary differential equations.
DiffEqFlux.jl is for universal differential equations, where these can include
delays, physical constraints, stochasticity, events, and all other kinds of
interesting behavior that shows up in scientific simulations. Neural networks can
be all or part of the model. They can be around the differential equation,
in the cost function, or inside of the differential equation. Neural networks
representing unknown portions of the model or functions can go anywhere you
have uncertainty in the form of the scientific simulator. For an overview of the
topic with applications, consult the paper <a href="https://arxiv.org/abs/2001.04385" rel="nofollow">Universal Differential Equations for
Scientific Machine Learning</a>.</p>
<p>As such, it is the first package to support and demonstrate:</p>
<ul>
<li>Stiff and non-stiff universal ordinary differential equations (universal ODEs)</li>
<li>Universal stochastic differential equations (universal SDEs)</li>
<li>Universal delay differential equations (universal DDEs)</li>
<li>Universal partial differential equations (universal PDEs)</li>
<li>Universal jump stochastic differential equations (universal jump diffusions)</li>
<li>Hybrid universal differential equations (universal DEs with event handling)</li>
</ul>
<p>with high order, adaptive, implicit, GPU-accelerated, Newton-Krylov, etc.
methods. For examples, please refer to
<a href="https://julialang.org/blog/2019/01/fluxdiffeq" rel="nofollow">the release blog post</a>.
Additional demonstrations, like neural
PDEs and neural jump SDEs, can be found
<a href="http://www.stochasticlifestyle.com/neural-jump-sdes-jump-diffusions-and-neural-pdes/" rel="nofollow">in this blog post</a>
(among many others!).</p>
<p>Do not limit yourself to the current neuralization. With this package, you can
explore various ways to integrate the two methodologies:</p>
<ul>
<li>Neural networks can be defined where the “activations” are nonlinear functions
described by differential equations</li>
<li>Neural networks can be defined where some layers are ODE solves</li>
<li>ODEs can be defined where some terms are neural networks</li>
<li>Cost functions on ODEs can define neural networks</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1814174/88589293-e8207f80-d026-11ea-86e2-8a3feb8252ca.gif"><img src="https://user-images.githubusercontent.com/1814174/88589293-e8207f80-d026-11ea-86e2-8a3feb8252ca.gif" alt="Flux ODE Training Animation" style="max-width:100%;"></a></p>
</article></div>