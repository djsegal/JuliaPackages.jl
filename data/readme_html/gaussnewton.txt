<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-gaussnewtonjl" class="anchor" aria-hidden="true" href="#gaussnewtonjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>GaussNewton.jl</h1>
<table>
<thead>
<tr>
<th align="center">Status</th>
<th align="center">Coverage</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a target="_blank" rel="noopener noreferrer" href="https://github.com/fabienlefloch/GaussNewton.jl/actions/workflows/julia-runtests.yml/badge.svg"><img src="https://github.com/fabienlefloch/GaussNewton.jl/actions/workflows/julia-runtests.yml/badge.svg" alt="Build Status" style="max-width: 100%;"></a></td>
<td align="center"><a href="http://codecov.io/github/fabienlefloch/GaussNewton.jl?branch=main" rel="nofollow"><img src="https://camo.githubusercontent.com/d0d3c1547e9155973d721f7aec005cd495fa4bb8df8c8e20579baccad7b6620f/687474703a2f2f636f6465636f762e696f2f6769746875622f66616269656e6c65666c6f63682f47617573734e6577746f6e2e6a6c2f636f7665726167652e7376673f6272616e63683d6d61696e" alt="codecov.io" data-canonical-src="http://codecov.io/github/fabienlefloch/GaussNewton.jl/coverage.svg?branch=main" style="max-width: 100%;"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">Klare and Miller Gauss-Newton Minimizer. Minimize sum of squares of residuals r using augmented Gauss-Newton step and Levenberg-Marquardt trust region.  Uses finite-difference derivatives and 1-D Jacobian updates.</p>
<p dir="auto">This is a port of Fortran90 Netlib.org/misc/gn code originally from Kenneth Klare (<a href="mailto:kklare@gmail.com">kklare@gmail.com</a>) and Guthrie Miller (<a href="mailto:guthriemiller@gmail.com">guthriemiller@gmail.com</a>).</p>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">The simple syntax mirrors the Optim.jl package syntax</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using GaussNewton
function rosenbrock(x)
	[1 - x[1], 100 * (x[2]-x[1]^2)]
end
x0 = zeros(2)
optimize(rosenbrock, x0)"><pre><span class="pl-k">using</span> GaussNewton
<span class="pl-k">function</span> <span class="pl-en">rosenbrock</span>(x)
	[<span class="pl-c1">1</span> <span class="pl-k">-</span> x[<span class="pl-c1">1</span>], <span class="pl-c1">100</span> <span class="pl-k">*</span> (x[<span class="pl-c1">2</span>]<span class="pl-k">-</span>x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>)]
<span class="pl-k">end</span>
x0 <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>)
<span class="pl-c1">optimize</span>(rosenbrock, x0)</pre></div>
<p dir="auto">A more optimized and powerful in place syntax is also possible, where the jacobian calculation may be passed as parameter:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using GaussNewton
function rosenbrock!(r,x)
	r[1] = 1 - x[1]
    r[2] = 100 * (x[2]-x[1]^2)
end
function rosenbrockDer!(J,x)
	J[1,1] = -1
    J[2,1] = -200*x[1]
    J[1,2] = 0
    J[2,2] = 100
end

x0 = zeros(2)
r = zeros(2) #output
optimize!(rosenbrock!, rosenbrockDer!, x0, r)"><pre><span class="pl-k">using</span> GaussNewton
<span class="pl-k">function</span> <span class="pl-en">rosenbrock!</span>(r,x)
	r[<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">1</span> <span class="pl-k">-</span> x[<span class="pl-c1">1</span>]
    r[<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">100</span> <span class="pl-k">*</span> (x[<span class="pl-c1">2</span>]<span class="pl-k">-</span>x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>)
<span class="pl-k">end</span>
<span class="pl-k">function</span> <span class="pl-en">rosenbrockDer!</span>(J,x)
	J[<span class="pl-c1">1</span>,<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1</span>
    J[<span class="pl-c1">2</span>,<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">200</span><span class="pl-k">*</span>x[<span class="pl-c1">1</span>]
    J[<span class="pl-c1">1</span>,<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">0</span>
    J[<span class="pl-c1">2</span>,<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">100</span>
<span class="pl-k">end</span>

x0 <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>)
r <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>) <span class="pl-c"><span class="pl-c">#</span>output</span>
<span class="pl-c1">optimize!</span>(rosenbrock!, rosenbrockDer!, x0, r)</pre></div>
<p dir="auto">where the <code>rosenbrockDer!</code> is optional, and may be automatically computed through the autodiff parameter.</p>
<p dir="auto">Additional optional parameters are:</p>
<ul dir="auto">
<li>stptol: step size for relative convergence test.</li>
<li>reltol, abstol: value relative/absolute convergence test.</li>
<li>derivstp in: the step for derivatives in autodiff = :single mode   Must be large enough to get some change in the function.    Must be small enough for some accuracy in the derivative.</li>
<li>limit  in: maximum number of all evaluations allowed, approximate.</li>
<li>tuning constants:
<ul dir="auto">
<li>ZLOW,ZHIGH change bounds of trust region (del) (.5,2).  Small changes in the path set by them greatly affect results.</li>
<li>ZCP Cauchy step size (1).</li>
<li>ZCPMIN minimum Cauchy step size (0.1).</li>
<li>ZCPMAX maximum Cauchy step size (1000).</li>
<li>MXBAD number bad steps with rank-1 updates (1).</li>
</ul>
</li>
<li>NewtStep1st=true start with Newton step. Use on linear problems.</li>
<li>iscale=0, no scaling, iscale=1, variable scaling, iscale=2, fixed scaling based on D0, which must be allocated</li>
</ul>
<p dir="auto">The function returns the final sum of squares, and the minimum is stored in x0. In addition, it returns a detailed result structure from which success may be inferred through</p>
<ul dir="auto">
<li><code>is_fatal(result::GNResult)</code> if a fatal error occured</li>
<li><code>has_converged(result::GNResult) = has_converged_abstol(result) || has_converged_reltol(result) || has_converged_stptol(result)</code></li>
<li><code>has_converged_stptol(result::GNResult)</code></li>
<li><code>has_converged_reltol(result::GNResult)</code></li>
<li><code>has_converged_abstol(result::GNResult)</code></li>
</ul>
<h2 dir="auto"><a id="user-content-autodiff-parameter" class="anchor" aria-hidden="true" href="#autodiff-parameter"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>autodiff parameter</h2>
<p dir="auto">if the explicit jacobian calculation fcnDer! is not passed as a parameter (is nothing), then the parameter autodiff controls how the jacobian is calculated:</p>
<ul dir="auto">
<li>autodiff = :forward uses the ForwarDiff package to compute the jacobian by automatic forward differentiation,</li>
<li>autodiff = :centered uses the FiniteDiff package to compute the jacobian</li>
<li>autodiff = :single for single sided finite difference, as per the original code of Klare and Miller.</li>
</ul>
</article></div>