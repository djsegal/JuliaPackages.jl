<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-autooffloadjl" class="anchor" aria-hidden="true" href="#autooffloadjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>AutoOffload.jl</h1>
<p>AutoOffload.jl is an experimental library looking into automatic offloading
of costly computations to accelerators like GPUs for user-friendly speedups.
While not as efficient as an algorithm fully designed to stay on an accelerator
due to the data syncing, for costly operations, like matrix multiplications
and FFTs, this can give a sizable speedup. The purpose of this library is
to attempt to automatically determine cutoff points for which offloading
to an accelerator makes sense, and then utilize this so that all other libraries
auto-GPU/TPU/distribute/etc. when appropriate.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>AutoOffload.jl does not depend on the accelerator libraries. Thus in order to
allow usage of an accelerator, you must have already installed it. For example,
for GPU offloading, we require that you have done <code>]add CuArrays</code>.</p>
<h2><a id="user-content-design-goal" class="anchor" aria-hidden="true" href="#design-goal"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Design Goal</h2>
<p>The goal is to have an <code>autotune()</code> function which runs some benchmarks to
determine optimal cutoff values for your hardware configuration, and from this
setup internal calls so that acclerated versions will auto-offload. The calls
are all appended with <code>accelerated</code>, like:</p>
<ul>
<li><code>accelerated_mul!</code></li>
<li><code>accelerated_fft</code></li>
<li><code>accelerated_ldiv!</code></li>
</ul>
<p>This library is made to be automatic, using compile-time checking to enable
offloads based on installed compatible packages, but not require any special
dependencies. This means that a library is safe to depend on and use AutoOffload.jl
for the <code>accelerated</code> functions without getting a dependency on the GPU/TPU/etc.
libraries.</p>
<h2><a id="user-content-pirate-mode" class="anchor" aria-hidden="true" href="#pirate-mode"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Pirate Mode</h2>
<p>We plan to implement a pirated version, so that <code>using AutoOffload.Pirate</code>
will replace the common <code>*</code>, <code>mul!</code>, etc. calls with the accelerated versions,
which will allow auto-acceleration in libraries which have not been setup with
the <code>accelerated</code> interface functions.</p>
</article></div>