<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-naivenaslib" class="anchor" aria-hidden="true" href="#naivenaslib"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>NaiveNASlib</h1>
<p><a href="https://github.com/DrChainsaw/NaiveNASlib.jl/actions"><img src="https://github.com/DrChainsaw/NaiveNASlib.jl/workflows/CI/badge.svg?branch=master" alt="Build status" style="max-width:100%;"></a>
<a href="https://ci.appveyor.com/project/DrChainsaw/NaiveNASlib-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/d7f0a64c07527dd2f06639a768d1e666c22d664c499baa380b476b0c3b9081bf/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f4472436861696e7361772f4e616976654e41536c69622e6a6c3f7376673d74727565" alt="Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/DrChainsaw/NaiveNASlib.jl?svg=true" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/DrChainsaw/NaiveNASlib.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/02f1475042ef7107171d1a5e45a371572b62f39ce983a2906f0babebd7e09c36/68747470733a2f2f636f6465636f762e696f2f67682f4472436861696e7361772f4e616976654e41536c69622e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Codecov" data-canonical-src="https://codecov.io/gh/DrChainsaw/NaiveNASlib.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p>NaiveNASlib is a library of functions for mutating computation graphs. It is designed with Neural Architecture Search (NAS) in mind, but can be used for any purpose where doing changes to a model architecture is desired.</p>
<p>It is "batteries excluded" in the sense that it is independent of both neural network implementation and search policy implementation. If you need batteries, check out <a href="https://github.com/DrChainsaw/NaiveNASflux.jl">NaiveNASflux</a>.</p>
<p>Its only contribution to this world is some help with the sometimes annoyingly complex procedure of changing an existing neural network into a new, similar yet different, neural network.</p>
<h2><a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Basic usage</h2>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="]add NaiveNASlib
"><pre>]add NaiveNASlib</pre></div>
<p>Main supported operations:</p>
<ul>
<li>Change the input/output size of vertices</li>
<li>Parameter pruning/insertion (policy excluded)</li>
<li>Add vertices to the graph</li>
<li>Remove vertices from the graph</li>
<li>Add edges to a vertex</li>
<li>Remove edges to a vertex</li>
</ul>
<p>For each of the above operations, NaiveNASlib makes the necessary changes to neighboring vertices to ensure that the computation graph is consistent w.r.t dimensions of the activations.</p>
<p>The price one has to pay is that the computation graph must be explicitly defined in the "language" of this library, similar to what some older frameworks using less modern programming languages used to do. In its defense, the sole reason anyone would use this library to begin with is to not have to create computation graphs themselves.</p>
<p>Just to get started, lets create a simple graph for the summation of two numbers:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using NaiveNASlib
using Test
in1 = inputvertex(&quot;in1&quot;, 1)
in2 = inputvertex(&quot;in2&quot;, 1)

# Create a new vertex which computes the sum of in1 and in2
computation = in1 + in2
@test typeof(computation) == MutationVertex

# CompGraph helps evaluating the whole graph as a function
graph = CompGraph([in1, in2], computation);

# Evaluate the function represented by graph
@test graph(2,3) == 5
"><pre><span class="pl-k">using</span> NaiveNASlib
<span class="pl-k">using</span> Test
in1 <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in1<span class="pl-pds">"</span></span>, <span class="pl-c1">1</span>)
in2 <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in2<span class="pl-pds">"</span></span>, <span class="pl-c1">1</span>)

<span class="pl-c"><span class="pl-c">#</span> Create a new vertex which computes the sum of in1 and in2</span>
computation <span class="pl-k">=</span> in1 <span class="pl-k">+</span> in2
<span class="pl-c1">@test</span> <span class="pl-c1">typeof</span>(computation) <span class="pl-k">==</span> MutationVertex

<span class="pl-c"><span class="pl-c">#</span> CompGraph helps evaluating the whole graph as a function</span>
graph <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>([in1, in2], computation);

<span class="pl-c"><span class="pl-c">#</span> Evaluate the function represented by graph</span>
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>(<span class="pl-c1">2</span>,<span class="pl-c1">3</span>) <span class="pl-k">==</span> <span class="pl-c1">5</span></pre></div>
<p>Now for a more to the point example.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="# First we need something to mutate. Batteries excluded, remember?
mutable struct SimpleLayer
    W
    SimpleLayer(W) = new(W)
    SimpleLayer(nin, nout) = new(ones(Int, nin,nout))
end
(l::SimpleLayer)(x) = x * l.W

# Helper function which creates a mutable layer.
layer(in, outsize) = absorbvertex(SimpleLayer(nout(in), outsize), outsize, in, mutation=IoSize)

invertex = inputvertex(&quot;input&quot;, 3)
layer1 = layer(invertex, 4);
layer2 = layer(layer1, 5);

@test [nout(layer1)] == nin(layer2) == [4]

# Lets change the output size of layer1:
Δnout(layer1, -2);

@test [nout(layer1)] == nin(layer2) == [2]
"><pre><span class="pl-c"><span class="pl-c">#</span> First we need something to mutate. Batteries excluded, remember?</span>
<span class="pl-k">mutable struct</span> SimpleLayer
    W
    <span class="pl-en">SimpleLayer</span>(W) <span class="pl-k">=</span> <span class="pl-c1">new</span>(W)
    <span class="pl-en">SimpleLayer</span>(nin, nout) <span class="pl-k">=</span> <span class="pl-c1">new</span>(<span class="pl-c1">ones</span>(Int, nin,nout))
<span class="pl-k">end</span>
(l<span class="pl-k">::</span><span class="pl-c1">SimpleLayer</span>)(x) <span class="pl-k">=</span> x <span class="pl-k">*</span> l<span class="pl-k">.</span>W

<span class="pl-c"><span class="pl-c">#</span> Helper function which creates a mutable layer.</span>
<span class="pl-en">layer</span>(in, outsize) <span class="pl-k">=</span> <span class="pl-c1">absorbvertex</span>(<span class="pl-c1">SimpleLayer</span>(<span class="pl-c1">nout</span>(in), outsize), outsize, in, mutation<span class="pl-k">=</span>IoSize)

invertex <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>input<span class="pl-pds">"</span></span>, <span class="pl-c1">3</span>)
layer1 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertex, <span class="pl-c1">4</span>);
layer2 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(layer1, <span class="pl-c1">5</span>);

<span class="pl-c1">@test</span> [<span class="pl-c1">nout</span>(layer1)] <span class="pl-k">==</span> <span class="pl-c1">nin</span>(layer2) <span class="pl-k">==</span> [<span class="pl-c1">4</span>]

<span class="pl-c"><span class="pl-c">#</span> Lets change the output size of layer1:</span>
<span class="pl-c1">Δnout</span>(layer1, <span class="pl-k">-</span><span class="pl-c1">2</span>);

<span class="pl-c1">@test</span> [<span class="pl-c1">nout</span>(layer1)] <span class="pl-k">==</span> <span class="pl-c1">nin</span>(layer2) <span class="pl-k">==</span> [<span class="pl-c1">2</span>]</pre></div>
<p>As can be seen above, the consequence of changing the output size of <code>layer1</code> was that the input size of <code>layer2</code> also was changed.</p>
<p>Besides the very simple graph, this mutation was trivial because both layers are of the type <code>SizeAbsorb</code>, meaning that a change in number of inputs/outputs does not propagate further in the graph.</p>
<p>Lets do a non-trivial example where changes propagate:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="# First a few &quot;normal&quot; layers
invertex = inputvertex(&quot;input&quot;, 6);
start = layer(invertex, 6);
split = layer(start, div(nout(invertex) , 3));

# When multiplying with a scalar, the output size is the same as the input size.
# This vertex type is said to be SizeInvariant (in lack of better words).
scalarmult(v, f::Integer) = invariantvertex(x -&gt; x .* f, v)

# Concatenation is a third type of vertex, called SizeStack where the output size is the sum of input sizes
joined = conc(scalarmult(split, 2), scalarmult(split,3), scalarmult(split,5), dims=2);
@test trait(joined) == SizeStack()

# Elementwise addition is SizeInvariant
out = start + joined;
@test trait(out) == SizeInvariant()

@test [nout(invertex)] == nin(start) == nin(split) == [3 * nout(split)] == [sum(nin(joined))] == [nout(out)] == [6]
@test [nout(start), nout(joined)] == nin(out) == [6, 6]

graph = CompGraph(invertex, out)
@test graph((ones(Int, 1,6))) == [78  78  114  114  186  186]

# Ok, lets try to change the size of the vertex &quot;out&quot;.
# First we need to realize that we can only change it by integer multiples of 3
# This is because it is connected to &quot;split&quot; through three paths which require nin==nout
# Therefore, any size change to nout of &quot;split&quot; will result in 3 times the change of nin of &quot;out&quot;.
# Equivalently, nout of &quot;split&quot; is nin of &quot;out&quot; divided by 3 and nin/nout must be integers.

# We need this information from the layer. Some layers have other requirements
NaiveNASlib.minΔnoutfactor(::SimpleLayer) = 1
NaiveNASlib.minΔninfactor(::SimpleLayer) = 1

@test minΔnoutfactor(out) == minΔninfactor(out) == 3

# Next, we need to define how to mutate our SimpleLayer
NaiveNASlib.mutate_inputs(l::SimpleLayer, newInSize) = l.W = ones(Int, newInSize, size(l.W,2))
NaiveNASlib.mutate_outputs(l::SimpleLayer, newOutSize) = l.W = ones(Int, size(l.W,1), newOutSize)

# In some cases it is useful to hold on to the old graph before mutating
# To do so, we need to define the clone operation for our SimpleLayer
NaiveNASlib.clone(l::SimpleLayer) = SimpleLayer(l.W)
parentgraph = copy(graph)

Δnout(out, 3)

# We didn't touch the input when mutating...
@test [nout(invertex)] == nin(start) == [6]
# Start and joined must have the same size due to elementwise op.
# All three scalarmult vertices are transparent and propagate the size change to split
@test [nout(start)] == nin(split) == [3 * nout(split)] == [sum(nin(joined))] == [nout(out)] == [9]
@test [nout(start), nout(joined)] == nin(out) == [9, 9]

# However, this only updated the mutation metadata, not the actual layer.
# Some reasons for this are shown in the pruning example below
@test graph((ones(Int, 1,6))) == [78  78  114  114  186  186]

# To mutate the graph, we need to apply the mutation:
apply_mutation(graph);

@test graph((ones(Int, 1,6))) == [114  114  114  168  168  168  276  276  276]

# Copy is still intact
@test parentgraph((ones(Int, 1,6))) == [78  78  114  114  186  186]

"><pre><span class="pl-c"><span class="pl-c">#</span> First a few "normal" layers</span>
invertex <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>input<span class="pl-pds">"</span></span>, <span class="pl-c1">6</span>);
start <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertex, <span class="pl-c1">6</span>);
split <span class="pl-k">=</span> <span class="pl-c1">layer</span>(start, <span class="pl-c1">div</span>(<span class="pl-c1">nout</span>(invertex) , <span class="pl-c1">3</span>));

<span class="pl-c"><span class="pl-c">#</span> When multiplying with a scalar, the output size is the same as the input size.</span>
<span class="pl-c"><span class="pl-c">#</span> This vertex type is said to be SizeInvariant (in lack of better words).</span>
<span class="pl-en">scalarmult</span>(v, f<span class="pl-k">::</span><span class="pl-c1">Integer</span>) <span class="pl-k">=</span> <span class="pl-c1">invariantvertex</span>(x <span class="pl-k">-&gt;</span> x <span class="pl-k">.*</span> f, v)

<span class="pl-c"><span class="pl-c">#</span> Concatenation is a third type of vertex, called SizeStack where the output size is the sum of input sizes</span>
joined <span class="pl-k">=</span> <span class="pl-c1">conc</span>(<span class="pl-c1">scalarmult</span>(split, <span class="pl-c1">2</span>), <span class="pl-c1">scalarmult</span>(split,<span class="pl-c1">3</span>), <span class="pl-c1">scalarmult</span>(split,<span class="pl-c1">5</span>), dims<span class="pl-k">=</span><span class="pl-c1">2</span>);
<span class="pl-c1">@test</span> <span class="pl-c1">trait</span>(joined) <span class="pl-k">==</span> <span class="pl-c1">SizeStack</span>()

<span class="pl-c"><span class="pl-c">#</span> Elementwise addition is SizeInvariant</span>
out <span class="pl-k">=</span> start <span class="pl-k">+</span> joined;
<span class="pl-c1">@test</span> <span class="pl-c1">trait</span>(out) <span class="pl-k">==</span> <span class="pl-c1">SizeInvariant</span>()

<span class="pl-c1">@test</span> [<span class="pl-c1">nout</span>(invertex)] <span class="pl-k">==</span> <span class="pl-c1">nin</span>(start) <span class="pl-k">==</span> <span class="pl-c1">nin</span>(split) <span class="pl-k">==</span> [<span class="pl-c1">3</span> <span class="pl-k">*</span> <span class="pl-c1">nout</span>(split)] <span class="pl-k">==</span> [<span class="pl-c1">sum</span>(<span class="pl-c1">nin</span>(joined))] <span class="pl-k">==</span> [<span class="pl-c1">nout</span>(out)] <span class="pl-k">==</span> [<span class="pl-c1">6</span>]
<span class="pl-c1">@test</span> [<span class="pl-c1">nout</span>(start), <span class="pl-c1">nout</span>(joined)] <span class="pl-k">==</span> <span class="pl-c1">nin</span>(out) <span class="pl-k">==</span> [<span class="pl-c1">6</span>, <span class="pl-c1">6</span>]

graph <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>(invertex, out)
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>((<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>,<span class="pl-c1">6</span>))) <span class="pl-k">==</span> [<span class="pl-c1">78</span>  <span class="pl-c1">78</span>  <span class="pl-c1">114</span>  <span class="pl-c1">114</span>  <span class="pl-c1">186</span>  <span class="pl-c1">186</span>]

<span class="pl-c"><span class="pl-c">#</span> Ok, lets try to change the size of the vertex "out".</span>
<span class="pl-c"><span class="pl-c">#</span> First we need to realize that we can only change it by integer multiples of 3</span>
<span class="pl-c"><span class="pl-c">#</span> This is because it is connected to "split" through three paths which require nin==nout</span>
<span class="pl-c"><span class="pl-c">#</span> Therefore, any size change to nout of "split" will result in 3 times the change of nin of "out".</span>
<span class="pl-c"><span class="pl-c">#</span> Equivalently, nout of "split" is nin of "out" divided by 3 and nin/nout must be integers.</span>

<span class="pl-c"><span class="pl-c">#</span> We need this information from the layer. Some layers have other requirements</span>
NaiveNASlib<span class="pl-k">.</span><span class="pl-en">minΔnoutfactor</span>(<span class="pl-k">::</span><span class="pl-c1">SimpleLayer</span>) <span class="pl-k">=</span> <span class="pl-c1">1</span>
NaiveNASlib<span class="pl-k">.</span><span class="pl-en">minΔninfactor</span>(<span class="pl-k">::</span><span class="pl-c1">SimpleLayer</span>) <span class="pl-k">=</span> <span class="pl-c1">1</span>

<span class="pl-c1">@test</span> <span class="pl-c1">minΔnoutfactor</span>(out) <span class="pl-k">==</span> <span class="pl-c1">minΔninfactor</span>(out) <span class="pl-k">==</span> <span class="pl-c1">3</span>

<span class="pl-c"><span class="pl-c">#</span> Next, we need to define how to mutate our SimpleLayer</span>
NaiveNASlib<span class="pl-k">.</span><span class="pl-en">mutate_inputs</span>(l<span class="pl-k">::</span><span class="pl-c1">SimpleLayer</span>, newInSize) <span class="pl-k">=</span> l<span class="pl-k">.</span>W <span class="pl-k">=</span> <span class="pl-c1">ones</span>(Int, newInSize, <span class="pl-c1">size</span>(l<span class="pl-k">.</span>W,<span class="pl-c1">2</span>))
NaiveNASlib<span class="pl-k">.</span><span class="pl-en">mutate_outputs</span>(l<span class="pl-k">::</span><span class="pl-c1">SimpleLayer</span>, newOutSize) <span class="pl-k">=</span> l<span class="pl-k">.</span>W <span class="pl-k">=</span> <span class="pl-c1">ones</span>(Int, <span class="pl-c1">size</span>(l<span class="pl-k">.</span>W,<span class="pl-c1">1</span>), newOutSize)

<span class="pl-c"><span class="pl-c">#</span> In some cases it is useful to hold on to the old graph before mutating</span>
<span class="pl-c"><span class="pl-c">#</span> To do so, we need to define the clone operation for our SimpleLayer</span>
NaiveNASlib<span class="pl-k">.</span><span class="pl-en">clone</span>(l<span class="pl-k">::</span><span class="pl-c1">SimpleLayer</span>) <span class="pl-k">=</span> <span class="pl-c1">SimpleLayer</span>(l<span class="pl-k">.</span>W)
parentgraph <span class="pl-k">=</span> <span class="pl-c1">copy</span>(graph)

<span class="pl-c1">Δnout</span>(out, <span class="pl-c1">3</span>)

<span class="pl-c"><span class="pl-c">#</span> We didn't touch the input when mutating...</span>
<span class="pl-c1">@test</span> [<span class="pl-c1">nout</span>(invertex)] <span class="pl-k">==</span> <span class="pl-c1">nin</span>(start) <span class="pl-k">==</span> [<span class="pl-c1">6</span>]
<span class="pl-c"><span class="pl-c">#</span> Start and joined must have the same size due to elementwise op.</span>
<span class="pl-c"><span class="pl-c">#</span> All three scalarmult vertices are transparent and propagate the size change to split</span>
<span class="pl-c1">@test</span> [<span class="pl-c1">nout</span>(start)] <span class="pl-k">==</span> <span class="pl-c1">nin</span>(split) <span class="pl-k">==</span> [<span class="pl-c1">3</span> <span class="pl-k">*</span> <span class="pl-c1">nout</span>(split)] <span class="pl-k">==</span> [<span class="pl-c1">sum</span>(<span class="pl-c1">nin</span>(joined))] <span class="pl-k">==</span> [<span class="pl-c1">nout</span>(out)] <span class="pl-k">==</span> [<span class="pl-c1">9</span>]
<span class="pl-c1">@test</span> [<span class="pl-c1">nout</span>(start), <span class="pl-c1">nout</span>(joined)] <span class="pl-k">==</span> <span class="pl-c1">nin</span>(out) <span class="pl-k">==</span> [<span class="pl-c1">9</span>, <span class="pl-c1">9</span>]

<span class="pl-c"><span class="pl-c">#</span> However, this only updated the mutation metadata, not the actual layer.</span>
<span class="pl-c"><span class="pl-c">#</span> Some reasons for this are shown in the pruning example below</span>
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>((<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>,<span class="pl-c1">6</span>))) <span class="pl-k">==</span> [<span class="pl-c1">78</span>  <span class="pl-c1">78</span>  <span class="pl-c1">114</span>  <span class="pl-c1">114</span>  <span class="pl-c1">186</span>  <span class="pl-c1">186</span>]

<span class="pl-c"><span class="pl-c">#</span> To mutate the graph, we need to apply the mutation:</span>
<span class="pl-c1">apply_mutation</span>(graph);

<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>((<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>,<span class="pl-c1">6</span>))) <span class="pl-k">==</span> [<span class="pl-c1">114</span>  <span class="pl-c1">114</span>  <span class="pl-c1">114</span>  <span class="pl-c1">168</span>  <span class="pl-c1">168</span>  <span class="pl-c1">168</span>  <span class="pl-c1">276</span>  <span class="pl-c1">276</span>  <span class="pl-c1">276</span>]

<span class="pl-c"><span class="pl-c">#</span> Copy is still intact</span>
<span class="pl-c1">@test</span> <span class="pl-c1">parentgraph</span>((<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>,<span class="pl-c1">6</span>))) <span class="pl-k">==</span> [<span class="pl-c1">78</span>  <span class="pl-c1">78</span>  <span class="pl-c1">114</span>  <span class="pl-c1">114</span>  <span class="pl-c1">186</span>  <span class="pl-c1">186</span>]
</pre></div>
<p>As seen above, things get a little bit out of hand when using:</p>
<ul>
<li>Layers which require nin==nout, such as batch normalization and pooling</li>
<li>Element wise operations</li>
<li>Concatenation of activations</li>
</ul>
<p>The core idea of NaiveNASlib is basically to annotate the type of vertex in the graph so that functions know what is the proper way to deal with the neighboring vertices when mutating a vertex.</p>
<p>This is done through labeling vertices into three major types:</p>
<ul>
<li>
<p><code>SizeAbsorb</code>: Assumes <code>nout(v)</code> and <code>nin(v)</code> may change independently. This means that size changes are absorbed by this vertex in the sense they don't propagate further.</p>
</li>
<li>
<p><code>SizeStack</code>: Assumes <code>nout(v) == sum(nin(v))</code>. This means that size changes propagate forwards (i.e. input -&gt; output and output -&gt; input).</p>
</li>
<li>
<p><code>SizeInvariant</code>: Assumes <code>[nout(v)] == unique(nin(v))</code>. This means that size changes propagate both forwards and backwards as changing any input size or the output size means all others must change as well.</p>
</li>
</ul>
<p>To use this library to mutate architectures for some neural network library basically means annotating up the above type for each layer type.</p>
<p>Lets just do a few quick examples of the other use cases.</p>
<p>Prune (and insert) neurons:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="# Some mockup 'batteries' for this example

# First, how to select or add rows or columns to a matrix
# Negative values in selected indicate rows/cols insertion at that index
function select_params(W, selected, dim)
    Wsize = collect(size(W))
    indskeep = repeat(Any[Colon()], 2)
    newmap = repeat(Any[Colon()], 2)

    # The selected indices
    indskeep[dim] = filter(ind -&gt; ind &gt; 0, selected)
    # Where they are 'placed', others will be zero
    newmap[dim] = selected .&gt; 0
    Wsize[dim] = length(newmap[dim])

    newmat = zeros(Int64, Wsize...)
    newmat[newmap...] = W[indskeep...]
    return newmat
end

NaiveNASlib.mutate_inputs(l::SimpleLayer, selected::Vector{&lt;:Integer}) = l.W = select_params(l.W, selected, 1)
NaiveNASlib.mutate_outputs(l::SimpleLayer, selected::Vector{&lt;:Integer}) = l.W = select_params(l.W, selected, 2)

# Return layer just so we can easiliy look at it
function prunablelayer(in, outsize)
    l = SimpleLayer(reshape(1: nout(in) * outsize, nout(in), :))
    return absorbvertex(l, outsize, in), l
end

# Ok, now lets get down to business!
invertices = inputvertex.([&quot;in1&quot;, &quot;in2&quot;], [3,4])
v1, l1 = prunablelayer(invertices[1], 4)
v2, l2 = prunablelayer(invertices[2], 3)
merged = conc(v1, v2, dims=2)
v3, l3 = prunablelayer(merged, 2)
graph = CompGraph(invertices, v3)

# These weights are of course complete nonsense from a neural network perspective.
# They are just to make it easier to spot what has changed after pruning below.
@test l1.W ==
[ 1  4  7  10 ;
  2  5  8  11 ;
  3  6  9  12 ]

@test l2.W ==
[ 1  5   9 ;
  2  6  10 ;
  3  7  11 ;
  4  8  12 ]

@test l3.W ==
[ 1   8 ;
  2   9 ;
  3  10 ;
  4  11 ;
  5  12 ;
  6  13 ;
  7  14 ]

# A limitation in current implementation is that one must change the size before pruning
# See https://github.com/DrChainsaw/NaiveNASlib.jl/issues/40
Δnin(v3, -3)

# What did that do?
@test nout(v1) == 2
@test nout(v2) == 2

# Doing this however makes it possible to do several mutations without throwing away
# more information than needed.
# For example, if we had first applied the previous mutation we would have thrown away
# weights for v2 which would then just be replaced by 0s when doing this:
Δnout(v2, 2)

# What did that do?
@test nout(v1) == 2
@test nout(v2) == 4
@test nin(v3) == [6]
# Net result is that v1 shall decrease output size by 1 and v2 shall increase its output size by 1

# Now, we need a utility/value metric per neuron in order to determine which neurons to keep
# Give high utility to neurons 1 and 3 of v1, same for all others...
utility(v) = v == v1 ? [10, 1, 10, 1] : ones(nout_org(v))
# Then select the neurons.
Δoutputs(graph, utility)
# And apply it to the actual weights
apply_mutation(graph)

@test l1.W ==
[ 1  7 ;
  2  8 ;
  3  9 ]

# Note how column 3 was not replaced by zeros: We increased the target size before pruning
@test l2.W ==
[ 1  5   9  0;
  2  6  10  0;
  3  7  11  0;
  4  8  12  0]

@test l3.W ==
[ 1   8 ;
  3  10 ;
  5  12 ;
  6  13 ;
  7  14 ;
  0   0]
"><pre><span class="pl-c"><span class="pl-c">#</span> Some mockup 'batteries' for this example</span>

<span class="pl-c"><span class="pl-c">#</span> First, how to select or add rows or columns to a matrix</span>
<span class="pl-c"><span class="pl-c">#</span> Negative values in selected indicate rows/cols insertion at that index</span>
<span class="pl-k">function</span> <span class="pl-en">select_params</span>(W, selected, dim)
    Wsize <span class="pl-k">=</span> <span class="pl-c1">collect</span>(<span class="pl-c1">size</span>(W))
    indskeep <span class="pl-k">=</span> <span class="pl-c1">repeat</span>(Any[<span class="pl-c1">Colon</span>()], <span class="pl-c1">2</span>)
    newmap <span class="pl-k">=</span> <span class="pl-c1">repeat</span>(Any[<span class="pl-c1">Colon</span>()], <span class="pl-c1">2</span>)

    <span class="pl-c"><span class="pl-c">#</span> The selected indices</span>
    indskeep[dim] <span class="pl-k">=</span> <span class="pl-c1">filter</span>(ind <span class="pl-k">-&gt;</span> ind <span class="pl-k">&gt;</span> <span class="pl-c1">0</span>, selected)
    <span class="pl-c"><span class="pl-c">#</span> Where they are 'placed', others will be zero</span>
    newmap[dim] <span class="pl-k">=</span> selected <span class="pl-k">.&gt;</span> <span class="pl-c1">0</span>
    Wsize[dim] <span class="pl-k">=</span> <span class="pl-c1">length</span>(newmap[dim])

    newmat <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(Int64, Wsize<span class="pl-k">...</span>)
    newmat[newmap<span class="pl-k">...</span>] <span class="pl-k">=</span> W[indskeep<span class="pl-k">...</span>]
    <span class="pl-k">return</span> newmat
<span class="pl-k">end</span>

NaiveNASlib<span class="pl-k">.</span><span class="pl-en">mutate_inputs</span>(l<span class="pl-k">::</span><span class="pl-c1">SimpleLayer</span>, selected<span class="pl-k">::</span><span class="pl-c1">Vector{&lt;:Integer}</span>) <span class="pl-k">=</span> l<span class="pl-k">.</span>W <span class="pl-k">=</span> <span class="pl-c1">select_params</span>(l<span class="pl-k">.</span>W, selected, <span class="pl-c1">1</span>)
NaiveNASlib<span class="pl-k">.</span><span class="pl-en">mutate_outputs</span>(l<span class="pl-k">::</span><span class="pl-c1">SimpleLayer</span>, selected<span class="pl-k">::</span><span class="pl-c1">Vector{&lt;:Integer}</span>) <span class="pl-k">=</span> l<span class="pl-k">.</span>W <span class="pl-k">=</span> <span class="pl-c1">select_params</span>(l<span class="pl-k">.</span>W, selected, <span class="pl-c1">2</span>)

<span class="pl-c"><span class="pl-c">#</span> Return layer just so we can easiliy look at it</span>
<span class="pl-k">function</span> <span class="pl-en">prunablelayer</span>(in, outsize)
    l <span class="pl-k">=</span> <span class="pl-c1">SimpleLayer</span>(<span class="pl-c1">reshape</span>(<span class="pl-c1">1</span><span class="pl-k">:</span> <span class="pl-c1">nout</span>(in) <span class="pl-k">*</span> outsize, <span class="pl-c1">nout</span>(in), :))
    <span class="pl-k">return</span> <span class="pl-c1">absorbvertex</span>(l, outsize, in), l
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> Ok, now lets get down to business!</span>
invertices <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>.([<span class="pl-s"><span class="pl-pds">"</span>in1<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>in2<span class="pl-pds">"</span></span>], [<span class="pl-c1">3</span>,<span class="pl-c1">4</span>])
v1, l1 <span class="pl-k">=</span> <span class="pl-c1">prunablelayer</span>(invertices[<span class="pl-c1">1</span>], <span class="pl-c1">4</span>)
v2, l2 <span class="pl-k">=</span> <span class="pl-c1">prunablelayer</span>(invertices[<span class="pl-c1">2</span>], <span class="pl-c1">3</span>)
merged <span class="pl-k">=</span> <span class="pl-c1">conc</span>(v1, v2, dims<span class="pl-k">=</span><span class="pl-c1">2</span>)
v3, l3 <span class="pl-k">=</span> <span class="pl-c1">prunablelayer</span>(merged, <span class="pl-c1">2</span>)
graph <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>(invertices, v3)

<span class="pl-c"><span class="pl-c">#</span> These weights are of course complete nonsense from a neural network perspective.</span>
<span class="pl-c"><span class="pl-c">#</span> They are just to make it easier to spot what has changed after pruning below.</span>
<span class="pl-c1">@test</span> l1<span class="pl-k">.</span>W <span class="pl-k">==</span>
[ <span class="pl-c1">1</span>  <span class="pl-c1">4</span>  <span class="pl-c1">7</span>  <span class="pl-c1">10</span> ;
  <span class="pl-c1">2</span>  <span class="pl-c1">5</span>  <span class="pl-c1">8</span>  <span class="pl-c1">11</span> ;
  <span class="pl-c1">3</span>  <span class="pl-c1">6</span>  <span class="pl-c1">9</span>  <span class="pl-c1">12</span> ]

<span class="pl-c1">@test</span> l2<span class="pl-k">.</span>W <span class="pl-k">==</span>
[ <span class="pl-c1">1</span>  <span class="pl-c1">5</span>   <span class="pl-c1">9</span> ;
  <span class="pl-c1">2</span>  <span class="pl-c1">6</span>  <span class="pl-c1">10</span> ;
  <span class="pl-c1">3</span>  <span class="pl-c1">7</span>  <span class="pl-c1">11</span> ;
  <span class="pl-c1">4</span>  <span class="pl-c1">8</span>  <span class="pl-c1">12</span> ]

<span class="pl-c1">@test</span> l3<span class="pl-k">.</span>W <span class="pl-k">==</span>
[ <span class="pl-c1">1</span>   <span class="pl-c1">8</span> ;
  <span class="pl-c1">2</span>   <span class="pl-c1">9</span> ;
  <span class="pl-c1">3</span>  <span class="pl-c1">10</span> ;
  <span class="pl-c1">4</span>  <span class="pl-c1">11</span> ;
  <span class="pl-c1">5</span>  <span class="pl-c1">12</span> ;
  <span class="pl-c1">6</span>  <span class="pl-c1">13</span> ;
  <span class="pl-c1">7</span>  <span class="pl-c1">14</span> ]

<span class="pl-c"><span class="pl-c">#</span> A limitation in current implementation is that one must change the size before pruning</span>
<span class="pl-c"><span class="pl-c">#</span> See https://github.com/DrChainsaw/NaiveNASlib.jl/issues/40</span>
<span class="pl-c1">Δnin</span>(v3, <span class="pl-k">-</span><span class="pl-c1">3</span>)

<span class="pl-c"><span class="pl-c">#</span> What did that do?</span>
<span class="pl-c1">@test</span> <span class="pl-c1">nout</span>(v1) <span class="pl-k">==</span> <span class="pl-c1">2</span>
<span class="pl-c1">@test</span> <span class="pl-c1">nout</span>(v2) <span class="pl-k">==</span> <span class="pl-c1">2</span>

<span class="pl-c"><span class="pl-c">#</span> Doing this however makes it possible to do several mutations without throwing away</span>
<span class="pl-c"><span class="pl-c">#</span> more information than needed.</span>
<span class="pl-c"><span class="pl-c">#</span> For example, if we had first applied the previous mutation we would have thrown away</span>
<span class="pl-c"><span class="pl-c">#</span> weights for v2 which would then just be replaced by 0s when doing this:</span>
<span class="pl-c1">Δnout</span>(v2, <span class="pl-c1">2</span>)

<span class="pl-c"><span class="pl-c">#</span> What did that do?</span>
<span class="pl-c1">@test</span> <span class="pl-c1">nout</span>(v1) <span class="pl-k">==</span> <span class="pl-c1">2</span>
<span class="pl-c1">@test</span> <span class="pl-c1">nout</span>(v2) <span class="pl-k">==</span> <span class="pl-c1">4</span>
<span class="pl-c1">@test</span> <span class="pl-c1">nin</span>(v3) <span class="pl-k">==</span> [<span class="pl-c1">6</span>]
<span class="pl-c"><span class="pl-c">#</span> Net result is that v1 shall decrease output size by 1 and v2 shall increase its output size by 1</span>

<span class="pl-c"><span class="pl-c">#</span> Now, we need a utility/value metric per neuron in order to determine which neurons to keep</span>
<span class="pl-c"><span class="pl-c">#</span> Give high utility to neurons 1 and 3 of v1, same for all others...</span>
<span class="pl-en">utility</span>(v) <span class="pl-k">=</span> v <span class="pl-k">==</span> v1 <span class="pl-k">?</span> [<span class="pl-c1">10</span>, <span class="pl-c1">1</span>, <span class="pl-c1">10</span>, <span class="pl-c1">1</span>] <span class="pl-k">:</span> <span class="pl-c1">ones</span>(<span class="pl-c1">nout_org</span>(v))
<span class="pl-c"><span class="pl-c">#</span> Then select the neurons.</span>
<span class="pl-c1">Δoutputs</span>(graph, utility)
<span class="pl-c"><span class="pl-c">#</span> And apply it to the actual weights</span>
<span class="pl-c1">apply_mutation</span>(graph)

<span class="pl-c1">@test</span> l1<span class="pl-k">.</span>W <span class="pl-k">==</span>
[ <span class="pl-c1">1</span>  <span class="pl-c1">7</span> ;
  <span class="pl-c1">2</span>  <span class="pl-c1">8</span> ;
  <span class="pl-c1">3</span>  <span class="pl-c1">9</span> ]

<span class="pl-c"><span class="pl-c">#</span> Note how column 3 was not replaced by zeros: We increased the target size before pruning</span>
<span class="pl-c1">@test</span> l2<span class="pl-k">.</span>W <span class="pl-k">==</span>
[ <span class="pl-c1">1</span>  <span class="pl-c1">5</span>   <span class="pl-c1">9</span>  <span class="pl-c1">0</span>;
  <span class="pl-c1">2</span>  <span class="pl-c1">6</span>  <span class="pl-c1">10</span>  <span class="pl-c1">0</span>;
  <span class="pl-c1">3</span>  <span class="pl-c1">7</span>  <span class="pl-c1">11</span>  <span class="pl-c1">0</span>;
  <span class="pl-c1">4</span>  <span class="pl-c1">8</span>  <span class="pl-c1">12</span>  <span class="pl-c1">0</span>]

<span class="pl-c1">@test</span> l3<span class="pl-k">.</span>W <span class="pl-k">==</span>
[ <span class="pl-c1">1</span>   <span class="pl-c1">8</span> ;
  <span class="pl-c1">3</span>  <span class="pl-c1">10</span> ;
  <span class="pl-c1">5</span>  <span class="pl-c1">12</span> ;
  <span class="pl-c1">6</span>  <span class="pl-c1">13</span> ;
  <span class="pl-c1">7</span>  <span class="pl-c1">14</span> ;
  <span class="pl-c1">0</span>   <span class="pl-c1">0</span>]</pre></div>
<p>Add a vertex to a graph:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="invertex = inputvertex(&quot;input&quot;, 3)
layer1 = layer(invertex, 5)
graph = CompGraph(invertex, layer1)

@test nv(graph) == 2
@test graph(ones(Int, 1, 3)) == [3 3 3 3 3]

# Insert a layer between invertex and layer1
insert!(invertex, vertex -&gt; layer(vertex, nout(vertex)))

@test nv(graph) == 3
@test graph(ones(Int, 1, 3)) == [9 9 9 9 9]
"><pre>invertex <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>input<span class="pl-pds">"</span></span>, <span class="pl-c1">3</span>)
layer1 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertex, <span class="pl-c1">5</span>)
graph <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>(invertex, layer1)

<span class="pl-c1">@test</span> <span class="pl-c1">nv</span>(graph) <span class="pl-k">==</span> <span class="pl-c1">2</span>
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>(<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>, <span class="pl-c1">3</span>)) <span class="pl-k">==</span> [<span class="pl-c1">3</span> <span class="pl-c1">3</span> <span class="pl-c1">3</span> <span class="pl-c1">3</span> <span class="pl-c1">3</span>]

<span class="pl-c"><span class="pl-c">#</span> Insert a layer between invertex and layer1</span>
<span class="pl-c1">insert!</span>(invertex, vertex <span class="pl-k">-&gt;</span> <span class="pl-c1">layer</span>(vertex, <span class="pl-c1">nout</span>(vertex)))

<span class="pl-c1">@test</span> <span class="pl-c1">nv</span>(graph) <span class="pl-k">==</span> <span class="pl-c1">3</span>
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>(<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>, <span class="pl-c1">3</span>)) <span class="pl-k">==</span> [<span class="pl-c1">9</span> <span class="pl-c1">9</span> <span class="pl-c1">9</span> <span class="pl-c1">9</span> <span class="pl-c1">9</span>]</pre></div>
<p>Remove a vertex from a graph:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="invertex = inputvertex(&quot;input&quot;, 3)
layer1 = layer(invertex, 5)
layer2 = layer(layer1, 4)
graph = CompGraph(invertex, layer2)

@test nv(graph) == 3
@test graph(ones(Int, 1, 3)) == [15 15 15 15]

# Remove layer1 and change nin of layer2 from 5 to 3
# Would perhaps have been better to increase nout of invertex, but it is immutable
remove!(layer1)
apply_mutation(graph)

@test nv(graph) == 2
@test graph(ones(Int, 1, 3)) == [3 3 3 3]
"><pre>invertex <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>input<span class="pl-pds">"</span></span>, <span class="pl-c1">3</span>)
layer1 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertex, <span class="pl-c1">5</span>)
layer2 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(layer1, <span class="pl-c1">4</span>)
graph <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>(invertex, layer2)

<span class="pl-c1">@test</span> <span class="pl-c1">nv</span>(graph) <span class="pl-k">==</span> <span class="pl-c1">3</span>
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>(<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>, <span class="pl-c1">3</span>)) <span class="pl-k">==</span> [<span class="pl-c1">15</span> <span class="pl-c1">15</span> <span class="pl-c1">15</span> <span class="pl-c1">15</span>]

<span class="pl-c"><span class="pl-c">#</span> Remove layer1 and change nin of layer2 from 5 to 3</span>
<span class="pl-c"><span class="pl-c">#</span> Would perhaps have been better to increase nout of invertex, but it is immutable</span>
<span class="pl-c1">remove!</span>(layer1)
<span class="pl-c1">apply_mutation</span>(graph)

<span class="pl-c1">@test</span> <span class="pl-c1">nv</span>(graph) <span class="pl-k">==</span> <span class="pl-c1">2</span>
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>(<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>, <span class="pl-c1">3</span>)) <span class="pl-k">==</span> [<span class="pl-c1">3</span> <span class="pl-c1">3</span> <span class="pl-c1">3</span> <span class="pl-c1">3</span>]</pre></div>
<p>Add an edge to a vertex:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="invertices = inputvertex.([&quot;input1&quot;, &quot;input2&quot;], [3, 2])
layer1 = layer(invertices[1], 4)
layer2 = layer(invertices[2], 4)
add = layer1 + layer2
out = layer(add, 5)
graph = CompGraph(invertices, out)

@test nin(add) == [4, 4]
# Two inputs this time, remember?
@test graph(ones(Int, 1, 3), ones(Int, 1, 2)) == [20 20 20 20 20]

# This graph is not interesting enough for there to be a good showcase for adding a new edge.
# Lets create a new layer which has a different output size just to see how things change
# The only vertex which support more than one input is add
layer3 = layer(invertices[2], 6)
create_edge!(layer3, add)
apply_mutation(graph)

# By default, NaiveNASlib will try to increase the size in case of a mismatch
@test nin(add) == [6, 6, 6]
@test graph(ones(Int, 1, 3), ones(Int, 1, 2)) == [42 42 42 42 42]
"><pre>invertices <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>.([<span class="pl-s"><span class="pl-pds">"</span>input1<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>input2<span class="pl-pds">"</span></span>], [<span class="pl-c1">3</span>, <span class="pl-c1">2</span>])
layer1 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertices[<span class="pl-c1">1</span>], <span class="pl-c1">4</span>)
layer2 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertices[<span class="pl-c1">2</span>], <span class="pl-c1">4</span>)
add <span class="pl-k">=</span> layer1 <span class="pl-k">+</span> layer2
out <span class="pl-k">=</span> <span class="pl-c1">layer</span>(add, <span class="pl-c1">5</span>)
graph <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>(invertices, out)

<span class="pl-c1">@test</span> <span class="pl-c1">nin</span>(add) <span class="pl-k">==</span> [<span class="pl-c1">4</span>, <span class="pl-c1">4</span>]
<span class="pl-c"><span class="pl-c">#</span> Two inputs this time, remember?</span>
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>(<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>, <span class="pl-c1">3</span>), <span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>)) <span class="pl-k">==</span> [<span class="pl-c1">20</span> <span class="pl-c1">20</span> <span class="pl-c1">20</span> <span class="pl-c1">20</span> <span class="pl-c1">20</span>]

<span class="pl-c"><span class="pl-c">#</span> This graph is not interesting enough for there to be a good showcase for adding a new edge.</span>
<span class="pl-c"><span class="pl-c">#</span> Lets create a new layer which has a different output size just to see how things change</span>
<span class="pl-c"><span class="pl-c">#</span> The only vertex which support more than one input is add</span>
layer3 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertices[<span class="pl-c1">2</span>], <span class="pl-c1">6</span>)
<span class="pl-c1">create_edge!</span>(layer3, add)
<span class="pl-c1">apply_mutation</span>(graph)

<span class="pl-c"><span class="pl-c">#</span> By default, NaiveNASlib will try to increase the size in case of a mismatch</span>
<span class="pl-c1">@test</span> <span class="pl-c1">nin</span>(add) <span class="pl-k">==</span> [<span class="pl-c1">6</span>, <span class="pl-c1">6</span>, <span class="pl-c1">6</span>]
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>(<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>, <span class="pl-c1">3</span>), <span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>)) <span class="pl-k">==</span> [<span class="pl-c1">42</span> <span class="pl-c1">42</span> <span class="pl-c1">42</span> <span class="pl-c1">42</span> <span class="pl-c1">42</span>]</pre></div>
<p>Remove an edge from a vertex:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="invertex = inputvertex(&quot;input&quot;, 4)
layer1 = layer(invertex, 3)
layer2 = layer(invertex, 5)
merged = conc(layer1, layer2, layer1, dims=2)
out = layer(merged, 3)
graph = CompGraph(invertex, out)

@test nin(merged) == [3, 5, 3]
@test graph(ones(Int, 1, 4)) == [44 44 44]

remove_edge!(layer1, merged)
apply_mutation(graph)

@test nin(merged) == [5, 3]
@test graph(ones(Int, 1, 4)) == [32 32 32]
"><pre>invertex <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>input<span class="pl-pds">"</span></span>, <span class="pl-c1">4</span>)
layer1 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertex, <span class="pl-c1">3</span>)
layer2 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertex, <span class="pl-c1">5</span>)
merged <span class="pl-k">=</span> <span class="pl-c1">conc</span>(layer1, layer2, layer1, dims<span class="pl-k">=</span><span class="pl-c1">2</span>)
out <span class="pl-k">=</span> <span class="pl-c1">layer</span>(merged, <span class="pl-c1">3</span>)
graph <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>(invertex, out)

<span class="pl-c1">@test</span> <span class="pl-c1">nin</span>(merged) <span class="pl-k">==</span> [<span class="pl-c1">3</span>, <span class="pl-c1">5</span>, <span class="pl-c1">3</span>]
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>(<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>, <span class="pl-c1">4</span>)) <span class="pl-k">==</span> [<span class="pl-c1">44</span> <span class="pl-c1">44</span> <span class="pl-c1">44</span>]

<span class="pl-c1">remove_edge!</span>(layer1, merged)
<span class="pl-c1">apply_mutation</span>(graph)

<span class="pl-c1">@test</span> <span class="pl-c1">nin</span>(merged) <span class="pl-k">==</span> [<span class="pl-c1">5</span>, <span class="pl-c1">3</span>]
<span class="pl-c1">@test</span> <span class="pl-c1">graph</span>(<span class="pl-c1">ones</span>(Int, <span class="pl-c1">1</span>, <span class="pl-c1">4</span>)) <span class="pl-k">==</span> [<span class="pl-c1">32</span> <span class="pl-c1">32</span> <span class="pl-c1">32</span>]</pre></div>
<h2><a id="user-content-advanced-usage" class="anchor" aria-hidden="true" href="#advanced-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Advanced usage</h2>
<p>The previous examples have been focused on giving an overview of the purpose of this library. For more advanced usage, there are many of ways to customize the behavior and in other ways alter or hook in to the functionality. Here are a few of the most important.</p>
<h3><a id="user-content-strategies" class="anchor" aria-hidden="true" href="#strategies"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Strategies</h3>
<p>For more or less all operations which mutate the graph, it is possible achieve fine grained control of the operation through selecting a strategy.</p>
<p>Here is an example of strategies for changing the size:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="# A simple graph where one vertex has a constraint for changing the size.
invertex = inputvertex(&quot;in&quot;, 3)
layer1 = layer(invertex, 4)
joined = conc(scalarmult(layer1, 2), scalarmult(layer1, 3), dims=2)

# joined can only change in steps of 2
@test minΔnoutfactor(joined) == 2

# all_in_graph finds all vertices in the same graph as the given vertex
verts = all_in_graph(joined)

# Strategy to try to change it by one and throw an error when not successful
exactOrFail = ΔNout{Exact}(joined, 1, ΔSizeFailError(&quot;Size change failed!!&quot;))

# Note that we now call Δsize instead of Δnout as the direction is given by the strategy
@test_throws ErrorException Δsize(exactOrFail, verts)

# No change was made
@test nout(joined) == 2*nout(layer1) == 8

# Try to change by one and fail silently when not successful
exactOrNoop = ΔNout{Exact}(joined, 1, ΔSizeFailNoOp())

Δsize(exactOrNoop, verts)

# No change was made
@test nout(joined) == 2*nout(layer1) == 8

# In many cases it is ok to not get the exact change which was requested
relaxedOrFail = ΔNout{Relaxed}(joined, 1, ΔSizeFailError(&quot;This should not happen!!&quot;))

Δsize(relaxedOrFail, verts)

# Changed by two as this was the smallest possible change
@test nout(joined) == 2*nout(layer1) == 10

# Logging when fallback is applied is also possible
using Logging
# Yeah, this is not easy on the eyes, but it gets the job done...
exactOrLogThenRelax = ΔNout{Exact}(joined, 1, LogΔSizeExec(Logging.Info, &quot;Exact failed, relaxing&quot;, ΔNout{Relaxed}(joined, 1, ΔSizeFailError(&quot;This should not happen!!&quot;))))

@test_logs (:info, &quot;Exact failed, relaxing&quot;) Δsize(exactOrLogThenRelax, verts)

@test nout(joined) == 2*nout(layer1) == 12
"><pre><span class="pl-c"><span class="pl-c">#</span> A simple graph where one vertex has a constraint for changing the size.</span>
invertex <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in<span class="pl-pds">"</span></span>, <span class="pl-c1">3</span>)
layer1 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertex, <span class="pl-c1">4</span>)
joined <span class="pl-k">=</span> <span class="pl-c1">conc</span>(<span class="pl-c1">scalarmult</span>(layer1, <span class="pl-c1">2</span>), <span class="pl-c1">scalarmult</span>(layer1, <span class="pl-c1">3</span>), dims<span class="pl-k">=</span><span class="pl-c1">2</span>)

<span class="pl-c"><span class="pl-c">#</span> joined can only change in steps of 2</span>
<span class="pl-c1">@test</span> <span class="pl-c1">minΔnoutfactor</span>(joined) <span class="pl-k">==</span> <span class="pl-c1">2</span>

<span class="pl-c"><span class="pl-c">#</span> all_in_graph finds all vertices in the same graph as the given vertex</span>
verts <span class="pl-k">=</span> <span class="pl-c1">all_in_graph</span>(joined)

<span class="pl-c"><span class="pl-c">#</span> Strategy to try to change it by one and throw an error when not successful</span>
exactOrFail <span class="pl-k">=</span> <span class="pl-c1">ΔNout</span><span class="pl-c1">{Exact}</span>(joined, <span class="pl-c1">1</span>, <span class="pl-c1">ΔSizeFailError</span>(<span class="pl-s"><span class="pl-pds">"</span>Size change failed!!<span class="pl-pds">"</span></span>))

<span class="pl-c"><span class="pl-c">#</span> Note that we now call Δsize instead of Δnout as the direction is given by the strategy</span>
<span class="pl-c1">@test_throws</span> ErrorException <span class="pl-c1">Δsize</span>(exactOrFail, verts)

<span class="pl-c"><span class="pl-c">#</span> No change was made</span>
<span class="pl-c1">@test</span> <span class="pl-c1">nout</span>(joined) <span class="pl-k">==</span> <span class="pl-c1">2</span><span class="pl-k">*</span><span class="pl-c1">nout</span>(layer1) <span class="pl-k">==</span> <span class="pl-c1">8</span>

<span class="pl-c"><span class="pl-c">#</span> Try to change by one and fail silently when not successful</span>
exactOrNoop <span class="pl-k">=</span> <span class="pl-c1">ΔNout</span><span class="pl-c1">{Exact}</span>(joined, <span class="pl-c1">1</span>, <span class="pl-c1">ΔSizeFailNoOp</span>())

<span class="pl-c1">Δsize</span>(exactOrNoop, verts)

<span class="pl-c"><span class="pl-c">#</span> No change was made</span>
<span class="pl-c1">@test</span> <span class="pl-c1">nout</span>(joined) <span class="pl-k">==</span> <span class="pl-c1">2</span><span class="pl-k">*</span><span class="pl-c1">nout</span>(layer1) <span class="pl-k">==</span> <span class="pl-c1">8</span>

<span class="pl-c"><span class="pl-c">#</span> In many cases it is ok to not get the exact change which was requested</span>
relaxedOrFail <span class="pl-k">=</span> <span class="pl-c1">ΔNout</span><span class="pl-c1">{Relaxed}</span>(joined, <span class="pl-c1">1</span>, <span class="pl-c1">ΔSizeFailError</span>(<span class="pl-s"><span class="pl-pds">"</span>This should not happen!!<span class="pl-pds">"</span></span>))

<span class="pl-c1">Δsize</span>(relaxedOrFail, verts)

<span class="pl-c"><span class="pl-c">#</span> Changed by two as this was the smallest possible change</span>
<span class="pl-c1">@test</span> <span class="pl-c1">nout</span>(joined) <span class="pl-k">==</span> <span class="pl-c1">2</span><span class="pl-k">*</span><span class="pl-c1">nout</span>(layer1) <span class="pl-k">==</span> <span class="pl-c1">10</span>

<span class="pl-c"><span class="pl-c">#</span> Logging when fallback is applied is also possible</span>
<span class="pl-k">using</span> Logging
<span class="pl-c"><span class="pl-c">#</span> Yeah, this is not easy on the eyes, but it gets the job done...</span>
exactOrLogThenRelax <span class="pl-k">=</span> <span class="pl-c1">ΔNout</span><span class="pl-c1">{Exact}</span>(joined, <span class="pl-c1">1</span>, <span class="pl-c1">LogΔSizeExec</span>(Logging<span class="pl-k">.</span>Info, <span class="pl-s"><span class="pl-pds">"</span>Exact failed, relaxing<span class="pl-pds">"</span></span>, <span class="pl-c1">ΔNout</span><span class="pl-c1">{Relaxed}</span>(joined, <span class="pl-c1">1</span>, <span class="pl-c1">ΔSizeFailError</span>(<span class="pl-s"><span class="pl-pds">"</span>This should not happen!!<span class="pl-pds">"</span></span>))))

<span class="pl-c1">@test_logs</span> (<span class="pl-c1">:info</span>, <span class="pl-s"><span class="pl-pds">"</span>Exact failed, relaxing<span class="pl-pds">"</span></span>) <span class="pl-c1">Δsize</span>(exactOrLogThenRelax, verts)

<span class="pl-c1">@test</span> <span class="pl-c1">nout</span>(joined) <span class="pl-k">==</span> <span class="pl-c1">2</span><span class="pl-k">*</span><span class="pl-c1">nout</span>(layer1) <span class="pl-k">==</span> <span class="pl-c1">12</span></pre></div>
<p>A similar pattern is used for most other mutating operations. Use the built-in documentation to explore the options until I find the energy and time to write proper documentation. As I could not let go of the OO habit of having abstract base types for everything, the existing strategies can be discovered using <code>subtypes</code> as a stop-gap solution.</p>
<h3><a id="user-content-traits" class="anchor" aria-hidden="true" href="#traits"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Traits</h3>
<p>A variant (bastardization?) of the <a href="https://docs.julialang.org/en/v1/manual/methods/#Trait-based-dispatch-1" rel="nofollow">holy trait</a> pattern is used to annotate the type of a vertex. In the examples above the three 'core' types <code>SizeAbsorb</code>, <code>SizeStack</code> and <code>SizeInvariant</code> are shown, but it is also possible to attach other information and behaviors by freeriding on this mechanism.</p>
<p>This is done by adding the argument <code>traitdecoration</code> when creating a vertex and supplying a function which takes a trait and return a new trait (which typically wraps the input).</p>
<p>Some examples:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="noname = layer(inputvertex(&quot;in&quot;, 2), 2)
@test name(noname) == &quot;MutationVertex::SizeAbsorb&quot;

# Naming vertices is so useful for logging and debugging I almost made it mandatory
named = absorbvertex(SimpleLayer(2, 3), 3, inputvertex(&quot;in&quot;, 2), traitdecoration = t -&gt; NamedTrait(t, &quot;named layer&quot;))
@test name(named) == &quot;named layer&quot;

# Speaking of logging...
layer1 = absorbvertex(SimpleLayer(2, 3), 3, inputvertex(&quot;in&quot;, 2), traitdecoration = t -&gt; SizeChangeLogger(NamedTrait(t, &quot;layer1&quot;)))

# What info is shown can be controlled by supplying an extra argument to SizeChangeLogger
nameonly = NameInfoStr()
layer2 = absorbvertex(SimpleLayer(nout(layer1), 4), 4, layer1, traitdecoration = t -&gt; SizeChangeLogger(nameonly, NamedTrait(t, &quot;layer2&quot;)))

@test_logs(
(:info, &quot;Change nout of layer1, inputs=[in], outputs=[layer2], nin=[2], nout=[3], SizeAbsorb() by 1&quot;),
(:info, &quot;Change nin of layer2 by 1&quot;), # Note: less verbose compared to layer1 due to NameInfoStr
 Δnout(layer1, 1))

 # traitdecoration works exactly the same for conc and invariantvertex as well, no need for an example

 # Use the &gt;&gt; operator when creating SizeInvariant vertices using arithmetic operators:
 add = &quot;addvertex&quot; &gt;&gt; inputvertex(&quot;in1&quot;, 1) + inputvertex(&quot;in2&quot;, 1)
 @test name(add) == &quot;addvertex&quot;

 # For more elaborate traits one can use traitconf
 add2 = traitconf(t -&gt; SizeChangeLogger(NamedTrait(t, &quot;layer1 + layer2&quot;))) &gt;&gt; layer1 + layer2
 @test name(add2) == &quot;layer1 + layer2&quot;

 @test_logs(
 (:info, &quot;Change nout of layer1, inputs=[in], outputs=[layer2, layer1 + layer2], nin=[2], nout=[4], SizeAbsorb() by 1&quot;),
 (:info, &quot;Change nin of layer2 by 1&quot;),
 (:info, &quot;Change nout of layer2 by 1&quot;),
 (:info, &quot;Change nin of layer1 + layer2, inputs=[layer1, layer2], outputs=[], nin=[4, 4], nout=[4], SizeInvariant() by 1, 1&quot;),
 (:info, &quot;Change nout of layer1 + layer2, inputs=[layer1, layer2], outputs=[], nin=[5, 5], nout=[4], SizeInvariant() by 1&quot;),
  Δnout(layer1, 1))

  # When creating own trait wrappers, remember to subtype DecoratingTrait or else there will be pain!

  # Wrong!! Not a subtype of DecoratingTrait
  struct PainfulTrait{T&lt;:MutationTrait} &lt;: MutationTrait
      base::T
  end
  painlayer = absorbvertex(SimpleLayer(2, 3), 3, inputvertex(&quot;in&quot;, 2), traitdecoration = PainfulTrait)

  # Now one must implement a lot of methods for PainfulTrait...
  @test_throws MethodError Δnout(painlayer, 1)

  # Right! Is a subtype of DecoratingTrait
  struct SmoothSailingTrait{T&lt;:MutationTrait} &lt;: DecoratingTrait
      base::T
  end
  # Just implement base and all will be fine
  NaiveNASlib.base(t::SmoothSailingTrait) = t.base

  smoothlayer = absorbvertex(SimpleLayer(2, 3), 3, inputvertex(&quot;in&quot;, 2), traitdecoration = SmoothSailingTrait)

  Δnout(smoothlayer, 1)
  @test nout(smoothlayer) == 4

"><pre>noname <span class="pl-k">=</span> <span class="pl-c1">layer</span>(<span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in<span class="pl-pds">"</span></span>, <span class="pl-c1">2</span>), <span class="pl-c1">2</span>)
<span class="pl-c1">@test</span> <span class="pl-c1">name</span>(noname) <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>MutationVertex::SizeAbsorb<span class="pl-pds">"</span></span>

<span class="pl-c"><span class="pl-c">#</span> Naming vertices is so useful for logging and debugging I almost made it mandatory</span>
named <span class="pl-k">=</span> <span class="pl-c1">absorbvertex</span>(<span class="pl-c1">SimpleLayer</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>), <span class="pl-c1">3</span>, <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in<span class="pl-pds">"</span></span>, <span class="pl-c1">2</span>), traitdecoration <span class="pl-k">=</span> t <span class="pl-k">-&gt;</span> <span class="pl-c1">NamedTrait</span>(t, <span class="pl-s"><span class="pl-pds">"</span>named layer<span class="pl-pds">"</span></span>))
<span class="pl-c1">@test</span> <span class="pl-c1">name</span>(named) <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>named layer<span class="pl-pds">"</span></span>

<span class="pl-c"><span class="pl-c">#</span> Speaking of logging...</span>
layer1 <span class="pl-k">=</span> <span class="pl-c1">absorbvertex</span>(<span class="pl-c1">SimpleLayer</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>), <span class="pl-c1">3</span>, <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in<span class="pl-pds">"</span></span>, <span class="pl-c1">2</span>), traitdecoration <span class="pl-k">=</span> t <span class="pl-k">-&gt;</span> <span class="pl-c1">SizeChangeLogger</span>(<span class="pl-c1">NamedTrait</span>(t, <span class="pl-s"><span class="pl-pds">"</span>layer1<span class="pl-pds">"</span></span>)))

<span class="pl-c"><span class="pl-c">#</span> What info is shown can be controlled by supplying an extra argument to SizeChangeLogger</span>
nameonly <span class="pl-k">=</span> <span class="pl-c1">NameInfoStr</span>()
layer2 <span class="pl-k">=</span> <span class="pl-c1">absorbvertex</span>(<span class="pl-c1">SimpleLayer</span>(<span class="pl-c1">nout</span>(layer1), <span class="pl-c1">4</span>), <span class="pl-c1">4</span>, layer1, traitdecoration <span class="pl-k">=</span> t <span class="pl-k">-&gt;</span> <span class="pl-c1">SizeChangeLogger</span>(nameonly, <span class="pl-c1">NamedTrait</span>(t, <span class="pl-s"><span class="pl-pds">"</span>layer2<span class="pl-pds">"</span></span>)))

<span class="pl-c1">@test_logs</span>(
(<span class="pl-c1">:info</span>, <span class="pl-s"><span class="pl-pds">"</span>Change nout of layer1, inputs=[in], outputs=[layer2], nin=[2], nout=[3], SizeAbsorb() by 1<span class="pl-pds">"</span></span>),
(<span class="pl-c1">:info</span>, <span class="pl-s"><span class="pl-pds">"</span>Change nin of layer2 by 1<span class="pl-pds">"</span></span>), <span class="pl-c"><span class="pl-c">#</span> Note: less verbose compared to layer1 due to NameInfoStr</span>
 <span class="pl-c1">Δnout</span>(layer1, <span class="pl-c1">1</span>))

 <span class="pl-c"><span class="pl-c">#</span> traitdecoration works exactly the same for conc and invariantvertex as well, no need for an example</span>

 <span class="pl-c"><span class="pl-c">#</span> Use the &gt;&gt; operator when creating SizeInvariant vertices using arithmetic operators:</span>
 add <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>addvertex<span class="pl-pds">"</span></span> <span class="pl-k">&gt;&gt;</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in1<span class="pl-pds">"</span></span>, <span class="pl-c1">1</span>) <span class="pl-k">+</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in2<span class="pl-pds">"</span></span>, <span class="pl-c1">1</span>)
 <span class="pl-c1">@test</span> <span class="pl-c1">name</span>(add) <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>addvertex<span class="pl-pds">"</span></span>

 <span class="pl-c"><span class="pl-c">#</span> For more elaborate traits one can use traitconf</span>
 add2 <span class="pl-k">=</span> <span class="pl-c1">traitconf</span>(t <span class="pl-k">-&gt;</span> <span class="pl-c1">SizeChangeLogger</span>(<span class="pl-c1">NamedTrait</span>(t, <span class="pl-s"><span class="pl-pds">"</span>layer1 + layer2<span class="pl-pds">"</span></span>))) <span class="pl-k">&gt;&gt;</span> layer1 <span class="pl-k">+</span> layer2
 <span class="pl-c1">@test</span> <span class="pl-c1">name</span>(add2) <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>layer1 + layer2<span class="pl-pds">"</span></span>

 <span class="pl-c1">@test_logs</span>(
 (<span class="pl-c1">:info</span>, <span class="pl-s"><span class="pl-pds">"</span>Change nout of layer1, inputs=[in], outputs=[layer2, layer1 + layer2], nin=[2], nout=[4], SizeAbsorb() by 1<span class="pl-pds">"</span></span>),
 (<span class="pl-c1">:info</span>, <span class="pl-s"><span class="pl-pds">"</span>Change nin of layer2 by 1<span class="pl-pds">"</span></span>),
 (<span class="pl-c1">:info</span>, <span class="pl-s"><span class="pl-pds">"</span>Change nout of layer2 by 1<span class="pl-pds">"</span></span>),
 (<span class="pl-c1">:info</span>, <span class="pl-s"><span class="pl-pds">"</span>Change nin of layer1 + layer2, inputs=[layer1, layer2], outputs=[], nin=[4, 4], nout=[4], SizeInvariant() by 1, 1<span class="pl-pds">"</span></span>),
 (<span class="pl-c1">:info</span>, <span class="pl-s"><span class="pl-pds">"</span>Change nout of layer1 + layer2, inputs=[layer1, layer2], outputs=[], nin=[5, 5], nout=[4], SizeInvariant() by 1<span class="pl-pds">"</span></span>),
  <span class="pl-c1">Δnout</span>(layer1, <span class="pl-c1">1</span>))

  <span class="pl-c"><span class="pl-c">#</span> When creating own trait wrappers, remember to subtype DecoratingTrait or else there will be pain!</span>

  <span class="pl-c"><span class="pl-c">#</span> Wrong!! Not a subtype of DecoratingTrait</span>
  <span class="pl-k">struct</span> PainfulTrait{T<span class="pl-k">&lt;:</span><span class="pl-c1">MutationTrait</span>} <span class="pl-k">&lt;:</span> <span class="pl-c1">MutationTrait</span>
      base<span class="pl-k">::</span><span class="pl-c1">T</span>
  <span class="pl-k">end</span>
  painlayer <span class="pl-k">=</span> <span class="pl-c1">absorbvertex</span>(<span class="pl-c1">SimpleLayer</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>), <span class="pl-c1">3</span>, <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in<span class="pl-pds">"</span></span>, <span class="pl-c1">2</span>), traitdecoration <span class="pl-k">=</span> PainfulTrait)

  <span class="pl-c"><span class="pl-c">#</span> Now one must implement a lot of methods for PainfulTrait...</span>
  <span class="pl-c1">@test_throws</span> MethodError <span class="pl-c1">Δnout</span>(painlayer, <span class="pl-c1">1</span>)

  <span class="pl-c"><span class="pl-c">#</span> Right! Is a subtype of DecoratingTrait</span>
  <span class="pl-k">struct</span> SmoothSailingTrait{T<span class="pl-k">&lt;:</span><span class="pl-c1">MutationTrait</span>} <span class="pl-k">&lt;:</span> <span class="pl-c1">DecoratingTrait</span>
      base<span class="pl-k">::</span><span class="pl-c1">T</span>
  <span class="pl-k">end</span>
  <span class="pl-c"><span class="pl-c">#</span> Just implement base and all will be fine</span>
  NaiveNASlib<span class="pl-k">.</span><span class="pl-en">base</span>(t<span class="pl-k">::</span><span class="pl-c1">SmoothSailingTrait</span>) <span class="pl-k">=</span> t<span class="pl-k">.</span>base

  smoothlayer <span class="pl-k">=</span> <span class="pl-c1">absorbvertex</span>(<span class="pl-c1">SimpleLayer</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>), <span class="pl-c1">3</span>, <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in<span class="pl-pds">"</span></span>, <span class="pl-c1">2</span>), traitdecoration <span class="pl-k">=</span> SmoothSailingTrait)

  <span class="pl-c1">Δnout</span>(smoothlayer, <span class="pl-c1">1</span>)
  <span class="pl-c1">@test</span> <span class="pl-c1">nout</span>(smoothlayer) <span class="pl-k">==</span> <span class="pl-c1">4</span>
</pre></div>
<h3><a id="user-content-graph-instrumentation-and-modification" class="anchor" aria-hidden="true" href="#graph-instrumentation-and-modification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Graph instrumentation and modification</h3>
<p>In many cases it is desirable to change things like traits of an existing graph. This can be achieved by supplying an extra argument when copying the graph. The extra argument is a function which determines how each individual component of the graph shall be copied.</p>
<p>Depending on what one wants to achieve, it can be more or less messy. Here is a pretty messy example:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="invertex = inputvertex(&quot;in&quot;, 2)
layer1 = layer(invertex, 3)
layer2 = layer(layer1, 4)

graph = CompGraph(invertex, layer2)

@test name.(vertices(graph)) == [&quot;in&quot;, &quot;MutationVertex::SizeAbsorb&quot;, &quot;MutationVertex::SizeAbsorb&quot;]

# Ok, lets add names to layer1 and layer2 and change the name of invertex

# Lets first define the default: Fallback to &quot;clone&quot;
# clone is the built-in function to copy things in this manner as I did not want to override Base.copy
copyfun(args...;cf) = clone(args...;cf=cf) # Keyword argument cf is the function to use for copying all fields of the input

# Add a name to layer1 and layer2
function copyfun(v::MutationVertex,args...;cf)
    # This is probably not practical to do in a real graph, so make sure you have names when first creating it...
    name = v == layer1 ? &quot;layer1&quot; : &quot;layer2&quot;
    addname(args...;cf) = clone(args...;cf=cf)
    addname(t::SizeAbsorb;cf) = NamedTrait(t, name) # SizeAbsorb has no fields, otherwise we would have had to run cf for each one of them...
    clone(v, args...;cf=addname)
end

# Change name of invertex
# Here we can assume that invertex name is unique in the whole graph or else we would have had to use the above way
copyfun(s::String; cf) = s == name(invertex) ? &quot;in changed&quot; : s

# Now supply copyfun when copying the graph.
# I must admit that thinking about what this does makes me a bit dizzy...
namedgraph = copy(graph, copyfun)

@test name.(vertices(namedgraph)) == [&quot;in changed&quot;, &quot;layer1&quot;, &quot;layer2&quot;]
"><pre>invertex <span class="pl-k">=</span> <span class="pl-c1">inputvertex</span>(<span class="pl-s"><span class="pl-pds">"</span>in<span class="pl-pds">"</span></span>, <span class="pl-c1">2</span>)
layer1 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(invertex, <span class="pl-c1">3</span>)
layer2 <span class="pl-k">=</span> <span class="pl-c1">layer</span>(layer1, <span class="pl-c1">4</span>)

graph <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>(invertex, layer2)

<span class="pl-c1">@test</span> <span class="pl-c1">name</span>.(<span class="pl-c1">vertices</span>(graph)) <span class="pl-k">==</span> [<span class="pl-s"><span class="pl-pds">"</span>in<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>MutationVertex::SizeAbsorb<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>MutationVertex::SizeAbsorb<span class="pl-pds">"</span></span>]

<span class="pl-c"><span class="pl-c">#</span> Ok, lets add names to layer1 and layer2 and change the name of invertex</span>

<span class="pl-c"><span class="pl-c">#</span> Lets first define the default: Fallback to "clone"</span>
<span class="pl-c"><span class="pl-c">#</span> clone is the built-in function to copy things in this manner as I did not want to override Base.copy</span>
<span class="pl-en">copyfun</span>(args<span class="pl-k">...</span>;cf) <span class="pl-k">=</span> <span class="pl-c1">clone</span>(args<span class="pl-k">...</span>;cf<span class="pl-k">=</span>cf) <span class="pl-c"><span class="pl-c">#</span> Keyword argument cf is the function to use for copying all fields of the input</span>

<span class="pl-c"><span class="pl-c">#</span> Add a name to layer1 and layer2</span>
<span class="pl-k">function</span> <span class="pl-en">copyfun</span>(v<span class="pl-k">::</span><span class="pl-c1">MutationVertex</span>,args<span class="pl-k">...</span>;cf)
    <span class="pl-c"><span class="pl-c">#</span> This is probably not practical to do in a real graph, so make sure you have names when first creating it...</span>
    name <span class="pl-k">=</span> v <span class="pl-k">==</span> layer1 <span class="pl-k">?</span> <span class="pl-s"><span class="pl-pds">"</span>layer1<span class="pl-pds">"</span></span> <span class="pl-k">:</span> <span class="pl-s"><span class="pl-pds">"</span>layer2<span class="pl-pds">"</span></span>
    <span class="pl-en">addname</span>(args<span class="pl-k">...</span>;cf) <span class="pl-k">=</span> <span class="pl-c1">clone</span>(args<span class="pl-k">...</span>;cf<span class="pl-k">=</span>cf)
    <span class="pl-en">addname</span>(t<span class="pl-k">::</span><span class="pl-c1">SizeAbsorb</span>;cf) <span class="pl-k">=</span> <span class="pl-c1">NamedTrait</span>(t, name) <span class="pl-c"><span class="pl-c">#</span> SizeAbsorb has no fields, otherwise we would have had to run cf for each one of them...</span>
    <span class="pl-c1">clone</span>(v, args<span class="pl-k">...</span>;cf<span class="pl-k">=</span>addname)
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> Change name of invertex</span>
<span class="pl-c"><span class="pl-c">#</span> Here we can assume that invertex name is unique in the whole graph or else we would have had to use the above way</span>
<span class="pl-en">copyfun</span>(s<span class="pl-k">::</span><span class="pl-c1">String</span>; cf) <span class="pl-k">=</span> s <span class="pl-k">==</span> <span class="pl-c1">name</span>(invertex) <span class="pl-k">?</span> <span class="pl-s"><span class="pl-pds">"</span>in changed<span class="pl-pds">"</span></span> <span class="pl-k">:</span> s

<span class="pl-c"><span class="pl-c">#</span> Now supply copyfun when copying the graph.</span>
<span class="pl-c"><span class="pl-c">#</span> I must admit that thinking about what this does makes me a bit dizzy...</span>
namedgraph <span class="pl-k">=</span> <span class="pl-c1">copy</span>(graph, copyfun)

<span class="pl-c1">@test</span> <span class="pl-c1">name</span>.(<span class="pl-c1">vertices</span>(namedgraph)) <span class="pl-k">==</span> [<span class="pl-s"><span class="pl-pds">"</span>in changed<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>layer1<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>layer2<span class="pl-pds">"</span></span>]</pre></div>
<h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contributing</h2>
<p>All contributions are welcome. Please file an issue before creating a PR.</p>
</article></div>