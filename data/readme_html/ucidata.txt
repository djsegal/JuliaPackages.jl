<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-ucidatajl" class="anchor" aria-hidden="true" href="#ucidatajl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>UCIData.jl</h1>
<p dir="auto">This is a package for accessing <a href="http://archive.ics.uci.edu/ml/datasets.html" rel="nofollow">UCI Machine Learning Repository</a> datasets (and some from other sources) inside Julia. The UCI ML repository is a useful source for machine learning datasets for testing and benchmarking, but the format of datasets is not consistent. This means effort is required in order to make use of new datasets since they need to be read differently.</p>
<p dir="auto">Instead, the aim is to convert the datasets into a common format (CSV), where each line is as follows:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="ID,attribute_1,attribute_2,...,attribute_n,class"><pre class="notranslate"><code>ID,attribute_1,attribute_2,...,attribute_n,class
</code></pre></div>
<p dir="auto">The attribute header names start with <code>C</code> or <code>N</code>, indicating categoric or numeric variables.</p>
<p dir="auto">These datasets can be accessed as <code>DataFrames</code> in Julia using the following, with categoric columns pooled into <code>PooledDataArray</code> type (here we load the "iris" dataset):</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using UCIData
UCIData.dataset(&quot;iris&quot;)"><pre class="notranslate"><code>using UCIData
UCIData.dataset("iris")
</code></pre></div>
<p dir="auto">You can get a list of dataset types with</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="UCIData.list_dataset_types()"><pre class="notranslate"><code>UCIData.list_dataset_types()
</code></pre></div>
<p dir="auto">and then a list of the available datasets for a given type with</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="UCIData.list_datasets(&quot;classification&quot;)"><pre class="notranslate"><code>UCIData.list_datasets("classification")
</code></pre></div>
<p dir="auto">The datasets are not checked in to git in order to minimise the size of the repository and to avoid rehosting the data. As such, the script downloads any missing datasets directly from UCI as it runs, using <a href="https://github.com/oxinabox/DataDeps.jl">DataDeps.jl</a></p>
<h2 dir="auto"><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributing</h2>
<p dir="auto">Please feel free to add new datasets via pull request!</p>
</article></div>