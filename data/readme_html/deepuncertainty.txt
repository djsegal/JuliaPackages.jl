<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-deepuncertainty" class="anchor" aria-hidden="true" href="#deepuncertainty"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DeepUncertainty</h1>
<p dir="auto"><a href="https://aced-differentiate.github.io/DeepUncertainty.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://aced-differentiate.github.io/DeepUncertainty.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/aced-differentiate/DeepUncertainty.jl/actions"><img src="https://github.com/aced-differentiate/DeepUncertainty.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/aced-differentiate/DeepUncertainty.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/a7944ea1cae8b8bc8ed2146b59925d2cc6934f02abc0dfb7a3b3cacbdaef7ae4/68747470733a2f2f636f6465636f762e696f2f67682f616365642d646966666572656e74696174652f44656570556e6365727461696e74792e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d395844564a33544f4533" alt="codecov" data-canonical-src="https://codecov.io/gh/aced-differentiate/DeepUncertainty.jl/branch/main/graph/badge.svg?token=9XDVJ3TOE3" style="max-width: 100%;"></a></p>
<p dir="auto">Tools for uncertianty estimation in Deep Learning models. Use the below command in REPL to install.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="] add DeepUncertainty"><pre class="notranslate"><code>] add DeepUncertainty
</code></pre></div>
<h2 dir="auto"><a id="user-content-basics" class="anchor" aria-hidden="true" href="#basics"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basics</h2>
<p dir="auto">Neural Networks are usually trained to minimize a loss function that approximates model performance on any given task. The weights (parameters) of the network are estimated using first-order gradient based optimization algorithms that usually result in a point estimates.</p>
<p dir="auto">We can also take take a Bayesian view point and place a distribution on each weight instead of interpreting it as a point estimate. We can calculate the uncertianty in our estimates of the parameters, since we optimize the distribution parameters insteaf of point estimates directly.</p>
<h2 dir="auto"><a id="user-content-current-inventory" class="anchor" aria-hidden="true" href="#current-inventory"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Current Inventory</h2>
<ul dir="auto">
<li><a href="https://arxiv.org/abs/1506.02142" rel="nofollow">MC Dropout</a></li>
<li><a href="https://arxiv.org/abs/2002.06715" rel="nofollow">BatchEnsemble</a></li>
<li><a href="https://arxiv.org/abs/1505.05424" rel="nofollow">Variational Inference</a></li>
<li><a href="https://arxiv.org/abs/2005.07186" rel="nofollow">Bayesian BatchEnsemble</a></li>
</ul>
</article></div>