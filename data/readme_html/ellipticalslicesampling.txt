<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-ellipticalslicesamplingjl" class="anchor" aria-hidden="true" href="#ellipticalslicesamplingjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>EllipticalSliceSampling.jl</h1>
<p>Julia implementation of elliptical slice sampling.</p>
<p><a href="https://www.repostatus.org/#active" rel="nofollow"><img src="https://camo.githubusercontent.com/fd7a93e9eedafe6205ebee65c9e3579f44df25b7/68747470733a2f2f7777772e7265706f7374617475732e6f72672f6261646765732f6c61746573742f6163746976652e737667" alt="Project Status: Active â€“ The project has reached a stable, usable state and is being actively developed." data-canonical-src="https://www.repostatus.org/badges/latest/active.svg" style="max-width:100%;"></a>
<a href="https://travis-ci.com/TuringLang/EllipticalSliceSampling.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/c25f740f811a219295c848d9f3d55d54c60cfb35/68747470733a2f2f7472617669732d63692e636f6d2f547572696e674c616e672f456c6c6970746963616c536c69636553616d706c696e672e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/TuringLang/EllipticalSliceSampling.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://github.com/TuringLang/EllipticalSliceSampling.jl/actions?query=workflow%3ACI"><img src="https://github.com/TuringLang/EllipticalSliceSampling.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/TuringLang/EllipticalSliceSampling.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/fc153f14b4c488175729ae84ad580a429e22df83/68747470733a2f2f636f6465636f762e696f2f67682f547572696e674c616e672f456c6c6970746963616c536c69636553616d706c696e672e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Codecov" data-canonical-src="https://codecov.io/gh/TuringLang/EllipticalSliceSampling.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/TuringLang/EllipticalSliceSampling.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/4c2eff477960c3fd357abfd1629cb63f57c1ab08/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f547572696e674c616e672f456c6c6970746963616c536c69636553616d706c696e672e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coveralls" data-canonical-src="https://coveralls.io/repos/github/TuringLang/EllipticalSliceSampling.jl/badge.svg?branch=master" style="max-width:100%;"></a></p>
<h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Overview</h2>
<p>This package implements elliptical slice sampling in the Julia language, as described in
<a href="http://proceedings.mlr.press/v9/murray10a/murray10a.pdf" rel="nofollow">Murray, Adams &amp; MacKay (2010)</a>.</p>
<p>Elliptical slice sampling is a "Markov chain Monte Carlo algorithm for performing
inference in models with multivariate Gaussian priors" (Murray, Adams &amp; MacKay (2010)).</p>
<p>Without loss of generality, the originally described algorithm assumes that the Gaussian
prior has zero mean. For convenience we allow the user to specify arbitrary Gaussian
priors with non-zero means and handle the change of variables internally.</p>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<p>Probably most users would like to use the exported function</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">ESS_mcmc</span>([rng, ]prior, loglikelihood, N[; kwargs<span class="pl-k">...</span>])</pre></div>
<p>which returns a vector of <code>N</code> samples for approximating the posterior of
a model with a Gaussian prior that allows sampling from the <code>prior</code> and
evaluation of the log likelihood <code>loglikelihood</code>.</p>
<p>If you want to have more control about the sampling procedure (e.g., if you
only want to save a subset of samples or want to use another stopping
criterion), the function</p>
<div class="highlight highlight-source-julia"><pre>AbstractMCMC<span class="pl-k">.</span><span class="pl-c1">steps!</span>(
    [rng,]
    EllipticalSliceSampling<span class="pl-k">.</span><span class="pl-c1">Model</span>(prior, loglikelihood),
    EllipticalSliceSampling<span class="pl-k">.</span><span class="pl-c1">EllipticalSliceSampler</span>();
    kwargs<span class="pl-k">...</span>
)</pre></div>
<p>gives you access to an iterator from which you can generate an unlimited
number of samples.</p>
<h3><a id="user-content-prior" class="anchor" aria-hidden="true" href="#prior"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Prior</h3>
<p>You may specify Gaussian priors with arbitrary means. EllipticalSliceSampling.jl
provides first-class support for the scalar and multivariate normal distributions
in <a href="https://github.com/JuliaStats/Distributions.jl">Distributions.jl</a>. For
instance, if the prior distribution is a standard normal distribution, you can
choose</p>
<div class="highlight highlight-source-julia"><pre>prior <span class="pl-k">=</span> <span class="pl-c1">Normal</span>()</pre></div>
<p>However, custom Gaussian priors are supported as well. For instance, if you want to
use a custom distribution type <code>GaussianPrior</code>, the following methods should be
implemented:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span> state that the distribution is actually Gaussian</span>
EllipticalSliceSampling<span class="pl-k">.</span><span class="pl-en">isgaussian</span>(<span class="pl-k">::</span><span class="pl-c1">Type{&lt;:GaussianPrior}</span>) <span class="pl-k">=</span> <span class="pl-c1">true</span>

<span class="pl-c"><span class="pl-c">#</span> define the mean of the distribution</span>
<span class="pl-c"><span class="pl-c">#</span> alternatively implement `proposal(prior, ...)` and</span>
<span class="pl-c"><span class="pl-c">#</span> `proposal!(out, prior, ...)` (only if the samples are mutable)</span>
Statistics<span class="pl-k">.</span><span class="pl-en">mean</span>(dist<span class="pl-k">::</span><span class="pl-c1">GaussianPrior</span>) <span class="pl-k">=</span> <span class="pl-k">...</span>

<span class="pl-c"><span class="pl-c">#</span> define how to sample from the distribution</span>
<span class="pl-c"><span class="pl-c">#</span> only one of the following methods is needed:</span>
<span class="pl-c"><span class="pl-c">#</span> - if the samples are immutable (e.g., numbers or static arrays) only</span>
<span class="pl-c"><span class="pl-c">#</span>   `rand(rng, dist)` should be implemented</span>
<span class="pl-c"><span class="pl-c">#</span> - otherwise only `rand!(rng, dist, sample)` is required</span>
Base<span class="pl-k">.</span><span class="pl-en">rand</span>(rng<span class="pl-k">::</span><span class="pl-c1">AbstractRNG</span>, dist<span class="pl-k">::</span><span class="pl-c1">GaussianPrior</span>) <span class="pl-k">=</span> <span class="pl-k">...</span>
Random<span class="pl-k">.</span><span class="pl-en">rand!</span>(rng<span class="pl-k">::</span><span class="pl-c1">AbstractRNG</span>, dist<span class="pl-k">::</span><span class="pl-c1">GaussianPrior</span>, sample) <span class="pl-k">=</span> <span class="pl-k">...</span>

<span class="pl-c"><span class="pl-c">#</span> specify the type of a sample from the distribution</span>
Base<span class="pl-k">.</span><span class="pl-en">eltype</span>(<span class="pl-k">::</span><span class="pl-c1">Type{&lt;:GaussianPrior}</span>) <span class="pl-k">=</span> <span class="pl-k">...</span>

<span class="pl-c"><span class="pl-c">#</span> in the case of mutable samples, specify the array size of the samples</span>
Base<span class="pl-k">.</span><span class="pl-en">size</span>(dist<span class="pl-k">::</span><span class="pl-c1">GaussianPrior</span>) <span class="pl-k">=</span> <span class="pl-k">...</span></pre></div>
<h3><a id="user-content-log-likelihood" class="anchor" aria-hidden="true" href="#log-likelihood"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Log likelihood</h3>
<p>In addition to the prior, you have to specify a Julia implementation of
the log likelihood function. Here the predefined log densities and log
likelihood functions in
<a href="https://github.com/JuliaStats/Distributions.jl">Distributions.jl</a> might
be useful.</p>
<h3><a id="user-content-progress-monitor" class="anchor" aria-hidden="true" href="#progress-monitor"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Progress monitor</h3>
<p>If you use a package such as <a href="https://junolab.org/" rel="nofollow">Juno</a> or
<a href="https://github.com/c42f/TerminalLoggers.jl">TerminalLoggers.jl</a> that supports
progress logs created by the
<a href="https://github.com/JunoLab/ProgressLogging.jl">ProgressLogging.jl</a> API, then you can
monitor the progress of the sampling algorithm. If you do not specify a progress
logging frontend explicitly,
<a href="https://github.com/TuringLang/AbstractMCMC.jl">AbstractMCMC.jl</a> picks a frontend
for you automatically.</p>
<h2><a id="user-content-bibliography" class="anchor" aria-hidden="true" href="#bibliography"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Bibliography</h2>
<p>Murray, I., Adams, R. &amp; MacKay, D.. (2010). Elliptical slice sampling. Proceedings of Machine Learning Research, 9:541-548.</p>
</article></div>