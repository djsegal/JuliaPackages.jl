<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-binomialgpu" class="anchor" aria-hidden="true" href="#binomialgpu"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>BinomialGPU</h1>
<p><a href="https://buildkite.com/julialang/binomialgpu-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/0d7d0ffe2b28d88d0fcb1a3dccef87b630433a1e1181d0f2f06f5dec2691e9b8/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f37306138633131323539363538616436663833366134393831373931656431343462616338306536353330323239316430642e7376673f6272616e63683d6d6173746572" alt="Build status" data-canonical-src="https://badge.buildkite.com/70a8c11259658ad6f836a4981791ed144bac80e65302291d0d.svg?branch=master" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/JuliaGPU/BinomialGPU.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/0bea3ebec12895c53724f9b73a1b83b65ea176d6f41097a7bb63f113896005c9/68747470733a2f2f636f6465636f762e696f2f67682f4a756c69614750552f42696e6f6d69616c4750552e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/JuliaGPU/BinomialGPU.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p>This package provides a function <code>rand_binomial!</code> to produce <code>CuArrays</code> with binomially distributed entries, analogous to <code>CUDA.rand_poisson!</code> for Poisson-distributed ones.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>Use the built-in package manager:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="import Pkg; Pkg.add(&quot;BinomialGPU&quot;)
"><pre><span class="pl-k">import</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>BinomialGPU<span class="pl-pds">"</span></span>)</pre></div>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<p>Sample <code>CuArrays</code> with binomial random variates in-place:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using CUDA, BinomialGPU

A = CUDA.zeros(Int, 16)
rand_binomial!(A, count = 10, prob = 0.5)
"><pre><span class="pl-k">using</span> CUDA, BinomialGPU

A <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">zeros</span>(Int, <span class="pl-c1">16</span>)
<span class="pl-c1">rand_binomial!</span>(A, count <span class="pl-k">=</span> <span class="pl-c1">10</span>, prob <span class="pl-k">=</span> <span class="pl-c1">0.5</span>)</pre></div>
<p>The function currently also supports broadcast over arrays of parameters of the same size as the one to be filled:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="A      = CUDA.zeros(Int, 8)
counts = [1,2,4,8,16,32,64,128]
probs  = CUDA.rand(8)
rand_binomial!(A, count = counts, prob = probs)
"><pre>A      <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">zeros</span>(Int, <span class="pl-c1">8</span>)
counts <span class="pl-k">=</span> [<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">4</span>,<span class="pl-c1">8</span>,<span class="pl-c1">16</span>,<span class="pl-c1">32</span>,<span class="pl-c1">64</span>,<span class="pl-c1">128</span>]
probs  <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">rand</span>(<span class="pl-c1">8</span>)
<span class="pl-c1">rand_binomial!</span>(A, count <span class="pl-k">=</span> counts, prob <span class="pl-k">=</span> probs)</pre></div>
<p>as well as broadcasts over arrays of parameters whose dimensions are a prefix of the dimensions of A, e.g.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="A      = CUDA.zeros(Int, (2, 4, 8))
counts = rand(1:128, 2, 4)
probs  = CUDA.rand(2)
rand_binomial!(A, count = counts, prob = probs)
"><pre>A      <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">zeros</span>(Int, (<span class="pl-c1">2</span>, <span class="pl-c1">4</span>, <span class="pl-c1">8</span>))
counts <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">128</span>, <span class="pl-c1">2</span>, <span class="pl-c1">4</span>)
probs  <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">rand</span>(<span class="pl-c1">2</span>)
<span class="pl-c1">rand_binomial!</span>(A, count <span class="pl-k">=</span> counts, prob <span class="pl-k">=</span> probs)</pre></div>
<h2><a id="user-content-issues" class="anchor" aria-hidden="true" href="#issues"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Issues</h2>
<ul>
<li>The speed is slower when using optimal thread allocation than when defaulting to 256 threads. See <a href="https://github.com/JuliaGPU/BinomialGPU.jl/issues/2">issue #2</a></li>
<li>Are there any other samplers that are comparably fast or faster? I compared the following: sample an array of size <code>(1024, 1024)</code> with <code>count = 128</code> and <code>prob</code> of size <code>(1024, 1024)</code> with uniformly drawn entries. Timings on an RTX2070 card: BinomialGPU.jl 0.8ms, PyTorch 11ms, CuPy 18ms, tensorflow 400ms. Timings for other samplers are very welcome; please open an issue if you find one.</li>
</ul>
</article></div>