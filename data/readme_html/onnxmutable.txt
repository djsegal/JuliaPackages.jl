<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-onnxmutable" class="anchor" aria-hidden="true" href="#onnxmutable"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ONNXmutable</h1>
<p><a href="https://travis-ci.com/DrChainsaw/ONNXmutable.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/881573aee9999f8e1d24ad179ff698a8394eaacd/68747470733a2f2f7472617669732d63692e636f6d2f4472436861696e7361772f4f4e4e586d757461626c652e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/DrChainsaw/ONNXmutable.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://ci.appveyor.com/project/DrChainsaw/ONNXmutable-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/f9af637c0ac7dd478850f6b1dfe32f72b6c02068/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f4472436861696e7361772f4f4e4e586d757461626c652e6a6c3f7376673d74727565" alt="Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/DrChainsaw/ONNXmutable.jl?svg=true" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/DrChainsaw/ONNXmutable.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/b5a42211623ac298fc728c409f240ac5fe4afb63/68747470733a2f2f636f6465636f762e696f2f67682f4472436861696e7361772f4f4e4e586d757461626c652e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Codecov" data-canonical-src="https://codecov.io/gh/DrChainsaw/ONNXmutable.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p>ONNXmutable is an extension of <a href="https://github.com/FluxML/ONNX.jl">ONNX.jl</a> which adds serialization of (almost) arbitrary functions into <a href="https://onnx.ai" rel="nofollow">ONNX</a> models.</p>
<p>It is also capable of deserializing models into <a href="https://github.com/DrChainsaw/NaiveNASflux.jl">NaiveNASflux</a> graphs, bringing its powerful mutation capabilities to the transfer learning context.</p>
<h2><a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Basic usage</h2>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>https://github.com/DrChainsaw/ONNXmutable.jl<span class="pl-pds">"</span></span>)</pre></div>
<p>Serialization is done using the <code>onnx</code> function which accepts a filename <code>String</code> or an <code>IO</code> as first argument:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span> Save model as model.onnx where inputshapes are tuples with sizes of input</span>
<span class="pl-c1">onnx</span>(<span class="pl-s"><span class="pl-pds">"</span>model.onnx<span class="pl-pds">"</span></span>, model, inputshapes<span class="pl-k">...</span>)

<span class="pl-c"><span class="pl-c">#</span> Load model as a CompGraph</span>
graph <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>(<span class="pl-s"><span class="pl-pds">"</span>model.onnx<span class="pl-pds">"</span></span>)</pre></div>
<p>More elaborate example:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> ONNXmutable, NaiveNASflux, Test

l1 <span class="pl-k">=</span> <span class="pl-c1">Conv</span>((<span class="pl-c1">3</span>,<span class="pl-c1">3</span>), <span class="pl-c1">2</span><span class="pl-k">=&gt;</span><span class="pl-c1">3</span>, relu)
l2 <span class="pl-k">=</span> <span class="pl-c1">Dense</span>(<span class="pl-c1">3</span>, <span class="pl-c1">4</span>, elu)

f <span class="pl-k">=</span> <span class="pl-k">function</span>(x,y)
    x <span class="pl-k">=</span> <span class="pl-c1">l1</span>(x)
    <span class="pl-c"><span class="pl-c">#</span> Home-brewed global average pool</span>
    x <span class="pl-k">=</span> <span class="pl-c1">dropdims</span>(<span class="pl-c1">mean</span>(x, dims<span class="pl-k">=</span>(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>)), dims<span class="pl-k">=</span>(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>))
    x <span class="pl-k">=</span> <span class="pl-c1">l2</span>(x)
    <span class="pl-k">return</span> x <span class="pl-k">+</span> y
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> Serialize f. Use a string to save to file instead</span>
io <span class="pl-k">=</span> <span class="pl-c1">PipeBuffer</span>()
x_shape <span class="pl-k">=</span> (<span class="pl-c1">:W</span>, <span class="pl-c1">:H</span>, <span class="pl-c1">2</span>, <span class="pl-c1">:Batch</span>)
y_shape <span class="pl-k">=</span> (<span class="pl-c1">4</span>, <span class="pl-c1">:Batch</span>)
<span class="pl-c1">onnx</span>(io, f, x_shape, y_shape)

<span class="pl-c"><span class="pl-c">#</span> Deserialize as a NaiveNASflux CompGraph (or use the deserialization method from ONNX.jl)</span>
g <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>(io)

x <span class="pl-k">=</span> <span class="pl-c1">ones</span>(Float32, <span class="pl-c1">5</span>,<span class="pl-c1">4</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>)
y <span class="pl-k">=</span> <span class="pl-c1">ones</span>(Float32, <span class="pl-c1">4</span>, <span class="pl-c1">3</span>)
<span class="pl-c1">@test</span> <span class="pl-c1">g</span>(x,y) <span class="pl-k">≈</span> <span class="pl-c1">f</span>(x,y)

<span class="pl-c"><span class="pl-c">#</span> Serialization of CompGraphs does not require input shapes to be provided as they can be inferred.</span>
io <span class="pl-k">=</span> <span class="pl-c1">PipeBuffer</span>()
<span class="pl-c1">onnx</span>(io, g)

g <span class="pl-k">=</span> <span class="pl-c1">CompGraph</span>(io)
<span class="pl-c1">@test</span> <span class="pl-c1">g</span>(x,y) <span class="pl-k">≈</span> <span class="pl-c1">f</span>(x,y)</pre></div>
<h2><a id="user-content-supported-operations" class="anchor" aria-hidden="true" href="#supported-operations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Supported Operations</h2>
<pre><code>Add
AveragePool
BatchNormalization
Concat
Constant
Conv
Dropout
Elu
Flatten
Gemm
GlobalAveragePool
GlobalMaxPool
LSTM
MaxPool
Mul
RNN
ReduceMean
Relu
Reshape
Selu
Softmax
Squeeze
Tanh
</code></pre>
<h2><a id="user-content-adding-operations" class="anchor" aria-hidden="true" href="#adding-operations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Adding Operations</h2>
<p>While the list of supported operations is currently quite meager, it is relatively straightforward to add support for more.</p>
<p>Serialization uses a lightweight graph tracing mechanism where <code>AbstractProbe</code>s are sent through the function to collect all ONNX operations they encounter.</p>
<p>To map the function <code>myfun(args::SomeType....)</code> to an ONNX operation one just defines a method <code>myfun(args::AbstractProbe...)</code> which</p>
<ol>
<li>Adds ONNX information to one of the inputs (does not matter which one)</li>
<li>Returns at least one <code>AbstractProbe</code> with information for the next function</li>
</ol>
<p>This function typically looks something like this:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> ONNXmutable<span class="pl-k">:</span> AbstractProbe, recursename, nextname, newfrom, add!, name
<span class="pl-k">function</span> <span class="pl-en">myfun</span>(probes<span class="pl-k">::</span><span class="pl-c1">AbstractProbe...</span>)
    p <span class="pl-k">=</span> probes[<span class="pl-c1">1</span>] <span class="pl-c"><span class="pl-c">#</span> select any probe</span>
    optype <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>MyOpType<span class="pl-pds">"</span></span>
    <span class="pl-c"><span class="pl-c">#</span> Naming strategy (e.g. how to avoid duplicate names) is provided by the probe</span>
    <span class="pl-c"><span class="pl-c">#</span> Not strictly needed, but the onnx model is basically corrupt if duplicates exist</span>
    nodename <span class="pl-k">=</span> <span class="pl-c1">recursename</span>(optype, <span class="pl-c1">nextname</span>(p))

    <span class="pl-c"><span class="pl-c">#</span> Add ONNX node info</span>
    <span class="pl-c1">add!</span>(p, ONNX<span class="pl-k">.</span>Proto<span class="pl-k">.</span><span class="pl-c1">NodeProto</span>(
    <span class="pl-c"><span class="pl-c">#</span> Names of input is provided by probes. This is why new probes need to be provided as output</span>
    input <span class="pl-k">=</span> <span class="pl-c1">collect</span>(<span class="pl-c1">name</span>.(probes)),
    <span class="pl-c"><span class="pl-c">#</span> Name of output from this node</span>
    output <span class="pl-k">=</span> [nodename],
    op_type <span class="pl-k">=</span> optype))

    <span class="pl-c"><span class="pl-c">#</span> Probes can procreate like this</span>
    <span class="pl-k">return</span> <span class="pl-c1">newfrom</span>(p, nodename, s <span class="pl-k">-&gt;</span> s)
<span class="pl-k">end</span></pre></div>
<p>See <a href="src/serialize/serialize.jl">serialize.jl</a> for existing operations.</p>
<p>Deserialization is done by simply mapping operation types to functions in a dictionary in a very similar manner as it is done in <a href="https://github.com/FluxML/ONNX.jl">ONNX.jl</a>. This allows for both easy extension as well as overwriting of existing mappings with own implementations:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> ONNXmutable<span class="pl-k">:</span> actfuns

<span class="pl-c"><span class="pl-c">#</span> All inputs which are not output from another node in the graph are provided in the method call</span>
actfuns[<span class="pl-c1">:SomeOp</span>] <span class="pl-k">=</span> (params, α, β) <span class="pl-k">-&gt;</span> x <span class="pl-k">-&gt;</span> x<span class="pl-k">^</span>α <span class="pl-k">+</span> β
<span class="pl-c"><span class="pl-c">#</span> Params contains a Dict with attributes.</span>
actfuns[<span class="pl-c1">:AnotherOp</span>] <span class="pl-k">=</span> <span class="pl-k">function</span>(params)
    α <span class="pl-k">=</span> <span class="pl-c1">get</span>(params, <span class="pl-c1">:alpha</span>, <span class="pl-c1">1</span>)
    <span class="pl-k">return</span> x <span class="pl-k">-&gt;</span> α <span class="pl-k">/</span> x
<span class="pl-k">end</span>
ONNXmutable<span class="pl-k">.</span><span class="pl-c1">refresh</span>()</pre></div>
<p>Note: After adding/changing an operation mapping one needs to call <code>ONNXmutable.refresh()</code> for it to take effect.
See <a href="src/deserialize/ops.jl">ops.jl</a> for existing operations.</p>
<h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contributing</h2>
<p>All contributions are welcome. Please file an issue before creating a PR.</p>
</article></div>