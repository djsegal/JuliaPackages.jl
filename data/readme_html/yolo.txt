<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-yolojl" class="anchor" aria-hidden="true" href="#yolojl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>YOLO.jl</h1>
<p>Currently only supports loading <a href="https://github.com/pjreddie/darknet/blob/master/cfg/yolov2-tiny.cfg">YOLOv2-tiny</a> and the <a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/" rel="nofollow">VOC-2007</a> pretrained model (pretrained on <a href="https://pjreddie.com/darknet/" rel="nofollow">Darknet</a>).</p>
<p>Made possible by Yavuz Bakman's <a href="https://github.com/Ybakman/YoloV2">YoloV2</a></p>
<p>Consider also checking out:</p>
<ul>
<li><a href="https://github.com/r3tex/ObjectDetector.jl">ObjectDetector.jl</a> -&gt; A Flux-based implementation of YOLO (testing only)</li>
<li><a href="https://github.com/ianshmean/Darknet.jl">Darknet.jl</a> -&gt; A julia wrapper of AlexeyAB's fork of Darknet (testing only)</li>
</ul>
<p>
<a target="_blank" rel="noopener noreferrer" href="examples/boat.png"><img src="examples/boat.png" alt="drawing" width="200" style="max-width:100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="examples/bikes.png"><img src="examples/bikes.png" alt="bikes" width="200" style="max-width:100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="examples/cowcat.png"><img src="examples/cowcat.png" alt="cowcat" width="200" style="max-width:100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="examples/cars.png"><img src="examples/cars.png" alt="cars" width="200" style="max-width:100%;"></a>
</p>
<p>See below for examples or ask questions on <a href="https://slackinvite.julialang.org" rel="nofollow"><img src="https://camo.githubusercontent.com/c69ef2c4b0814b5eace75155d7974cdc8c2db725/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736c61636b2d2532336d616368696e652d2d6c6561726e696e672d79656c6c6f77" alt="Join the julia slack" data-canonical-src="https://img.shields.io/badge/slack-%23machine--learning-yellow" style="max-width:100%;"></a></p>
<table>
<thead>
<tr>
<th align="center"><strong>Platform</strong></th>
<th align="center"><strong>Build Status</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Linux &amp; MacOS x86</td>
<td align="center"><a href="https://travis-ci.com/ianshmean/YOLO.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/05855898fd26f2fad9d20aca4686ad7ee02342d2/68747470733a2f2f7472617669732d63692e636f6d2f69616e73686d65616e2f594f4c4f2e6a6c2e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://travis-ci.com/ianshmean/YOLO.jl.svg?branch=master" style="max-width:100%;"></a></td>
</tr>
<tr>
<td align="center">Windows 32/64-bit</td>
<td align="center"><a href="https://ci.appveyor.com/project/ianshmean/YOLO-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/b42a7f9ac5133a8366451354c522dc05042be804/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f69616e73686d65616e2f594f4c4f2e6a6c3f7376673d74727565" alt="" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/ianshmean/YOLO.jl?svg=true" style="max-width:100%;"></a></td>
</tr>
<tr>
<td align="center">Linux ARM 32/64-bit</td>
<td align="center"><a href="https://cloud.drone.io/ianshmean/YOLO.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/104eee0a0f437f94d54b6ba1e3845a4828c26f95/68747470733a2f2f636c6f75642e64726f6e652e696f2f6170692f6261646765732f69616e73686d65616e2f594f4c4f2e6a6c2f7374617475732e737667" alt="" data-canonical-src="https://cloud.drone.io/api/badges/ianshmean/YOLO.jl/status.svg" style="max-width:100%;"></a></td>
</tr>
<tr>
<td align="center">FreeBSD x86</td>
<td align="center"><a href="https://cirrus-ci.com/github/ianshmean/YOLO.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/523b52f3f0ce4c918464ba701277763fefa93fb2/68747470733a2f2f6170692e6369727275732d63692e636f6d2f6769746875622f69616e73686d65616e2f594f4c4f2e6a6c2e737667" alt="" data-canonical-src="https://api.cirrus-ci.com/github/ianshmean/YOLO.jl.svg" style="max-width:100%;"></a></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"><a href="https://codecov.io/gh/ianshmean/YOLO.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/cf4d0c52e5893d43c3d1b4148afc897ba35c325b/68747470733a2f2f636f6465636f762e696f2f67682f69616e73686d65616e2f594f4c4f2e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Codecoverage Status" data-canonical-src="https://codecov.io/gh/ianshmean/YOLO.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a><br><a href="https://coveralls.io/github/ianshmean/YOLO.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/174d0d81ac789aafb3667ca5d6e9cec871db8359/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f69616e73686d65616e2f594f4c4f2e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coveralls Status" data-canonical-src="https://coveralls.io/repos/github/ianshmean/YOLO.jl/badge.svg?branch=master" style="max-width:100%;"></a></td>
</tr>
</tbody>
</table>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<p>The package can be installed with the Julia package manager.
From the Julia REPL, type <code>]</code> to enter the Pkg REPL mode and run:</p>
<pre><code>pkg&gt; add YOLO
</code></pre>
<p>If you have a CUDA-supported graphics card, make sure that you have CUDA set up such that it satisfies <a href="https://github.com/JuliaGPU/CUDAapi.jl">CUDAapi.jl</a> or <a href="https://github.com/JuliaGPU/CuArrays.jl">CuArrays.jl</a> builds.</p>
<p>If you just want to run on CPU (or on a GPU-less CI instance) Knet.jl is currently dependent on a system compiler for the GPU-less conv layer, so make sure you have a compiler installed: i.e. <code>apt-get update &amp;&amp; apt-get install gcc g++</code> for linux or install visual studio for windows</p>
<h2><a id="user-content-example-usage-wip" class="anchor" aria-hidden="true" href="#example-usage-wip"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Example Usage (WIP)</h2>
<h3><a id="user-content-testing-a-dataset" class="anchor" aria-hidden="true" href="#testing-a-dataset"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Testing a dataset</h3>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> YOLO

<span class="pl-c"><span class="pl-c">#</span>First time only (downloads 5011 images &amp; labels!)</span>
YOLO<span class="pl-k">.</span><span class="pl-c1">download_dataset</span>(<span class="pl-s"><span class="pl-pds">"</span>voc2007<span class="pl-pds">"</span></span>)

settings <span class="pl-k">=</span> YOLO<span class="pl-k">.</span>pretrained<span class="pl-k">.</span>v2_tiny_voc<span class="pl-k">.</span><span class="pl-c1">load</span>(minibatch_size<span class="pl-k">=</span><span class="pl-c1">1</span>) <span class="pl-c"><span class="pl-c">#</span>run 1 image at a time</span>
model <span class="pl-k">=</span> YOLO<span class="pl-k">.</span>v2_tiny<span class="pl-k">.</span><span class="pl-c1">load</span>(settings)
YOLO<span class="pl-k">.</span><span class="pl-c1">loadWeights!</span>(model, settings)

voc <span class="pl-k">=</span> YOLO<span class="pl-k">.</span>datasets<span class="pl-k">.</span>VOC<span class="pl-k">.</span><span class="pl-c1">populate</span>()
vocloaded <span class="pl-k">=</span> YOLO<span class="pl-k">.</span><span class="pl-c1">load</span>(voc, settings, indexes <span class="pl-k">=</span> [<span class="pl-c1">100</span>]) <span class="pl-c"><span class="pl-c">#</span>load image #100 (a single image)</span>

<span class="pl-c"><span class="pl-c">#</span>Run the model</span>
res <span class="pl-k">=</span> <span class="pl-c1">model</span>(vocloaded<span class="pl-k">.</span>imstack_mat);

<span class="pl-c"><span class="pl-c">#</span>Convert the output into readable predictions</span>
predictions <span class="pl-k">=</span> YOLO<span class="pl-k">.</span><span class="pl-c1">postprocess</span>(res, settings, conf_thresh <span class="pl-k">=</span> <span class="pl-c1">0.3</span>, iou_thresh <span class="pl-k">=</span> <span class="pl-c1">0.3</span>)</pre></div>
<h3><a id="user-content-testing-a-single-custom-image" class="anchor" aria-hidden="true" href="#testing-a-single-custom-image"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Testing a single custom image</h3>
<p>To pass an image through, the image needs to be loaded, and scaled to the appropriate input size.
For YOLOv2-tiny that would be <code>(w, h, color_channels, minibatch_size) == (416, 416, 3, 1)</code>.</p>
<p><code>loadResizePadImageToFit</code> can be used to load, resize &amp; pad the image, while maintaining aspect ratio and anti-aliasing during the resize process.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> YOLO
<span class="pl-c"><span class="pl-c">#</span># Load once</span>
settings <span class="pl-k">=</span> YOLO<span class="pl-k">.</span>pretrained<span class="pl-k">.</span>v2_tiny_voc<span class="pl-k">.</span><span class="pl-c1">load</span>(minibatch_size<span class="pl-k">=</span><span class="pl-c1">1</span>) <span class="pl-c"><span class="pl-c">#</span>run 1 image at a time</span>
model <span class="pl-k">=</span> YOLO<span class="pl-k">.</span>v2_tiny<span class="pl-k">.</span><span class="pl-c1">load</span>(settings)
YOLO<span class="pl-k">.</span><span class="pl-c1">loadWeights!</span>(model, settings)

<span class="pl-c"><span class="pl-c">#</span># Run for each image</span>
imgmat <span class="pl-k">=</span> YOLO<span class="pl-k">.</span><span class="pl-c1">loadResizePadImageToFit</span>(<span class="pl-s"><span class="pl-pds">"</span>image.jpeg<span class="pl-pds">"</span></span>, settings)
res <span class="pl-k">=</span> <span class="pl-c1">model</span>(imgmat)
predictions <span class="pl-k">=</span> YOLO<span class="pl-k">.</span><span class="pl-c1">postprocess</span>(res, settings, conf_thresh <span class="pl-k">=</span> <span class="pl-c1">0.3</span>, iou_thresh <span class="pl-k">=</span> <span class="pl-c1">0.3</span>)</pre></div>
<p>or if the image is already in memory</p>
<pre><code>imgmat = loadResizePadImageToFit(img, settings)
res = model(imgmat)
predictions = YOLO.postprocess(res, settings, conf_thresh = 0.3, iou_thresh = 0.3)
</code></pre>
<h3><a id="user-content-rendering-results" class="anchor" aria-hidden="true" href="#rendering-results"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Rendering results</h3>
<p>To render results, first load <code>Makie</code> before <code>YOLO</code> (in a fresh julia instance):</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Makie, YOLO
<span class="pl-c"><span class="pl-c">#</span># Repeat all above steps to load &amp; run the model</span>
scene <span class="pl-k">=</span> YOLO<span class="pl-k">.</span><span class="pl-c1">renderResult</span>(vocloaded<span class="pl-k">.</span>imstack_mat[:,:,:,<span class="pl-c1">1</span>], predictions, settings, save_file <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>test.png<span class="pl-pds">"</span></span>)
<span class="pl-c1">display</span>(scene)</pre></div>
<h3><a id="user-content-testing-inference-speed" class="anchor" aria-hidden="true" href="#testing-inference-speed"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Testing inference speed</h3>
<p>The package tests include a small benchmark.
A 2018 macbook pro i7. CPU-only:</p>
<pre><code>[ Info: YOLO_v2_tiny inference time per image: 0.1313 seconds (7.62 fps)
[ Info: YOLO_v2_tiny postprocess time per image: 0.0023 seconds (444.07 fps)
[ Info: Total time per image: 0.1336 seconds (7.49 fps)
</code></pre>
<p>An i7 desktop with a GTX 1070 GPU:</p>
<pre><code>[ Info: YOLO_v2_tiny inference time per image: 0.0039 seconds (254.79 fps)
[ Info: YOLO_v2_tiny postprocess time per image: 0.0024 seconds (425.51 fps)
[ Info: Total time per image: 0.0063 seconds (159.36 fps)
</code></pre>
</article></div>