<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-hyperdimensional-computing-in-julia" class="anchor" aria-hidden="true" href="#hyperdimensional-computing-in-julia"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Hyperdimensional Computing in Julia</h1>
<p dir="auto"><a href="https://dimiboeckaerts.github.io/HyperdimensionalComputing.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://dimiboeckaerts.github.io/HyperdimensionalComputing.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/dimiboeckaerts/HyperdimensionalComputing.jl/actions"><img src="https://github.com/dimiboeckaerts/HyperdimensionalComputing.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/dimiboeckaerts/HyperdimensionalComputing.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/8cd3a72053d8677ca49be79436b1a39464b4b8f4481f13263f4fe6188b56daf3/68747470733a2f2f636f6465636f762e696f2f67682f64696d69626f65636b61657274732f487970657264696d656e73696f6e616c436f6d707574696e672e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/dimiboeckaerts/HyperdimensionalComputing.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">This package implements special types of vectors and associated methods for hyperdimensional computing. Hyperdimensional computing (HDC) is a paragdigm to represent patterns by means of a high-dimensional vectors (typically 10,000 dimensions). Specific operations can be used to create new vectors by combining the information or encoding some kind of position. HDC is an alternative machine learning method that is extremely computationally efficient. It is inspired by the distributed, holographic representation of patterns in the brain. Typically, the high-dimensionality is more important than the nature of the operations. This package provides various types of vectors (binary, graded, bipolar...) with sensible operations for <em>aggragating</em>, <em>binding</em> and <em>permutation</em>. Basic functionality for fitting a k-NN like classifier is also supported.</p>
<h2 dir="auto"><a id="user-content-basic-use" class="anchor" aria-hidden="true" href="#basic-use"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basic use</h2>
<p dir="auto">Several types of vectors are implemented. Random vectors can be initialized of different sizes.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using HyperdimensionalComputing

x = BipolarHDV()  # default length is 10,000

y = BinaryHDV(20)  # different length

z = RealHDV(Float32)  # specify data type"><pre><span class="pl-k">using</span> HyperdimensionalComputing

x <span class="pl-k">=</span> <span class="pl-c1">BipolarHDV</span>()  <span class="pl-c"><span class="pl-c">#</span> default length is 10,000</span>

y <span class="pl-k">=</span> <span class="pl-c1">BinaryHDV</span>(<span class="pl-c1">20</span>)  <span class="pl-c"><span class="pl-c">#</span> different length</span>

z <span class="pl-k">=</span> <span class="pl-c1">RealHDV</span>(Float32)  <span class="pl-c"><span class="pl-c">#</span> specify data type</span></pre></div>
<p dir="auto">The basic operations are <code>aggregate</code> (creating a vector that is similar to the provided vectors), <code>bind</code> (creating a vector that is dissimilar to the vectors) and <code>circshift</code> (shifting the vector inplace to create a new vector). For <code>aggregate</code> and <code>bind</code>, we overload <code>+</code> and <code>*</code> as binary operators, while <code>Π</code> is an alias for <code>circshift</code>. The latter is lazily implemented. All functions have an inplace version, using the <code>!</code> prefix.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="x, y, z = GradedHDV(10), GradedHDV(10), GradedHDV(10)

# aggregation

aggregate([x, y, z])

x + y

# binding

bind([x, y, z])
x * y

# permutation

circshift(x, 2)  # shifts the coordinates
Π(x, 2)  # same

Π!(y, 1)  # inplace"><pre>x, y, z <span class="pl-k">=</span> <span class="pl-c1">GradedHDV</span>(<span class="pl-c1">10</span>), <span class="pl-c1">GradedHDV</span>(<span class="pl-c1">10</span>), <span class="pl-c1">GradedHDV</span>(<span class="pl-c1">10</span>)

<span class="pl-c"><span class="pl-c">#</span> aggregation</span>

<span class="pl-c1">aggregate</span>([x, y, z])

x <span class="pl-k">+</span> y

<span class="pl-c"><span class="pl-c">#</span> binding</span>

<span class="pl-c1">bind</span>([x, y, z])
x <span class="pl-k">*</span> y

<span class="pl-c"><span class="pl-c">#</span> permutation</span>

<span class="pl-c1">circshift</span>(x, <span class="pl-c1">2</span>)  <span class="pl-c"><span class="pl-c">#</span> shifts the coordinates</span>
<span class="pl-c1">Π</span>(x, <span class="pl-c1">2</span>)  <span class="pl-c"><span class="pl-c">#</span> same</span>

<span class="pl-c1">Π!</span>(y, <span class="pl-c1">1</span>)  <span class="pl-c"><span class="pl-c">#</span> inplace</span></pre></div>
<p dir="auto">See the table for which operations are used for which type.</p>
<h2 dir="auto"><a id="user-content-embedding-sequences" class="anchor" aria-hidden="true" href="#embedding-sequences"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Embedding sequences</h2>
<p dir="auto">HDC is particularly powerful for embedding sequences. This is done by creating embeddings for n-grams and aggregating the n-grams found in the sequence.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# create dictionary for embedding
alphabet = &quot;ATCG&quot;
basis = Dict(c=&gt;RealHDV(100) for (c, hdv) in zip(alphabet, hdvs))

sequence = &quot;TAGTTTGAGGATCCGCTCGCTGCAACGCG&quot;

seq_embedding = sequence_embedding(sequence, basis, 3)  # embedding using 3-grams"><pre><span class="pl-c"><span class="pl-c">#</span> create dictionary for embedding</span>
alphabet <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>ATCG<span class="pl-pds">"</span></span>
basis <span class="pl-k">=</span> <span class="pl-c1">Dict</span>(c<span class="pl-k">=&gt;</span><span class="pl-c1">RealHDV</span>(<span class="pl-c1">100</span>) <span class="pl-k">for</span> (c, hdv) <span class="pl-k">in</span> <span class="pl-c1">zip</span>(alphabet, hdvs))

sequence <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>TAGTTTGAGGATCCGCTCGCTGCAACGCG<span class="pl-pds">"</span></span>

seq_embedding <span class="pl-k">=</span> <span class="pl-c1">sequence_embedding</span>(sequence, basis, <span class="pl-c1">3</span>)  <span class="pl-c"><span class="pl-c">#</span> embedding using 3-grams</span></pre></div>
<p dir="auto">If the size of the number of n-grams is not too large, it makes sense to precompute these to speed up the encoding process.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="threegrams = compute_3_grams(basis)

sequence_embedding(sequence, threegrams) "><pre>threegrams <span class="pl-k">=</span> <span class="pl-c1">compute_3_grams</span>(basis)

<span class="pl-c1">sequence_embedding</span>(sequence, threegrams) </pre></div>
<h2 dir="auto"><a id="user-content-training" class="anchor" aria-hidden="true" href="#training"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Training</h2>
<p dir="auto">A model is basically trained by making an aggregation of all elements within a class. Training is simple. Prediction is done by nearest-neighbor search based on <code>similarity</code>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="hdvs = [BipolarHDV() for i in 1:1000]  # 1000 vectors
y = rand(Bool, 1000)  # two labels

centers = train(y, hdvs)

predict(BipolarHDV(), centers)  # predict for a random vector
predict(hdvs, centers)  # repredict the labels"><pre>hdvs <span class="pl-k">=</span> [<span class="pl-c1">BipolarHDV</span>() <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">1000</span>]  <span class="pl-c"><span class="pl-c">#</span> 1000 vectors</span>
y <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Bool, <span class="pl-c1">1000</span>)  <span class="pl-c"><span class="pl-c">#</span> two labels</span>

centers <span class="pl-k">=</span> <span class="pl-c1">train</span>(y, hdvs)

<span class="pl-c1">predict</span>(<span class="pl-c1">BipolarHDV</span>(), centers)  <span class="pl-c"><span class="pl-c">#</span> predict for a random vector</span>
<span class="pl-c1">predict</span>(hdvs, centers)  <span class="pl-c"><span class="pl-c">#</span> repredict the labels</span></pre></div>
<p dir="auto">In practice, this leads to suboptimal performance. One can retrain the model by reaggregating the wrongly classified labels.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="retrain!(centers, y, hdvs, niters=10)"><pre><span class="pl-c1">retrain!</span>(centers, y, hdvs, niters<span class="pl-k">=</span><span class="pl-c1">10</span>)</pre></div>
<h2 dir="auto"><a id="user-content-overview-of-operations" class="anchor" aria-hidden="true" href="#overview-of-operations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Overview of operations</h2>
<table>
<thead>
<tr>
<th>Vector</th>
<th>element domain</th>
<th>aggregate</th>
<th>binding</th>
<th>similarity</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BinaryHDV</code></td>
<td>0, 1</td>
<td>majority</td>
<td>xor</td>
<td>Jaccard</td>
</tr>
<tr>
<td><code>BipolarHDV</code></td>
<td>-1, 0, 1</td>
<td>sum and threshold</td>
<td>multiply</td>
<td>cosine</td>
</tr>
<tr>
<td><code>GradedHDV</code></td>
<td>[0, 1]</td>
<td>3π</td>
<td>fuzzy xor</td>
<td>Jaccard</td>
</tr>
<tr>
<td><code>GradedBipolarHDV</code></td>
<td>[-1, 1]</td>
<td>3π</td>
<td>fuzzy xor</td>
<td>cosine</td>
</tr>
<tr>
<td><code>RealHDV</code></td>
<td>real</td>
<td>sum weighted to keep vector norm</td>
<td>multiply</td>
<td>cosine</td>
</tr>
</tbody>
</table>
</article></div>