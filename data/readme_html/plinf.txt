<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-plinfjl" class="anchor" aria-hidden="true" href="#plinfjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Plinf.jl</h1>
<p dir="auto">An architecture for planning, inverse planning, and inference in planning,
using <a href="https://github.com/ztangent/PDDL.jl">PDDL</a> and <a href="https://www.gen.dev/" rel="nofollow">Gen</a>.</p>
<h2 dir="auto"><a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Setup</h2>
<p dir="auto">To use this library in your own projects, press <code>]</code> at the Julia REPL to
enter the package manager, then run:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="add https://github.com/JuliaPlanners/PDDL.jl.git
add https://github.com/ztangent/Plinf.jl.git"><pre>add https<span class="pl-k">:</span><span class="pl-k">//</span>github<span class="pl-k">.</span>com<span class="pl-k">/</span>JuliaPlanners<span class="pl-k">/</span>PDDL<span class="pl-k">.</span>jl<span class="pl-k">.</span>git
add https<span class="pl-k">:</span><span class="pl-k">//</span>github<span class="pl-k">.</span>com<span class="pl-k">/</span>ztangent<span class="pl-k">/</span>Plinf<span class="pl-k">.</span>jl<span class="pl-k">.</span>git</pre></div>
<p dir="auto">To explore the examples provided in this repository, clone this repository,
press <code>]</code> at the Julia REPL to enter the package manager, then run <code>activate .</code>
and <code>instantiate</code> to install all necessary dependencies.</p>
<h2 dir="auto"><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h2>
<p dir="auto">Plinf.jl can be used to model agents that perform model-based heuristic search
to achieve their goals. Below, we visualize a sampled trace for a replanning
agent that interleaves resource-bounded plan search with plan execution:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="./img/replanning-agent.gif"><img src="./img/replanning-agent.gif" height="300" data-animated-image="" style="max-width: 100%;"></a></p>
<p dir="auto">We can then perform goal inference for these agents:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="./img/goal-inference-backtracking.gif"><img src="./img/goal-inference-backtracking.gif" height="300" data-animated-image="" style="max-width: 100%;"></a></p>
<p dir="auto">Notice that the correct goal is eventually inferred, despite backtracking
by the agent. This is because we model the agent as <em>boundedly rational</em>:
it does not always produce optimal plans. Indeed, this modeling assumption
also allows us to infer goals from <em>failed plans</em>:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="./img/goal-inference-failure.gif"><img src="./img/goal-inference-failure.gif" height="300" data-animated-image="" style="max-width: 100%;"></a></p>
<p dir="auto">Because we use the Planning Domain Definition Language (PDDL) as our underlying
state representation, our architecture supports a large range of domains,
including the classic Blocks World:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="./img/bw-goal-inference.gif"><img src="./img/bw-goal-inference.gif" height="300" data-animated-image="" style="max-width: 100%;"></a></p>
<p dir="auto">For more details about the modeling and inference architecture,
consult our paper:</p>
<p dir="auto">T. Zhi-Xuan, J. L. Mann, T. Silver, J. B. Tenenbaum, and V. K. Mansinghka,
<a href="http://arxiv.org/abs/2006.07532" rel="nofollow">“Online Bayesian Goal Inference for Boundedly-Rational Planning Agents,”</a> arXiv:2006.07532 [cs], Jun. 2020.</p>
<p dir="auto">Full example code for several domains can be found here:
<a href="domains/gridworld/example.jl">Gridworld</a>;
<a href="domains/doors-keys-gems/example.jl">Doors, Keys &amp; Gems</a>;
<a href="domains/block-words/example.jl">Block Words</a></p>
</article></div>