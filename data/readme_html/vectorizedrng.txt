<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-vectorizedrng" class="anchor" aria-hidden="true" href="#vectorizedrng"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>VectorizedRNG</h1>
<p dir="auto"><a href="https://JuliaSIMD.github.io/VectorizedRNG.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://JuliaSIMD.github.io/VectorizedRNG.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667" alt="Latest" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/JuliaSIMD/VectorizedRNG.jl/actions?query=workflow%3ACI"><img src="https://github.com/JuliaSIMD/VectorizedRNG.jl/workflows/CI/badge.svg" alt="CI" style="max-width: 100%;"></a>
<a href="https://github.com/JuliaSIMD/VectorizedRNG.jl/actions?query=workflow%3A%22CI+%28Julia+nightly%29%22"><img src="https://github.com/JuliaSIMD/VectorizedRNG.jl/workflows/CI%20(Julia%20nightly)/badge.svg" alt="CI (Julia nightly)" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/JuliaSIMD/VectorizedRNG.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/0d0710a91cdef88e4aeceade2aec4292ee86301931b0e7841d2c5b185f7c4ffa/68747470733a2f2f636f6465636f762e696f2f67682f4a756c696153494d442f566563746f72697a6564524e472e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Codecov" data-canonical-src="https://codecov.io/gh/JuliaSIMD/VectorizedRNG.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">This library provides a vectorized Xoshiro256++ random number generator. The larger the host computers SIMD vector width, the better they will perform. On a machine with AVX-512, they are faster than <a href="http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/SFMT/" rel="nofollow">SIMD-oriented Fast Mersenne Twister (SFMT)</a>. Base Julia used dSFMT, up to version 1.7, which in a few tests appears to outperform this library on AVX2 systems in generating uniformly distributed random numbers.</p>
<p dir="auto">You can get a thread-local instance of the <code>Xoshiro</code> generator with <code>local_rng()</code>. Each parallel stream jumps ahead <code>2^128</code> samples, which should be more than enough samples per stream for any real calculation. Each thread gets 8 parallel streams with AVX, or 16 with AVX512, allowing there to be up to <code>2^125</code> or <code>2^124</code> threads with AVX512.</p>
<p dir="auto">Testing on an old haswell machine (AVX2-only):</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using BenchmarkTools, Random, VectorizedRNG

julia&gt; x = Vector{Float64}(undef, 1024);

julia&gt; @benchmark randn!($x)
BenchmarkTools.Trial:
  memory estimate:  0 bytes
  allocs estimate:  0
  --------------
  minimum time:     7.235 μs (0.00% GC)
  median time:      7.900 μs (0.00% GC)
  mean time:        8.034 μs (0.00% GC)
  maximum time:     233.290 μs (0.00% GC)
  --------------
  samples:          10000
  evals/sample:     5
 
julia&gt; @benchmark randn!(local_rng(), $x)
BenchmarkTools.Trial:
  memory estimate:  0 bytes
  allocs estimate:  0
  --------------
  minimum time:     3.744 μs (0.00% GC)
  median time:      4.156 μs (0.00% GC)
  mean time:        4.137 μs (0.00% GC)
  maximum time:     59.169 μs (0.00% GC)
  --------------
  samples:          10000
  evals/sample:     8"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> BenchmarkTools, Random, VectorizedRNG

julia<span class="pl-k">&gt;</span> x <span class="pl-k">=</span> <span class="pl-c1">Vector</span><span class="pl-c1">{Float64}</span>(undef, <span class="pl-c1">1024</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">randn!</span>(<span class="pl-k">$</span>x)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span>
  memory estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span> bytes
  allocs estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span>
  <span class="pl-k">--------------</span>
  minimum time<span class="pl-k">:</span>     <span class="pl-c1">7.235</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  median time<span class="pl-k">:</span>      <span class="pl-c1">7.900</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  mean time<span class="pl-k">:</span>        <span class="pl-c1">8.034</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  maximum time<span class="pl-k">:</span>     <span class="pl-c1">233.290</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  <span class="pl-k">--------------</span>
  samples<span class="pl-k">:</span>          <span class="pl-c1">10000</span>
  evals<span class="pl-k">/</span>sample<span class="pl-k">:</span>     <span class="pl-c1">5</span>
 
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">randn!</span>(<span class="pl-c1">local_rng</span>(), <span class="pl-k">$</span>x)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span>
  memory estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span> bytes
  allocs estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span>
  <span class="pl-k">--------------</span>
  minimum time<span class="pl-k">:</span>     <span class="pl-c1">3.744</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  median time<span class="pl-k">:</span>      <span class="pl-c1">4.156</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  mean time<span class="pl-k">:</span>        <span class="pl-c1">4.137</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  maximum time<span class="pl-k">:</span>     <span class="pl-c1">59.169</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  <span class="pl-k">--------------</span>
  samples<span class="pl-k">:</span>          <span class="pl-c1">10000</span>
  evals<span class="pl-k">/</span>sample<span class="pl-k">:</span>     <span class="pl-c1">8</span></pre></div>
<p dir="auto">The performance advantage is thanks primarily to a fast SIMD <a href="https://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform" rel="nofollow">Box-Muller</a> implementation; <code>randn(::MersenneTwister)</code> uses the ziggurat algorithm, which is more efficient for scalars. Performance is closer when only comparing random-uniform generation:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; @benchmark rand!($x)
BenchmarkTools.Trial:
  memory estimate:  0 bytes
  allocs estimate:  0
  --------------
  minimum time:     791.047 ns (0.00% GC)
  median time:      904.541 ns (0.00% GC)
  mean time:        915.753 ns (0.00% GC)
  maximum time:     13.978 μs (0.00% GC)
  --------------
  samples:          10000
  evals/sample:     85
 
julia&gt; @benchmark rand!(local_rng(), $x)
BenchmarkTools.Trial:
  memory estimate:  0 bytes
  allocs estimate:  0
  --------------
  minimum time:     513.000 ns (0.00% GC)
  median time:      568.578 ns (0.00% GC)
  mean time:        571.597 ns (0.00% GC)
  maximum time:     4.706 μs (0.00% GC)
  --------------
  samples:          10000
  evals/sample:     192"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">rand!</span>(<span class="pl-k">$</span>x)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span>
  memory estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span> bytes
  allocs estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span>
  <span class="pl-k">--------------</span>
  minimum time<span class="pl-k">:</span>     <span class="pl-c1">791.047</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  median time<span class="pl-k">:</span>      <span class="pl-c1">904.541</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  mean time<span class="pl-k">:</span>        <span class="pl-c1">915.753</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  maximum time<span class="pl-k">:</span>     <span class="pl-c1">13.978</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  <span class="pl-k">--------------</span>
  samples<span class="pl-k">:</span>          <span class="pl-c1">10000</span>
  evals<span class="pl-k">/</span>sample<span class="pl-k">:</span>     <span class="pl-c1">85</span>
 
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">rand!</span>(<span class="pl-c1">local_rng</span>(), <span class="pl-k">$</span>x)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span>
  memory estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span> bytes
  allocs estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span>
  <span class="pl-k">--------------</span>
  minimum time<span class="pl-k">:</span>     <span class="pl-c1">513.000</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  median time<span class="pl-k">:</span>      <span class="pl-c1">568.578</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  mean time<span class="pl-k">:</span>        <span class="pl-c1">571.597</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  maximum time<span class="pl-k">:</span>     <span class="pl-c1">4.706</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  <span class="pl-k">--------------</span>
  samples<span class="pl-k">:</span>          <span class="pl-c1">10000</span>
  evals<span class="pl-k">/</span>sample<span class="pl-k">:</span>     <span class="pl-c1">192</span></pre></div>
<p dir="auto">This library shines on a system with AVX512:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using BenchmarkTools, Random, VectorizedRNG

julia&gt; x = Vector{Float64}(undef, 1024);

julia&gt; @benchmark randn!($x)
BenchmarkTools.Trial:
  memory estimate:  0 bytes
  allocs estimate:  0
  --------------
  minimum time:     1.676 μs (0.00% GC)
  median time:      1.798 μs (0.00% GC)
  mean time:        1.883 μs (0.00% GC)
  maximum time:     5.769 μs (0.00% GC)
  --------------
  samples:          10000
  evals/sample:     10

julia&gt; @benchmark randn!(local_rng(), $x)
BenchmarkTools.Trial:
  memory estimate:  0 bytes
  allocs estimate:  0
  --------------
  minimum time:     854.446 ns (0.00% GC)
  median time:      962.369 ns (0.00% GC)
  mean time:        991.798 ns (0.00% GC)
  maximum time:     1.818 μs (0.00% GC)
  --------------
  samples:          10000
  evals/sample:     65

julia&gt; @benchmark rand!($x)
BenchmarkTools.Trial:
  memory estimate:  0 bytes
  allocs estimate:  0
  --------------
  minimum time:     549.856 ns (0.00% GC)
  median time:      567.626 ns (0.00% GC)
  mean time:        603.958 ns (0.00% GC)
  maximum time:     1.124 μs (0.00% GC)
  --------------
  samples:          10000
  evals/sample:     187

julia&gt; @benchmark rand!(local_rng(), $x)
BenchmarkTools.Trial:
  memory estimate:  0 bytes
  allocs estimate:  0
  --------------
  minimum time:     159.907 ns (0.00% GC)
  median time:      171.258 ns (0.00% GC)
  mean time:        174.272 ns (0.00% GC)
  maximum time:     958.197 ns (0.00% GC)
  --------------
  samples:          10000
  evals/sample:     788

julia&gt; versioninfo()
Julia Version 1.6.0-DEV.1581
Commit 377aa809eb (2020-11-26 01:44 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-11.0.0 (ORCJIT, tigerlake)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> BenchmarkTools, Random, VectorizedRNG

julia<span class="pl-k">&gt;</span> x <span class="pl-k">=</span> <span class="pl-c1">Vector</span><span class="pl-c1">{Float64}</span>(undef, <span class="pl-c1">1024</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">randn!</span>(<span class="pl-k">$</span>x)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span>
  memory estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span> bytes
  allocs estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span>
  <span class="pl-k">--------------</span>
  minimum time<span class="pl-k">:</span>     <span class="pl-c1">1.676</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  median time<span class="pl-k">:</span>      <span class="pl-c1">1.798</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  mean time<span class="pl-k">:</span>        <span class="pl-c1">1.883</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  maximum time<span class="pl-k">:</span>     <span class="pl-c1">5.769</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  <span class="pl-k">--------------</span>
  samples<span class="pl-k">:</span>          <span class="pl-c1">10000</span>
  evals<span class="pl-k">/</span>sample<span class="pl-k">:</span>     <span class="pl-c1">10</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">randn!</span>(<span class="pl-c1">local_rng</span>(), <span class="pl-k">$</span>x)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span>
  memory estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span> bytes
  allocs estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span>
  <span class="pl-k">--------------</span>
  minimum time<span class="pl-k">:</span>     <span class="pl-c1">854.446</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  median time<span class="pl-k">:</span>      <span class="pl-c1">962.369</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  mean time<span class="pl-k">:</span>        <span class="pl-c1">991.798</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  maximum time<span class="pl-k">:</span>     <span class="pl-c1">1.818</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  <span class="pl-k">--------------</span>
  samples<span class="pl-k">:</span>          <span class="pl-c1">10000</span>
  evals<span class="pl-k">/</span>sample<span class="pl-k">:</span>     <span class="pl-c1">65</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">rand!</span>(<span class="pl-k">$</span>x)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span>
  memory estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span> bytes
  allocs estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span>
  <span class="pl-k">--------------</span>
  minimum time<span class="pl-k">:</span>     <span class="pl-c1">549.856</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  median time<span class="pl-k">:</span>      <span class="pl-c1">567.626</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  mean time<span class="pl-k">:</span>        <span class="pl-c1">603.958</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  maximum time<span class="pl-k">:</span>     <span class="pl-c1">1.124</span> μs (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  <span class="pl-k">--------------</span>
  samples<span class="pl-k">:</span>          <span class="pl-c1">10000</span>
  evals<span class="pl-k">/</span>sample<span class="pl-k">:</span>     <span class="pl-c1">187</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">rand!</span>(<span class="pl-c1">local_rng</span>(), <span class="pl-k">$</span>x)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span>
  memory estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span> bytes
  allocs estimate<span class="pl-k">:</span>  <span class="pl-c1">0</span>
  <span class="pl-k">--------------</span>
  minimum time<span class="pl-k">:</span>     <span class="pl-c1">159.907</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  median time<span class="pl-k">:</span>      <span class="pl-c1">171.258</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  mean time<span class="pl-k">:</span>        <span class="pl-c1">174.272</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  maximum time<span class="pl-k">:</span>     <span class="pl-c1">958.197</span> ns (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)
  <span class="pl-k">--------------</span>
  samples<span class="pl-k">:</span>          <span class="pl-c1">10000</span>
  evals<span class="pl-k">/</span>sample<span class="pl-k">:</span>     <span class="pl-c1">788</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">versioninfo</span>()
Julia Version <span class="pl-c1">1.6</span>.<span class="pl-c1">0</span><span class="pl-k">-</span>DEV.<span class="pl-c1">1581</span>
Commit <span class="pl-c1">377</span>aa809eb (<span class="pl-c1">2020</span><span class="pl-k">-</span><span class="pl-c1">11</span><span class="pl-k">-</span><span class="pl-c1">26</span> <span class="pl-c1">01</span><span class="pl-k">:</span><span class="pl-c1">44</span> UTC)
Platform Info<span class="pl-k">:</span>
  OS<span class="pl-k">:</span> Linux (x86_64<span class="pl-k">-</span>linux<span class="pl-k">-</span>gnu)
  CPU<span class="pl-k">:</span> <span class="pl-c1">11</span>th Gen <span class="pl-c1">Intel</span>(R) <span class="pl-c1">Core</span>(TM) i7<span class="pl-k">-</span><span class="pl-c1">1165</span>G7 @ <span class="pl-c1">2.80</span>GHz
  WORD_SIZE<span class="pl-k">:</span> <span class="pl-c1">64</span>
  LIBM<span class="pl-k">:</span> libopenlibm
  LLVM<span class="pl-k">:</span> libLLVM<span class="pl-k">-</span><span class="pl-c1">11.0</span>.<span class="pl-c1">0</span> (ORCJIT, tigerlake)</pre></div>
<h2 dir="auto"><a id="user-content-setting-the-seed" class="anchor" aria-hidden="true" href="#setting-the-seed"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Setting the seed</h2>
<p dir="auto">VectorizedRNG is initialized with a random seed (based on the default <code>Random.GLOBAL_RNG</code>) when loaded, but <code>Random.seed!</code> wont change the state of the VectorizedRNG. You can set the seed of the VectorizedRNG with <code>VectorizedRNG.seed!</code>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using VectorizedRNG

julia&gt; rand(local_rng(), 15)'
1×15 LinearAlgebra.Adjoint{Float64,Array{Float64,1}}:
 0.580812  0.813531  0.359055  0.590277  0.551968  0.635421  0.160614  0.312387  0.00787783  0.554571  0.368705  0.0219756  0.804188  0.0740875  0.939065

julia&gt; VectorizedRNG.seed!(1)

julia&gt; rand(local_rng(), 15)'
1×15 LinearAlgebra.Adjoint{Float64,Array{Float64,1}}:
 0.371016  0.804553  0.243923  0.261726  0.875966  0.942672  0.875786  0.0255004  0.236359  0.59697  0.480488  0.790366  0.0263995  0.715227  0.514725

julia&gt; rand(local_rng(), 15)'
1×15 LinearAlgebra.Adjoint{Float64,Array{Float64,1}}:
 0.246595  0.326417  0.98997  0.335991  0.839723  0.628247  0.814513  0.924231  0.398405  0.604068  0.915064  0.984332  0.773448  0.325699  0.490881

julia&gt; VectorizedRNG.seed!(1)

julia&gt; rand(local_rng(), 15)'
1×15 LinearAlgebra.Adjoint{Float64,Array{Float64,1}}:
 0.371016  0.804553  0.243923  0.261726  0.875966  0.942672  0.875786  0.0255004  0.236359  0.59697  0.480488  0.790366  0.0263995  0.715227  0.514725

julia&gt; rand(local_rng(), 15)'
1×15 LinearAlgebra.Adjoint{Float64,Array{Float64,1}}:
 0.246595  0.326417  0.98997  0.335991  0.839723  0.628247  0.814513  0.924231  0.398405  0.604068  0.915064  0.984332  0.773448  0.325699  0.490881"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> VectorizedRNG

julia<span class="pl-k">&gt;</span> <span class="pl-c1">rand</span>(<span class="pl-c1">local_rng</span>(), <span class="pl-c1">15</span>)<span class="pl-k">'</span>
<span class="pl-c1">1</span><span class="pl-k">×</span><span class="pl-c1">15</span> LinearAlgebra<span class="pl-k">.</span>Adjoint{Float64,Array{Float64,<span class="pl-c1">1</span>}}<span class="pl-k">:</span>
 <span class="pl-c1">0.580812</span>  <span class="pl-c1">0.813531</span>  <span class="pl-c1">0.359055</span>  <span class="pl-c1">0.590277</span>  <span class="pl-c1">0.551968</span>  <span class="pl-c1">0.635421</span>  <span class="pl-c1">0.160614</span>  <span class="pl-c1">0.312387</span>  <span class="pl-c1">0.00787783</span>  <span class="pl-c1">0.554571</span>  <span class="pl-c1">0.368705</span>  <span class="pl-c1">0.0219756</span>  <span class="pl-c1">0.804188</span>  <span class="pl-c1">0.0740875</span>  <span class="pl-c1">0.939065</span>

julia<span class="pl-k">&gt;</span> VectorizedRNG<span class="pl-k">.</span><span class="pl-c1">seed!</span>(<span class="pl-c1">1</span>)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">rand</span>(<span class="pl-c1">local_rng</span>(), <span class="pl-c1">15</span>)<span class="pl-k">'</span>
<span class="pl-c1">1</span><span class="pl-k">×</span><span class="pl-c1">15</span> LinearAlgebra<span class="pl-k">.</span>Adjoint{Float64,Array{Float64,<span class="pl-c1">1</span>}}<span class="pl-k">:</span>
 <span class="pl-c1">0.371016</span>  <span class="pl-c1">0.804553</span>  <span class="pl-c1">0.243923</span>  <span class="pl-c1">0.261726</span>  <span class="pl-c1">0.875966</span>  <span class="pl-c1">0.942672</span>  <span class="pl-c1">0.875786</span>  <span class="pl-c1">0.0255004</span>  <span class="pl-c1">0.236359</span>  <span class="pl-c1">0.59697</span>  <span class="pl-c1">0.480488</span>  <span class="pl-c1">0.790366</span>  <span class="pl-c1">0.0263995</span>  <span class="pl-c1">0.715227</span>  <span class="pl-c1">0.514725</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">rand</span>(<span class="pl-c1">local_rng</span>(), <span class="pl-c1">15</span>)<span class="pl-k">'</span>
<span class="pl-c1">1</span><span class="pl-k">×</span><span class="pl-c1">15</span> LinearAlgebra<span class="pl-k">.</span>Adjoint{Float64,Array{Float64,<span class="pl-c1">1</span>}}<span class="pl-k">:</span>
 <span class="pl-c1">0.246595</span>  <span class="pl-c1">0.326417</span>  <span class="pl-c1">0.98997</span>  <span class="pl-c1">0.335991</span>  <span class="pl-c1">0.839723</span>  <span class="pl-c1">0.628247</span>  <span class="pl-c1">0.814513</span>  <span class="pl-c1">0.924231</span>  <span class="pl-c1">0.398405</span>  <span class="pl-c1">0.604068</span>  <span class="pl-c1">0.915064</span>  <span class="pl-c1">0.984332</span>  <span class="pl-c1">0.773448</span>  <span class="pl-c1">0.325699</span>  <span class="pl-c1">0.490881</span>

julia<span class="pl-k">&gt;</span> VectorizedRNG<span class="pl-k">.</span><span class="pl-c1">seed!</span>(<span class="pl-c1">1</span>)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">rand</span>(<span class="pl-c1">local_rng</span>(), <span class="pl-c1">15</span>)<span class="pl-k">'</span>
<span class="pl-c1">1</span><span class="pl-k">×</span><span class="pl-c1">15</span> LinearAlgebra<span class="pl-k">.</span>Adjoint{Float64,Array{Float64,<span class="pl-c1">1</span>}}<span class="pl-k">:</span>
 <span class="pl-c1">0.371016</span>  <span class="pl-c1">0.804553</span>  <span class="pl-c1">0.243923</span>  <span class="pl-c1">0.261726</span>  <span class="pl-c1">0.875966</span>  <span class="pl-c1">0.942672</span>  <span class="pl-c1">0.875786</span>  <span class="pl-c1">0.0255004</span>  <span class="pl-c1">0.236359</span>  <span class="pl-c1">0.59697</span>  <span class="pl-c1">0.480488</span>  <span class="pl-c1">0.790366</span>  <span class="pl-c1">0.0263995</span>  <span class="pl-c1">0.715227</span>  <span class="pl-c1">0.514725</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">rand</span>(<span class="pl-c1">local_rng</span>(), <span class="pl-c1">15</span>)<span class="pl-k">'</span>
<span class="pl-c1">1</span><span class="pl-k">×</span><span class="pl-c1">15</span> LinearAlgebra<span class="pl-k">.</span>Adjoint{Float64,Array{Float64,<span class="pl-c1">1</span>}}<span class="pl-k">:</span>
 <span class="pl-c1">0.246595</span>  <span class="pl-c1">0.326417</span>  <span class="pl-c1">0.98997</span>  <span class="pl-c1">0.335991</span>  <span class="pl-c1">0.839723</span>  <span class="pl-c1">0.628247</span>  <span class="pl-c1">0.814513</span>  <span class="pl-c1">0.924231</span>  <span class="pl-c1">0.398405</span>  <span class="pl-c1">0.604068</span>  <span class="pl-c1">0.915064</span>  <span class="pl-c1">0.984332</span>  <span class="pl-c1">0.773448</span>  <span class="pl-c1">0.325699</span>  <span class="pl-c1">0.490881</span></pre></div>
<h2 dir="auto"><a id="user-content-bigcrush" class="anchor" aria-hidden="true" href="#bigcrush"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>BigCrush</h2>
<p dir="auto">The generators pass <a href="https://github.com/andreasnoack/RNGTest.jl">BigCrush</a>. We can run BigCrush in a matter of minutes on a multicore system (10980XE CPU). Testing the uniform number generator:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Distributed; addprocs(); nprocs()
37

julia&gt; @everywhere using RNGTest, VectorizedRNG, Random

julia&gt; @everywhere struct U01 &lt;: Random.AbstractRNG end

julia&gt; @everywhere Random.rand!(r::U01, x::AbstractArray) = rand!(local_rng(), x)

julia&gt; u01 = U01()
U01()

julia&gt; rngunif = RNGTest.wrap(U01(), Float64);

julia&gt; @time bcjunif = RNGTest.bigcrushJulia(rngunif);
511.531281 seconds (31.91 M allocations: 1.619 GiB, 0.10% gc time)

julia&gt; minimum(minimum.(bcjunif))
0.004345184234132201

julia&gt; maximum(maximum.(bcjunif))
0.99900365621945"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Distributed; <span class="pl-c1">addprocs</span>(); <span class="pl-c1">nprocs</span>()
<span class="pl-c1">37</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@everywhere</span> <span class="pl-k">using</span> RNGTest, VectorizedRNG, Random

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@everywhere</span> <span class="pl-k">struct</span> U01 <span class="pl-k">&lt;:</span> <span class="pl-c1">Random.AbstractRNG</span> <span class="pl-k">end</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@everywhere</span> Random<span class="pl-k">.</span><span class="pl-en">rand!</span>(r<span class="pl-k">::</span><span class="pl-c1">U01</span>, x<span class="pl-k">::</span><span class="pl-c1">AbstractArray</span>) <span class="pl-k">=</span> <span class="pl-c1">rand!</span>(<span class="pl-c1">local_rng</span>(), x)

julia<span class="pl-k">&gt;</span> u01 <span class="pl-k">=</span> <span class="pl-c1">U01</span>()
<span class="pl-c1">U01</span>()

julia<span class="pl-k">&gt;</span> rngunif <span class="pl-k">=</span> RNGTest<span class="pl-k">.</span><span class="pl-c1">wrap</span>(<span class="pl-c1">U01</span>(), Float64);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@time</span> bcjunif <span class="pl-k">=</span> RNGTest<span class="pl-k">.</span><span class="pl-c1">bigcrushJulia</span>(rngunif);
<span class="pl-c1">511.531281</span> seconds (<span class="pl-c1">31.91</span> M allocations<span class="pl-k">:</span> <span class="pl-c1">1.619</span> GiB, <span class="pl-c1">0.10</span><span class="pl-k">%</span> gc time)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">minimum</span>(<span class="pl-c1">minimum</span>.(bcjunif))
<span class="pl-c1">0.004345184234132201</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">maximum</span>(<span class="pl-c1">maximum</span>.(bcjunif))
<span class="pl-c1">0.99900365621945</span></pre></div>
<p dir="auto">While not great looking minimum or maximum p-values. For comparison, the default MersenneTwister:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; wrappedtwister = RNGTest.wrap(MersenneTwister(), Float64);

julia&gt; @time bcjmtwister = RNGTest.bigcrushJulia(wrappedtwister);
481.782432 seconds (9.73 M allocations: 508.753 MiB, 0.04% gc time)

julia&gt; minimum(minimum.(bcjmtwister))
0.0015850804769910467

julia&gt; maximum(maximum.(bcjmtwister))
0.9912021397939957"><pre>julia<span class="pl-k">&gt;</span> wrappedtwister <span class="pl-k">=</span> RNGTest<span class="pl-k">.</span><span class="pl-c1">wrap</span>(<span class="pl-c1">MersenneTwister</span>(), Float64);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@time</span> bcjmtwister <span class="pl-k">=</span> RNGTest<span class="pl-k">.</span><span class="pl-c1">bigcrushJulia</span>(wrappedtwister);
<span class="pl-c1">481.782432</span> seconds (<span class="pl-c1">9.73</span> M allocations<span class="pl-k">:</span> <span class="pl-c1">508.753</span> MiB, <span class="pl-c1">0.04</span><span class="pl-k">%</span> gc time)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">minimum</span>(<span class="pl-c1">minimum</span>.(bcjmtwister))
<span class="pl-c1">0.0015850804769910467</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">maximum</span>(<span class="pl-c1">maximum</span>.(bcjmtwister))
<span class="pl-c1">0.9912021397939957</span></pre></div>
<p dir="auto">Interestingly, this completed faster. I should've monitored clock speeds, but can say that (subjectively) the CPU fans were louder when running this benchmark, making me wonder if this is a case where downclocking of non-AVX code decreases performance.</p>
<p dir="auto">Watch out when mixing vectorized and non-vectorized code.</p>
<hr>
<p dir="auto">On vectorization: the strategy is to simply have many distinct streams, and sample from them simultaneously via SIMD operations.</p>
</article></div>