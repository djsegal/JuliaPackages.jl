<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-tulliojl" class="anchor" aria-hidden="true" href="#tulliojl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tullio.jl</h1>
<p><a href="https://travis-ci.org/mcabbott/Tullio.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/6c1720942def9e0f7956d26f82b5c3c59d032051/68747470733a2f2f7472617669732d63692e6f72672f6d636162626f74742f54756c6c696f2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/mcabbott/Tullio.jl.svg?branch=master" style="max-width:100%;"></a></p>
<p>This is a package is for writing array operations in index notation, such as:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">@tullio</span> M[x,y,c] <span class="pl-k">:=</span> N[x<span class="pl-k">+</span>i, y<span class="pl-k">+</span>j,c] <span class="pl-k">*</span> K[i,j]     <span class="pl-c"><span class="pl-c">#</span> sum over i,j, and create M</span>

<span class="pl-c1">@tullio</span> S[x] <span class="pl-k">=</span> P[x,y] <span class="pl-k">*</span> <span class="pl-c1">log</span>(Q[x,y] <span class="pl-k">/</span> R[y])     <span class="pl-c"><span class="pl-c">#</span> sum over y, and write into S</span>

<span class="pl-c1">@tullio</span> A[i,j] <span class="pl-k">+=</span> B[i,k,l] <span class="pl-k">*</span> C[l,j] <span class="pl-k">*</span> D[k,j]   <span class="pl-c"><span class="pl-c">#</span> sum over k,l, and add to values in A</span>

<span class="pl-c1">@tullio</span> (<span class="pl-k">*</span>) Z[j] <span class="pl-k">:=</span> X[ind[k],j] <span class="pl-k">*</span> <span class="pl-c1">exp</span>(<span class="pl-k">-</span>Y[k])   <span class="pl-c"><span class="pl-c">#</span> product over k</span></pre></div>
<p>Used by itself the macro writes ordinary nested loops much like <a href="https://github.com/ahwillia/Einsum.jl"><code>Einsum.@einsum</code></a>.
One difference is that it can parse more expressions (such as the convolution <code>M</code>, and worse).
Another is that it will use multi-threading (via <a href="https://julialang.org/blog/2019/07/multithreading/" rel="nofollow"><code>Threads.@spawn</code></a>), dividing large enough arrays into blocks.
But it also co-operates with various other packages, provided they are loaded before the macro is called:</p>
<ul>
<li>
<p>It can use <a href="https://github.com/chriselrod/LoopVectorization.jl"><code>LoopVectorization.@avx</code></a> to speed many things up. (Disable with <code>avx=false</code>.)</p>
</li>
<li>
<p>It can use <a href="https://github.com/JuliaGPU/KernelAbstractions.jl"><code>KernelAbstractions.@kernel</code></a> to make a GPU version. (Disable with <code>cuda=false</code>.)</p>
</li>
<li>
<p>It can use <a href="https://github.com/Jutho/TensorOperations.jl"><code>TensorOperations.@tensor</code></a> on expressions which this understands. (Disable with <code>tensor=false</code>.) These must be Einstein-convention contractions of one term; none of the examples above qualify.</p>
</li>
</ul>
<p>Gradients are handled as follows:</p>
<ul>
<li>
<p>It will try to take a symbolic derivative of the right hand side expression, for use with any of <a href="https://github.com/FluxML/Tracker.jl">Tracker</a>, <a href="https://github.com/FluxML/Zygote.jl">Zygote</a> or <a href="https://github.com/JuliaDiff/ReverseDiff.jl">ReverseDiff</a>. (Disable with <code>grad=false</code>.) When using <code>@tensor</code>, this writes another <code>@tensor</code> expression for each input array. Otherwise, it generates one set of loops to fill in all the gradient arrays at once.</p>
</li>
<li>
<p>The option <code>grad=Dual</code> uses instead <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff</a> to differentiate the right hand side. This allows for more complicated expressions.</p>
</li>
</ul>
<p>The expression need not be just one line, for example:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">@tullio</span> out[x,y,n] <span class="pl-k">:=</span> <span class="pl-k">begin</span>              <span class="pl-c"><span class="pl-c">#</span> sum over a,b</span>
        i <span class="pl-k">=</span> <span class="pl-c1">mod</span>(x<span class="pl-k">+</span>a, <span class="pl-c1">axes</span>(mat,<span class="pl-c1">1</span>))
        j <span class="pl-k">=</span> <span class="pl-c1">mod</span>(y<span class="pl-k">+</span>b, <span class="pl-c1">axes</span>(mat,<span class="pl-c1">2</span>))
        <span class="pl-c1">@inbounds</span> mat[i,j,n] <span class="pl-k">*</span> <span class="pl-c1">abs</span>(kern[a,b])
    <span class="pl-k">end</span> (x <span class="pl-k">in</span> <span class="pl-c1">axes</span>(mat,<span class="pl-c1">1</span>), y <span class="pl-k">in</span> <span class="pl-c1">axes</span>(mat,<span class="pl-c1">2</span>)) grad<span class="pl-k">=</span>Dual</pre></div>
<p>Here the macro cannot infer the range of the output's indices <code>x,y</code>,
so they must be provided explicitly. (If writing into an existing array,
with <code>out[x,y,n] = begin ...</code> or <code>+=</code>, then ranges would be taken from there.)
It knows that it should not sum over indices <code>i,j</code>, but since it can't be sure
of their ranges, it will not add <code>@inbounds</code> in such cases.
It will also not be able to take a symbolic derivative here, but dual numbers will work fine.</p>
<p>The option <code>@tullio verbose=true</code> will cause it to print index ranges, symbolic derivatives,
and notices when it is unable to use the packages mentioned above.</p>
<details><summary><b>Notation</b></summary>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Pkg; <span class="pl-s"><span class="pl-pds"><span class="pl-c1">pkg</span>"</span>add Tullio<span class="pl-pds">"</span></span> <span class="pl-c"><span class="pl-c">#</span> now registered</span>
<span class="pl-k">using</span> Tullio
A <span class="pl-k">=</span> [<span class="pl-c1">abs2</span>(i <span class="pl-k">-</span> <span class="pl-c1">11</span>) <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">21</span>]

<span class="pl-c"><span class="pl-c">#</span> Downsample -- range of i is that allowed by both terms:</span>
<span class="pl-c1">@tullio</span> D[i] <span class="pl-k">:=</span> (A[<span class="pl-c1">2</span>i] <span class="pl-k">+</span> A[<span class="pl-c1">2</span>i<span class="pl-k">+</span><span class="pl-c1">1</span>])<span class="pl-k">/</span><span class="pl-c1">2</span>  <span class="pl-c"><span class="pl-c">#</span> 1:10 == intersect(1:10, 0:10)</span>

<span class="pl-c"><span class="pl-c">#</span> Shifts -- range of i calculated in terms of that given for j:</span>
<span class="pl-c1">@tullio</span> M[i,j] <span class="pl-k">:=</span> A[i<span class="pl-k">+</span>j<span class="pl-k">-</span><span class="pl-c1">1</span>]  (j <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">15</span>)  <span class="pl-c"><span class="pl-c">#</span> i in 1:7</span>

<span class="pl-k">using</span> OffsetArrays <span class="pl-c"><span class="pl-c">#</span> Convolve a filter:</span>
K <span class="pl-k">=</span> <span class="pl-c1">OffsetArray</span>([<span class="pl-c1">1</span>,<span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">1</span>], <span class="pl-k">-</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">2</span>)
<span class="pl-c1">@tullio</span> C[i] <span class="pl-k">:=</span> A[i<span class="pl-k">+</span>j] <span class="pl-k">*</span> K[j]  <span class="pl-c"><span class="pl-c">#</span> j ∈ -2:2 implies i ∈ 3:19</span>

<span class="pl-c"><span class="pl-c">#</span> Index by the values in K</span>
<span class="pl-c1">@tullio</span> D[i,j] <span class="pl-k">:=</span> A[<span class="pl-c1">2</span>K[j]<span class="pl-k">+</span>i] <span class="pl-k">÷</span> K[j] <span class="pl-c"><span class="pl-c">#</span> extrema(K)==(-1,2) implies i ∈ 3:17</span>

<span class="pl-k">using</span> FFTW <span class="pl-c"><span class="pl-c">#</span> Functions of the indices are OK:</span>
S <span class="pl-k">=</span> [<span class="pl-c1">0</span>,<span class="pl-c1">1</span>,<span class="pl-c1">0</span>,<span class="pl-c1">0</span>, <span class="pl-c1">0</span>,<span class="pl-c1">0</span>,<span class="pl-c1">0</span>,<span class="pl-c1">0</span>]
<span class="pl-c1">fft</span>(S) <span class="pl-k">≈</span> <span class="pl-c1">@tullio</span> (k <span class="pl-k">∈</span> <span class="pl-c1">axes</span>(S,<span class="pl-c1">1</span>)) F[k] <span class="pl-k">:=</span> S[x] <span class="pl-k">*</span> <span class="pl-c1">exp</span>(<span class="pl-k">-</span>im<span class="pl-k">*</span>pi<span class="pl-k">/</span><span class="pl-c1">8</span> <span class="pl-k">*</span> (k<span class="pl-k">-</span><span class="pl-c1">1</span>) <span class="pl-k">*</span> x)

<span class="pl-c"><span class="pl-c">#</span> Access to fields &amp; arrays -- this uses j ∈ eachindex(first(N).c)</span>
N <span class="pl-k">=</span> [(a<span class="pl-k">=</span>i, b<span class="pl-k">=</span>i<span class="pl-k">^</span><span class="pl-c1">2</span>, c<span class="pl-k">=</span><span class="pl-c1">fill</span>(i<span class="pl-k">^</span><span class="pl-c1">3</span>,<span class="pl-c1">3</span>)) <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">10</span>]
<span class="pl-c1">@tullio</span> T[i,j] <span class="pl-k">:=</span> (N[i]<span class="pl-k">.</span>a <span class="pl-k">//</span> <span class="pl-c1">1</span>, N[i]<span class="pl-k">.</span>c[j])

<span class="pl-c"><span class="pl-c">#</span> Functions which create arrays are evaluated once:</span>
<span class="pl-c1">@tullio</span> R[i,j] <span class="pl-k">:=</span> <span class="pl-c1">abs</span>.((<span class="pl-c1">rand</span>(Int8, <span class="pl-c1">5</span>)[i], <span class="pl-c1">rand</span>(Int8, <span class="pl-c1">5</span>)[j]))

<span class="pl-k">using</span> NamedDims, AxisKeys <span class="pl-c"><span class="pl-c">#</span> Dimension names, plus pretty printing:</span>
<span class="pl-c1">@tullio</span> M[row<span class="pl-k">=</span>i, col<span class="pl-k">=</span>j, z<span class="pl-k">=</span>k] <span class="pl-k">:=</span> A[i<span class="pl-k">+</span>j<span class="pl-k">-</span><span class="pl-c1">1</span>]  (j <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">15</span>, k <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2</span>)
<span class="pl-c1">@tullio</span> S[i] <span class="pl-k">:=</span> M[col<span class="pl-k">=</span>j<span class="pl-k">-</span>i, z<span class="pl-k">=</span>k, row<span class="pl-k">=</span>i<span class="pl-k">+</span><span class="pl-c1">1</span>] <span class="pl-c"><span class="pl-c">#</span> sum over j,k</span></pre></div>
</details>
<details><summary><b>Threads &amp; SIMD</b></summary>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Tullio, LoopVectorization, NNlib, BenchmarkTools

<span class="pl-c"><span class="pl-c">#</span> Batched matmul with batch index first in B, defined with @avx loops:</span>
<span class="pl-en">bmm_rev</span>(A, B) <span class="pl-k">=</span> <span class="pl-c1">@tullio</span> C[i,k,b] <span class="pl-k">:=</span> A[i,j,b] <span class="pl-k">*</span> B[b,k,j]  <span class="pl-c"><span class="pl-c">#</span> (sum over j)</span>

A <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">20</span>,<span class="pl-c1">30</span>,<span class="pl-c1">500</span>); B <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">500</span>,<span class="pl-c1">40</span>,<span class="pl-c1">30</span>);
<span class="pl-c1">bmm_rev</span>(A, B) <span class="pl-k">≈</span> NNlib<span class="pl-k">.</span><span class="pl-c1">batched_mul</span>(A, <span class="pl-c1">permutedims</span>(B, (<span class="pl-c1">3</span>,<span class="pl-c1">2</span>,<span class="pl-c1">1</span>))) <span class="pl-c"><span class="pl-c">#</span> true</span>

<span class="pl-c1">@btime</span> <span class="pl-c1">bmm_rev</span>(<span class="pl-k">$</span>A, <span class="pl-k">$</span>B); <span class="pl-c"><span class="pl-c">#</span> 317.526 μs μs, same speed as un-permuted bmm</span>
<span class="pl-c1">@btime</span> NNlib<span class="pl-k">.</span><span class="pl-c1">batched_mul</span>(<span class="pl-k">$</span>A, <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>B, (<span class="pl-c1">3</span>,<span class="pl-c1">2</span>,<span class="pl-c1">1</span>))); <span class="pl-c"><span class="pl-c">#</span> 1.478 ms, with MKL</span>

<span class="pl-c"><span class="pl-c">#</span> Complete reduction, without first materialising X .* log.(Y')</span>
<span class="pl-en">sum_opp</span>(X, Y<span class="pl-k">=</span>X) <span class="pl-k">=</span> <span class="pl-c1">@tullio</span> s <span class="pl-k">:=</span> X[i,j] <span class="pl-k">*</span> <span class="pl-c1">log</span>(Y[j,i])

X <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">1000</span>,<span class="pl-c1">1000</span>);
<span class="pl-c1">@btime</span> <span class="pl-c1">sum_opp</span>(<span class="pl-k">$</span>X)                    <span class="pl-c"><span class="pl-c">#</span>   499.814 μs (173 allocations: 14.20 KiB)</span>
<span class="pl-c1">@btime</span> <span class="pl-c1">sum</span>(<span class="pl-k">$</span>X <span class="pl-k">.*</span> <span class="pl-c1">log</span>.(<span class="pl-c1">transpose</span>(<span class="pl-k">$</span>X))) <span class="pl-c"><span class="pl-c">#</span> 8.759 ms (2 allocations: 7.63 MiB)</span></pre></div>
</details>
<details><summary><b>Derivatives &amp; GPU</b></summary>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Tullio
<span class="pl-en">mul</span>(A, B) <span class="pl-k">=</span> <span class="pl-c1">@tullio</span> C[i,k] <span class="pl-k">:=</span> A[i,j] <span class="pl-k">*</span> B[j,k] 

A <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">3</span>,<span class="pl-c1">40</span>); B <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">40</span>,<span class="pl-c1">500</span>);
A <span class="pl-k">*</span> B <span class="pl-k">≈</span> <span class="pl-c1">mul</span>(A, B) <span class="pl-c"><span class="pl-c">#</span> true</span>

<span class="pl-k">using</span> Tracker
ΔA <span class="pl-k">=</span> Tracker<span class="pl-k">.</span><span class="pl-c1">gradient</span>((A,B) <span class="pl-k">-&gt;</span> <span class="pl-c1">sum</span>(<span class="pl-c1">mul</span>(A, B)), A, B)[<span class="pl-c1">1</span>]
ΔA <span class="pl-k">≈</span> <span class="pl-c1">ones</span>(<span class="pl-c1">3</span>,<span class="pl-c1">500</span>) <span class="pl-k">*</span> B<span class="pl-k">'</span> <span class="pl-c"><span class="pl-c">#</span> true</span>

<span class="pl-k">using</span> CuArrays, KernelAbstractions <span class="pl-c"><span class="pl-c">#</span> Now defined with a GPU version:</span>
<span class="pl-en">mul</span>(A, B) <span class="pl-k">=</span> <span class="pl-c1">@tullio</span> C[i,k] <span class="pl-k">:=</span> A[i,j] <span class="pl-k">*</span> B[j,k]

<span class="pl-c1">cu</span>(A <span class="pl-k">*</span> B) <span class="pl-k">≈</span> <span class="pl-c1">mul</span>(<span class="pl-c1">cu</span>(A), <span class="pl-c1">cu</span>(B)) <span class="pl-c"><span class="pl-c">#</span> true</span>

<span class="pl-c1">cu</span>(ΔA) <span class="pl-k">≈</span> Tracker<span class="pl-k">.</span><span class="pl-c1">gradient</span>((A,B) <span class="pl-k">-&gt;</span> <span class="pl-c1">sum</span>(<span class="pl-c1">mul</span>(A, B)), <span class="pl-c1">cu</span>(A), <span class="pl-c1">cu</span>(B))[<span class="pl-c1">1</span>] <span class="pl-c"><span class="pl-c">#</span> true</span></pre></div>
</details>
<details><summary><b>Larger expressions</b></summary>
<div class="highlight highlight-source-julia"><pre>mat <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">10</span>,<span class="pl-c1">10</span>,<span class="pl-c1">1</span>); mat[<span class="pl-c1">1</span>,<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">101</span>;
<span class="pl-c1">@tullio</span> kern[i,j] <span class="pl-k">:=</span> <span class="pl-c1">1</span><span class="pl-k">/</span>(<span class="pl-c1">1</span><span class="pl-k">+</span>i<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">+</span>j<span class="pl-k">^</span><span class="pl-c1">2</span>)  (i <span class="pl-k">in</span> <span class="pl-k">-</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">2</span>, j <span class="pl-k">in</span> <span class="pl-k">-</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">2</span>)

<span class="pl-c1">@tullio</span> out[x,y,c] <span class="pl-k">:=</span> <span class="pl-k">begin</span>
    xi <span class="pl-k">=</span> <span class="pl-c1">mod</span>(x<span class="pl-k">+</span>i, <span class="pl-c1">axes</span>(mat,<span class="pl-c1">1</span>)) <span class="pl-c"><span class="pl-c">#</span> xi = ... means that it won't be summed,</span>
    yj <span class="pl-k">=</span> <span class="pl-c1">mod</span>(y<span class="pl-k">+</span>j, <span class="pl-c1">axes</span>(mat,<span class="pl-c1">2</span>))
    <span class="pl-c1">@inbounds</span> <span class="pl-c1">trunc</span>(Int, mat[xi, yj, c] <span class="pl-k">*</span> kern[i,j]) <span class="pl-c"><span class="pl-c">#</span> and disables automatic @inbounds,</span>
<span class="pl-k">end</span> (x <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">10</span>, y <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">10</span>) <span class="pl-c"><span class="pl-c">#</span> and prevents range of x from being inferred.</span></pre></div>
</details>
<details><summary><b>Options</b></summary>
<p>The default setting is:
<code>@tullio threads=true fastmath=true avx=true tensor=true cuda=256 grad=Base verbose=false A[i,j] := ...</code></p>
<ul>
<li><code>threads=false</code> turns off threading, while <code>threads=64^3</code> sets a threshold size at which to divide the work (replacing the macro's best guess).</li>
<li><code>avx=false</code> turns off the use of <code>LoopVectorization</code>, while <code>avx=4</code> inserts <code>@avx unroll=4 for i in ...</code>.</li>
<li><code>grad=false</code> turns off gradient calculation, and <code>grad=Dual</code> switches it to use <code>ForwardDiff</code> (which must be loaded).</li>
<li><code>tensor=false</code> turns off the use of <code>TensorOperations</code>.</li>
<li>Assignment <code>xi = ...</code> removes <code>xi</code> from the list of indices: its range is note calculated, and it will not be summed over. It also disables <code>@inbounds</code> since this is now up to you.</li>
<li><code>verbose=true</code> prints things like the index ranges inferred, and gradient calculations. <code>verbose=2</code> prints absolutely everything.</li>
<li><code>A[i,j] := ...</code> makes a new array, while <code>A[i,j] = ...</code> and <code>A[i,j] += ...</code> write into an existing one. <code>A[row=i, col=j] := ...</code> makes a new <code>NamedDimsArray</code>.</li>
<li><code>@tullio (*) A[i,j] := ...</code> is a product, as is <code>@tullio A[i,j] *= ...</code>.</li>
</ul>
<p>Implicit:</p>
<ul>
<li>Indices without shifts must have the same range everywhere they appear, but those with shifts (even <code>A[i+0]</code>) run over the inersection of possible ranges.</li>
<li>Shifted output indices must start at 1, unless <code>OffsetArrays</code> is visible in the calling module.</li>
<li>The use of <code>@avx</code>, and the calculation of gradients, are switched off by sufficiently complex syntax (such as arrays of arrays).</li>
<li>Gradient hooks are attached for any or all of <code>ReverseDiff</code>, <code>Tracker</code> &amp; <code>Zygote</code>. These packages need not be loaded when the macro is run.</li>
<li>Gradients are only defined for reductions over <code>(+)</code> (default) and <code>min</code>, <code>max</code>.</li>
<li>GPU kernels are only constructed when both <code>KernelAbstractions</code> and <code>CuArray</code> are visible. The default <code>cuda=256</code> is passed to <code>kernel(CUDA(), 256)</code>.</li>
<li>The CPU kernels from <code>KernelAbstractions</code> are called only when <code>threads=false</code>; they are not at present very fast, but perhaps useful for testing.</li>
</ul>
<p>Extras:</p>
<ul>
<li><code>A[i] := i^2  (i in 1:10)</code> is how you specify a range for indices when this can't be inferred.</li>
<li><code>A[i] := B[i, $col] - C[i, 2]</code> is how you fix one index to a constant (to prevent <code>col</code> being summed over).</li>
<li><code>A[i] := $d * B[i]</code> is the preferred way to include other constants. Note that no gradient is calculated for <code>d</code>.</li>
<li><code>Tullio.@printgrad (x+y)*log(x/z)   x y z</code> prints out how symbolic derivatives will be done.</li>
</ul>
</details>
<details><summary><b>Elsewhere</b></summary>
<p>Back-end friends &amp; relatives:</p>
<ul>
<li>
<p><a href="https://github.com/chriselrod/LoopVectorization.jl">LoopVectorization.jl</a> is used here, if available.</p>
</li>
<li>
<p><a href="https://github.com/MasonProtter/Gaius.jl">Gaius.jl</a> and <a href="https://github.com/chriselrod/PaddedMatrices.jl">PaddedMatrices.jl</a> build on that.</p>
</li>
<li>
<p><a href="https://github.com/vchuravy/GPUifyLoops.jl">GPUifyLoops.jl</a> and <a href="https://github.com/JuliaGPU/KernelAbstractions.jl">KernelAbstractions.jl</a> generate GPU-compatable kernels.</p>
</li>
<li>
<p><a href="https://github.com/tkf/ThreadsX.jl">ThreadsX.jl</a> does threaded reductions, and much else.</p>
</li>
<li>
<p><a href="https://github.com/Jutho/Strided.jl">Strided.jl</a> does multi-threaded broadcasting.</p>
</li>
</ul>
<p>Front-end near-lookalikes:</p>
<ul>
<li>
<p><a href="https://github.com/ahwillia/Einsum.jl">Einsum.jl</a> makes simple loops. See <a href="https://github.com/mcabbott/Tullio.jl/blob/master/test/einsum.jl">tests/einsum.jl</a> where <code>using Tullio: @einsum</code> is an almost-seamless replaceement.</p>
</li>
<li>
<p><a href="https://github.com/Jutho/TensorOperations.jl">TensorOperations.jl</a> and <a href="https://github.com/under-Peter/OMEinsum.jl">OMEinsum.jl</a> identify patterns on which they can call various basic operations.</p>
</li>
<li>
<p><a href="https://github.com/mcabbott/TensorCast.jl">TensorCast.jl</a> expresses everything as Julia array operations, broadcasting and reduction. (OMEinsum.jl also treats some cases as a special lazy broadcast-reduction.)</p>
</li>
</ul>
<p>Things you can't run:</p>
<ul>
<li>
<p><a href="https://www.youtube.com/watch?v=Rp7sTl9oPNI" rel="nofollow">Tortilla.jl</a> seems to exist, publicly, only in this very nice talk.</p>
</li>
<li>
<p><a href="https://github.com/shashi/ArrayMeta.jl">ArrayMeta.jl</a> was a Julia 0.5 take on some of this.</p>
</li>
<li>
<p><a href="https://github.com/MikeInnes/Tokamak">Tokamak.jl</a> was another, see <a href="https://github.com/tkelman/Tokamak.jl">readme here</a>.</p>
</li>
</ul>
</details></article></div>