<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-objectdetectorjl" class="anchor" aria-hidden="true" href="#objectdetectorjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ObjectDetector.jl</h1>
<p>Object detection via YOLO in Julia. YOLO models are loaded directly from Darknet .cfg and .weights files as Flux models.
Uses CUDA, if available.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>Requires julia v1.3+. From the Julia REPL, type <code>]</code> to enter the Pkg REPL mode and run:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="pkg&gt; add ObjectDetector
"><pre><code>pkg&gt; add ObjectDetector
</code></pre></div>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<p><a target="_blank" rel="noopener noreferrer" href="examples/prettyprint.png"><img src="examples/prettyprint.png" alt="prettyprint example" style="max-width:100%;"></a></p>
<h3><a id="user-content-loading-and-running-on-an-image" class="anchor" aria-hidden="true" href="#loading-and-running-on-an-image"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Loading and running on an image</h3>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using ObjectDetector, FileIO

yolomod = YOLO.v3_608_COCO(batch=1, silent=true) # Load the YOLOv3-tiny model pretrained on COCO, with a batch size of 1

batch = emptybatch(yolomod) # Create a batch object. Automatically uses the GPU if available

img = load(joinpath(dirname(dirname(pathof(ObjectDetector))),&quot;test&quot;,&quot;images&quot;,&quot;dog-cycle-car.png&quot;))

batch[:,:,:,1], padding = prepareImage(img, yolomod) # Send resized image to the batch

res = yolomod(batch, detectThresh=0.5, overlapThresh=0.8) # Run the model on the length-1 batch
"><pre><span class="pl-k">using</span> ObjectDetector, FileIO

yolomod <span class="pl-k">=</span> YOLO<span class="pl-k">.</span><span class="pl-c1">v3_608_COCO</span>(batch<span class="pl-k">=</span><span class="pl-c1">1</span>, silent<span class="pl-k">=</span><span class="pl-c1">true</span>) <span class="pl-c"><span class="pl-c">#</span> Load the YOLOv3-tiny model pretrained on COCO, with a batch size of 1</span>

batch <span class="pl-k">=</span> <span class="pl-c1">emptybatch</span>(yolomod) <span class="pl-c"><span class="pl-c">#</span> Create a batch object. Automatically uses the GPU if available</span>

img <span class="pl-k">=</span> <span class="pl-c1">load</span>(<span class="pl-c1">joinpath</span>(<span class="pl-c1">dirname</span>(<span class="pl-c1">dirname</span>(<span class="pl-c1">pathof</span>(ObjectDetector))),<span class="pl-s"><span class="pl-pds">"</span>test<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>images<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>dog-cycle-car.png<span class="pl-pds">"</span></span>))

batch[:,:,:,<span class="pl-c1">1</span>], padding <span class="pl-k">=</span> <span class="pl-c1">prepareImage</span>(img, yolomod) <span class="pl-c"><span class="pl-c">#</span> Send resized image to the batch</span>

res <span class="pl-k">=</span> <span class="pl-c1">yolomod</span>(batch, detectThresh<span class="pl-k">=</span><span class="pl-c1">0.5</span>, overlapThresh<span class="pl-k">=</span><span class="pl-c1">0.8</span>) <span class="pl-c"><span class="pl-c">#</span> Run the model on the length-1 batch</span></pre></div>
<p>Note that while the convention in Julia is column-major, where images are loaded
such that a <em>widescreen</em> image matrix would have a smaller 1st dimension than 2nd.
Darknet is row-major, so the image matrix needs to have its first and second dims
permuted before being passed to batch. Otherwise features may not be detected due to
being rotated 90º. The function <code>prepareImage()</code> includes this conversion automatically.</p>
<p>Also, non-square models can be loaded, but care should be taken to ensure that each
dimension is an integer multiple of the filter size of the first conv layer (typically 16 or 32).</p>
<h3><a id="user-content-visualizing-the-result" class="anchor" aria-hidden="true" href="#visualizing-the-result"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Visualizing the result</h3>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="imgBoxes = drawBoxes(img, yolomod, padding, res)
save(&quot;result.png&quot;, imgBoxes)
"><pre>imgBoxes <span class="pl-k">=</span> <span class="pl-c1">drawBoxes</span>(img, yolomod, padding, res)
<span class="pl-c1">save</span>(<span class="pl-s"><span class="pl-pds">"</span>result.png<span class="pl-pds">"</span></span>, imgBoxes)</pre></div>
<p><a target="_blank" rel="noopener noreferrer" href="test/results/dog-cycle-car/v3_608_COCO.png"><img src="test/results/dog-cycle-car/v3_608_COCO.png" alt="dog-cycle-car with boxes" style="max-width:100%;"></a></p>
<h2><a id="user-content-pretrained-models" class="anchor" aria-hidden="true" href="#pretrained-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Pretrained Models</h2>
<p>The darknet YOLO models from <a href="https://pjreddie.com/darknet/yolo/" rel="nofollow">https://pjreddie.com/darknet/yolo/</a> that are pretrained on the COCO dataset are available:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="YOLO.v2_COCO() #Currently broken
YOLO.v2_tiny_COCO()

YOLO.v3_COCO()
YOLO.v3_spp_608_COCO() #Currently broken
YOLO.v3_tiny_COCO()
"><pre>YOLO<span class="pl-k">.</span><span class="pl-c1">v2_COCO</span>() <span class="pl-c"><span class="pl-c">#</span>Currently broken</span>
YOLO<span class="pl-k">.</span><span class="pl-c1">v2_tiny_COCO</span>()

YOLO<span class="pl-k">.</span><span class="pl-c1">v3_COCO</span>()
YOLO<span class="pl-k">.</span><span class="pl-c1">v3_spp_608_COCO</span>() <span class="pl-c"><span class="pl-c">#</span>Currently broken</span>
YOLO<span class="pl-k">.</span><span class="pl-c1">v3_tiny_COCO</span>()</pre></div>
<p>Their width and height can be modified with:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="YOLO.v3_COCO(w=416,h=416)
"><pre>YOLO<span class="pl-k">.</span><span class="pl-c1">v3_COCO</span>(w<span class="pl-k">=</span><span class="pl-c1">416</span>,h<span class="pl-k">=</span><span class="pl-c1">416</span>)</pre></div>
<p>and further configurations can be modified by editing the .cfg file structure after its read, but before its loaded:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="yolomod = YOLO.v3_COCO(silent=false, cfgchanges=[(:net, 1, :width, 512), (:net, 1, :height, 384)])
"><pre>yolomod <span class="pl-k">=</span> YOLO<span class="pl-k">.</span><span class="pl-c1">v3_COCO</span>(silent<span class="pl-k">=</span><span class="pl-c1">false</span>, cfgchanges<span class="pl-k">=</span>[(<span class="pl-c1">:net</span>, <span class="pl-c1">1</span>, <span class="pl-c1">:width</span>, <span class="pl-c1">512</span>), (<span class="pl-c1">:net</span>, <span class="pl-c1">1</span>, <span class="pl-c1">:height</span>, <span class="pl-c1">384</span>)])</pre></div>
<p><code>cfgchanges</code> takes the form of a vector of tuples with:
<code>(layer symbol, ith layer that matches given symbol, field symbol, value)</code>
Note that if <code>cfgchanges</code> is provided, optional <code>h</code> and <code>w</code> args are ignored.</p>
<p>Also, convenient sized models can be loaded via:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="YOLO.v2_608_COCO()
YOLO.v2_tiny_416_COCO()

YOLO.v3_320_COCO()
YOLO.v3_416_COCO()
YOLO.v3_608_COCO()
YOLO.v3_spp_608_COCO()
YOLO.v3_tiny_416_COCO()
"><pre>YOLO<span class="pl-k">.</span><span class="pl-c1">v2_608_COCO</span>()
YOLO<span class="pl-k">.</span><span class="pl-c1">v2_tiny_416_COCO</span>()

YOLO<span class="pl-k">.</span><span class="pl-c1">v3_320_COCO</span>()
YOLO<span class="pl-k">.</span><span class="pl-c1">v3_416_COCO</span>()
YOLO<span class="pl-k">.</span><span class="pl-c1">v3_608_COCO</span>()
YOLO<span class="pl-k">.</span><span class="pl-c1">v3_spp_608_COCO</span>()
YOLO<span class="pl-k">.</span><span class="pl-c1">v3_tiny_416_COCO</span>()</pre></div>
<p>Or custom models can be loaded with:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="YOLO.yolo(&quot;path/to/model.cfg&quot;, &quot;path/to/weights.weights&quot;, 1) # `1` is the batch size.
"><pre>YOLO<span class="pl-k">.</span><span class="pl-c1">yolo</span>(<span class="pl-s"><span class="pl-pds">"</span>path/to/model.cfg<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>path/to/weights.weights<span class="pl-pds">"</span></span>, <span class="pl-c1">1</span>) <span class="pl-c"><span class="pl-c">#</span> `1` is the batch size.</span></pre></div>
<p>For instance the pretrained models are defined as:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="function v3_COCO(;batch=1, silent=false, cfgchanges=nothing, w=416, h=416)
    cfgchanges=[(:net, 1, :width, w), (:net, 1, :height, h)]
    yolo(joinpath(models_dir,&quot;yolov3-416.cfg&quot;), joinpath(artifact&quot;yolov3-COCO&quot;, &quot;yolov3-COCO.weights&quot;), batch, silent=silent, cfgchanges=cfgchanges)
end
"><pre><span class="pl-k">function</span> <span class="pl-en">v3_COCO</span>(;batch<span class="pl-k">=</span><span class="pl-c1">1</span>, silent<span class="pl-k">=</span><span class="pl-c1">false</span>, cfgchanges<span class="pl-k">=</span><span class="pl-c1">nothing</span>, w<span class="pl-k">=</span><span class="pl-c1">416</span>, h<span class="pl-k">=</span><span class="pl-c1">416</span>)
    cfgchanges<span class="pl-k">=</span>[(<span class="pl-c1">:net</span>, <span class="pl-c1">1</span>, <span class="pl-c1">:width</span>, w), (<span class="pl-c1">:net</span>, <span class="pl-c1">1</span>, <span class="pl-c1">:height</span>, h)]
    <span class="pl-c1">yolo</span>(<span class="pl-c1">joinpath</span>(models_dir,<span class="pl-s"><span class="pl-pds">"</span>yolov3-416.cfg<span class="pl-pds">"</span></span>), <span class="pl-c1">joinpath</span>(<span class="pl-s"><span class="pl-pds"><span class="pl-c1">artifact</span>"</span>yolov3-COCO<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>yolov3-COCO.weights<span class="pl-pds">"</span></span>), batch, silent<span class="pl-k">=</span>silent, cfgchanges<span class="pl-k">=</span>cfgchanges)
<span class="pl-k">end</span></pre></div>
<p>The weights are stored as lazily-loaded julia artifacts (introduced in Julia 1.3).</p>
<h2><a id="user-content-benchmarking" class="anchor" aria-hidden="true" href="#benchmarking"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Benchmarking</h2>
<p>Pretrained models can be easily tested with <code>ObjectDetector.benchmark()</code>.</p>
<p>Note that the benchmark was run once before the examples here. Initial load time
of the first model loaded is typically between 3-20 seconds. See the <a href="#package-compilation">package-compilation</a>  section below for compilation instructions to speed up loading.</p>
<p>A desktop with a GTX 2060:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="julia&gt; ObjectDetector.benchmark()

┌──────────────────┬─────────┬───────────────┬──────┬──────────────┬────────────────┐
│            Model │ loaded? │ load time (s) │ ran? │ run time (s) │ run time (fps) │
├──────────────────┼─────────┼───────────────┼──────┼──────────────┼────────────────┤
│ v2_tiny_416_COCO │    true │          0.16 │ true │       0.0037 │          266.7 │
│ v3_tiny_416_COCO │    true │         0.243 │ true │       0.0042 │          236.4 │
│      v3_320_COCO │    true │         1.264 │ true │       0.0209 │           47.8 │
│      v3_416_COCO │    true │         1.456 │ true │        0.031 │           32.3 │
│      v3_608_COCO │    true │         2.423 │ true │       0.0686 │           14.6 │
└──────────────────┴─────────┴───────────────┴──────┴──────────────┴────────────────┘
"><pre><code>julia&gt; ObjectDetector.benchmark()

┌──────────────────┬─────────┬───────────────┬──────┬──────────────┬────────────────┐
│            Model │ loaded? │ load time (s) │ ran? │ run time (s) │ run time (fps) │
├──────────────────┼─────────┼───────────────┼──────┼──────────────┼────────────────┤
│ v2_tiny_416_COCO │    true │          0.16 │ true │       0.0037 │          266.7 │
│ v3_tiny_416_COCO │    true │         0.243 │ true │       0.0042 │          236.4 │
│      v3_320_COCO │    true │         1.264 │ true │       0.0209 │           47.8 │
│      v3_416_COCO │    true │         1.456 │ true │        0.031 │           32.3 │
│      v3_608_COCO │    true │         2.423 │ true │       0.0686 │           14.6 │
└──────────────────┴─────────┴───────────────┴──────┴──────────────┴────────────────┘
</code></pre></div>
<p>A 2019 Macbook Pro (CPU-only, no CUDA):</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="┌──────────────────┬─────────┬───────────────┬──────┬──────────────┬────────────────┐
│            Model │ loaded? │ load time (s) │ ran? │ run time (s) │ run time (fps) │
├──────────────────┼─────────┼───────────────┼──────┼──────────────┼────────────────┤
│ v2_tiny_416_COCO │    true │         0.305 │ true │       0.1383 │            7.2 │
│ v3_tiny_416_COCO │    true │         0.267 │ true │       0.1711 │            5.8 │
│      v3_320_COCO │    true │         1.617 │ true │       0.8335 │            1.2 │
│      v3_416_COCO │    true │         2.377 │ true │       1.4138 │            0.7 │
│      v3_608_COCO │    true │         4.239 │ true │       3.1122 │            0.3 │
└──────────────────┴─────────┴───────────────┴──────┴──────────────┴────────────────┘
"><pre><code>┌──────────────────┬─────────┬───────────────┬──────┬──────────────┬────────────────┐
│            Model │ loaded? │ load time (s) │ ran? │ run time (s) │ run time (fps) │
├──────────────────┼─────────┼───────────────┼──────┼──────────────┼────────────────┤
│ v2_tiny_416_COCO │    true │         0.305 │ true │       0.1383 │            7.2 │
│ v3_tiny_416_COCO │    true │         0.267 │ true │       0.1711 │            5.8 │
│      v3_320_COCO │    true │         1.617 │ true │       0.8335 │            1.2 │
│      v3_416_COCO │    true │         2.377 │ true │       1.4138 │            0.7 │
│      v3_608_COCO │    true │         4.239 │ true │       3.1122 │            0.3 │
└──────────────────┴─────────┴───────────────┴──────┴──────────────┴────────────────┘
</code></pre></div>
<h2><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples</h2>
<p>All run with <code>detectThresh = 0.5</code>, <code>overlapThresh = 0.5</code></p>
<h3><a id="user-content-yolov2_tiny_416_coco" class="anchor" aria-hidden="true" href="#yolov2_tiny_416_coco"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>YOLO.v2_tiny_416_COCO</h3>
<p><a target="_blank" rel="noopener noreferrer" href="test/results/dog-cycle-car/v2_tiny_416_COCO.png"><img src="test/results/dog-cycle-car/v2_tiny_416_COCO.png" alt="v2_tiny_416_COCO" style="max-width:100%;"></a></p>
<h3><a id="user-content-yolov3_tiny_416_coco" class="anchor" aria-hidden="true" href="#yolov3_tiny_416_coco"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>YOLO.v3_tiny_416_COCO</h3>
<p><a target="_blank" rel="noopener noreferrer" href="test/results/dog-cycle-car/v3_tiny_416_COCO.png"><img src="test/results/dog-cycle-car/v3_tiny_416_COCO.png" alt="v3_tiny_416_COCO" style="max-width:100%;"></a></p>
<h3><a id="user-content-yolov3_320_coco" class="anchor" aria-hidden="true" href="#yolov3_320_coco"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>YOLO.v3_320_COCO</h3>
<p><a target="_blank" rel="noopener noreferrer" href="test/results/dog-cycle-car/v3_320_COCO.png"><img src="test/results/dog-cycle-car/v3_320_COCO.png" alt="v3_320_COCO" style="max-width:100%;"></a></p>
<h3><a id="user-content-yolov3_416_coco" class="anchor" aria-hidden="true" href="#yolov3_416_coco"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>YOLO.v3_416_COCO</h3>
<p><a target="_blank" rel="noopener noreferrer" href="test/results/dog-cycle-car/v3_416_COCO.png"><img src="test/results/dog-cycle-car/v3_416_COCO.png" alt="v3_416_COCO" style="max-width:100%;"></a></p>
<h3><a id="user-content-yolov3_608_coco" class="anchor" aria-hidden="true" href="#yolov3_608_coco"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>YOLO.v3_608_COCO</h3>
<p><a target="_blank" rel="noopener noreferrer" href="test/results/dog-cycle-car/v3_608_COCO.png"><img src="test/results/dog-cycle-car/v3_608_COCO.png" alt="v3_608_COCO" style="max-width:100%;"></a></p>
<h2><a id="user-content-package-compilation" class="anchor" aria-hidden="true" href="#package-compilation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Package Compilation</h2>
<p>If initial load times are critical, the package can be compiled and loaded as a
sysimage, such that initial load time reduces to ~4 seconds, and loading of the
first model also takes ~4 seconds (as opposed to current performance on 1.3.0 of
~20 seconds for package load, and ~20 seconds for first model load).</p>
<p>See <a href="dev/compilation/compiler.jl">dev/compilation/compiler.jl</a> for instructions.</p>
</article></div>