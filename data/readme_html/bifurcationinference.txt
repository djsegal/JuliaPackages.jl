<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-bifurcationinferencejl" class="anchor" aria-hidden="true" href="#bifurcationinferencejl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>BifurcationInference.jl</h1>
<p dir="auto">This library implements the method described in <strong>Szep, G. Dalchau, N. and Csikasz-Nagy, A. 2021. <a href="https://arxiv.org/abs/2106.04243" rel="nofollow">Parameter Inference with Bifurcation Diagrams</a></strong> using parameter continuation library <a href="https://github.com/rveltz/BifurcationKit.jl"><code>BifurcationKit.jl</code></a> and auto-differentiation <a href="https://github.com/JuliaDiff/ForwardDiff.jl"><code>ForwardDiff.jl</code></a>. This implementation enables continuation methods can be used as layers in machine learning proceedures, and inference can be run end-to-end directly on the geometry of state space.</p>
<p dir="auto"><a href="https://github.com/gszep/BifurcationInference.jl/actions?query=workflow%3ACI"><img src="https://github.com/gszep/BifurcationInference.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/gszep/BifurcationInference.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/d2a61cfb917576226c61ad5b99c5c7f8b911b8bdaf47ea241342322437fccfcb/68747470733a2f2f636f6465636f762e696f2f67682f67737a65702f4269667572636174696f6e496e666572656e63652e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/gszep/BifurcationInference.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a>
<a href="https://arxiv.org/abs/2106.04243" rel="nofollow"><img src="https://camo.githubusercontent.com/ae87788c17749eb7b168f500a623e2dace20f435bc2fef86a99d7023f00799d2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61725869762d323130362e30343234332d6233316231622e737667" alt="arXiv" data-canonical-src="https://img.shields.io/badge/arXiv-2106.04243-b31b1b.svg" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basic Usage</h2>
<p dir="auto">The model definition requires a distpatched method on <code>F(z::BorderedArray,θ::AbstractVector)</code> where <code>BorderedArray</code> is a type that contains the state vector <code>u</code> and control condition <code>p</code> used by the library <a href="https://github.com/rveltz/BifurcationKit.jl"><code>BifurcationKit.jl</code></a>. <code>θ</code> is a vector of parameters to be optimised.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using BifurcationInference, StaticArrays

F(z::BorderedArray,θ::AbstractVector) = F(z.u,(θ=θ,p=z.p))
function F(u::AbstractVector,parameters::NamedTuple)

	@unpack θ,p = parameters
	μ₁,μ₂, a₁,a₂, k = θ

	f = first(u)*first(p)*first(θ)
	F = similar(u,typeof(f))

	F[1] = ( 10^a₁ + (p*u[2])^2 ) / ( 1 + (p*u[2])^2 ) - u[1]*10^μ₁
	F[2] = ( 10^a₂ + (k*u[1])^2 ) / ( 1 + (k*u[1])^2 ) - u[2]*10^μ₂

	return F
end"><pre><span class="pl-k">using</span> BifurcationInference, StaticArrays

<span class="pl-en">F</span>(z<span class="pl-k">::</span><span class="pl-c1">BorderedArray</span>,θ<span class="pl-k">::</span><span class="pl-c1">AbstractVector</span>) <span class="pl-k">=</span> <span class="pl-c1">F</span>(z<span class="pl-k">.</span>u,(θ<span class="pl-k">=</span>θ,p<span class="pl-k">=</span>z<span class="pl-k">.</span>p))
<span class="pl-k">function</span> <span class="pl-en">F</span>(u<span class="pl-k">::</span><span class="pl-c1">AbstractVector</span>,parameters<span class="pl-k">::</span><span class="pl-c1">NamedTuple</span>)

	<span class="pl-c1">@unpack</span> θ,p <span class="pl-k">=</span> parameters
	μ₁,μ₂, a₁,a₂, k <span class="pl-k">=</span> θ

	f <span class="pl-k">=</span> <span class="pl-c1">first</span>(u)<span class="pl-k">*</span><span class="pl-c1">first</span>(p)<span class="pl-k">*</span><span class="pl-c1">first</span>(θ)
	F <span class="pl-k">=</span> <span class="pl-c1">similar</span>(u,<span class="pl-c1">typeof</span>(f))

	F[<span class="pl-c1">1</span>] <span class="pl-k">=</span> ( <span class="pl-c1">10</span><span class="pl-k">^</span>a₁ <span class="pl-k">+</span> (p<span class="pl-k">*</span>u[<span class="pl-c1">2</span>])<span class="pl-k">^</span><span class="pl-c1">2</span> ) <span class="pl-k">/</span> ( <span class="pl-c1">1</span> <span class="pl-k">+</span> (p<span class="pl-k">*</span>u[<span class="pl-c1">2</span>])<span class="pl-k">^</span><span class="pl-c1">2</span> ) <span class="pl-k">-</span> u[<span class="pl-c1">1</span>]<span class="pl-k">*</span><span class="pl-c1">10</span><span class="pl-k">^</span>μ₁
	F[<span class="pl-c1">2</span>] <span class="pl-k">=</span> ( <span class="pl-c1">10</span><span class="pl-k">^</span>a₂ <span class="pl-k">+</span> (k<span class="pl-k">*</span>u[<span class="pl-c1">1</span>])<span class="pl-k">^</span><span class="pl-c1">2</span> ) <span class="pl-k">/</span> ( <span class="pl-c1">1</span> <span class="pl-k">+</span> (k<span class="pl-k">*</span>u[<span class="pl-c1">1</span>])<span class="pl-k">^</span><span class="pl-c1">2</span> ) <span class="pl-k">-</span> u[<span class="pl-c1">2</span>]<span class="pl-k">*</span><span class="pl-c1">10</span><span class="pl-k">^</span>μ₂

	<span class="pl-k">return</span> F
<span class="pl-k">end</span></pre></div>
<p dir="auto">The targets are specified with <code>StateSpace( dimension::Integer, condition::AbstractRange, targets::AbstractVector )</code>. It contains the dimension of the state space, which must match that of the defined model, the control condition range that we would like to perform the continuation method in, and a vector of target conditions we would like to match.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="X = StateSpace( 2, 0.01:0.01:10, [4,5] )"><pre>X <span class="pl-k">=</span> <span class="pl-c1">StateSpace</span>( <span class="pl-c1">2</span>, <span class="pl-c1">0.01</span><span class="pl-k">:</span><span class="pl-c1">0.01</span><span class="pl-k">:</span><span class="pl-c1">10</span>, [<span class="pl-c1">4</span>,<span class="pl-c1">5</span>] )</pre></div>
<p dir="auto">The optimisation needs to be initialised using a <code>NamedTuple</code> containing the initial guess for <code>θ</code> and the initial value <code>p</code> from which to begin the continuation.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Flux: Optimise
parameters = ( θ=SizedVector{5}(0.5,0.5,0.5470,2.0,7.5), p=minimum(X.parameter) )
train!( F, parameters, X;  iter=200, optimiser=Optimise.ADAM(0.01) )"><pre><span class="pl-k">using</span> Flux<span class="pl-k">:</span> Optimise
parameters <span class="pl-k">=</span> ( θ<span class="pl-k">=</span><span class="pl-c1">SizedVector</span><span class="pl-c1">{5}</span>(<span class="pl-c1">0.5</span>,<span class="pl-c1">0.5</span>,<span class="pl-c1">0.5470</span>,<span class="pl-c1">2.0</span>,<span class="pl-c1">7.5</span>), p<span class="pl-k">=</span><span class="pl-c1">minimum</span>(X<span class="pl-k">.</span>parameter) )
<span class="pl-c1">train!</span>( F, parameters, X;  iter<span class="pl-k">=</span><span class="pl-c1">200</span>, optimiser<span class="pl-k">=</span>Optimise<span class="pl-k">.</span><span class="pl-c1">ADAM</span>(<span class="pl-c1">0.01</span>) )</pre></div>
</article></div>