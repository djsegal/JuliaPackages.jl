<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-alphagojl" class="anchor" aria-hidden="true" href="#alphagojl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>AlphaGo.jl</h1>
<p>AlphaGo.jl is pure Julia implementation of AlphaGo Zero using Flux.jl.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>To install this package simply run</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="pkg&gt; add https://github.com/tejank10/AlphaGo.jl
"><pre><code>pkg&gt; add https://github.com/tejank10/AlphaGo.jl
</code></pre></div>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="using AlphaGo
"><pre><code>using AlphaGo
</code></pre></div>
<p>Making an environment of Go is simple<br>
<code>env = GoEnv(9)</code><br>
Here 9 is the size of board i.e., a 9x9 board is created.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="   A B C D E F G H J  
 9 . . . . . . . . . 9  
 8 . . . . . . . . . 8  
 7 . . . . . . . . . 7  
 6 . . . . . . . . . 6  
 5 . . . . . . . . . 5  
 4 . . . . . . . . . 4  
 3 . . . . . . . . . 3  
 2 . . . . . . . . . 2  
 1 . . . . . . . . . 1  
   A B C D E F G H J  
Move: 0. Captures X: 0 O: 0  
To Play: X(BLACK)  
"><pre><code>   A B C D E F G H J  
 9 . . . . . . . . . 9  
 8 . . . . . . . . . 8  
 7 . . . . . . . . . 7  
 6 . . . . . . . . . 6  
 5 . . . . . . . . . 5  
 4 . . . . . . . . . 4  
 3 . . . . . . . . . 3  
 2 . . . . . . . . . 2  
 1 . . . . . . . . . 1  
   A B C D E F G H J  
Move: 0. Captures X: 0 O: 0  
To Play: X(BLACK)  
</code></pre></div>
<p>Training is done using <code>train()</code> method. <code>train()</code> method is used by the user to train the model based on the following parameters:</p>
<ul>
<li><code>env</code></li>
<li><code>num_games</code>: Number of self-play games to be played
Optional arguments:</li>
<li><code>memory_size</code>: Size of the memory buffer</li>
<li><code>batch_size</code></li>
<li><code>epochs</code>: Number of epochs to train the data on</li>
<li><code>ckp_freq</code>: Frequecy of saving the model and weights</li>
<li><code>tower_height</code>: AlphaGo Zero Architecture uses residual networks stacked together. This is called a tower of residual networks. <code>tower_height</code> specifies how many residual blocks to be stacked.</li>
<li><code>model</code>: Object of type <code>NeuralNet</code></li>
<li><code>readouts</code>: number of readouts by <code>MCTSPlayer</code></li>
<li><code>start_training_after</code>: Number of games after which training will be started</li>
</ul>
<p>The network can be tested to play against humans by using the <code>play()</code> method. <code>play()</code> takes following arguments:</p>
<ul>
<li><code>env</code></li>
<li><code>nn</code>: an object of type <code>NeuralNet</code></li>
<li><code>tower_height</code></li>
<li><code>num_readouts</code></li>
<li><code>mode</code>: It specifies human will play as Black or white. If <code>mode</code> is 0 then human is Black, else White.</li>
</ul>
<h1><a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>TODO</h1>
<ul>
<li>Structure for memory buffer</li>
<li>GUI</li>
</ul>
</article></div>