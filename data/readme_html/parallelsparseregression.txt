<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-parallelsparseregression" class="anchor" aria-hidden="true" href="#parallelsparseregression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>ParallelSparseRegression</h1>
<p><a href="https://travis-ci.org/madeleineudell/ParallelSparseRegression.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/ffbb06272e10ef7325c9836c0ee52184bf2b15a9/68747470733a2f2f7472617669732d63692e6f72672f6d6164656c65696e657564656c6c2f506172616c6c656c53706172736552656772657373696f6e2e6a6c2e706e67" alt="Build Status" data-canonical-src="https://travis-ci.org/madeleineudell/ParallelSparseRegression.jl.png" style="max-width:100%;"></a></p>
<p>A Julia library for parallel sparse regression using shared memory.
This library implements solvers for regression problems
including least squares, ridge regression, lasso, non-negative least squares,
and elastic net.
It also proposes to add fast methods to obtain regularization paths.</p>
<p>Using the <a href="http://www.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf" rel="nofollow">Alternating Direction Method of Multipliers</a>,
all of these problems can be reduced to computing the prox of each term in the objective.
We rely on the fact that the prox of each term in the objective
of these regression problems can be efficiently computed in parallel.</p>
<h1><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h1>
<p>To install, just open a Julia prompt and call</p>
<pre><code>Pkg.clone("git@github.com:madeleineudell/ParallelSparseRegression.jl.git")
</code></pre>
<p>You'll also need to use a version of IterativeSolvers with support for caching temporary variables,</p>
<pre><code>Pkg.clone("git@github.com:madeleineudell/IterativeSolvers.jl.git")
</code></pre>
<h1><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Usage</h1>
<p>Before you begin, initialize all the processes you want to participate in multiplying by your matrix.
You'll suffer decreased performance if you add more processes
than you have hyperthreads on your shared-memory computer.</p>
<pre><code>addprocs(3)
using ParallelSparseRegression
</code></pre>
<p>We will solve a sparse non-negative least squares problem.</p>
<pre><code>m,n,p = 100,20,.1
A = sprand(m,n,p)
x0 = Base.shmem_randn(n)
b = A*x0
rho = 1
quiet = false
maxiters = 100

params = Params(rho,quiet,maxiters)
z = nnlsq(A,b; params=params)
</code></pre>
<p>We can verify the solution obtained is better than merely thresholding
the entries of the least squares solution to be positive.</p>
<pre><code>println("Norm of Az-b is $(norm(A*z-b))")
xp = max(x0,0)
println("Norm of A(x)_+ -b is $(norm(A*xp-b))")
</code></pre>
</article></div>