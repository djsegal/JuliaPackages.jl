<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-mljtuning" class="anchor" aria-hidden="true" href="#mljtuning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>MLJTuning</h1>
<p dir="auto">Hyperparameter optimization for
<a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> machine
learning models.</p>
<p dir="auto">See <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/tuning_models" rel="nofollow"><strong>Tuning Models Â· MLJ</strong></a> for usage examples.</p>
<p dir="auto"><a href="https://github.com/JuliaAI/MLJTuning.jl/actions"><img src="https://github.com/JuliaAI/MLJTuning.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="http://codecov.io/github/JuliaAI/MLJTuning.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/0f9c8463c0a18d8c21baf27e7d6141def835f6ae8f77ea75d66163bf810768bd/687474703a2f2f636f6465636f762e696f2f6769746875622f4a756c696141492f4d4c4a54756e696e672e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/JuliaAI/MLJTuning.jl/coverage.svg?branch=master" style="max-width: 100%;"></a></p>
<h3 dir="auto"><a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contents</h3>
<ul dir="auto">
<li><a href="#who-is-this-repo-for">Who is this repo for?</a></li>
<li><a href="#what-is-provided-here">What's provided here?</a></li>
<li><a href="#how-do-i-implement-a-new-tuning-strategy">How do I implement a new tuning strategy?</a></li>
<li><a href="#how-do-i-implement-a-new-selection-heuristic">How do I implement a new selection heuristic?</a></li>
</ul>
<p dir="auto"><em>Note:</em> This component of the <a href="https://github.com/alan-turing-institute/MLJ.jl#the-mlj-universe">MLJ
stack</a>
applies to MLJ versions 0.8.0 and higher. Prior to 0.8.0, tuning
algorithms resided in
<a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a>.</p>
<h2 dir="auto"><a id="user-content-who-is-this-repo-for" class="anchor" aria-hidden="true" href="#who-is-this-repo-for"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Who is this repo for?</h2>
<p dir="auto">This repository is not intended to be directly imported by the general
MLJ user. Rather, MLJTuning is a dependency of the
<a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> machine
learning platform, which allows MLJ users to perform a variety of
hyperparameter optimization tasks from there.</p>
<p dir="auto">MLJTuning is the place for developers to integrate hyperparameter
optimization algorithms (here called <em>tuning strategies</em>) into MLJ,
either by adding code to <a href="/src/strategies">/src/strategies</a>, or by
importing MLJTuning into a third-party package and implementing
MLJTuning's <a href="#how-do-i-implement-a-new-tuning-strategy">tuning strategy interface</a>.</p>
<p dir="auto">MLJTuning is a component of the <a href="https://github.com/alan-turing-institute/MLJ.jl#the-mlj-universe">MLJ
stack</a>
which does not have
<a href="https://github.com/alan-turing-institute/MLJModels.jl">MLJModels</a>
as a dependency (no ability to search and load registered MLJ
models). It does however depend on
<a href="https://github.com/JuliaAI/MLJBase.jl">MLJBase</a> and,
in particular, on the resampling functionality currently residing
there.</p>
<h2 dir="auto"><a id="user-content-what-is-provided-here" class="anchor" aria-hidden="true" href="#what-is-provided-here"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>What is provided here?</h2>
<p dir="auto">This repository contains:</p>
<ul dir="auto">
<li>
<p dir="auto">a <strong>tuning wrapper</strong> called <code>TunedModel</code> for transforming arbitrary
MLJ models into "self-tuning" ones - that is, into models which,
when fit, automatically optimize a specified subset of the original
hyperparameters (using cross-validation or other resampling
strategy) before training the optimal model on all supplied data</p>
</li>
<li>
<p dir="auto">an abstract <strong><a href="#how-do-i-implement-a-new-tuning-strategy">tuning strategy
interface</a></strong> to allow
developers to conveniently implement common hyperparameter
optimization strategies, such as:</p>
<ul class="contains-task-list">
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> search models generated by an arbitrary iterator, eg <code>models = [model1, model2, ...]</code> (built-in <code>Explicit</code> strategy)</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> grid search (built-in <code>Grid</code> strategy)</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Latin hypercubes (built-in <code>LatinHypercube</code> strategy,
interfacing the
<a href="https://github.com/MrUrq/LatinHypercubeSampling.jl">LatinHypercubeSampling</a>
package)</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> random search (built-in <code>RandomSearch</code> strategy)</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> particle swarm optimization (<a href="https://github.com/JuliaAI/MLJParticleSwarmOptimization.jl">MLJParticleOptimization.jl</a>)</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> bandit</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> simulated annealing</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> Bayesian optimization using Gaussian processes</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> structured tree Parzen estimators (<code>MLJTreeParzenTuning</code> from
<a href="https://github.com/IQVIA-ML/TreeParzen.jl">TreeParzen.jl</a>)</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> multi-objective (Pareto) optimization</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> genetic algorithms</p>
</li>
<li class="task-list-item">
<p dir="auto"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> AD-powered gradient descent methods</p>
</li>
</ul>
</li>
<li>
<p dir="auto">a selection of <strong>implementations</strong> of the tuning strategy interface,
currently all those accessible from
<a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> itself.</p>
</li>
<li>
<p dir="auto">the code defining the MLJ functions <code>learning_curves!</code> and <code>learning_curve</code> as
these are essentially one-dimensional grid searches</p>
</li>
</ul>
<h2 dir="auto"><a id="user-content-how-do-i-implement-a-new-tuning-strategy" class="anchor" aria-hidden="true" href="#how-do-i-implement-a-new-tuning-strategy"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How do I implement a new tuning strategy?</h2>
<p dir="auto">This document assumes familiarity with the <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/evaluating_model_performance/" rel="nofollow">Evaluating Model
Performance</a>
and <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/performance_measures/" rel="nofollow">Performance
Measures</a>
sections of the MLJ manual. Tuning itself, from the user's
perspective, is described in <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/tuning_models/" rel="nofollow">Tuning
Models</a>.</p>
<h3 dir="auto"><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Overview</h3>
<p dir="auto">What follows is an overview of tuning in MLJ. After the overview is an
elaboration on those terms given in <em>italics</em>.</p>
<p dir="auto">All tuning in MLJ is conceptualized as an iterative procedure, each
iteration corresponding to a performance <em>evaluation</em> of a single
<em>model</em>. Each such model is a mutated clone of a fixed prototype. In the
general case, this prototype is a composite model, i.e., a model with
other models as hyperparameters, and while the type of the prototype
mutations is fixed, the types of the sub-models are allowed to vary.</p>
<p dir="auto">When all iterations of the algorithm are complete, the optimal model
is selected by applying a <em>selection heuristic</em> to a <em>history</em>
generated according to the specified <em>tuning strategy</em>. Iterations are
generally performed in batches, which are evaluated in parallel
(sequential tuning strategies degenerating into semi-sequential
strategies, unless the batch size is one). At the beginning of each
batch, both the history and an internal <em>state</em> object are consulted,
and, on the basis of the tuning strategy, a new batch of models to be
evaluated is generated. On the basis of these evaluations, and the
strategy, the history and internal state are updated.</p>
<p dir="auto">The tuning algorithm initializes the state object before iterations
begin, on the basis of the specific strategy and a user-specified
<em>range</em> object.</p>
<ul dir="auto">
<li>
<p dir="auto">Recall that in MLJ a <em>model</em> is an object storing the
hyperparameters of some learning algorithm indicated by the name of
the model type (e.g., <code>DecisionTreeRegressor</code>). Models do not
store learned parameters.</p>
</li>
<li>
<p dir="auto">An <em>evaluation</em> is an object <code>E</code> returned by some call to the
<code>evaluate!</code> method, when passed the resampling strategy (e.g.,
<code>resampling=CV(nfolds=9)</code>) and a battery of user-specified
performance measures (e.g., <code>measures=[cross_entropy, accuracy]</code>). An evaluation object <code>E</code> contains a list of measures
<code>E.measure</code> and a list of corresponding measurements
<code>E.measurement</code>, each of which is the aggregrate of measurements for
each resampling of the data, which are stored in <code>E.per_fold</code> (a
vector of vectors). In the case of a measure that reports a value
for each individual observation (to obtain the per-fold measurement,
by aggregation) the per-observation values can be retrieved from
<code>E.per_observation</code>. This last object includes <code>missing</code> entries for
measures that do not report per-observation values
(<code>reports_per_observation(measure) = false</code>) such as <code>auc</code>. See
<a href="https://alan-turing-institute.github.io/MLJ.jl/dev/evaluating_model_performance/" rel="nofollow">Evaluating Model
Performance</a>
for details. There is a trait for measures called <code>orientation</code>
which is <code>:loss</code> for measures you ordinarily want to minimize, and
<code>:score</code> for those you want to maximize. See <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/performance_measures/" rel="nofollow">Performance
measures</a>
for further details.</p>
</li>
<li>
<p dir="auto">A <em>tuning strategy</em> is an instance of some subtype <code>S &lt;: TuningStrategy</code>, the name <code>S</code> (e.g., <code>Grid</code>) indicating the tuning
(optimization) algorithm to be applied. The fields of the tuning
strategy - called <em>tuning hyperparameters</em> - are those tuning
parameters specific to the strategy that <strong>do not refer to specific
models or specific model hyperparameters</strong>. So, for example, a
default resolution to be used in a grid search is a hyperparameter
of <code>Grid</code>, but the resolution to be applied to a <em>specific</em>
hyperparameter (such as the maximum depth of a decision tree) is
<em>not</em>. This latter parameter would be part of the user-specified
range object. A <em>multi-objective</em> tuning strategy is one that
consults the measurements of all <code>measures</code> specified by the user;
otherwise only the <strong>first</strong> measure is consulted, although
measurements for all measures are nevertheless reported.</p>
</li>
<li>
<p dir="auto">A <em>selection heuristic</em> is a rule describing how the outcomes of the
model evaluations will be used to select the <em>best (optimal) model</em>,
after all iterations of the optimizer have concluded. For example,
the default <code>NaiveSelection()</code> heuristic
simply selects the model whose evaluation <code>E</code> has the smallest or
largest <code>E.measurement[1]</code> value, according to whether the metric
<code>E.measure[1]</code> is a <code>:loss</code> or <code>:score</code>. Most heuristics are
<em>generic</em> in the sense they will apply no matter what tuning
strategy is applied.  A selection heuristic supported by a
multi-objective tuning strategy must select <em>some</em> "best" model
(e.g., a random Pareto optimal solution).</p>
</li>
<li>
<p dir="auto">The <em>history</em> is a vector of identically-keyed named tuples, one
tuple per iteration. The tuple keys include:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>model</code>: for the MLJ model instance that has been evaluated</p>
</li>
<li>
<p dir="auto"><code>measure</code>, <code>measurement</code>, <code>per_fold</code>: for storing the values of
<code>E.measure</code>, <code>E.measurement</code> and <code>E.per_fold</code>, where <code>E</code> is the corresponding
evaluation object.</p>
</li>
<li>
<p dir="auto"><code>metadata</code>: for any tuning strategy-specific information required
to be recorded in the history <em>but not intended to be reported to
the user</em> (for example an implementation-specific representation
of <code>model</code>).</p>
</li>
</ul>
<p dir="auto">There may be additional keys for tuning-specific information that
<em>is</em> to be reported to the user (such as temperature in
simulated annhealing).</p>
</li>
<li>
<p dir="auto">A <em>range</em> is any object whose specification completes the
specification of the tuning task, after the prototype, tuning
strategy, resampling strategy, performance measure(s), selection
heuristic, and total iteration count are given. This definition is
intentionally broad and the interface places no restriction on the
allowed types of this object, although <strong>all strategies should
support the one-dimensional range objects</strong> defined in <code>MLJBase</code>
(see <a href="#range-types">below</a>). Generally, a range may be understood as
the "space" of models being searched <em>plus</em> strategy-specific data
explaining how models from that space are actually to be generated
(e.g., grid resolutions or probability distributions specific to
particular hyper-parameters). For more on range types see <a href="#range-types">Range
types</a> below.</p>
</li>
</ul>
<h3 dir="auto"><a id="user-content-interface-points-for-user-input" class="anchor" aria-hidden="true" href="#interface-points-for-user-input"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Interface points for user input</h3>
<p dir="auto">Recall, for context, that in MLJ tuning is implemented as a model
wrapper. A model is tuned by <em>fitting</em> the wrapped model to data
(which also trains the optimal model on all available data). This
process determines the optimal model, as defined by the selection
heuristic (see above). To use the optimal model one <em>predicts</em> using
the wrapped model. For more detail, see the <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/tuning_models/" rel="nofollow">Tuning
Models</a>
section of the MLJ manual.</p>
<p dir="auto">In setting up a tuning task, the user constructs an instance of the
<code>TunedModel</code> wrapper type, which has these principal fields:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>model</code>: the prototype model instance mutated during tuning (the
model being wrapped)</p>
</li>
<li>
<p dir="auto"><code>tuning</code>: the tuning strategy, an instance of a concrete
<code>TuningStrategy</code> subtype, such as <code>Grid</code></p>
</li>
<li>
<p dir="auto"><code>resampling</code>: the resampling strategy used for performance
evaluations, which must be an instance of a concrete
<code>ResamplingStrategy</code> subtype, such as <code>Holdout</code> or <code>CV</code></p>
</li>
<li>
<p dir="auto"><code>measure</code>: a measure (loss or score) or vector of measures available
to the tuning algorithm, the first of which is optimized in the
common case of single-objective tuning strategies</p>
</li>
<li>
<p dir="auto"><code>selection_heuristic</code>: some instance of <code>SelectionHeuristic</code>, such
as <code>NaiveSelection()</code> (default)</p>
</li>
<li>
<p dir="auto"><code>range</code>: as defined above - roughly, the space of models to be searched</p>
</li>
<li>
<p dir="auto"><code>n</code>: the number of iterations, which is the number of distinct model
evaluations that will be added to the history, unless the tuning
strategy's supply of models is exhausted (e.g., <code>Grid</code>). This is not
to be confused with an iteration count specific to the tuning strategy
(e.g., Particle Swarm Optimization).</p>
</li>
<li>
<p dir="auto"><code>acceleration</code>: the computational resources to be applied (e.g.,
<code>CPUProcesses()</code> for distributed computing and <code>CPUThreads()</code> for
multi-threaded processing)</p>
</li>
<li>
<p dir="auto"><code>acceleration_resampling</code>: the computational resources to be applied
at the level of resampling (e.g., in cross-validation)</p>
</li>
</ul>
<h3 dir="auto"><a id="user-content-implementation-requirements-for-new-tuning-strategies" class="anchor" aria-hidden="true" href="#implementation-requirements-for-new-tuning-strategies"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Implementation requirements for new tuning strategies</h3>
<p dir="auto">As sample implementations, see <a href="/src/strategies">/src/strategies/</a></p>
<h4 dir="auto"><a id="user-content-summary-of-functions" class="anchor" aria-hidden="true" href="#summary-of-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Summary of functions</h4>
<p dir="auto">Several functions are part of the tuning strategy API:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>clean!</code>: for validating and resetting invalid fields in tuning strategy (optional)</p>
</li>
<li>
<p dir="auto"><code>setup</code>: for initialization of state (compulsory)</p>
</li>
<li>
<p dir="auto"><code>extras</code>: for declaring and formatting additional user-inspectable information
going into the history</p>
</li>
<li>
<p dir="auto"><code>tuning_report</code>: for declaring any other strategy-specific information
to report to the user (optional)</p>
</li>
<li>
<p dir="auto"><code>models</code>: for generating batches of new models and updating the
state (compulsory)</p>
</li>
<li>
<p dir="auto"><code>default_n</code>: to specify the total number of models to be evaluated when
<code>n</code> is not specified by the user</p>
</li>
<li>
<p dir="auto"><code>supports_heuristic</code>: a trait used to encode which selection
heuristics are supported by the tuning strategy (only needed if you
define a strategy-specific heuristic)</p>
</li>
</ul>
<p dir="auto"><strong>Important note on the history.</strong> The initialization and update of the
history is carried out internally, i.e., is not the responsibility of
the tuning strategy implementation. The history is always initialized to
<code>nothing</code>, rather than an empty vector.</p>
<p dir="auto">The above functions are discussed further below, after discussing types.</p>
<h4 dir="auto"><a id="user-content-the-tuning-strategy-type" class="anchor" aria-hidden="true" href="#the-tuning-strategy-type"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The tuning strategy type</h4>
<p dir="auto">Each tuning algorithm must define a subtype of <code>TuningStrategy</code> whose
fields are the hyperparameters controlling the strategy that do not
directly refer to models or model hyperparameters. These would
include, for example, the default resolution of a grid search, or the
initial temperature in simulated annealing.</p>
<p dir="auto">The algorithm implementation must include a keyword constructor with
defaults. Here's an example:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="mutable struct Grid &lt;: TuningStrategy
	goal::Union{Nothing,Int}
	resolution::Int
	shuffle::Bool
	rng::Random.AbstractRNG
end

# Constructor with keywords
Grid(; goal=nothing, resolution=10, shuffle=true,
	 rng=Random.GLOBAL_RNG) =
	Grid(goal, resolution, MLJBase.shuffle_and_rng(shuffle, rng)...)"><pre><span class="pl-k">mutable struct</span> Grid <span class="pl-k">&lt;:</span> <span class="pl-c1">TuningStrategy</span>
	goal<span class="pl-k">::</span><span class="pl-c1">Union{Nothing,Int}</span>
	resolution<span class="pl-k">::</span><span class="pl-c1">Int</span>
	shuffle<span class="pl-k">::</span><span class="pl-c1">Bool</span>
	rng<span class="pl-k">::</span><span class="pl-c1">Random.AbstractRNG</span>
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> Constructor with keywords</span>
<span class="pl-c1">Grid</span>(; goal<span class="pl-k">=</span><span class="pl-c1">nothing</span>, resolution<span class="pl-k">=</span><span class="pl-c1">10</span>, shuffle<span class="pl-k">=</span><span class="pl-c1">true</span>,
	 rng<span class="pl-k">=</span>Random<span class="pl-k">.</span>GLOBAL_RNG) <span class="pl-k">=</span>
	<span class="pl-c1">Grid</span>(goal, resolution, MLJBase<span class="pl-k">.</span><span class="pl-c1">shuffle_and_rng</span>(shuffle, rng)<span class="pl-k">...</span>)</pre></div>
<h4 dir="auto"><a id="user-content-range-types" class="anchor" aria-hidden="true" href="#range-types"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Range types</h4>
<p dir="auto">Generally new types are defined for each class of range object a
tuning strategy should like to handle, and the tuning strategy
functions to be implemented are dispatched on these types. It is
recommended that every tuning strategy support at least these types:</p>
<ul dir="auto">
<li>
<p dir="auto">one-dimensional ranges <code>r</code>, where <code>r</code> is a <code>MLJBase.ParamRange</code> instance</p>
</li>
<li>
<p dir="auto">(optional) pairs of the form <code>(r, data)</code>, where <code>data</code> is extra
hyper-parameter-specific information, such as a resolution in a grid
search, or a distribution in a random search</p>
</li>
<li>
<p dir="auto">abstract vectors whose elements are of the above form</p>
</li>
</ul>
<p dir="auto">Recall that <code>ParamRange</code> has two concrete subtypes <code>NumericRange</code> and
<code>NominalRange</code>, whose instances are constructed with the <code>MLJBase</code>
extension to the <code>range</code> function.</p>
<p dir="auto">Note in particular that a <code>NominalRange</code> has a <code>values</code> field, while
<code>NumericRange</code> has the fields <code>upper</code>, <code>lower</code>, <code>scale</code>, <code>unit</code> and
<code>origin</code>. The <code>unit</code> field specifies a preferred length scale, while
<code>origin</code> a preferred "central value". These default to <code>(upper - lower)/2</code> and <code>(upper + lower)/2</code>, respectively, in the bounded case
(neither <code>upper = Inf</code> nor <code>lower = -Inf</code>). The fields <code>origin</code> and
<code>unit</code> are used in generating grids or fitting probability
distributions to unbounded ranges.</p>
<p dir="auto">A <code>ParamRange</code> object is always associated with the name of a
hyperparameter (a field of the prototype in the context of tuning)
which is recorded in its <code>field</code> attribute, a <code>Symbol</code>, but for
composite models this might be a be an <code>Expr</code>, such as
<code>:(atom.max_depth)</code>.</p>
<p dir="auto">Use the <code>iterator</code> and <code>sampler</code> methods to convert ranges into
one-dimensional grids or for random sampling, respectively. See the
<a href="https://alan-turing-institute.github.io/MLJ.jl/dev/tuning_models/#API-1" rel="nofollow">tuning
section</a>
of the MLJ manual or doc-strings for more on these methods and the
<code>Grid</code> and <code>RandomSearch</code> implementations.</p>
<h4 dir="auto"><a id="user-content-the-clean-method-for-validating-tuning-strategy" class="anchor" aria-hidden="true" href="#the-clean-method-for-validating-tuning-strategy"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The <code>clean!</code> method: For validating tuning strategy</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="MLJTuning.clean!(tuning::MyTuningStrategy)"><pre>MLJTuning<span class="pl-k">.</span><span class="pl-c1">clean!</span>(tuning<span class="pl-k">::</span><span class="pl-c1">MyTuningStrategy</span>)</pre></div>
<p dir="auto">Some tuning strategies have mutable fields that only support specific set of
values: a particle swarm strategy, for instance, should have at least three
agents for the algorithm to work. As such, it is recommended to implement the
<code>clean!</code> method to warn the user and correct invalid tuning hyperparameters.
The method should return a string message if some fields have been reset or an
empty string otherwise, and will be called internally whenever a <code>TunedModel</code>
machine is <code>fit!</code>.</p>
<p dir="auto">The default fallback for <code>clean!</code> returns an empty string.</p>
<h4 dir="auto"><a id="user-content-the-setup-method-to-initialize-state" class="anchor" aria-hidden="true" href="#the-setup-method-to-initialize-state"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The <code>setup</code> method: To initialize state</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="state = setup(tuning::MyTuningStrategy, model, range, n, verbosity)"><pre>state <span class="pl-k">=</span> <span class="pl-c1">setup</span>(tuning<span class="pl-k">::</span><span class="pl-c1">MyTuningStrategy</span>, model, range, n, verbosity)</pre></div>
<p dir="auto">The <code>setup</code> function is for initializing the <code>state</code> of the tuning
algorithm (available to the <code>models</code> method). Be sure to make this
object mutable if it needs to be updated by the <code>models</code> method. The
arguments <code>model</code> and <code>n</code> are what the user has specified in their
<code>TunedModel</code> instance; recall <code>model</code> is the prototype to be cloned
and mutated, and <code>n</code> the total number of mutations to be generated.</p>
<p dir="auto">The <code>state</code> is a place to record the outcomes of any necessary
intialization of the tuning algorithm (performed by <code>setup</code>) and a
place for the <code>models</code> method to save and read transient information
that does not need to be recorded in the history.</p>
<p dir="auto">The <code>setup</code> function is called once only, when a <code>TunedModel</code> machine
is <code>fit!</code> the first time, and not on subsequent calls (unless
<code>force=true</code>). (Specifically, <code>MLJBase.fit(::TunedModel, ...)</code> calls
<code>setup</code> but <code>MLJBase.update(::TunedModel, ...)</code> does not.)</p>
<p dir="auto">The <code>verbosity</code> is an integer indicating the level of logging: <code>0</code>
means logging should be restricted to warnings, <code>-1</code>, means completely
silent.</p>
<p dir="auto">The fallback for <code>setup</code> is:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="setup(tuning::TuningStrategy, model, range, n, verbosity) = range"><pre><span class="pl-en">setup</span>(tuning<span class="pl-k">::</span><span class="pl-c1">TuningStrategy</span>, model, range, n, verbosity) <span class="pl-k">=</span> range</pre></div>
<p dir="auto">However, a tuning strategy will generally want to implement a <code>setup</code>
method for each range type it is going to support:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="MLJTuning.setup(tuning::MyTuningStrategy, model, range::RangeType1, n, verbosity) = ...
MLJTuning.setup(tuning::MyTuningStrategy, model, range::RangeType2, n, verbosity) = ...
etc."><pre>MLJTuning<span class="pl-k">.</span><span class="pl-en">setup</span>(tuning<span class="pl-k">::</span><span class="pl-c1">MyTuningStrategy</span>, model, range<span class="pl-k">::</span><span class="pl-c1">RangeType1</span>, n, verbosity) <span class="pl-k">=</span> <span class="pl-k">...</span>
MLJTuning<span class="pl-k">.</span><span class="pl-en">setup</span>(tuning<span class="pl-k">::</span><span class="pl-c1">MyTuningStrategy</span>, model, range<span class="pl-k">::</span><span class="pl-c1">RangeType2</span>, n, verbosity) <span class="pl-k">=</span> <span class="pl-k">...</span>
etc.</pre></div>
<h4 dir="auto"><a id="user-content-the-extras-method-for-adding-user-inspectable-data-to-the-history" class="anchor" aria-hidden="true" href="#the-extras-method-for-adding-user-inspectable-data-to-the-history"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The <code>extras</code> method: For adding user-inspectable data to the history</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="MLJTuning.extras(tuning::MyTuningStrategy, history, state, E) -&gt; named_tuple"><pre>MLJTuning<span class="pl-k">.</span><span class="pl-c1">extras</span>(tuning<span class="pl-k">::</span><span class="pl-c1">MyTuningStrategy</span>, history, state, E) <span class="pl-k">-&gt;</span> named_tuple</pre></div>
<p dir="auto">This method should return any user-inspectable information to be
included in a new history entry, that is in addition to the <code>model</code>,
<code>measures</code>, <code>measurement</code> and <code>per_fold</code> data.
<em><strong>This method must return a named tuple</strong></em>,
human readable if possible. Each key of the
returned named tuple becomes a key of the new history entry.</p>
<p dir="auto">Here <code>E</code> is the full evalutation object for <code>model</code> and <code>history</code> the
current history (before adding the new entry).</p>
<p dir="auto">The fallback for <code>extras</code> returns an empty named tuple.</p>
<h4 dir="auto"><a id="user-content-the-models-method-for-generating-model-batches-to-evaluate" class="anchor" aria-hidden="true" href="#the-models-method-for-generating-model-batches-to-evaluate"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The <code>models</code> method: For generating model batches to evaluate</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="MLJTuning.models(tuning::MyTuningStrategy, model, history, state, n_remaining, verbosity)
	-&gt; vector_of_models, new_state"><pre>MLJTuning<span class="pl-k">.</span><span class="pl-c1">models</span>(tuning<span class="pl-k">::</span><span class="pl-c1">MyTuningStrategy</span>, model, history, state, n_remaining, verbosity)
	<span class="pl-k">-&gt;</span> vector_of_models, new_state</pre></div>
<p dir="auto">This is the core method of a new implementation. Given the existing
<code>history</code> and <code>state</code>, it must return a vector ("batch") of <em>new</em>
model instances <code>vector_of_models</code> to be evaluated, and the updated
<code>state</code>. Any number of models may be returned (and this includes an
empty vector or <code>nothing</code>) and the evaluations will be performed in
parallel (using the mode of parallelization defined by the
<code>acceleration</code> field of the <code>TunedModel</code> instance).</p>
<p dir="auto"><strong>Important note.</strong> Parallelization means the order in which the
<code>history</code> gets extended after <code>models(...)</code> returns its list of new
candidates is generally <em>not</em> the same order in which the candidates
are returned. Some implementations may therefore need to attach extra
"labeling" metadata to each model, as explained below, so that the
existing history can be suitably interpreted.</p>
<p dir="auto">If more models are returned than needed (because including them would
create a history whose length exceeds the user-specified number of
iterations <code>tuned_model.n</code>) then the surplus models are saved, for use
in a <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/machines/#Warm-restarts" rel="nofollow">"warm
restart"</a>
of tuning, when the user increases <code>tuned_model.n</code>. The remaining
models are then evaluated and these evaluations are added to the
history. <strong>In any warm restart, no new call to <code>models</code> will be made
until all saved models have been evaluated, and these evaluations
added to the history.</strong></p>
<p dir="auto">If the tuning algorithm exhausts it's supply of new models (because,
for example, there is only a finite supply, as in a <code>Grid</code> search)
then <code>vector_of_models</code> should be an empty vector or <code>nothing</code>. The
interface has no fixed "batch-size" parameter, and the tuning
algorithm is happy to receive any number of models; a surplus is
handled as explained above, a shortfall will trigger an early stop
(so that the final history has length less than <code>tuned_model.n</code>).</p>
<p dir="auto">If needed, extra metadata may be attached to each model returned; see
<a href="#including-model-metadata">below</a>.</p>
<p dir="auto">Sequential tuning strategies generating models non-deterministically
(e.g., simulated annealing) might choose to include a batch size
hyperparameter, and arrange that <code>models</code> returns batches of the
specified size (to be evaluated in parallel when <code>acceleration</code> is set
appropriately). However, the evaluations and history updates do not
occur until after the <code>models</code> call, so it may be complicated or
impossible to preserve the original (strictly) sequential algorithm in
that case, which should be clearly documented.</p>
<p dir="auto">Some simple tuning strategies, such as <code>RandomSearch</code>, will want to
return as many models as possible in one hit. To this end, the
variable <code>n_remaining</code> is passed to the <code>models</code> call; this is the
difference between the current length of the history and
<code>tuned_model.n</code>.</p>
<h5 dir="auto"><a id="user-content-including-model-metadata" class="anchor" aria-hidden="true" href="#including-model-metadata"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Including model metadata</h5>
<p dir="auto">If a tuning strategy implementation needs to record additional
metadata in the history, for each model generated, then instead of
model instances, <code>vector_of_models</code> should be vector of <em>tuples</em> of the
form <code>(m, metadata)</code>, where <code>m</code> is a model instance, and <code>metadata</code>
the associated data. <em><strong>To access the metadata for the <code>j</code>th element of
the existing history, use <code>history[j].metadata</code>.</strong></em></p>
<h4 dir="auto"><a id="user-content-the-tuning_report-method-to-add-to-the-user-inspectable-report" class="anchor" aria-hidden="true" href="#the-tuning_report-method-to-add-to-the-user-inspectable-report"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The <code>tuning_report</code> method: To add to the user-inspectable report</h4>
<p dir="auto">As with any model, fitting a <code>TunedModel</code> instance generates a
user-accessible report. Note that the fallback report already includes
additions to the history created by the <code>extras</code> method mentioned
above. To add more strategy-specific information to the report, one
overloads <code>tuning_report</code>.</p>
<p dir="auto">Specically, the report generated by fitting a <code>TunedModel</code> is
constructed with this code:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="report1 = (best_model         = best_model,
		   best_history_entry = best_user_history_entry,
		   history            = user_history,
		   best_report        = best_report)

report = merge(report1, tuning_report(tuning, history, state))"><pre>report1 <span class="pl-k">=</span> (best_model         <span class="pl-k">=</span> best_model,
		   best_history_entry <span class="pl-k">=</span> best_user_history_entry,
		   history            <span class="pl-k">=</span> user_history,
		   best_report        <span class="pl-k">=</span> best_report)

report <span class="pl-k">=</span> <span class="pl-c1">merge</span>(report1, <span class="pl-c1">tuning_report</span>(tuning, history, state))</pre></div>
<p dir="auto">where:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>best_model</code> is the best model instance (as selected according to
the user-specified <code>selection heuristic</code>).</p>
</li>
<li>
<p dir="auto"><code>best_user_history</code> is the corresponding entry in the history with <code>metadata</code> removed.</p>
</li>
<li>
<p dir="auto"><code>best_report</code> is the report generated when fitting the <code>best_model</code>
on all available data.</p>
</li>
<li>
<p dir="auto"><code>user_history</code> is the full history with <code>metadata</code> entries removed.</p>
</li>
<li>
<p dir="auto"><code>tuning_report(::MyTuningStrategy, ...)</code> is a method the implementer
may overload that ***must return a named tuple, preferably human readable</p>
</li>
</ul>
<p dir="auto">The fallback for <code>tuning_report</code> returns an empty named-tuple.</p>
<h4 dir="auto"><a id="user-content-the-default_n-method-for-declaring-the-default-number-of-iterations" class="anchor" aria-hidden="true" href="#the-default_n-method-for-declaring-the-default-number-of-iterations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The <code>default_n</code> method: For declaring the default number of iterations</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="MLJTuning.default_n(tuning::MyTuningStrategy, range)"><pre>MLJTuning<span class="pl-k">.</span><span class="pl-c1">default_n</span>(tuning<span class="pl-k">::</span><span class="pl-c1">MyTuningStrategy</span>, range)</pre></div>
<p dir="auto">The <code>models</code> method, which is allowed to return multiple models in
it's first return value <code>vector_of_models</code>, is called until one of the
following occurs:</p>
<ul dir="auto">
<li>
<p dir="auto">The length of the history matches the number of iterations specified
by the user, namely <code>tuned_model.n</code> where <code>tuned_model</code> is the user's
<code>TunedModel</code> instance. If <code>tuned_model.n</code> is <code>nothing</code> (because the
user has not specified a value) then <code>default_n(tuning, range)</code> is
used instead.</p>
</li>
<li>
<p dir="auto"><code>vector_of_models</code> is empty or <code>nothing</code>.</p>
</li>
</ul>
<p dir="auto">The fallback is</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="default_n(tuning::TuningStrategy, range) = DEFAULT_N"><pre><span class="pl-en">default_n</span>(tuning<span class="pl-k">::</span><span class="pl-c1">TuningStrategy</span>, range) <span class="pl-k">=</span> DEFAULT_N</pre></div>
<p dir="auto">where <code>DEFAULT_N</code> is a global constant. Do <code>using MLJTuning; MLJTuning.DEFAULT_N</code> to see check the current value.</p>
<h4 dir="auto"><a id="user-content-the-supports_heuristic-trait" class="anchor" aria-hidden="true" href="#the-supports_heuristic-trait"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The <code>supports_heuristic</code> trait</h4>
<p dir="auto">If you define a selection heuristic <code>SpecialHeuristic</code> (see
<a href="#how-do-i-implement-a-new-selection-heuristic">below</a>) and that
heuristic is specific to a tuning strategy <code>TuningStrategy</code> then you
must define</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="MLJTuning.supports_heuristic(::TuningStrategy, ::SpecialHeuristic) = true"><pre>MLJTuning<span class="pl-k">.</span><span class="pl-en">supports_heuristic</span>(<span class="pl-k">::</span><span class="pl-c1">TuningStrategy</span>, <span class="pl-k">::</span><span class="pl-c1">SpecialHeuristic</span>) <span class="pl-k">=</span> <span class="pl-c1">true</span></pre></div>
<h3 dir="auto"><a id="user-content-sample-implementations" class="anchor" aria-hidden="true" href="#sample-implementations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Sample implementations</h3>
<p dir="auto">A number of built-in tuning strategy implementations of the MLJTuning
API can be found at <a href="/src/strategies">/src/strategies</a>.</p>
<p dir="auto">The simplest <code>Explicit</code> strategy is the simplest but is also an odd
case as the <code>range</code> is just an iterator of MLJ models. These models
need not share a common type and <code>model</code> is never cloned.</p>
<p dir="auto">For slightly less trivial example, see
<a href="/src/strategies/grid.jl">the <code>Grid</code> search code</a></p>
<h2 dir="auto"><a id="user-content-how-do-i-implement-a-new-selection-heuristic" class="anchor" aria-hidden="true" href="#how-do-i-implement-a-new-selection-heuristic"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How do I implement a new selection heuristic?</h2>
<p dir="auto">Recall that a <em>selection heuristic</em> is a rule which decides on the
"best model" given the model evaluations in the tuning history. New
heuristics are introduced by defining a new struct <code>SomeHeuristic</code> subtyping
<code>SelectionHeuristic</code> and implementing a method</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="MLJTuning.best(heuristic::SomeHeuristic, history) -&gt; history_entry"><pre>MLJTuning<span class="pl-k">.</span><span class="pl-c1">best</span>(heuristic<span class="pl-k">::</span><span class="pl-c1">SomeHeuristic</span>, history) <span class="pl-k">-&gt;</span> history_entry</pre></div>
<p dir="auto">where <code>history_entry</code> is the entry in the history corresponding to the model deemed "best".</p>
<p dir="auto">Below is a simplified version of <a href="src/selection_heuristics.jl">code</a>
defining the default heuristic <code>NaiveSelection()</code>
which simply chooses the model with the lowest (or highest) aggregated
performance estimate, based on the first measure specified by the user
in his <code>TunedModel</code> construction (she may specify more than one).</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="struct NaiveSelection &lt;: MLJTuning.SelectionHeuristic end

function best(heuristic::NaiveSelection, history)
	measurements = [h.measurement[1] for h in history]
	measure = first(history).measure[1]
	if orientation(measure) == :score
		measurements = -measurements
	end
	best_index = argmin(measurements)
	return history[best_index]
end"><pre><span class="pl-k">struct</span> NaiveSelection <span class="pl-k">&lt;:</span> <span class="pl-c1">MLJTuning.SelectionHeuristic</span> <span class="pl-k">end</span>

<span class="pl-k">function</span> <span class="pl-en">best</span>(heuristic<span class="pl-k">::</span><span class="pl-c1">NaiveSelection</span>, history)
	measurements <span class="pl-k">=</span> [h<span class="pl-k">.</span>measurement[<span class="pl-c1">1</span>] <span class="pl-k">for</span> h <span class="pl-k">in</span> history]
	measure <span class="pl-k">=</span> <span class="pl-c1">first</span>(history)<span class="pl-k">.</span>measure[<span class="pl-c1">1</span>]
	<span class="pl-k">if</span> <span class="pl-c1">orientation</span>(measure) <span class="pl-k">==</span> <span class="pl-c1">:score</span>
		measurements <span class="pl-k">=</span> <span class="pl-k">-</span>measurements
	<span class="pl-k">end</span>
	best_index <span class="pl-k">=</span> <span class="pl-c1">argmin</span>(measurements)
	<span class="pl-k">return</span> history[best_index]
<span class="pl-k">end</span></pre></div>
<p dir="auto">Because this selection heuristic is generic (applies to all tuning
strategies) we additionally define</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="MLJTuning.supports_heuristic(strategy, heuristic::NaiveSelection) = true"><pre>MLJTuning<span class="pl-k">.</span><span class="pl-en">supports_heuristic</span>(strategy, heuristic<span class="pl-k">::</span><span class="pl-c1">NaiveSelection</span>) <span class="pl-k">=</span> <span class="pl-c1">true</span></pre></div>
<p dir="auto">For strategy-specific selection heuristics, see
<a href="#the-supportsheuristic-trait">above</a> on how to set this trait.</p>
</article></div>