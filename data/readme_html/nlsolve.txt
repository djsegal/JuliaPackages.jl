<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-nlsolvejl" class="anchor" aria-hidden="true" href="#nlsolvejl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>NLsolve.jl</h1>
<p>Solving non-linear systems of equations in Julia.</p>
<p>NLsolve.jl is part of the <a href="https://github.com/JuliaNLSolvers">JuliaNLSolvers</a> family.</p>
<p><a href="https://travis-ci.org/JuliaNLSolvers/NLsolve.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/43693050db46384970ae0ebe6777a5df86d38709372fa84d59274ce3c8bcd07a/68747470733a2f2f7472617669732d63692e6f72672f4a756c69614e4c536f6c766572732f4e4c736f6c76652e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/JuliaNLSolvers/NLsolve.jl.svg?branch=master" style="max-width:100%;"></a></p>
<p><a href="https://zenodo.org/badge/latestdoi/14562045" rel="nofollow"><img src="https://camo.githubusercontent.com/060912c36350e8ea886296002f2f6b47646a098805e65cf8c18cb8f4fe0d7e2c/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f31343536323034352e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/14562045.svg" style="max-width:100%;"></a></p>
<h1><a id="user-content-non-linear-systems-of-equations" class="anchor" aria-hidden="true" href="#non-linear-systems-of-equations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Non-linear systems of equations</h1>
<p>The NLsolve package solves systems of nonlinear equations. Formally, if <code>F</code> is
a multivalued function, then this package looks for some vector <code>x</code> that
satisfies <code>F(x)=0</code> to some accuracy.</p>
<p>The package is also able to solve mixed complementarity problems, which are
similar to systems of nonlinear equations, except that the equality to zero is
allowed to become an inequality if some boundary condition is satisfied. See
further below for a formal definition and the related commands.</p>
<p>There is also an identical API for solving fixed points (i.e., taking as input a function <code>F(x)</code>, and solving <code>F(x) = x</code>).</p>
<h1><a id="user-content-simple-example" class="anchor" aria-hidden="true" href="#simple-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Simple example</h1>
<p>We consider the following bivariate function of two variables:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="(x, y) -&gt; ((x+3)*(y^3-7)+18, sin(y*exp(x)-1))
"><pre>(x, y) <span class="pl-k">-&gt;</span> ((x<span class="pl-k">+</span><span class="pl-c1">3</span>)<span class="pl-k">*</span>(y<span class="pl-k">^</span><span class="pl-c1">3</span><span class="pl-k">-</span><span class="pl-c1">7</span>)<span class="pl-k">+</span><span class="pl-c1">18</span>, <span class="pl-c1">sin</span>(y<span class="pl-k">*</span><span class="pl-c1">exp</span>(x)<span class="pl-k">-</span><span class="pl-c1">1</span>))</pre></div>
<p>In order to find a zero of this function and display it, you would write the
following program:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using NLsolve

function f!(F, x)
    F[1] = (x[1]+3)*(x[2]^3-7)+18
    F[2] = sin(x[2]*exp(x[1])-1)
end

function j!(J, x)
    J[1, 1] = x[2]^3-7
    J[1, 2] = 3*x[2]^2*(x[1]+3)
    u = exp(x[1])*cos(x[2]*exp(x[1])-1)
    J[2, 1] = x[2]*u
    J[2, 2] = u
end

nlsolve(f!, j!, [ 0.1; 1.2])
"><pre><span class="pl-k">using</span> NLsolve

<span class="pl-k">function</span> <span class="pl-en">f!</span>(F, x)
    F[<span class="pl-c1">1</span>] <span class="pl-k">=</span> (x[<span class="pl-c1">1</span>]<span class="pl-k">+</span><span class="pl-c1">3</span>)<span class="pl-k">*</span>(x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">3</span><span class="pl-k">-</span><span class="pl-c1">7</span>)<span class="pl-k">+</span><span class="pl-c1">18</span>
    F[<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">sin</span>(x[<span class="pl-c1">2</span>]<span class="pl-k">*</span><span class="pl-c1">exp</span>(x[<span class="pl-c1">1</span>])<span class="pl-k">-</span><span class="pl-c1">1</span>)
<span class="pl-k">end</span>

<span class="pl-k">function</span> <span class="pl-en">j!</span>(J, x)
    J[<span class="pl-c1">1</span>, <span class="pl-c1">1</span>] <span class="pl-k">=</span> x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">3</span><span class="pl-k">-</span><span class="pl-c1">7</span>
    J[<span class="pl-c1">1</span>, <span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">3</span><span class="pl-k">*</span>x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">*</span>(x[<span class="pl-c1">1</span>]<span class="pl-k">+</span><span class="pl-c1">3</span>)
    u <span class="pl-k">=</span> <span class="pl-c1">exp</span>(x[<span class="pl-c1">1</span>])<span class="pl-k">*</span><span class="pl-c1">cos</span>(x[<span class="pl-c1">2</span>]<span class="pl-k">*</span><span class="pl-c1">exp</span>(x[<span class="pl-c1">1</span>])<span class="pl-k">-</span><span class="pl-c1">1</span>)
    J[<span class="pl-c1">2</span>, <span class="pl-c1">1</span>] <span class="pl-k">=</span> x[<span class="pl-c1">2</span>]<span class="pl-k">*</span>u
    J[<span class="pl-c1">2</span>, <span class="pl-c1">2</span>] <span class="pl-k">=</span> u
<span class="pl-k">end</span>

<span class="pl-c1">nlsolve</span>(f!, j!, [ <span class="pl-c1">0.1</span>; <span class="pl-c1">1.2</span>])</pre></div>
<p>First, note that the function <code>f!</code> computes the residuals of the nonlinear
system, and stores them in a preallocated vector passed as first argument.
Similarly, the function <code>j!</code> computes the Jacobian of the system and stores it
in a preallocated matrix passed as first argument. Residuals and Jacobian
functions can take different shapes, see below.</p>
<p>Second, when calling the <code>nlsolve</code> function, it is necessary to give a starting
point to the iterative algorithm.</p>
<p>Finally, the <code>nlsolve</code> function returns an object of type <code>SolverResults</code>. In
particular, the field <code>zero</code> of that structure contains the solution if
convergence has occurred. If <code>r</code> is an object of type <code>SolverResults</code>, then
<code>converged(r)</code> indicates if convergence has occurred.</p>
<h1><a id="user-content-specifying-the-function-and-its-jacobian" class="anchor" aria-hidden="true" href="#specifying-the-function-and-its-jacobian"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Specifying the function and its Jacobian</h1>
<p>There are various ways of specifying the residuals function and possibly its
Jacobian.</p>
<h2><a id="user-content-with-functions-modifying-arguments-in-place" class="anchor" aria-hidden="true" href="#with-functions-modifying-arguments-in-place"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>With functions modifying arguments in-place</h2>
<p>This is the most efficient method, because it minimizes the memory allocations.</p>
<p>In the following, it is assumed that you have defined a function
<code>f!(F::AbstractVector, x::AbstractVector)</code> or, more generally,
<code>f!(F::AbstractArray, x::AbstractArray)</code> computing the residual of the system at point <code>x</code> and putting it into the <code>F</code> argument.</p>
<p>In turn, there 3 ways of specifying how the Jacobian should be computed:</p>
<h3><a id="user-content-finite-differencing" class="anchor" aria-hidden="true" href="#finite-differencing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Finite differencing</h3>
<p>If you do not have a function that compute the Jacobian, it is possible to
have it computed by finite difference. In that case, the syntax is simply:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="nlsolve(f!, initial_x)
"><pre><span class="pl-c1">nlsolve</span>(f!, initial_x)</pre></div>
<p>Alternatively, you can construct an object of type
<code>OnceDifferentiable</code> and pass it to <code>nlsolve</code>, as in:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="
initial_x = ...
initial_F = similar(initial_x)
df = OnceDifferentiable(f!, initial_x, initial_F)
nlsolve(df, initial_x)
"><pre>initial_x <span class="pl-k">=</span> <span class="pl-k">...</span>
initial_F <span class="pl-k">=</span> <span class="pl-c1">similar</span>(initial_x)
df <span class="pl-k">=</span> <span class="pl-c1">OnceDifferentiable</span>(f!, initial_x, initial_F)
<span class="pl-c1">nlsolve</span>(df, initial_x)</pre></div>
<p>Notice, we passed <code>initial_x</code> and <code>initial_F</code> to the constructor for <code>df</code>. This
does not need to be the actual initial <code>x</code> and the residual vector at <code>x</code>, but it is used to
initialize cache variables in <code>df</code>, so the types and dimensions
of them have to be as if they were.</p>
<h3><a id="user-content-automatic-differentiation" class="anchor" aria-hidden="true" href="#automatic-differentiation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Automatic differentiation</h3>
<p>Another option if you do not have a function computing the Jacobian is to use
automatic differentiation, thanks to the <code>ForwardDiff</code> package. The syntax is
simply:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="nlsolve(f!, initial_x, autodiff = :forward)
"><pre><span class="pl-c1">nlsolve</span>(f!, initial_x, autodiff <span class="pl-k">=</span> <span class="pl-c1">:forward</span>)</pre></div>
<h3><a id="user-content-jacobian-available" class="anchor" aria-hidden="true" href="#jacobian-available"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Jacobian available</h3>
<p>If, in addition to <code>f!(F::AbstractArray, x::AbstractArray)</code>, you have a function <code>j!(J::AbstractArray, x::AbstractArray)</code> for computing the Jacobian of the system, then the syntax is, as in the example above:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="nlsolve(f!, j!, initial_x)
"><pre><span class="pl-c1">nlsolve</span>(f!, j!, initial_x)</pre></div>
<p>Again it is also possible to specify two functions <code>f!(F::AbstractArray, x::AbstractArray)</code> and <code>j!(J::AbstractArray, x::AbstractArray)</code> that work on arbitrary arrays <code>x</code>.</p>
<p>Note, that you should not assume that the Jacobian <code>J</code> passed into <code>j!</code> is initialized to a zero matrix. You must set all the elements of the matrix in the function <code>j!</code>.</p>
<p>Alternatively, you can construct an object of type
<code>OnceDifferentiable</code> and pass it to <code>nlsolve</code>, as in:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="df = OnceDifferentiable(f!, j!, initial_x, initial_F)
nlsolve(df, initial_x)
"><pre>df <span class="pl-k">=</span> <span class="pl-c1">OnceDifferentiable</span>(f!, j!, initial_x, initial_F)
<span class="pl-c1">nlsolve</span>(df, initial_x)</pre></div>
<h3><a id="user-content-optimization-of-simultaneous-residuals-and-jacobian" class="anchor" aria-hidden="true" href="#optimization-of-simultaneous-residuals-and-jacobian"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optimization of simultaneous residuals and Jacobian</h3>
<p>If, in addition to <code>f!</code> and <code>j!</code>, you have a function <code>fj!(F::AbstractArray, J::AbstractArray, x::AbstractArray)</code> that computes both the residual and the
Jacobian at the same time, you can use the following syntax</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="df = OnceDifferentiable(f!, j!, fj!, initial_x, initial_F)
nlsolve(df, initial_x)
"><pre>df <span class="pl-k">=</span> <span class="pl-c1">OnceDifferentiable</span>(f!, j!, fj!, initial_x, initial_F)
<span class="pl-c1">nlsolve</span>(df, initial_x)</pre></div>
<p>If the function <code>fj!</code> uses some optimization that make it cost less than
calling <code>f!</code> and <code>j!</code> successively, then this syntax can possibly improve the
performance.</p>
<h3><a id="user-content-providing-only-fj" class="anchor" aria-hidden="true" href="#providing-only-fj"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Providing only fj!</h3>
<p>If a function is available for calculating residuals and the Jacobian,
there is a special syntax for an, arguably, simpler approach. First,
define the function as</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="function myfun!(F, J, x)
    # shared calculations begin
    # ...
    # shared calculation end
    if !(F == nothing)
        # mutating calculations specific to f! goes here
    end
    if !(J == nothing)
        # mutating calculations specific to j! goes
    end
end
"><pre><span class="pl-k">function</span> <span class="pl-en">myfun!</span>(F, J, x)
    <span class="pl-c"><span class="pl-c">#</span> shared calculations begin</span>
    <span class="pl-c"><span class="pl-c">#</span> ...</span>
    <span class="pl-c"><span class="pl-c">#</span> shared calculation end</span>
    <span class="pl-k">if</span> <span class="pl-k">!</span>(F <span class="pl-k">==</span> <span class="pl-c1">nothing</span>)
        <span class="pl-c"><span class="pl-c">#</span> mutating calculations specific to f! goes here</span>
    <span class="pl-k">end</span>
    <span class="pl-k">if</span> <span class="pl-k">!</span>(J <span class="pl-k">==</span> <span class="pl-c1">nothing</span>)
        <span class="pl-c"><span class="pl-c">#</span> mutating calculations specific to j! goes</span>
    <span class="pl-k">end</span>
<span class="pl-k">end</span></pre></div>
<p>and solve using</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="nlsolve(only_fj!(myfun), initial_x)
"><pre><span class="pl-c1">nlsolve</span>(<span class="pl-c1">only_fj!</span>(myfun), initial_x)</pre></div>
<p>This will make enable <code>nlsolve</code> to efficiently calculate <code>F(x)</code> and <code>J(x)</code>
together, but still be efficient when calculating either <code>F(x)</code> or <code>J(x)</code>
separately.</p>
<h2><a id="user-content-with-functions-returning-residuals-and-jacobian-as-output" class="anchor" aria-hidden="true" href="#with-functions-returning-residuals-and-jacobian-as-output"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>With functions returning residuals and Jacobian as output</h2>
<p>Here it is assumed that you have a function <code>f(x::AbstractArray)</code> that returns
a newly-allocated vector containing the residuals. Simply pass it to <code>nlsolve</code>,
and it will automatically detect if <code>f</code> is defined for one or two arguments:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="nlsolve(f, initial_x)
"><pre><span class="pl-c1">nlsolve</span>(f, initial_x)</pre></div>
<p>Note, that this means that if you have a function <code>f</code> with a method that accepts
one argument, and another method that accepts two arguments, it will assume that
the two argument version is a mutating <code>f</code>, such as described above.</p>
<p>Via the <code>autodiff</code> keyword both finite-differencing and autodifferentiation can
be used to compute the Jacobian in that case.</p>
<p>If, in addition to <code>f(x::AbstractArray)</code>, there is a function
<code>j(x::AbstractArray)</code> returning a newly-allocated matrix containing the
Jacobian, we again simply pass these to <code>nlsolve</code>:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="nlsolve(f, j, initial_x)
"><pre><span class="pl-c1">nlsolve</span>(f, j, initial_x)</pre></div>
<p>If, in addition to <code>f</code> and <code>j</code>, there is a function <code>fj</code> returning a tuple of a
newly-allocated vector of residuals and a newly-allocated matrix of the
Jacobian, the approach is the same:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="nlsolve(f, j, fj, initial_x)
"><pre><span class="pl-c1">nlsolve</span>(f, j, fj, initial_x)</pre></div>
<h2><a id="user-content-with-functions-taking-several-scalar-arguments" class="anchor" aria-hidden="true" href="#with-functions-taking-several-scalar-arguments"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>With functions taking several scalar arguments</h2>
<p>If you have a function <code>f(x::Float64, y::Float64, ...)</code> that takes the point of
interest as several scalars and returns a vector or a tuple containing the
residuals, you can use the helper function <code>n_ary</code>. The complete syntax is
therefore:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="nlsolve(n_ary(f), initial_x)
"><pre><span class="pl-c1">nlsolve</span>(<span class="pl-c1">n_ary</span>(f), initial_x)</pre></div>
<p>Finite-differencing is used to compute the Jacobian.</p>
<h2><a id="user-content-if-the-jacobian-is-sparse" class="anchor" aria-hidden="true" href="#if-the-jacobian-is-sparse"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>If the Jacobian is sparse</h2>
<p>If the Jacobian of your function is sparse, it is possible to ask the routines
to manipulate sparse matrices instead of full ones, in order to increase
performance on large systems. This means that we must necessarily provide an
appropriate Jacobian type so the solver knows what to feed <code>j!</code>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="df = OnceDifferentiable(f!, j!, x0, F0, J0)
nlsolve(df, initial_x)
"><pre>df <span class="pl-k">=</span> <span class="pl-c1">OnceDifferentiable</span>(f!, j!, x0, F0, J0)
<span class="pl-c1">nlsolve</span>(df, initial_x)</pre></div>
<p>It is possible to give an optional third function <code>fj!</code> to the constructor, as
for the full Jacobian case.</p>
<p>Note that the Jacobian matrix is not reset across function calls. As a result,
you need to be careful and ensure that you
don't forget to overwrite all nonzeros elements that could have been
initialized by a previous function call. If in doubt, you can clear the sparse
matrix at the beginning of the function. If <code>J</code> is the sparse Jacobian, this
can be achieved with:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="fill!(a, 0)
dropzeros!(a) # if you also want to remove the sparsity pattern
"><pre><span class="pl-c1">fill!</span>(a, <span class="pl-c1">0</span>)
<span class="pl-c1">dropzeros!</span>(a) <span class="pl-c"><span class="pl-c">#</span> if you also want to remove the sparsity pattern</span></pre></div>
<h1><a id="user-content-fine-tunings" class="anchor" aria-hidden="true" href="#fine-tunings"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Fine tunings</h1>
<p>Three algorithms are currently available. The choice between these is achieved
by setting the optional <code>method</code> argument of <code>nlsolve</code>. The default algorithm
is the trust region method.</p>
<h2><a id="user-content-trust-region-method" class="anchor" aria-hidden="true" href="#trust-region-method"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Trust region method</h2>
<p>This is the well-known solution method which relies on a quadratic
approximation of the least-squares objective, considered to be valid over a
compact region centered around the current iterate.</p>
<p>This method is selected with <code>method = :trust_region</code>.</p>
<p>This method accepts the following custom parameters:</p>
<ul>
<li><code>factor</code>: determines the size of the initial trust region. This size is set
to the product of factor and the euclidean norm of <code>initial_x</code> if nonzero, or
else to factor itself. Default: <code>1.0</code>.</li>
<li><code>autoscale</code>: if <code>true</code>, then the variables will be automatically rescaled.
The scaling factors are the norms of the Jacobian columns. Default: <code>true</code>.</li>
</ul>
<h2><a id="user-content-newton-method-with-linesearch" class="anchor" aria-hidden="true" href="#newton-method-with-linesearch"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Newton method with linesearch</h2>
<p>This is the classical Newton algorithm with optional linesearch.</p>
<p>This method is selected with <code>method = :newton</code>.</p>
<p>This method accepts a custom parameter <code>linesearch</code>, which must be equal to a
function computing the linesearch. Currently, available values are taken from
the <a href="https://github.com/JuliaNLSolvers/LineSearches.jl"><code>LineSearches</code></a> package.
By default, no linesearch is performed.
<strong>Note:</strong> it is assumed that a passed linesearch function will at least update the solution
vector and evaluate the function at the new point.</p>
<h2><a id="user-content-anderson-acceleration" class="anchor" aria-hidden="true" href="#anderson-acceleration"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Anderson acceleration</h2>
<p>This method is selected with <code>method = :anderson</code>.</p>
<p>It is also known as DIIS or Pulay mixing, this method is based on the
acceleration of the fixed-point iteration <code>xₙ₊₁ = xₙ + beta*f(xₙ)</code>, where
by default <code>beta=1</code>. It does not use Jacobian information or linesearch,
but has a history whose size is controlled by the <code>m</code> parameter: <code>m=0</code>
(the default) corresponds to the simple fixed-point iteration above,
and higher values use a larger history size to accelerate the
iterations. Higher values of <code>m</code> usually increase the speed of
convergence, but increase the storage and computation requirements and
might lead to instabilities. This method is useful to accelerate a
fixed-point iteration <code>xₙ₊₁ = g(xₙ)</code> (in which case use this solver
with <code>f(x) = g(x) - x</code>).</p>
<p>Reference: H. Walker, P. Ni, Anderson acceleration for fixed-point
iterations, SIAM Journal on Numerical Analysis, 2011</p>
<h2><a id="user-content-common-options" class="anchor" aria-hidden="true" href="#common-options"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Common options</h2>
<p>Other optional arguments to <code>nlsolve</code>, available for all algorithms, are:</p>
<ul>
<li><code>xtol</code>: norm difference in <code>x</code> between two successive iterates under which
convergence is declared. Default: <code>0.0</code>.</li>
<li><code>ftol</code>: infinite norm of residuals under which convergence is declared.
Default: <code>1e-8</code>.</li>
<li><code>iterations</code>: maximum number of iterations. Default: <code>1_000</code>.</li>
<li><code>store_trace</code>: should a trace of the optimization algorithm's state be
stored? Default: <code>false</code>.</li>
<li><code>show_trace</code>: should a trace of the optimization algorithm's state be shown
on <code>STDOUT</code>? Default: <code>false</code>.</li>
<li><code>extended_trace</code>: should additifonal algorithm internals be added to the state
trace? Default: <code>false</code>.</li>
</ul>
<h2><a id="user-content-fixed-points" class="anchor" aria-hidden="true" href="#fixed-points"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Fixed Points</h2>
<p>There is a <code>fixedpoint()</code> wrapper around <code>nlsolve()</code> which maps an input function <code>F(x)</code> to <code>G(x) = F(x) - x</code>, and likewise for the in-place. This allows convenient solution of fixed-point problems, e.g. of the kind commonly encountered in computational economics. Some notes:</p>
<ul>
<li>The default method is <code>:anderson</code> with <code>m = 5</code>. Naive "Picard"-style iteration can be achieved by setting <code>m=0</code>, but that isn't advisable for contractions whose Lipschitz constants are close to 1. If convergence fails, though, you may consider lowering it.</li>
<li>Autodifferentiation is supported; e.g. <code>fixedpoint(f!, init_x; method = :newton, autodiff = :true)</code>.</li>
<li>Tolerances and iteration bounds can be set exactly as in <code>nlsolve()</code>, since this function is a wrapper, e.g. <code>fixedpoint(f, init_x; iterations = 500, ...)</code>.</li>
</ul>
<p><strong>Note:</strong> If you are supplying your own derivative, make sure that it is appropriately transformed (i.e., we currently map <code>f -&gt; f - x</code>, but are waiting on the API to stabilize before mapping <code>J -&gt; J - I</code>, so you'll need to do that yourself.)</p>
<h1><a id="user-content-mixed-complementarity-problems" class="anchor" aria-hidden="true" href="#mixed-complementarity-problems"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Mixed complementarity problems</h1>
<p>Given a multivariate function <code>f</code> and two vectors <code>a</code> and <code>b</code>, the solution to
the mixed complementarity problem (MCP) is a vector <code>x</code> such that one of the
following holds for every index <code>i</code>:</p>
<ul>
<li>either <code>f_i(x) = 0</code> and <code>a_i &lt;= x_i &lt;= b_i</code></li>
<li>or <code>f_i(x) &gt; 0</code> and <code>x_i = a_i</code></li>
<li>or <code>f_i(x) &lt; 0</code> and <code>x_i = b_i</code></li>
</ul>
<p>The vector <code>a</code> can contain elements equal to <code>-Inf</code>, while the vector
<code>b</code> can contain elements equal to <code>Inf</code>. In the particular case where all
elements of <code>a</code> are equal to <code>-Inf</code>, and all elements of <code>b</code> are equal to
<code>Inf</code>, the MCP is exactly equivalent to the multivariate root finding problem
described above.</p>
<p>The package solves MCPs by reformulating them as the solution to a system of
nonlinear equations (as described by Miranda and Fackler, 2002, though NLsolve
uses the sign convention opposite to theirs).</p>
<p>The function <code>mcpsolve</code> solves MCPs. It takes the same arguments as <code>nlsolve</code>,
except that the vectors <code>a</code> and <code>b</code> must immediately follow the argument(s)
corresponding to <code>f</code> (and possibly its derivative). There is also an extra
optional argument <code>reformulation</code>, which can take two values:</p>
<ul>
<li><code>reformulation = :smooth</code>: use a smooth reformulation of the problem using
the Fischer function. This is the default, since it is more robust for complex
problems.</li>
<li><code>reformulation = :minmax</code>: use a min-max reformulation of the problem. It is
faster than the smooth approximation, since it uses less algebra, but is less
robust since the reformulated problem has kinks.</li>
</ul>
<p>Here is a complete example:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using NLsolve

function f!(F, x)
    F[1]=3*x[1]^2+2*x[1]*x[2]+2*x[2]^2+x[3]+3*x[4]-6
    F[2]=2*x[1]^2+x[1]+x[2]^2+3*x[3]+2*x[4]-2
    F[3]=3*x[1]^2+x[1]*x[2]+2*x[2]^2+2*x[3]+3*x[4]-1
    F[4]=x[1]^2+3*x[2]^2+2*x[3]+3*x[4]-3
end

r = mcpsolve(f!, [0., 0., 0., 0.], [Inf, Inf, Inf, Inf],
             [1.25, 0., 0., 0.5], reformulation = :smooth, autodiff = :forward)
"><pre><span class="pl-k">using</span> NLsolve

<span class="pl-k">function</span> <span class="pl-en">f!</span>(F, x)
    F[<span class="pl-c1">1</span>]<span class="pl-k">=</span><span class="pl-c1">3</span><span class="pl-k">*</span>x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">+</span><span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">1</span>]<span class="pl-k">*</span>x[<span class="pl-c1">2</span>]<span class="pl-k">+</span><span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">+</span>x[<span class="pl-c1">3</span>]<span class="pl-k">+</span><span class="pl-c1">3</span><span class="pl-k">*</span>x[<span class="pl-c1">4</span>]<span class="pl-k">-</span><span class="pl-c1">6</span>
    F[<span class="pl-c1">2</span>]<span class="pl-k">=</span><span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">+</span>x[<span class="pl-c1">1</span>]<span class="pl-k">+</span>x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">+</span><span class="pl-c1">3</span><span class="pl-k">*</span>x[<span class="pl-c1">3</span>]<span class="pl-k">+</span><span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">4</span>]<span class="pl-k">-</span><span class="pl-c1">2</span>
    F[<span class="pl-c1">3</span>]<span class="pl-k">=</span><span class="pl-c1">3</span><span class="pl-k">*</span>x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">+</span>x[<span class="pl-c1">1</span>]<span class="pl-k">*</span>x[<span class="pl-c1">2</span>]<span class="pl-k">+</span><span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">+</span><span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">3</span>]<span class="pl-k">+</span><span class="pl-c1">3</span><span class="pl-k">*</span>x[<span class="pl-c1">4</span>]<span class="pl-k">-</span><span class="pl-c1">1</span>
    F[<span class="pl-c1">4</span>]<span class="pl-k">=</span>x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">+</span><span class="pl-c1">3</span><span class="pl-k">*</span>x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">+</span><span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">3</span>]<span class="pl-k">+</span><span class="pl-c1">3</span><span class="pl-k">*</span>x[<span class="pl-c1">4</span>]<span class="pl-k">-</span><span class="pl-c1">3</span>
<span class="pl-k">end</span>

r <span class="pl-k">=</span> <span class="pl-c1">mcpsolve</span>(f!, [<span class="pl-c1">0.</span>, <span class="pl-c1">0.</span>, <span class="pl-c1">0.</span>, <span class="pl-c1">0.</span>], [<span class="pl-c1">Inf</span>, <span class="pl-c1">Inf</span>, <span class="pl-c1">Inf</span>, <span class="pl-c1">Inf</span>],
             [<span class="pl-c1">1.25</span>, <span class="pl-c1">0.</span>, <span class="pl-c1">0.</span>, <span class="pl-c1">0.5</span>], reformulation <span class="pl-k">=</span> <span class="pl-c1">:smooth</span>, autodiff <span class="pl-k">=</span> <span class="pl-c1">:forward</span>)</pre></div>
<p>The solution is:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; r.zero
4-element Array{Float64,1}:
  1.22474
  0.0
 -1.378e-19
  0.5
"><pre>julia<span class="pl-k">&gt;</span> r<span class="pl-k">.</span>zero
<span class="pl-c1">4</span><span class="pl-k">-</span>element Array{Float64,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
  <span class="pl-c1">1.22474</span>
  <span class="pl-c1">0.0</span>
 <span class="pl-k">-</span><span class="pl-c1">1.378e-19</span>
  <span class="pl-c1">0.5</span></pre></div>
<p>The lower bounds are hit for the second and third components, hence the second
and third components of the function are positive at the solution. On the other
hand, the first and fourth components of the function are zero at the solution.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; F = similar(r.zero)

julia&gt; f!(F, r.zero)

julia&gt; F
4-element Array{Float64,1}:
 -1.26298e-9
  3.22474
  5.0
  3.62723e-11
"><pre>julia<span class="pl-k">&gt;</span> F <span class="pl-k">=</span> <span class="pl-c1">similar</span>(r<span class="pl-k">.</span>zero)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">f!</span>(F, r<span class="pl-k">.</span>zero)

julia<span class="pl-k">&gt;</span> F
<span class="pl-c1">4</span><span class="pl-k">-</span>element Array{Float64,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-k">-</span><span class="pl-c1">1.26298e-9</span>
  <span class="pl-c1">3.22474</span>
  <span class="pl-c1">5.0</span>
  <span class="pl-c1">3.62723e-11</span></pre></div>
<h1><a id="user-content-todolist" class="anchor" aria-hidden="true" href="#todolist"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Todolist</h1>
<ul>
<li>Broyden updating of Jacobian in trust-region</li>
<li>Homotopy methods</li>
<li><a href="http://www.mathematik.uni-wuerzburg.de/~kanzow/" rel="nofollow">LMMCP algorithm by C. Kanzow</a></li>
</ul>
<h1><a id="user-content-related-packages" class="anchor" aria-hidden="true" href="#related-packages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Related Packages</h1>
<ul>
<li><a href="https://github.com/JuliaOpt/JuMP.jl">JuMP.jl</a> can also solve non linear equations. Just reformulate your problem as an optimization problem with non linear constraints: use the set of equations as constraints, and enter 1.0 as the objective function. JuMP currently supports a number of open-source and commercial solvers.</li>
<li><a href="https://github.com/chkwon/Complementarity.jl">Complementarity.jl</a> brings the powerful modeling language of JuMP.jl to complementarity problems. It supports two solvers: <a href="https://github.com/chkwon/PATHSolver.jl">PATHSolver.jl</a> and NLsolve.jl.</li>
</ul>
<h1><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>References</h1>
<p>Nocedal, Jorge and Wright, Stephen J. (2006): "Numerical Optimization", second
edition, Springer</p>
<p><a href="http://www.netlib.org/minpack/" rel="nofollow">MINPACK</a> by Jorge More', Burt Garbow, and Ken
Hillstrom at Argonne National Laboratory</p>
<p>Miranda, Mario J. and Fackler, Paul L. (2002): "Applied Computational Economics
and Finance", MIT Press</p>
</article></div>