<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-mlutilsjl" class="anchor" aria-hidden="true" href="#mlutilsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>MLUtils.jl</h1>
<p dir="auto"><a href="https://JuliaML.github.io/MLUtils.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://JuliaML.github.io/MLUtils.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/JuliaML/MLUtils.jl/actions/workflows/CI.yml?query=branch%3Amain"><img src="https://github.com/JuliaML/MLUtils.jl/actions/workflows/CI.yml/badge.svg?branch=main" alt="" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/JuliaML/MLUtils.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/7bc4cbd81b9ff9da3db5e10211843f0beda33b698633ee53e162325ffa764da6/68747470733a2f2f636f6465636f762e696f2f67682f4a756c69614d4c2f4d4c5574696c732e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="" data-canonical-src="https://codecov.io/gh/JuliaML/MLUtils.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><em>MLUtils.jl</em> defines interfaces and implements common utilities for Machine Learning pipelines.</p>
<h2 dir="auto"><a id="user-content-features" class="anchor" aria-hidden="true" href="#features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Features</h2>
<ul dir="auto">
<li>An extensible dataset interface  (<code>numobs</code> and <code>getobs</code>).</li>
<li>Data iteration and dataloaders (<code>eachobs</code> and <code>DataLoader</code>).</li>
<li>Lazy data views (<code>obsview</code>).</li>
<li>Resampling procedures (<code>undersample</code> and <code>oversample</code>).</li>
<li>Train/test splits (<code>splitobs</code>)</li>
<li>Data partitioning and aggregation tools (<code>batch</code>, <code>unbatch</code>, <code>chunk</code>, <code>group_counts</code>, <code>group_indices</code>).</li>
<li>Folds for cross-validation (<code>kfolds</code>, <code>leavepout</code>).</li>
<li>Datasets lazy tranformations (<code>mapobs</code>, <code>filterobs</code>, <code>groupobs</code>, <code>joinobs</code>, <code>shuffleobs</code>).</li>
<li>Toy datasets for demonstration purpose.</li>
<li>Other data handling utilities (<code>flatten</code>, <code>normalise</code>, <code>unsqueeze</code>, <code>stack</code>, <code>unstack</code>).</li>
</ul>
<h2 dir="auto"><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h2>
<p dir="auto">Let us take a look at a hello world example to get a feeling for
how to use this package in a typical ML scenario.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using MLUtils

# X is a matrix of floats
# Y is a vector of strings
X, Y = load_iris()

# The iris dataset is ordered according to their labels,
# which means that we should shuffle the dataset before
# partitioning it into training- and test-set.
Xs, Ys = shuffleobs((X, Y))

# We leave out 15 % of the data for testing
cv_data, test_data = splitobs((Xs, Ys); at=0.85)

# Next we partition the data using a 10-fold scheme.
for (train_data, val_data) in kfolds(cv_data; k=10)

    # We apply a lazy transform for data augmentation
    train_data = mapobs(xy -&gt; (xy[1] .+ 0.1 .* randn.(), xy[2]),  train_data)

    for epoch = 1:10
        # Iterate over the data using mini-batches of 5 observations each
        for (x, y) in eachobs(train_data, batchsize=5)
            # ... train supervised model on minibatches here
        end
    end
end"><pre><span class="pl-k">using</span> MLUtils

<span class="pl-c"><span class="pl-c">#</span> X is a matrix of floats</span>
<span class="pl-c"><span class="pl-c">#</span> Y is a vector of strings</span>
X, Y <span class="pl-k">=</span> <span class="pl-c1">load_iris</span>()

<span class="pl-c"><span class="pl-c">#</span> The iris dataset is ordered according to their labels,</span>
<span class="pl-c"><span class="pl-c">#</span> which means that we should shuffle the dataset before</span>
<span class="pl-c"><span class="pl-c">#</span> partitioning it into training- and test-set.</span>
Xs, Ys <span class="pl-k">=</span> <span class="pl-c1">shuffleobs</span>((X, Y))

<span class="pl-c"><span class="pl-c">#</span> We leave out 15 % of the data for testing</span>
cv_data, test_data <span class="pl-k">=</span> <span class="pl-c1">splitobs</span>((Xs, Ys); at<span class="pl-k">=</span><span class="pl-c1">0.85</span>)

<span class="pl-c"><span class="pl-c">#</span> Next we partition the data using a 10-fold scheme.</span>
<span class="pl-k">for</span> (train_data, val_data) <span class="pl-k">in</span> <span class="pl-c1">kfolds</span>(cv_data; k<span class="pl-k">=</span><span class="pl-c1">10</span>)

    <span class="pl-c"><span class="pl-c">#</span> We apply a lazy transform for data augmentation</span>
    train_data <span class="pl-k">=</span> <span class="pl-c1">mapobs</span>(xy <span class="pl-k">-&gt;</span> (xy[<span class="pl-c1">1</span>] <span class="pl-k">.+</span> <span class="pl-c1">0.1</span> <span class="pl-k">.*</span> <span class="pl-c1">randn</span>.(), xy[<span class="pl-c1">2</span>]),  train_data)

    <span class="pl-k">for</span> epoch <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">10</span>
        <span class="pl-c"><span class="pl-c">#</span> Iterate over the data using mini-batches of 5 observations each</span>
        <span class="pl-k">for</span> (x, y) <span class="pl-k">in</span> <span class="pl-c1">eachobs</span>(train_data, batchsize<span class="pl-k">=</span><span class="pl-c1">5</span>)
            <span class="pl-c"><span class="pl-c">#</span> ... train supervised model on minibatches here</span>
        <span class="pl-k">end</span>
    <span class="pl-k">end</span>
<span class="pl-k">end</span></pre></div>
<p dir="auto">In the above code snippet, the inner loop for <code>eachobs</code> is the
only place where data other than indices is actually being
copied. In fact, while <code>x</code> and <code>y</code> are materialized arrays,
all the rest are data views.</p>
<h2 dir="auto"><a id="user-content-related-packages" class="anchor" aria-hidden="true" href="#related-packages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Related Packages</h2>
<p dir="auto"><em>MLUtils.jl</em> brings together functionalities previously found in <a href="https://github.com/JuliaML/LearnBase.jl">LearnBase.jl</a> , <a href="https://github.com/JuliaML/MLDataPattern.jl">MLDataPattern.jl</a> and <a href="https://github.com/JuliaML/MLLabelUtils.jl">MLLabelUtils.jl</a>. These packages are now discontinued.</p>
<p dir="auto">Other features were ported from the deep learning library <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a>, as they are of general use.</p>
<p dir="auto"><a href="https://alan-turing-institute.github.io/MLJ.jl/dev/" rel="nofollow">MLJ.jl</a> is a more complete package for managing the whole machine learning pipeline if you are looking for a sklearn replacement.</p>
</article></div>