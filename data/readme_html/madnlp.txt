<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h2><a id="" class="anchor" aria-hidden="true" href="#"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a target="_blank" rel="noopener noreferrer" href="logo-full.svg"><img src="logo-full.svg" alt="Logo" style="max-width:100%;"></a></h2>
<p><a href="https://github.com/sshin23/MadNLP.jl/actions?query=workflow%3Abuild"><img src="https://github.com/sshin23/MadNLP.jl/workflows/build/badge.svg?branch=dev%2Fgithub_actions" alt="build" style="max-width:100%;"></a> <a href="https://codecov.io/gh/sshin23/MadNLP.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/304ffa23b59a7685531b87d7e121e21fe701bc1ea030b38a0e02b5918294eaa6/68747470733a2f2f636f6465636f762e696f2f67682f737368696e32332f4d61644e4c502e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/sshin23/MadNLP.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p>MadNLP is a <a href="https://en.wikipedia.org/wiki/Nonlinear_programming" rel="nofollow">nonlinear programming</a> (NLP) solver, purely implemented in <a href="https://julialang.org/" rel="nofollow">Julia</a>. MadNLP implements a filter line-search algorithm, as that used in <a href="https://github.com/coin-or/Ipopt">Ipopt</a>. MadNLP seeks to streamline the development of modeling and algorithmic paradigms in order to exploit structures and to make efficient use of high-performance computers.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="pkg&gt; add MadNLP
"><pre>pkg<span class="pl-k">&gt;</span> add MadNLP</pre></div>
<h2><a id="user-content-build" class="anchor" aria-hidden="true" href="#build"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Build</h2>
<p>The build process requires C and Fortran compilers. If they are not installed, do</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="shell&gt; sudo apt install gcc gfortran # Linux
shell&gt; brew cask install gcc gfortran # MacOS
"><pre>shell<span class="pl-k">&gt;</span> sudo apt install gcc gfortran <span class="pl-c"><span class="pl-c">#</span> Linux</span>
shell<span class="pl-k">&gt;</span> brew cask install gcc gfortran <span class="pl-c"><span class="pl-c">#</span> MacOS</span></pre></div>
<p>MadNLP is interfaced with non-Julia sparse/dense linear solvers:</p>
<ul>
<li><a href="https://people.engr.tamu.edu/davis/suitesparse.html" rel="nofollow">Umfpack</a></li>
<li><a href="http://mumps.enseeiht.fr/" rel="nofollow">Mumps</a></li>
<li><a href="https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-fortran/top/sparse-solver-routines/intel-mkl-pardiso-parallel-direct-sparse-solver-interface.html" rel="nofollow">MKL-Pardiso</a></li>
<li><a href="http://www.hsl.rl.ac.uk/ipopt/" rel="nofollow">HSL solvers</a> (optional)</li>
<li><a href="https://www.pardiso-project.org/" rel="nofollow">Pardiso</a> (optional)</li>
<li><a href="https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-fortran/top/lapack-routines.html" rel="nofollow">MKL-Lapack</a></li>
<li><a href="https://docs.nvidia.com/cuda/cusolver/index.html" rel="nofollow">cuSOLVER</a> (optional)</li>
</ul>
<p>All the dependencies except for HSL solvers, Pardiso, and CUDA are automatically installed. To build MadNLP with HSL linear solvers (Ma27, Ma57, Ma77, Ma86, Ma97), the source codes need to be obtained by the user from <a href="http://www.hsl.rl.ac.uk/ipopt/" rel="nofollow">http://www.hsl.rl.ac.uk/ipopt/</a> under Coin-HSL Full (Stable). Then, the tarball <code>coinhsl-2015.06.23.tar.gz</code> should be placed at <code>deps/download</code>. To use Pardiso, the user needs to obtain the Paridso shared libraries from <a href="https://www.pardiso-project.org/" rel="nofollow">https://www.pardiso-project.org/</a>, place the shared library file (e.g., <code>libpardiso600-GNU720-X86-64.so</code>) at <code>deps/download</code>, and place the license file in the home directory. The absolute path for <code>deps/download</code> can be obtained by:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; import MadNLP; joinpath(dirname(pathof(MadNLP)),&quot;..&quot;,&quot;deps&quot;,&quot;download&quot;)
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">import</span> MadNLP; <span class="pl-c1">joinpath</span>(<span class="pl-c1">dirname</span>(<span class="pl-c1">pathof</span>(MadNLP)),<span class="pl-s"><span class="pl-pds">"</span>..<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>deps<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>download<span class="pl-pds">"</span></span>)</pre></div>
<p>To use cuSOLVER, functional NVIDIA driver and corresponding CUDA toolkit need to be installed by the user. After obtaining the files, run</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="pkg&gt; build MadNLP
"><pre>pkg<span class="pl-k">&gt;</span> build MadNLP</pre></div>
<p>Build can be customized by setting the following environment variables.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; ENV[&quot;MADNLP_CC&quot;] = &quot;/usr/local/bin/gcc-9&quot;    # default is &quot;gcc&quot;
julia&gt; ENV[&quot;MADNLP_FC&quot;] = &quot;/usr/local/bin/gfortran&quot; # default is &quot;gfortran&quot;
julia&gt; ENV[&quot;MADNLP_BLAS&quot;] = &quot;openblas&quot;              # default is &quot;mkl&quot; if available &quot;openblas&quot; otherwise
julia&gt; ENV[&quot;MADNLP_ENALBE_OPENMP&quot;] = false          # default is &quot;true&quot;
julia&gt; ENV[&quot;MADNLP_OPTIMIZATION_FLAG&quot;] = &quot;-O2&quot;      # default is &quot;-O3&quot;
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">ENV</span>[<span class="pl-s"><span class="pl-pds">"</span>MADNLP_CC<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>/usr/local/bin/gcc-9<span class="pl-pds">"</span></span>    <span class="pl-c"><span class="pl-c">#</span> default is "gcc"</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">ENV</span>[<span class="pl-s"><span class="pl-pds">"</span>MADNLP_FC<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>/usr/local/bin/gfortran<span class="pl-pds">"</span></span> <span class="pl-c"><span class="pl-c">#</span> default is "gfortran"</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">ENV</span>[<span class="pl-s"><span class="pl-pds">"</span>MADNLP_BLAS<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>openblas<span class="pl-pds">"</span></span>              <span class="pl-c"><span class="pl-c">#</span> default is "mkl" if available "openblas" otherwise</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">ENV</span>[<span class="pl-s"><span class="pl-pds">"</span>MADNLP_ENALBE_OPENMP<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-c1">false</span>          <span class="pl-c"><span class="pl-c">#</span> default is "true"</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">ENV</span>[<span class="pl-s"><span class="pl-pds">"</span>MADNLP_OPTIMIZATION_FLAG<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>-O2<span class="pl-pds">"</span></span>      <span class="pl-c"><span class="pl-c">#</span> default is "-O3"</span></pre></div>
<p>Alternatively, if the user has already installed HSL/pardiso library, one can simply specify the library path as follows:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; ENV[&quot;MADNLP_HSL_LIBRARY_PATH&quot;] = &quot;/opt/lib/libcoinhsl.so&quot;
julia&gt; ENV[&quot;MADNLP_PARDISO_LIBRARY_PATH&quot;] = &quot;/opt/lib/libpardiso.so&quot; 
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">ENV</span>[<span class="pl-s"><span class="pl-pds">"</span>MADNLP_HSL_LIBRARY_PATH<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>/opt/lib/libcoinhsl.so<span class="pl-pds">"</span></span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">ENV</span>[<span class="pl-s"><span class="pl-pds">"</span>MADNLP_PARDISO_LIBRARY_PATH<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>/opt/lib/libpardiso.so<span class="pl-pds">"</span></span> </pre></div>
<p>In this case, the source code is not compiled and the provided shared library is directly used.</p>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<p>MadNLP is interfaced with modeling packages:</p>
<ul>
<li><a href="https://github.com/jump-dev/JuMP.jl">JuMP</a></li>
<li><a href="https://github.com/zavalab/Plasmo.jl">Plasmo</a></li>
<li><a href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl">NLPModels</a>.</li>
</ul>
<h3><a id="user-content-jump-interface" class="anchor" aria-hidden="true" href="#jump-interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>JuMP interface</h3>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using MadNLP, JuMP

model = Model(()-&gt;MadNLP.Optimizer(linear_solver=MadNLP.Ma57,print_level=MadNLP.INFO,max_iter=100))
@variable(model, x, start = 0.0)
@variable(model, y, start = 0.0)
@NLobjective(model, Min, (1 - x)^2 + 100 * (y - x^2)^2)

optimize!(model)

"><pre><span class="pl-k">using</span> MadNLP, JuMP

model <span class="pl-k">=</span> <span class="pl-c1">Model</span>(()<span class="pl-k">-&gt;</span>MadNLP<span class="pl-k">.</span><span class="pl-c1">Optimizer</span>(linear_solver<span class="pl-k">=</span>MadNLP<span class="pl-k">.</span>Ma57,print_level<span class="pl-k">=</span>MadNLP<span class="pl-k">.</span>INFO,max_iter<span class="pl-k">=</span><span class="pl-c1">100</span>))
<span class="pl-c1">@variable</span>(model, x, start <span class="pl-k">=</span> <span class="pl-c1">0.0</span>)
<span class="pl-c1">@variable</span>(model, y, start <span class="pl-k">=</span> <span class="pl-c1">0.0</span>)
<span class="pl-c1">@NLobjective</span>(model, Min, (<span class="pl-c1">1</span> <span class="pl-k">-</span> x)<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> <span class="pl-c1">100</span> <span class="pl-k">*</span> (y <span class="pl-k">-</span> x<span class="pl-k">^</span><span class="pl-c1">2</span>)<span class="pl-k">^</span><span class="pl-c1">2</span>)

<span class="pl-c1">optimize!</span>(model)
</pre></div>
<h3><a id="user-content-plasmo-interface" class="anchor" aria-hidden="true" href="#plasmo-interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Plasmo interface</h3>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using MadNLP, Plasmo

graph = OptiGraph()
@optinode(graph,n1)
@optinode(graph,n2)
@variable(n1,0 &lt;= x &lt;= 2)
@variable(n1,0 &lt;= y &lt;= 3)
@constraint(n1,x+y &lt;= 4)
@objective(n1,Min,x)
@variable(n2,x)
@NLnodeconstraint(n2,exp(x) &gt;= 2)
@linkconstraint(graph,n1[:x] == n2[:x])

MadNLP.optimize!(graph;linear_solver=MadNLP.Ma97,print_level=MadNLP.DEBUG,max_iter=100)

"><pre><span class="pl-k">using</span> MadNLP, Plasmo

graph <span class="pl-k">=</span> <span class="pl-c1">OptiGraph</span>()
<span class="pl-c1">@optinode</span>(graph,n1)
<span class="pl-c1">@optinode</span>(graph,n2)
<span class="pl-c1">@variable</span>(n1,<span class="pl-c1">0</span> <span class="pl-k">&lt;=</span> x <span class="pl-k">&lt;=</span> <span class="pl-c1">2</span>)
<span class="pl-c1">@variable</span>(n1,<span class="pl-c1">0</span> <span class="pl-k">&lt;=</span> y <span class="pl-k">&lt;=</span> <span class="pl-c1">3</span>)
<span class="pl-c1">@constraint</span>(n1,x<span class="pl-k">+</span>y <span class="pl-k">&lt;=</span> <span class="pl-c1">4</span>)
<span class="pl-c1">@objective</span>(n1,Min,x)
<span class="pl-c1">@variable</span>(n2,x)
<span class="pl-c1">@NLnodeconstraint</span>(n2,<span class="pl-c1">exp</span>(x) <span class="pl-k">&gt;=</span> <span class="pl-c1">2</span>)
<span class="pl-c1">@linkconstraint</span>(graph,n1[<span class="pl-c1">:x</span>] <span class="pl-k">==</span> n2[<span class="pl-c1">:x</span>])

MadNLP<span class="pl-k">.</span><span class="pl-c1">optimize!</span>(graph;linear_solver<span class="pl-k">=</span>MadNLP<span class="pl-k">.</span>Ma97,print_level<span class="pl-k">=</span>MadNLP<span class="pl-k">.</span>DEBUG,max_iter<span class="pl-k">=</span><span class="pl-c1">100</span>)
</pre></div>
<h3><a id="user-content-nlpmodels-interface" class="anchor" aria-hidden="true" href="#nlpmodels-interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>NLPModels interface</h3>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using MadNLP, CUTEst
model = CUTEstModel(&quot;PRIMALC1&quot;)
madnlp(model,linear_solver=MadNLP.PardisoMKL,print_level=MadNLP.WARN,max_wall_time=3600)
"><pre><span class="pl-k">using</span> MadNLP, CUTEst
model <span class="pl-k">=</span> <span class="pl-c1">CUTEstModel</span>(<span class="pl-s"><span class="pl-pds">"</span>PRIMALC1<span class="pl-pds">"</span></span>)
<span class="pl-c1">madnlp</span>(model,linear_solver<span class="pl-k">=</span>MadNLP<span class="pl-k">.</span>PardisoMKL,print_level<span class="pl-k">=</span>MadNLP<span class="pl-k">.</span>WARN,max_wall_time<span class="pl-k">=</span><span class="pl-c1">3600</span>)</pre></div>
<h3><a id="user-content-using-special-linear-solvers" class="anchor" aria-hidden="true" href="#using-special-linear-solvers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Using special linear solvers</h3>
<p>In order to use GPU solvers, <code>CUDA</code> should be imported to the <code>Main</code> module.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using MadNLP, CUDA
model = Model(()-&gt;MadNLP.Optimizer(linear_solver=MadNLP.LapackGPU))
# ...
"><pre><span class="pl-k">using</span> MadNLP, CUDA
model <span class="pl-k">=</span> <span class="pl-c1">Model</span>(()<span class="pl-k">-&gt;</span>MadNLP<span class="pl-k">.</span><span class="pl-c1">Optimizer</span>(linear_solver<span class="pl-k">=</span>MadNLP<span class="pl-k">.</span>LapackGPU))
<span class="pl-c"><span class="pl-c">#</span> ...</span></pre></div>
<p>In order to use multi-threaded solvers (<code>Schur</code> and <code>Schwawrz</code>), julia session should be started with <code>-t</code> flag.</p>
<div class="highlight highlight-source-shell position-relative" data-snippet-clipboard-copy-content="julia -t 16 # to use 16 threads
"><pre>julia -t 16 <span class="pl-c"><span class="pl-c">#</span> to use 16 threads</span></pre></div>
<h2><a id="user-content-solver-options" class="anchor" aria-hidden="true" href="#solver-options"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Solver options</h2>
<p>To see the list of MadNLP solver options, check the <a href="https://github.com/sshin23/MadNLP/blob/master/OPTIONS.md">OPTIONS.md</a> file.</p>
<h2><a id="user-content-bug-reports-and-support" class="anchor" aria-hidden="true" href="#bug-reports-and-support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Bug reports and support</h2>
<p>Please report issues and feature requests via the <a href="https://github.com/sshin23/MadNLP/issues">Github issue tracker</a>.</p>
</article></div>