<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Jutho/Strided.jl/blob/main/docs/src/assets/logo.svg"><img src="https://github.com/Jutho/Strided.jl/raw/main/docs/src/assets/logo.svg" width="150" style="max-width: 100%;"></a></p>
<h1 dir="auto"><a id="user-content-stridedjl" class="anchor" aria-hidden="true" href="#stridedjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Strided.jl</h1>
<p dir="auto">Strided array views with efficient (cache-friendly and multithreaded) manipulations</p>
<table>
<thead>
<tr>
<th align="center"><strong>Build Status</strong></th>
<th align="center"><strong>Coverage</strong></th>
<th align="center"><strong>Quality assurance</strong></th>
<th align="left"><strong>Downloads</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://github.com/Jutho/TensorOperations.jl/actions?query=workflow%3ACI"><img src="https://github.com/Jutho/TensorOperations.jl/workflows/CI/badge.svg" alt="CI" style="max-width: 100%;"></a> <a href="https://github.com/Jutho/Strided.jl/actions?query=workflow%3A%22CI+%28Julia+nightly%29%22"><img src="https://github.com/Jutho/Strided.jl/workflows/CI%20(Julia%20nightly)/badge.svg" alt="CI (Julia nightly)" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://codecov.io/gh/Jutho/Strided.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/2780329c0fe4fedeb2dc1ead6784c791b5ab0cddbb4676901795c2e95b142300/68747470733a2f2f636f6465636f762e696f2f67682f4a7574686f2f537472696465642e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="Codecov" data-canonical-src="https://codecov.io/gh/Jutho/Strided.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://github.com/JuliaTesting/Aqua.jl"><img src="https://raw.githubusercontent.com/JuliaTesting/Aqua.jl/master/badge.svg" alt="Aqua QA" style="max-width: 100%;"></a></td>
<td align="left"><a href="https://pkgs.genieframework.com?packages=Strided" rel="nofollow"><img src="https://camo.githubusercontent.com/9cf52060bf16c5c1ab0936f024352b554263c18ca7527e11b58fca0fa2ee711d/68747470733a2f2f736869656c64732e696f2f656e64706f696e743f75726c3d68747470733a2f2f706b67732e67656e69656672616d65776f726b2e636f6d2f6170692f76312f62616467652f53747269646564" alt="Strided Downloads" data-canonical-src="https://shields.io/endpoint?url=https://pkgs.genieframework.com/api/v1/badge/Strided" style="max-width: 100%;"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">A Julia package for working more efficiently with strided arrays, i.e. dense arrays whose
memory layout has a fixed stride along every dimension. Strided.jl does not make any
assumptions about the strides (such as stride 1 along first dimension, or monotonically
increasing strides) and provides multithreaded and cache friendly implementations for
mapping, reducing, broadcasting such arrays, as well as taking views, reshaping and
permuting dimensions. Most of these are simply accessible by annotating a block of standard
Julia code involving broadcasting and other array operations with the macro <code>@strided</code>.
Currently, Strided.jl only supports arrays in the main memory and does not provide
implementations for arrays on GPUs or other hardware accelerators.</p>
<h1 dir="auto"><a id="user-content-whats-new" class="anchor" aria-hidden="true" href="#whats-new"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>What's new</h1>
<p dir="auto">Strided.jl v2 reduces the complexity of the implementation. It discards of the
<code>UnsafeStridedView</code> type, which was pointer based and required to avoid allocations prior to
Julia v1.5 (because of <a href="https://github.com/JuliaLang/julia/issues/14955" data-hovercard-type="issue" data-hovercard-url="/JuliaLang/julia/issues/14955/hovercard">#14955</a>). The
associated <code>@unsafe_strided</code> macro has been deprecated.</p>
<p dir="auto">The main structured type <code>StridedView</code> for representing a strided view over a contiguous
array (<code>DenseArray</code>) is now defined in a separate package
<a href="https://github.com/Jutho/StridedViews.jl">StridedViews.jl</a>. This definition is device
agnostic and can thus also be used in combination with dense GPU arrays. However, at the
moment, the methods implemented in Strided.jl are restricted to strided views over <code>Array</code>
data.</p>
<h1 dir="auto"><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h1>
<p dir="auto">Running Julia with a single thread</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Strided

julia&gt; using BenchmarkTools

julia&gt; A = randn(4000,4000);

julia&gt; B = similar(A);

julia&gt; @btime $B .= ($A .+ $A') ./ 2;
  145.214 ms (0 allocations: 0 bytes)

julia&gt; @btime @strided $B .= ($A .+ $A') ./ 2;
  56.189 ms (6 allocations: 352 bytes)

julia&gt; A = randn(1000,1000);

julia&gt; B = similar(A);

julia&gt; @btime $B .= 3 .* $A';
  2.449 ms (0 allocations: 0 bytes)

julia&gt; @btime @strided $B .= 3 .* $A';
  1.459 ms (5 allocations: 288 bytes)

julia&gt; @btime $B .= $A .* exp.( -2 .* $A) .+ sin.( $A .* $A);
  22.493 ms (0 allocations: 0 bytes)

julia&gt; @btime @strided $B .= $A .* exp.( -2 .* $A) .+ sin.( $A .* $A);
  22.240 ms (10 allocations: 480 bytes)

julia&gt; A = randn(32,32,32,32);

julia&gt; B = similar(A);

julia&gt; @btime permutedims!($B, $A, (4,3,2,1));
  5.203 ms (2 allocations: 128 bytes)

julia&gt; @btime @strided permutedims!($B, $A, (4,3,2,1));
  2.201 ms (4 allocations: 320 bytes)

julia&gt; @btime $B .= permutedims($A, (1,2,3,4)) .+ permutedims($A, (2,3,4,1)) .+ permutedims($A, (3,4,1,2)) .+ permutedims($A, (4,1,2,3));
  21.863 ms (32 allocations: 32.00 MiB)

julia&gt; @btime @strided $B .= permutedims($A, (1,2,3,4)) .+ permutedims($A, (2,3,4,1)) .+ permutedims($A, (3,4,1,2)) .+ permutedims($A, (4,1,2,3));
  8.495 ms (9 allocations: 640 bytes)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Strided

julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> BenchmarkTools

julia<span class="pl-k">&gt;</span> A <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">4000</span>,<span class="pl-c1">4000</span>);

julia<span class="pl-k">&gt;</span> B <span class="pl-k">=</span> <span class="pl-c1">similar</span>(A);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> (<span class="pl-k">$</span>A <span class="pl-k">.+</span> <span class="pl-k">$</span>A<span class="pl-k">'</span>) <span class="pl-k">./</span> <span class="pl-c1">2</span>;
  <span class="pl-c1">145.214</span> ms (<span class="pl-c1">0</span> allocations<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">@strided</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> (<span class="pl-k">$</span>A <span class="pl-k">.+</span> <span class="pl-k">$</span>A<span class="pl-k">'</span>) <span class="pl-k">./</span> <span class="pl-c1">2</span>;
  <span class="pl-c1">56.189</span> ms (<span class="pl-c1">6</span> allocations<span class="pl-k">:</span> <span class="pl-c1">352</span> bytes)

julia<span class="pl-k">&gt;</span> A <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">1000</span>,<span class="pl-c1">1000</span>);

julia<span class="pl-k">&gt;</span> B <span class="pl-k">=</span> <span class="pl-c1">similar</span>(A);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-c1">3</span> <span class="pl-k">.*</span> <span class="pl-k">$</span>A<span class="pl-k">'</span>;
  <span class="pl-c1">2.449</span> ms (<span class="pl-c1">0</span> allocations<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">@strided</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-c1">3</span> <span class="pl-k">.*</span> <span class="pl-k">$</span>A<span class="pl-k">'</span>;
  <span class="pl-c1">1.459</span> ms (<span class="pl-c1">5</span> allocations<span class="pl-k">:</span> <span class="pl-c1">288</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-k">$</span>A <span class="pl-k">.*</span> <span class="pl-c1">exp</span>.( <span class="pl-k">-</span><span class="pl-c1">2</span> <span class="pl-k">.*</span> <span class="pl-k">$</span>A) <span class="pl-k">.+</span> <span class="pl-c1">sin</span>.( <span class="pl-k">$</span>A <span class="pl-k">.*</span> <span class="pl-k">$</span>A);
  <span class="pl-c1">22.493</span> ms (<span class="pl-c1">0</span> allocations<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">@strided</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-k">$</span>A <span class="pl-k">.*</span> <span class="pl-c1">exp</span>.( <span class="pl-k">-</span><span class="pl-c1">2</span> <span class="pl-k">.*</span> <span class="pl-k">$</span>A) <span class="pl-k">.+</span> <span class="pl-c1">sin</span>.( <span class="pl-k">$</span>A <span class="pl-k">.*</span> <span class="pl-k">$</span>A);
  <span class="pl-c1">22.240</span> ms (<span class="pl-c1">10</span> allocations<span class="pl-k">:</span> <span class="pl-c1">480</span> bytes)

julia<span class="pl-k">&gt;</span> A <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">32</span>,<span class="pl-c1">32</span>,<span class="pl-c1">32</span>,<span class="pl-c1">32</span>);

julia<span class="pl-k">&gt;</span> B <span class="pl-k">=</span> <span class="pl-c1">similar</span>(A);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">permutedims!</span>(<span class="pl-k">$</span>B, <span class="pl-k">$</span>A, (<span class="pl-c1">4</span>,<span class="pl-c1">3</span>,<span class="pl-c1">2</span>,<span class="pl-c1">1</span>));
  <span class="pl-c1">5.203</span> ms (<span class="pl-c1">2</span> allocations<span class="pl-k">:</span> <span class="pl-c1">128</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">@strided</span> <span class="pl-c1">permutedims!</span>(<span class="pl-k">$</span>B, <span class="pl-k">$</span>A, (<span class="pl-c1">4</span>,<span class="pl-c1">3</span>,<span class="pl-c1">2</span>,<span class="pl-c1">1</span>));
  <span class="pl-c1">2.201</span> ms (<span class="pl-c1">4</span> allocations<span class="pl-k">:</span> <span class="pl-c1">320</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>,<span class="pl-c1">1</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">3</span>,<span class="pl-c1">4</span>,<span class="pl-c1">1</span>,<span class="pl-c1">2</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">4</span>,<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>));
  <span class="pl-c1">21.863</span> ms (<span class="pl-c1">32</span> allocations<span class="pl-k">:</span> <span class="pl-c1">32.00</span> MiB)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">@strided</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>,<span class="pl-c1">1</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">3</span>,<span class="pl-c1">4</span>,<span class="pl-c1">1</span>,<span class="pl-c1">2</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">4</span>,<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>));
  <span class="pl-c1">8.495</span> ms (<span class="pl-c1">9</span> allocations<span class="pl-k">:</span> <span class="pl-c1">640</span> bytes)</pre></div>
<p dir="auto">And now with <code>export JULIA_NUM_THREADS = 4</code></p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Strided

julia&gt; using BenchmarkTools

julia&gt; A = randn(4000,4000);

julia&gt; B = similar(A);

julia&gt; @btime $B .= ($A .+ $A') ./ 2;
  146.618 ms (0 allocations: 0 bytes)

julia&gt; @btime @strided $B .= ($A .+ $A') ./ 2;
  30.355 ms (12 allocations: 912 bytes)

julia&gt; A = randn(1000,1000);

julia&gt; B = similar(A);

julia&gt; @btime $B .= 3 .* $A';
  2.030 ms (0 allocations: 0 bytes)

julia&gt; @btime @strided $B .= 3 .* $A';
  808.874 μs (11 allocations: 784 bytes)

julia&gt; @btime $B .= $A .* exp.( -2 .* $A) .+ sin.( $A .* $A);
  21.971 ms (0 allocations: 0 bytes)

julia&gt; @btime @strided $B .= $A .* exp.( -2 .* $A) .+ sin.( $A .* $A);
  5.811 ms (16 allocations: 1.05 KiB)

julia&gt; A = randn(32,32,32,32);

julia&gt; B = similar(A);

julia&gt; @btime permutedims!($B, $A, (4,3,2,1));
  5.334 ms (2 allocations: 128 bytes)

julia&gt; @btime @strided permutedims!($B, $A, (4,3,2,1));
  1.192 ms (10 allocations: 928 bytes)

julia&gt; @btime $B .= permutedims($A, (1,2,3,4)) .+ permutedims($A, (2,3,4,1)) .+ permutedims($A, (3,4,1,2)) .+ permutedims($A, (4,1,2,3));
  22.465 ms (32 allocations: 32.00 MiB)

julia&gt; @btime @strided $B .= permutedims($A, (1,2,3,4)) .+ permutedims($A, (2,3,4,1)) .+ permutedims($A, (3,4,1,2)) .+ permutedims($A, (4,1,2,3));
  2.796 ms (15 allocations: 1.44 KiB)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Strided

julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> BenchmarkTools

julia<span class="pl-k">&gt;</span> A <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">4000</span>,<span class="pl-c1">4000</span>);

julia<span class="pl-k">&gt;</span> B <span class="pl-k">=</span> <span class="pl-c1">similar</span>(A);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> (<span class="pl-k">$</span>A <span class="pl-k">.+</span> <span class="pl-k">$</span>A<span class="pl-k">'</span>) <span class="pl-k">./</span> <span class="pl-c1">2</span>;
  <span class="pl-c1">146.618</span> ms (<span class="pl-c1">0</span> allocations<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">@strided</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> (<span class="pl-k">$</span>A <span class="pl-k">.+</span> <span class="pl-k">$</span>A<span class="pl-k">'</span>) <span class="pl-k">./</span> <span class="pl-c1">2</span>;
  <span class="pl-c1">30.355</span> ms (<span class="pl-c1">12</span> allocations<span class="pl-k">:</span> <span class="pl-c1">912</span> bytes)

julia<span class="pl-k">&gt;</span> A <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">1000</span>,<span class="pl-c1">1000</span>);

julia<span class="pl-k">&gt;</span> B <span class="pl-k">=</span> <span class="pl-c1">similar</span>(A);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-c1">3</span> <span class="pl-k">.*</span> <span class="pl-k">$</span>A<span class="pl-k">'</span>;
  <span class="pl-c1">2.030</span> ms (<span class="pl-c1">0</span> allocations<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">@strided</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-c1">3</span> <span class="pl-k">.*</span> <span class="pl-k">$</span>A<span class="pl-k">'</span>;
  <span class="pl-c1">808.874</span> μs (<span class="pl-c1">11</span> allocations<span class="pl-k">:</span> <span class="pl-c1">784</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-k">$</span>A <span class="pl-k">.*</span> <span class="pl-c1">exp</span>.( <span class="pl-k">-</span><span class="pl-c1">2</span> <span class="pl-k">.*</span> <span class="pl-k">$</span>A) <span class="pl-k">.+</span> <span class="pl-c1">sin</span>.( <span class="pl-k">$</span>A <span class="pl-k">.*</span> <span class="pl-k">$</span>A);
  <span class="pl-c1">21.971</span> ms (<span class="pl-c1">0</span> allocations<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">@strided</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-k">$</span>A <span class="pl-k">.*</span> <span class="pl-c1">exp</span>.( <span class="pl-k">-</span><span class="pl-c1">2</span> <span class="pl-k">.*</span> <span class="pl-k">$</span>A) <span class="pl-k">.+</span> <span class="pl-c1">sin</span>.( <span class="pl-k">$</span>A <span class="pl-k">.*</span> <span class="pl-k">$</span>A);
  <span class="pl-c1">5.811</span> ms (<span class="pl-c1">16</span> allocations<span class="pl-k">:</span> <span class="pl-c1">1.05</span> KiB)

julia<span class="pl-k">&gt;</span> A <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">32</span>,<span class="pl-c1">32</span>,<span class="pl-c1">32</span>,<span class="pl-c1">32</span>);

julia<span class="pl-k">&gt;</span> B <span class="pl-k">=</span> <span class="pl-c1">similar</span>(A);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">permutedims!</span>(<span class="pl-k">$</span>B, <span class="pl-k">$</span>A, (<span class="pl-c1">4</span>,<span class="pl-c1">3</span>,<span class="pl-c1">2</span>,<span class="pl-c1">1</span>));
  <span class="pl-c1">5.334</span> ms (<span class="pl-c1">2</span> allocations<span class="pl-k">:</span> <span class="pl-c1">128</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">@strided</span> <span class="pl-c1">permutedims!</span>(<span class="pl-k">$</span>B, <span class="pl-k">$</span>A, (<span class="pl-c1">4</span>,<span class="pl-c1">3</span>,<span class="pl-c1">2</span>,<span class="pl-c1">1</span>));
  <span class="pl-c1">1.192</span> ms (<span class="pl-c1">10</span> allocations<span class="pl-k">:</span> <span class="pl-c1">928</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>,<span class="pl-c1">1</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">3</span>,<span class="pl-c1">4</span>,<span class="pl-c1">1</span>,<span class="pl-c1">2</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">4</span>,<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>));
  <span class="pl-c1">22.465</span> ms (<span class="pl-c1">32</span> allocations<span class="pl-k">:</span> <span class="pl-c1">32.00</span> MiB)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">@strided</span> <span class="pl-k">$</span>B <span class="pl-k">.=</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>,<span class="pl-c1">1</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">3</span>,<span class="pl-c1">4</span>,<span class="pl-c1">1</span>,<span class="pl-c1">2</span>)) <span class="pl-k">.+</span> <span class="pl-c1">permutedims</span>(<span class="pl-k">$</span>A, (<span class="pl-c1">4</span>,<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>));
  <span class="pl-c1">2.796</span> ms (<span class="pl-c1">15</span> allocations<span class="pl-k">:</span> <span class="pl-c1">1.44</span> KiB)</pre></div>
<h1 dir="auto"><a id="user-content-design-principles" class="anchor" aria-hidden="true" href="#design-principles"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Design principles</h1>
<h2 dir="auto"><a id="user-content-stridedview" class="anchor" aria-hidden="true" href="#stridedview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>StridedView</code></h2>
<p dir="auto">Strided.jl is centered around the type <code>StridedView</code>, which provides a view into a parent
array of type <code>DenseArray</code> such that the resulting view is strided. The definition of this
type, together with the set of methods that create <code>StridedView</code> instances, and transform
them into eachother, are now implemented in
<a href="https://github.com/Jutho/StridedViews.jl">StridedViews.jl</a>. This package is device agnostic
and never actually operators on the data in a nontrivial manner.</p>
<h2 dir="auto"><a id="user-content-broadcasting-and-mapreduce" class="anchor" aria-hidden="true" href="#broadcasting-and-mapreduce"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Broadcasting and <code>map(reduce)</code></h2>
<p dir="auto">Whenever an expression only contains <code>StridedView</code>s and non-array objects (scalars),
overloaded methods for broadcasting and functions as <code>map(!)</code> and <code>mapreduce</code> are used that
exploit the known strided structure in order to evaluate the result in a more efficient way,
at least for sufficiently large arrays where the overhead of the extra preparatory work is
negligible. In particular, this involves choosing a blocking strategy and loop order that
aims to avoid cache misses. This matters in particular if some of the <code>StridedView</code>s
involved have strides which are not monotonously increasing, e.g. if <code>transpose</code>, <code>adjoint</code>
or <code>permutedims</code> has been applied. The fact that the latter also acts lazily (whereas it
creates a copy of the data in Julia base) can potentially provide a further speedup.</p>
<h2 dir="auto"><a id="user-content-the-strided-macro-annotation" class="anchor" aria-hidden="true" href="#the-strided-macro-annotation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The <code>@strided</code> macro annotation</h2>
<p dir="auto">Rather than manually wrapping every array in a <code>StridedView</code>, there is the macro annotation
<code>@strided some_expression</code>, which will wrap all <code>DenseArray</code>s appearing in <code>some_expression</code>
in a <code>StridedView</code>. Note that, because <code>StridedView</code>s behave lazily under indexing with
ranges, this acts similar to the <code>@views</code> macro in Julia Base, i.e. there is no need to use
a view.</p>
<p dir="auto">The macro <code>@strided</code> acts as a contract, i.e. the user ensures that all array manipulations
in the following expressions will preserve the strided structure. Therefore, <code>reshape</code> and
<code>view</code> are are replaced by <code>sreshape</code> and <code>sview</code> respectively. As mentioned above,
<code>sreshape</code> will throw an error if the requested new shape is incompatible with preserving
the strided structure. The function <code>sview</code> is only defined for index arguments which are
ranges, <code>Int</code>s or <code>Colon</code> (<code>:</code>), and will thus also throw an error if indexed by anything
else.</p>
<h2 dir="auto"><a id="user-content-multithreading-support" class="anchor" aria-hidden="true" href="#multithreading-support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Multithreading support</h2>
<p dir="auto">The optimized methods in Strided.jl are implemented with support for multithreading. Thus,
if <code>Threads.nthreads() &gt; 1</code> and the arrays involved are sufficiently large, performance can
be boosted even for plain arrays with a strictly sequential memory layout, provided that the
broadcast operation is compute bound and not memory bound (i.e. the broadcast function is
sufficienlty complex).</p>
<p dir="auto">Strided.jl uses the @spawn threading infrastructure, and the number of tasks that will be
spawned is customizable via the function <code>Strided.set_num_threads(n)</code>, where <code>n</code> can be any
integer between 1 (no threading) and <code>Base.Threads.nthreads()</code>. This allows to spend only a
part of the Julia threads on multithreading, i.e. Strided will never spawn more than <code>n-1</code>
additional tasks. By default, <code>n = Base.Threads.nthreads()</code>, i.e. threading is enabled by
default. There are also convenience functions <code>Strided.enable_threads() = Strided.set_num_threads(Threads.nthreads())</code> and <code>Strided.disable_threads() = Strided.set_num_threads(1)</code>.</p>
<p dir="auto">Furthermore, there is an experimental feature (disabled by default) to apply multithreading
for matrix multiplication using a divide-and-conquer strategy. It can be enabled via
<code>Strided.enable_threaded_mul()</code> (and similarly <code>Strided.disable_threaded_mul()</code> to revert to
the default setting). For matrices with a <code>LinearAlgebra.BlasFloat</code> element type (i.e. any
of <code>Float32</code>, <code>Float64</code>, <code>ComplexF32</code> or <code>ComplexF64</code>), this is typically not necessary as
BLAS is multithreaded by default. However, it can be beneficial to implement the
multithreading using Julia Tasks, which then run on Julia's threads as distributed by
Julia's scheduler. Hence, this feature should likely be used in combination with
<code>LinearAlgebra.BLAS.set_num_threads(1)</code>. Performance seems to be on par (within a few
percent margin) with the threading strategies of OpenBLAS and MKL. However, note that the
latter call also disables any multithreading used in LAPACK (e.g. <code>eigen</code>, <code>svd</code>, <code>qr</code>, ...)
and Strided.jl does not help with that.</p>
<h2 dir="auto"><a id="user-content-stridedview-versus-stridedarray-and-blaslapack-compatibility" class="anchor" aria-hidden="true" href="#stridedview-versus-stridedarray-and-blaslapack-compatibility"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>StridedView</code> versus <code>StridedArray</code> and BLAS/LAPACK compatibility</h2>
<p dir="auto"><code>StridedArray</code> is a union type to denote arrays with a strided structure in Julia Base.
Because of its definition as a type union rather than an abstract type, it is impossible to
have user types be recognized as <code>StridedArray</code>. This is rather unfortunate, since
dispatching to BLAS and LAPACK routines is based on <code>StridedArray</code>. As a consequence,
<code>StridedView</code> will not fall back to BLAS or LAPACK by default. Currently, only matrix
multiplication is overloaded so as to fall back to BLAS (i.e. <code>gemm!</code>) if possible. In
general, one should not attempt use e.g. matrix factorizations or other lapack operations
within the <code>@strided</code> context. Support for this is on the TODO list. Some BLAS inspired
methods (<code>axpy!</code>, <code>axpby!</code>, scalar multiplication via <code>mul!</code>, <code>rmul!</code> or <code>lmul!</code>) are
however overloaded by relying on the optimized yet generic <code>map!</code> implementation.</p>
<p dir="auto"><code>StridedView</code>s can currently only be created with certainty from <code>DenseArray</code> (typically
just <code>Array</code> in Julia Base). For <code>Base.SubArray</code> or <code>Base.ReshapedArray</code> instances, the
<code>StridedView</code> constructor will first act on the underlying parent array, and then try to
mimic the corresponding view or reshape operation using <code>sview</code> and <code>sreshape</code>. These,
however, are more limited then their Base counterparts (because they need to guarantee that
the result still has a strided memory layout with respect to the new dimensions), so an
error can result. However, this approach can also succeed in creating <code>StridedView</code> wrappers
around combinations of <code>view</code> and <code>reshape</code> that are not recognised as <code>Base.StridedArray</code>.
For example, <code>reshape(view(randn(40,40), 1:36, 1:20), (6,6,5,4))</code> is not a
<code>Base.StridedArrray</code>, and indeed, it cannot statically be inferred to be strided, from only
knowing the argument types provided to <code>view</code> and <code>reshape</code>. For example, the similarly
looking <code>reshape(view(randn(40,40), 1:36, 1:20), (6,3,10,4))</code> is not strided. The
<code>StridedView</code> constructor will try to act on both, and yield a runtime error in the second
case. Note that <code>Base.ReinterpretArray</code> is currently not supported.</p>
<p dir="auto">Note again that, unlike <code>StridedArray</code>s, <code>StridedView</code>s behave lazily (i.e. still produce a
view on the same parent array) under <code>permutedims</code> and regular indexing with ranges.</p>
<h1 dir="auto"><a id="user-content-planned-features--wish-list" class="anchor" aria-hidden="true" href="#planned-features--wish-list"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Planned features / wish list</h1>
<ul dir="auto">
<li>Support for <code>GPUArray</code>s with dedicated GPU kernels?</li>
</ul>
</article></div>