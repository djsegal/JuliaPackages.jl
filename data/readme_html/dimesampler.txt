<div id="readme" class="rst" data-path="README.rst"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-dimesamplerjl" class="anchor" aria-hidden="true" href="#dimesamplerjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DIMESampler.jl</h1>
<a href="https://github.com/gboehl/DIMESampler.jl/actions"><img src="https://github.com/gboehl/DIMESampler.jl/workflows/Testing/badge.svg" style="max-width: 100%;">
</a>
<p dir="auto"><strong>Differential-Independence Mixture Ensemble ("DIME") MCMC sampling for Julia</strong></p>
<p dir="auto">This is a standalone Julia implementation of the DIME sampler proposed in <a href="https://gregorboehl.com/live/dime_mcmc_boehl.pdf" rel="nofollow">Ensemble MCMC Sampling for Robust Bayesian Inference</a> <em>(Gregor Boehl, 2022, SSRN No. 4250395)</em>.</p>
<p dir="auto">The sampler has a series of advantages over conventional samplers:</p>
<ol dir="auto">
<li>DIME MCMC is a (very fast) gradient-free <strong>global multi-start optimizer</strong> and, at the same time, a <strong>MCMC sampler</strong> that converges to the posterior distribution. This makes any posterior mode density maximization prior to MCMC sampling superfluous.</li>
<li>The DIME sampler is pretty robust for odd shaped, <strong>multimodal distributions</strong>.</li>
<li>DIME MCMC is <strong>parallelizable</strong>: many chains can run in parallel, and the necessary number of draws decreases almost one-to-one with the number of chains.</li>
<li>DIME proposals are generated from an <strong>endogenous and adaptive proposal distribution</strong>, thereby providing close-to-optimal proposal distributions for black box target distributions without the need for manual fine-tuning.</li>
</ol>
<div dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/gboehl/DIMESampler.jl/blob/main/docs/dist.png?raw=true"><img alt="Sample and target distribution" src="https://github.com/gboehl/DIMESampler.jl/raw/main/docs/dist.png?raw=true" style="width: 800px; max-width: 100%;"></a>
<p dir="auto">Figure: A trimodal example distribution in 35 dimensions</p>
</div>
<a name="user-content-installation"></a>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">Just get the package from the official Julia registry:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Pkg; Pkg.add(&quot;DIMESampler&quot;)"><pre><span class="pl-k">using</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>DIMESampler<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">The package should work with Julia versions starting from v1.6.
There exist complementary implementations <a href="https://github.com/gboehl/emcwrap">for Python</a> and <a href="https://github.com/gboehl/dime-mcmc-matlab">for matlab</a>.</p>
<a name="user-content-usage"></a>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">The core functionality is included in the function <code>RunDIME</code>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# import package
using DIMESampler

# define your density function
function LogProb(x):
    ...
    return lprob
end

# define the initial ensemble
initchain = ...

# define the number of iterations to run
niter = ...

# off you go sampling
chains, lprobs, propdist = RunDIME(LogProb, initchain, niter)
..."><pre><span class="pl-c"><span class="pl-c">#</span> import package</span>
<span class="pl-k">using</span> DIMESampler

<span class="pl-c"><span class="pl-c">#</span> define your density function</span>
<span class="pl-k">function</span> <span class="pl-en">LogProb</span>(x)<span class="pl-k">:</span>
    <span class="pl-k">...</span>
    <span class="pl-k">return</span> lprob
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> define the initial ensemble</span>
initchain <span class="pl-k">=</span> <span class="pl-k">...</span>

<span class="pl-c"><span class="pl-c">#</span> define the number of iterations to run</span>
niter <span class="pl-k">=</span> <span class="pl-k">...</span>

<span class="pl-c"><span class="pl-c">#</span> off you go sampling</span>
chains, lprobs, propdist <span class="pl-k">=</span> <span class="pl-c1">RunDIME</span>(LogProb, initchain, niter)
<span class="pl-k">...</span></pre></div>
<p dir="auto">The <code>LogProb</code> function returning the log-density must be vectorized, i.e. able to evaluate inputs with shape <code>[ndim, :]</code>.</p>
<p dir="auto">The ensemble can be evaluated in parallel, which is one of the central advantages of ensemble MCMC. To have <code>LogProb</code> evaluate its vectorized input in parallel you can e.g. use <code>pmap</code> from <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/" rel="nofollow">Distributed</a></p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="LogProbParallel(x) = pmap(LogProb, eachslice(x, dims=2))"><pre><span class="pl-en">LogProbParallel</span>(x) <span class="pl-k">=</span> <span class="pl-c1">pmap</span>(LogProb, <span class="pl-c1">eachslice</span>(x, dims<span class="pl-k">=</span><span class="pl-c1">2</span>))</pre></div>
<p dir="auto">and then pass this function to <code>RunDIME</code> instead.</p>
<a name="user-content-tutorial"></a>
<h2 dir="auto"><a id="user-content-tutorial" class="anchor" aria-hidden="true" href="#tutorial"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Tutorial</h2>
<p dir="auto">Define a challenging example distribution <strong>with three separate modes</strong> (the distribution from the figure above):</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# some imports
using DIMESampler, Distributions, Random, LinearAlgebra, Plots

# make it reproducible
Random.seed!(1)

# define distribution
m = 2
cov_scale = 0.05
weight = (0.33, 0.1)
ndim = 35

LogProb = CreateDIMETestFunc(ndim, weight, m, cov_scale)"><pre><span class="pl-c"><span class="pl-c">#</span> some imports</span>
<span class="pl-k">using</span> DIMESampler, Distributions, Random, LinearAlgebra, Plots

<span class="pl-c"><span class="pl-c">#</span> make it reproducible</span>
Random<span class="pl-k">.</span><span class="pl-c1">seed!</span>(<span class="pl-c1">1</span>)

<span class="pl-c"><span class="pl-c">#</span> define distribution</span>
m <span class="pl-k">=</span> <span class="pl-c1">2</span>
cov_scale <span class="pl-k">=</span> <span class="pl-c1">0.05</span>
weight <span class="pl-k">=</span> (<span class="pl-c1">0.33</span>, <span class="pl-c1">0.1</span>)
ndim <span class="pl-k">=</span> <span class="pl-c1">35</span>

LogProb <span class="pl-k">=</span> <span class="pl-c1">CreateDIMETestFunc</span>(ndim, weight, m, cov_scale)</pre></div>
<p dir="auto"><code>LogProb</code> will now return the log-PDF of a 35-dimensional Gaussian mixture.</p>
<p dir="auto"><strong>Important:</strong> the function returning the log-density must be vectorized, i.e. able to evaluate inputs with shape <code>[ndim, :]</code>. If you want to make use of parallelization (which is one of the central advantages of ensemble MCMC), you may want to ensure that this function evaluates its vectorized input in parallel, i.e. using <code>pmap</code> from <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/" rel="nofollow">Distributed</a>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="LogProbParallel(x) = pmap(LogProb, eachslice(x, dims=2))"><pre><span class="pl-en">LogProbParallel</span>(x) <span class="pl-k">=</span> <span class="pl-c1">pmap</span>(LogProb, <span class="pl-c1">eachslice</span>(x, dims<span class="pl-k">=</span><span class="pl-c1">2</span>))</pre></div>
<p dir="auto">For this example this is overkill since the overhead from parallelization is huge. Just using the vectorized <code>LogProb</code> is perfect.</p>
<p dir="auto">Next, define the initial ensemble. In a Bayesian setup, a good initial ensemble would be a sample from the prior distribution. Here, we will go for a sample from a rather flat Gaussian distribution.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="initvar = 2
nchain = ndim*5 # a sane default
initcov = I(ndim)*initvar
initmean = zeros(ndim)
initchain = rand(MvNormal(initmean, initcov), nchain)"><pre>initvar <span class="pl-k">=</span> <span class="pl-c1">2</span>
nchain <span class="pl-k">=</span> ndim<span class="pl-k">*</span><span class="pl-c1">5</span> <span class="pl-c"><span class="pl-c">#</span> a sane default</span>
initcov <span class="pl-k">=</span> <span class="pl-c1">I</span>(ndim)<span class="pl-k">*</span>initvar
initmean <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(ndim)
initchain <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">MvNormal</span>(initmean, initcov), nchain)</pre></div>
<p dir="auto">Setting the number of parallel chains to <code>5*ndim</code> is a sane default. For highly irregular distributions with several modes you should use more chains. Very simple distributions can go with less.</p>
<p dir="auto">Now let the sampler run for 5000 iterations.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="niter = 5000
chains, lprobs, propdist = RunDIME(LogProb, initchain, niter, progress=true, aimh_prob=0.1)"><pre>niter <span class="pl-k">=</span> <span class="pl-c1">5000</span>
chains, lprobs, propdist <span class="pl-k">=</span> <span class="pl-c1">RunDIME</span>(LogProb, initchain, niter, progress<span class="pl-k">=</span><span class="pl-c1">true</span>, aimh_prob<span class="pl-k">=</span><span class="pl-c1">0.1</span>)</pre></div>
<pre>[ll/MAF:  12.187(4e+00)/19% | -5e-04] 100.0%┣███████████████████████████████┫ 5.0k/5.0k [00:15&lt;00:00, 198it/s]
</pre>
<p dir="auto">The setting of <code>aimh_prob</code> is the actual default value. For less complex distributions (e.g. distributions closer to Gaussian) a higher value can be chosen, which accelerates burn-in. The information in the progress bar has the structure <code>[ll/MAF: &lt;maximum log-prob&gt;(&lt;standard deviation of log-prob&gt;)/&lt;mean acceptance fraction&gt; | &lt;log state weight&gt;]...</code>, where <code>&lt;log state weight&gt;</code> is the current log-weight on the history of the proposal distribution. The closer this value is to zero (i.e. the actual weight to one), the less relevant are current ensembles for the estimated proposal distribution. It can hence be seen as a measure of convergence.</p>
<p dir="auto">The following code creates the figure above, which is a plot of the marginal distribution along the first dimension (remember that this actually is a 35-dimensional distribution).</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# analytical marginal distribution in first dimension
x = range(-4,4,1000)
mpdf = DIMETestFuncMarginalPDF(x, cov_scale, m, weight)

plot(x, mpdf, label=&quot;Target&quot;, lw=2, legend_position=:topleft)
plot!(x, pdf.(Normal(0, sqrt(initvar)), x), label=&quot;Initialization&quot;)
plot!(x, pdf.(TDist(10), (x .- propdist.μ[1])./sqrt(propdist.Σ[1,1]*10/8)), label=&quot;Final proposal&quot;)
# histogram of the actual sample
histogram!(chains[end-niter÷2:end,:,1][:], normalize=true, alpha=.5, label=&quot;Sample&quot;, color=&quot;black&quot;, bins=100)"><pre><span class="pl-c"><span class="pl-c">#</span> analytical marginal distribution in first dimension</span>
x <span class="pl-k">=</span> <span class="pl-c1">range</span>(<span class="pl-k">-</span><span class="pl-c1">4</span>,<span class="pl-c1">4</span>,<span class="pl-c1">1000</span>)
mpdf <span class="pl-k">=</span> <span class="pl-c1">DIMETestFuncMarginalPDF</span>(x, cov_scale, m, weight)

<span class="pl-c1">plot</span>(x, mpdf, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Target<span class="pl-pds">"</span></span>, lw<span class="pl-k">=</span><span class="pl-c1">2</span>, legend_position<span class="pl-k">=</span><span class="pl-c1">:topleft</span>)
<span class="pl-c1">plot!</span>(x, <span class="pl-c1">pdf</span>.(<span class="pl-c1">Normal</span>(<span class="pl-c1">0</span>, <span class="pl-c1">sqrt</span>(initvar)), x), label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Initialization<span class="pl-pds">"</span></span>)
<span class="pl-c1">plot!</span>(x, <span class="pl-c1">pdf</span>.(<span class="pl-c1">TDist</span>(<span class="pl-c1">10</span>), (x <span class="pl-k">.-</span> propdist<span class="pl-k">.</span>μ[<span class="pl-c1">1</span>])<span class="pl-k">.</span><span class="pl-k">/</span><span class="pl-c1">sqrt</span>(propdist<span class="pl-k">.</span>Σ[<span class="pl-c1">1</span>,<span class="pl-c1">1</span>]<span class="pl-k">*</span><span class="pl-c1">10</span><span class="pl-k">/</span><span class="pl-c1">8</span>)), label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Final proposal<span class="pl-pds">"</span></span>)
<span class="pl-c"><span class="pl-c">#</span> histogram of the actual sample</span>
<span class="pl-c1">histogram!</span>(chains[<span class="pl-c1">end</span><span class="pl-k">-</span>niter<span class="pl-k">÷</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>,:,<span class="pl-c1">1</span>][:], normalize<span class="pl-k">=</span><span class="pl-c1">true</span>, alpha<span class="pl-k">=</span>.<span class="pl-c1">5</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Sample<span class="pl-pds">"</span></span>, color<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>black<span class="pl-pds">"</span></span>, bins<span class="pl-k">=</span><span class="pl-c1">100</span>)</pre></div>
<p dir="auto">To ensure proper mixing, let us also have a look at the MCMC traces, again focussing on the first dimension:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="plot(chains[:,:,1], color=&quot;cyan4&quot;, alpha=.1, legend=false, size=(900,600))"><pre><span class="pl-c1">plot</span>(chains[:,:,<span class="pl-c1">1</span>], color<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>cyan4<span class="pl-pds">"</span></span>, alpha<span class="pl-k">=</span>.<span class="pl-c1">1</span>, legend<span class="pl-k">=</span><span class="pl-c1">false</span>, size<span class="pl-k">=</span>(<span class="pl-c1">900</span>,<span class="pl-c1">600</span>))</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/gboehl/DIMESampler.jl/blob/main/docs/traces.png?raw=true"><img alt="MCMC traces" src="https://github.com/gboehl/DIMESampler.jl/raw/main/docs/traces.png?raw=true" style="width: 800px; max-width: 100%;"></a></p>
<p dir="auto">Note how chains are also switching between the three modes because of the global proposal kernel.</p>
<p dir="auto">While DIME is a MCMC sampler, it can straightforwardly be used as a global optimization routine. To this end, specify some broad starting region (in a non-Bayesian setup there is no prior) and let the sampler run for an extended number of iterations. Finally, assess whether the maximum value per ensemble did not change much in the last few hundred iterations. In a normal Bayesian setup, plotting the associated log-likelihood over time also helps to assess convergence to the posterior distribution.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="plot(lprobs[:,:], color=&quot;orange4&quot;, alpha=.05, legend=false, size=(900,300))
plot!(maximum(lprobs)*ones(niter), color=&quot;blue3&quot;)"><pre><span class="pl-c1">plot</span>(lprobs[:,:], color<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>orange4<span class="pl-pds">"</span></span>, alpha<span class="pl-k">=</span>.<span class="pl-c1">05</span>, legend<span class="pl-k">=</span><span class="pl-c1">false</span>, size<span class="pl-k">=</span>(<span class="pl-c1">900</span>,<span class="pl-c1">300</span>))
<span class="pl-c1">plot!</span>(<span class="pl-c1">maximum</span>(lprobs)<span class="pl-k">*</span><span class="pl-c1">ones</span>(niter), color<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>blue3<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/gboehl/DIMESampler.jl/blob/main/docs/lprobs.png?raw=true"><img alt="Log-likelihoods" src="https://github.com/gboehl/DIMESampler.jl/raw/main/docs/lprobs.png?raw=true" style="width: 800px; max-width: 100%;"></a></p>
<a name="user-content-references"></a>
<h2 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<p dir="auto">If you are using this software in your research, please cite</p>
<div class="highlight highlight-text-bibtex notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="@techreport{boehl2022mcmc,
author={Gregor Boehl},
title={Ensemble MCMC Sampling for Robust Bayesian Inference},
journal={Available at SSRN 4250395},
year={2022}
}"><pre><span class="pl-k">@techreport</span>{<span class="pl-en">boehl2022mcmc</span>,
<span class="pl-s">author</span>=<span class="pl-s"><span class="pl-pds">{</span>Gregor Boehl<span class="pl-pds">}</span></span>,
<span class="pl-s">title</span>=<span class="pl-s"><span class="pl-pds">{</span>Ensemble MCMC Sampling for Robust Bayesian Inference<span class="pl-pds">}</span></span>,
<span class="pl-s">journal</span>=<span class="pl-s"><span class="pl-pds">{</span>Available at SSRN 4250395<span class="pl-pds">}</span></span>,
<span class="pl-s">year</span>=<span class="pl-s"><span class="pl-pds">{</span>2022<span class="pl-pds">}</span></span>
}</pre></div>
<a name="user-content-contributors"></a>
<h2 dir="auto"><a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributors</h2>
<p dir="auto">Many thanks go to <a href="https://github.com/DominikHe262">DominikHe262</a>!</p>

</article></div>