<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-stheno" class="anchor" aria-hidden="true" href="#stheno"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Stheno</h1>
<p><a href="https://github.com/willtebbutt/Stheno.jl/actions"><img src="https://github.com/willtebbutt/Stheno.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width:100%;"></a>
<a href="http://codecov.io/github/JuliaGaussianProcesses/Stheno.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/8134ec281c854d532bc3235a2b9b53863470031b6e1647480adc8c4b004d0393/687474703a2f2f636f6465636f762e696f2f6769746875622f4a756c6961476175737369616e50726f6365737365732f537468656e6f2e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/JuliaGaussianProcesses/Stheno.jl/coverage.svg?branch=master" style="max-width:100%;"></a>
<a href="https://JuliaGaussianProcesses.github.io/Stheno.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/538c5843ffec23dd500a7fc00497bc1947d9d2ad4c3b62f61dcb0968ac3eb947/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-blue.svg" style="max-width:100%;"></a>
<a href="https://github.com/invenia/BlueStyle"><img src="https://camo.githubusercontent.com/c18fbaa52d94d16b90b19701fc90d289b8a5bb920c74c79bab200b14e75420a4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c75652d3434393564312e737667" alt="Code Style: Blue" data-canonical-src="https://img.shields.io/badge/code%20style-blue-4495d1.svg" style="max-width:100%;"></a>
<a href="https://github.com/SciML/ColPrac"><img src="https://camo.githubusercontent.com/a6c1efcb19a957860ecb25966a730260b03d6e05380d0c27992ee7f9e3b1feb3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f6c507261632d436f6e7472696275746f72277325323047756964652d626c756576696f6c6574" alt="ColPrac: Contributor's Guide on Collaborative Practices for Community Packages" data-canonical-src="https://img.shields.io/badge/ColPrac-Contributor's%20Guide-blueviolet" style="max-width:100%;"></a></p>
<p>Stheno is designed to make doing some kinds of non-standard things with Gaussian processes straightforward.
It has a simple modeling syntax, is inherently able to handle both multi-input and multi-output problems, and trivially supports interdomain pseudo-point approximations.</p>
<p><a href="https://github.com/wesselb/stheno">We also have a Python version of the package</a></p>
<p>Please open issues liberally -- if there's anything that's unclear or doesn't work, we would very much like to know about it.</p>
<p><strong>Installation</strong> - <code>] add Stheno</code>.</p>
<p><a href="https://www.youtube.com/watch?v=OO3BBkGEMV8" rel="nofollow">JuliaCon 2019 Talk</a></p>
<p><a href="https://github.com/willtebbutt/TemporalGPs.jl/">Go faster with TemporalGPs.jl</a></p>
<h2><a id="user-content-version-07" class="anchor" aria-hidden="true" href="#version-07"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Version 0.7</h2>
<p>Lots of things have changed in version 0.7. Please consult NEWS.md for details, or take a look at the examples below.</p>
<h2><a id="user-content-a-couple-of-examples" class="anchor" aria-hidden="true" href="#a-couple-of-examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>A Couple of Examples</h2>
<p>The primary sources of information regarding this package are the <a href="https://juliagaussianprocesses.github.io/Stheno.jl/stable" rel="nofollow">documentation</a> and the examples folder, but here are a couple of flashy examples to get started with.</p>
<p>Please raise an issue immediately if either of these examples don't work -- they're not currently included in CI, so there's always a higher chance that they'll be outdated than the internals of the package.</p>
<p>In this first example we define a simple Gaussian process, make observations of different bits of it, and visualise the posterior. We are trivially able to condition on both observations of both <code>f₁</code> <em>and</em> <code>f₃</code>, which isn't something that's typically straightforward.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="
#
# We'll get going by setting up our model, generating some toy observations,
# and constructing the posterior processes produced by conditioning on these
# observations.
#

using AbstractGPs, Stheno, Random, Plots

# Create a pseudo random number generator for reproducibility.
rng = MersenneTwister(123456);

# Define a distribution over f₁, f₂, and f₃, where f₃(x) = f₁(x) + f₂(x).
# This `GPPP` object is just an `AbstractGPs.AbstractGP` object.
f = @gppp let
    f₁ = GP(randn(rng), SEKernel())
    f₂ = GP(SEKernel())
    f₃ = f₁ + f₂
end;

# Sample `N₁` / `N₂` locations at which to measure `f₁` / `f₃`.
N₁, N₃ = 10, 11;
X₁ = GPPPInput(:f₁, rand(rng, N₁) * 10);
X₃ = GPPPInput(:f₃, rand(rng, N₃) * 10);
X = BlockData(X₁, X₃);

# Pick out the bits of `f` that we're interested in, and the variance
# of the noise under which we plan to measure them.
σ² = 1e-2
fx = f(X, 1e-2);

# Sample toy observations of `f₁` / `f₃` at `X₁` / `X₃`.
y = rand(rng, fx);

# You could work backwards to figure out which elements of `y` correspond to
# which of the elements of `X`, but `Stheno.jl` provides methods of `split` to
# do this for you.
ŷ₁, ŷ₃ = split(X, y);

# Compute the logpdf of the observations. Notice that this looks exactly like
# what you would write in AbstractGPs.jl.
l = logpdf(fx, y)

# Compute the ELBO of the observations, with pseudo-points at the same
# locations as the observations. Could have placed them in any of the processes
# in f, even in f₂.
l ≈ elbo(fx, y, f(X))

# Compute the posterior. This is just an `AbstractGPs.PosteriorGP`.
f′ = posterior(fx, y);



#
# The are various things that we can do with a Stheno model.
#

# Sample jointly from the posterior over all of the processes.
Np, S = 500, 11;
X_ = range(-2.5, stop=12.5, length=Np);
Xp1 = GPPPInput(:f₁, X_);
Xp2 = GPPPInput(:f₂, X_);
Xp3 = GPPPInput(:f₃, X_);
Xp = BlockData(Xp1, Xp2, Xp3);
f′_Xp = rand(rng, f′(Xp, 1e-9), S);

# Chop up posterior samples using `split`.
f₁′Xp, f₂′Xp, f₃′Xp = split(Xp, f′_Xp);



#
# We make use of the plotting recipes in AbstractGPs to plot the marginals,
# and manually plot the joint posterior samples.
#

# Instantiate plot and chose backend.
plotly();
posterior_plot = plot();

# Plot posterior over f1.
plot!(posterior_plot, X_, f′(Xp1); color=:red, label=&quot;f1&quot;);
plot!(posterior_plot, X_, f₁′Xp; color=:red, label=&quot;&quot;, alpha=0.2, linewidth=1);
scatter!(posterior_plot, X₁.x, ŷ₁;
    markercolor=:red,
    markershape=:circle,
    markerstrokewidth=0.0,
    markersize=4,
    markeralpha=0.7,
    label=&quot;&quot;,
);

# Plot posterior over f2.
plot!(posterior_plot, X_, f′(Xp2); color=:green, label=&quot;f2&quot;);
plot!(posterior_plot, X_, f₂′Xp; color=:green, label=&quot;&quot;, alpha=0.2, linewidth=1);

# Plot posterior over f3
plot!(posterior_plot, X_, f′(Xp3); color=:blue, label=&quot;f3&quot;);
plot!(posterior_plot, X_, f₃′Xp; color=:blue, label=&quot;&quot;, alpha=0.2, linewidth=1);
scatter!(posterior_plot, X₃.x, ŷ₃;
    markercolor=:blue,
    markershape=:circle,
    markerstrokewidth=0.0,
    markersize=4,
    markeralpha=0.7,
    label=&quot;&quot;,
);

display(posterior_plot);

"><pre><span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> We'll get going by setting up our model, generating some toy observations,</span>
<span class="pl-c"><span class="pl-c">#</span> and constructing the posterior processes produced by conditioning on these</span>
<span class="pl-c"><span class="pl-c">#</span> observations.</span>
<span class="pl-c"><span class="pl-c">#</span></span>

<span class="pl-k">using</span> AbstractGPs, Stheno, Random, Plots

<span class="pl-c"><span class="pl-c">#</span> Create a pseudo random number generator for reproducibility.</span>
rng <span class="pl-k">=</span> <span class="pl-c1">MersenneTwister</span>(<span class="pl-c1">123456</span>);

<span class="pl-c"><span class="pl-c">#</span> Define a distribution over f₁, f₂, and f₃, where f₃(x) = f₁(x) + f₂(x).</span>
<span class="pl-c"><span class="pl-c">#</span> This `GPPP` object is just an `AbstractGPs.AbstractGP` object.</span>
f <span class="pl-k">=</span> <span class="pl-c1">@gppp</span> <span class="pl-k">let</span>
    f₁ <span class="pl-k">=</span> <span class="pl-c1">GP</span>(<span class="pl-c1">randn</span>(rng), <span class="pl-c1">SEKernel</span>())
    f₂ <span class="pl-k">=</span> <span class="pl-c1">GP</span>(<span class="pl-c1">SEKernel</span>())
    f₃ <span class="pl-k">=</span> f₁ <span class="pl-k">+</span> f₂
<span class="pl-k">end</span>;

<span class="pl-c"><span class="pl-c">#</span> Sample `N₁` / `N₂` locations at which to measure `f₁` / `f₃`.</span>
N₁, N₃ <span class="pl-k">=</span> <span class="pl-c1">10</span>, <span class="pl-c1">11</span>;
X₁ <span class="pl-k">=</span> <span class="pl-c1">GPPPInput</span>(<span class="pl-c1">:f₁</span>, <span class="pl-c1">rand</span>(rng, N₁) <span class="pl-k">*</span> <span class="pl-c1">10</span>);
X₃ <span class="pl-k">=</span> <span class="pl-c1">GPPPInput</span>(<span class="pl-c1">:f₃</span>, <span class="pl-c1">rand</span>(rng, N₃) <span class="pl-k">*</span> <span class="pl-c1">10</span>);
X <span class="pl-k">=</span> <span class="pl-c1">BlockData</span>(X₁, X₃);

<span class="pl-c"><span class="pl-c">#</span> Pick out the bits of `f` that we're interested in, and the variance</span>
<span class="pl-c"><span class="pl-c">#</span> of the noise under which we plan to measure them.</span>
σ² <span class="pl-k">=</span> <span class="pl-c1">1e-2</span>
fx <span class="pl-k">=</span> <span class="pl-c1">f</span>(X, <span class="pl-c1">1e-2</span>);

<span class="pl-c"><span class="pl-c">#</span> Sample toy observations of `f₁` / `f₃` at `X₁` / `X₃`.</span>
y <span class="pl-k">=</span> <span class="pl-c1">rand</span>(rng, fx);

<span class="pl-c"><span class="pl-c">#</span> You could work backwards to figure out which elements of `y` correspond to</span>
<span class="pl-c"><span class="pl-c">#</span> which of the elements of `X`, but `Stheno.jl` provides methods of `split` to</span>
<span class="pl-c"><span class="pl-c">#</span> do this for you.</span>
ŷ₁, ŷ₃ <span class="pl-k">=</span> <span class="pl-c1">split</span>(X, y);

<span class="pl-c"><span class="pl-c">#</span> Compute the logpdf of the observations. Notice that this looks exactly like</span>
<span class="pl-c"><span class="pl-c">#</span> what you would write in AbstractGPs.jl.</span>
l <span class="pl-k">=</span> <span class="pl-c1">logpdf</span>(fx, y)

<span class="pl-c"><span class="pl-c">#</span> Compute the ELBO of the observations, with pseudo-points at the same</span>
<span class="pl-c"><span class="pl-c">#</span> locations as the observations. Could have placed them in any of the processes</span>
<span class="pl-c"><span class="pl-c">#</span> in f, even in f₂.</span>
l <span class="pl-k">≈</span> <span class="pl-c1">elbo</span>(fx, y, <span class="pl-c1">f</span>(X))

<span class="pl-c"><span class="pl-c">#</span> Compute the posterior. This is just an `AbstractGPs.PosteriorGP`.</span>
f′ <span class="pl-k">=</span> <span class="pl-c1">posterior</span>(fx, y);



<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> The are various things that we can do with a Stheno model.</span>
<span class="pl-c"><span class="pl-c">#</span></span>

<span class="pl-c"><span class="pl-c">#</span> Sample jointly from the posterior over all of the processes.</span>
Np, S <span class="pl-k">=</span> <span class="pl-c1">500</span>, <span class="pl-c1">11</span>;
X_ <span class="pl-k">=</span> <span class="pl-c1">range</span>(<span class="pl-k">-</span><span class="pl-c1">2.5</span>, stop<span class="pl-k">=</span><span class="pl-c1">12.5</span>, length<span class="pl-k">=</span>Np);
Xp1 <span class="pl-k">=</span> <span class="pl-c1">GPPPInput</span>(<span class="pl-c1">:f₁</span>, X_);
Xp2 <span class="pl-k">=</span> <span class="pl-c1">GPPPInput</span>(<span class="pl-c1">:f₂</span>, X_);
Xp3 <span class="pl-k">=</span> <span class="pl-c1">GPPPInput</span>(<span class="pl-c1">:f₃</span>, X_);
Xp <span class="pl-k">=</span> <span class="pl-c1">BlockData</span>(Xp1, Xp2, Xp3);
f′_Xp <span class="pl-k">=</span> <span class="pl-c1">rand</span>(rng, <span class="pl-c1">f′</span>(Xp, <span class="pl-c1">1e-9</span>), S);

<span class="pl-c"><span class="pl-c">#</span> Chop up posterior samples using `split`.</span>
f₁′Xp, f₂′Xp, f₃′Xp <span class="pl-k">=</span> <span class="pl-c1">split</span>(Xp, f′_Xp);



<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> We make use of the plotting recipes in AbstractGPs to plot the marginals,</span>
<span class="pl-c"><span class="pl-c">#</span> and manually plot the joint posterior samples.</span>
<span class="pl-c"><span class="pl-c">#</span></span>

<span class="pl-c"><span class="pl-c">#</span> Instantiate plot and chose backend.</span>
<span class="pl-c1">plotly</span>();
posterior_plot <span class="pl-k">=</span> <span class="pl-c1">plot</span>();

<span class="pl-c"><span class="pl-c">#</span> Plot posterior over f1.</span>
<span class="pl-c1">plot!</span>(posterior_plot, X_, <span class="pl-c1">f′</span>(Xp1); color<span class="pl-k">=</span><span class="pl-c1">:red</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>f1<span class="pl-pds">"</span></span>);
<span class="pl-c1">plot!</span>(posterior_plot, X_, f₁′Xp; color<span class="pl-k">=</span><span class="pl-c1">:red</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>, alpha<span class="pl-k">=</span><span class="pl-c1">0.2</span>, linewidth<span class="pl-k">=</span><span class="pl-c1">1</span>);
<span class="pl-c1">scatter!</span>(posterior_plot, X₁<span class="pl-k">.</span>x, ŷ₁;
    markercolor<span class="pl-k">=</span><span class="pl-c1">:red</span>,
    markershape<span class="pl-k">=</span><span class="pl-c1">:circle</span>,
    markerstrokewidth<span class="pl-k">=</span><span class="pl-c1">0.0</span>,
    markersize<span class="pl-k">=</span><span class="pl-c1">4</span>,
    markeralpha<span class="pl-k">=</span><span class="pl-c1">0.7</span>,
    label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>,
);

<span class="pl-c"><span class="pl-c">#</span> Plot posterior over f2.</span>
<span class="pl-c1">plot!</span>(posterior_plot, X_, <span class="pl-c1">f′</span>(Xp2); color<span class="pl-k">=</span><span class="pl-c1">:green</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>f2<span class="pl-pds">"</span></span>);
<span class="pl-c1">plot!</span>(posterior_plot, X_, f₂′Xp; color<span class="pl-k">=</span><span class="pl-c1">:green</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>, alpha<span class="pl-k">=</span><span class="pl-c1">0.2</span>, linewidth<span class="pl-k">=</span><span class="pl-c1">1</span>);

<span class="pl-c"><span class="pl-c">#</span> Plot posterior over f3</span>
<span class="pl-c1">plot!</span>(posterior_plot, X_, <span class="pl-c1">f′</span>(Xp3); color<span class="pl-k">=</span><span class="pl-c1">:blue</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>f3<span class="pl-pds">"</span></span>);
<span class="pl-c1">plot!</span>(posterior_plot, X_, f₃′Xp; color<span class="pl-k">=</span><span class="pl-c1">:blue</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>, alpha<span class="pl-k">=</span><span class="pl-c1">0.2</span>, linewidth<span class="pl-k">=</span><span class="pl-c1">1</span>);
<span class="pl-c1">scatter!</span>(posterior_plot, X₃<span class="pl-k">.</span>x, ŷ₃;
    markercolor<span class="pl-k">=</span><span class="pl-c1">:blue</span>,
    markershape<span class="pl-k">=</span><span class="pl-c1">:circle</span>,
    markerstrokewidth<span class="pl-k">=</span><span class="pl-c1">0.0</span>,
    markersize<span class="pl-k">=</span><span class="pl-c1">4</span>,
    markeralpha<span class="pl-k">=</span><span class="pl-c1">0.7</span>,
    label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>,
);

<span class="pl-c1">display</span>(posterior_plot);
</pre></div>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/willtebbutt/stheno_models/blob/master/exact/process_decomposition.png"><img src="https://github.com/willtebbutt/stheno_models/raw/master/exact/process_decomposition.png" alt="" style="max-width:100%;"></a></p>
<p>In the above figure, we have visualised the posterior distribution of all of the processes. Bold lines are posterior means, and shaded areas are three posterior standard deviations from these means. Thin lines are samples from the posterior processes.</p>
<p>This example can also be found in <code>examples/basic_gppp/process_decomposition.jl</code>, which also contains other toy examples of GPPP in action.</p>
<p>In this next example we make observations of two different noisy versions of the same latent process. Again, this is just about doable in existing GP packages if you know what you're doing, but isn't straightforward.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="
using AbstractGPs, Stheno, Random, Plots

# Create a pseudo random number generator for reproducibility.
rng = MersenneTwister(123456);

# Construct a Gaussian Process Probabilistic Programme,
# which is just an AbstractGP.
f = @gppp let

    # Define a smooth latent process that we wish to infer.
    f = GP(SEKernel())

    # Define the two noise processes described.
    g = x-&gt;sin.(x) .- 5.0 .+ sqrt.(abs.(x))
    noise1 = sqrt(1e-2) * GP(WhiteKernel()) + g
    noise2 = sqrt(1e-1) * GP(3.5, WhiteKernel())

    # Define the processes that we get to observe.
    y1 = f + noise1
    y2 = f + noise2
end;

# Generate some toy observations of `y1` and `y2`.
X1 = GPPPInput(:y1, rand(rng, 3) * 10);
X2 = GPPPInput(:y2, rand(rng, 10) * 10);
X = BlockData(X1, X2);
y = rand(rng, f(X));
ŷ1, ŷ2 = split(X, y);

# Compute the posterior GPPP.
f′ = posterior(f(X), y);

# Sample jointly from the posterior processes.
X_ = range(-2.5, stop=12.5, length=500);
Xp_f = GPPPInput(:f, X_);
Xp_y1 = GPPPInput(:y1, X_);
Xp_y2 = GPPPInput(:y2, X_);
Xp = BlockData(Xp_f, Xp_y1, Xp_y2);

# Sample jointly from posterior over process, and split up the result.
f′Xp, y1′Xp, y2′Xp = split(Xp, rand(rng, f′(Xp, 1e-9), 11));

# Compute and split up posterior marginals. We're not using the plotting
# recipes from AbstractGPs here, to make it clear how one might compute the
# posterior marginals manually.
ms = marginals(f′(Xp, 1e-9));
μf′, μy1′, μy2′ = split(Xp, mean.(ms));
σf′, σy1′, σy2′ = split(Xp, std.(ms));

# Instantiate plot and chose backend
plotly();
posterior_plot = plot();

# Plot posterior over y1.
plot!(posterior_plot, X_, μy1′; color=:red, ribbon=3σy1′, label=&quot;&quot;, fillalpha=0.3);
plot!(posterior_plot, X_, y1′Xp; color=:red, label=&quot;&quot;, alpha=0.2, linewidth=1);
scatter!(posterior_plot, X1.x, ŷ1;
    markercolor=:red,
    markershape=:circle,
    markerstrokewidth=0.0,
    markersize=4,
    markeralpha=0.8,
    label=&quot;Sensor 1&quot;,
);

# Plot posterior over y2.
plot!(posterior_plot, X_, μy2′; color=:green, ribbon=3σy2′, label=&quot;&quot;, fillalpha=0.3);
plot!(posterior_plot, X_, y2′Xp; color=:green, label=&quot;&quot;, alpha=0.2, linewidth=1);
scatter!(posterior_plot, X2.x, ŷ2;
    markercolor=:green,
    markershape=:circle,
    markerstrokewidth=0.0,
    markersize=4,
    markeralpha=0.8,
    label=&quot;Sensor 2&quot;,
);

# Plot posterior over f.
plot!(posterior_plot, X_, μf′; color=:blue, ribbon=3σf′, label=&quot;f&quot;, fillalpha=0.3);
plot!(posterior_plot, X_, f′Xp; color=:blue, label=&quot;&quot;, alpha=0.2, linewidth=1);

display(posterior_plot);

"><pre><span class="pl-k">using</span> AbstractGPs, Stheno, Random, Plots

<span class="pl-c"><span class="pl-c">#</span> Create a pseudo random number generator for reproducibility.</span>
rng <span class="pl-k">=</span> <span class="pl-c1">MersenneTwister</span>(<span class="pl-c1">123456</span>);

<span class="pl-c"><span class="pl-c">#</span> Construct a Gaussian Process Probabilistic Programme,</span>
<span class="pl-c"><span class="pl-c">#</span> which is just an AbstractGP.</span>
f <span class="pl-k">=</span> <span class="pl-c1">@gppp</span> <span class="pl-k">let</span>

    <span class="pl-c"><span class="pl-c">#</span> Define a smooth latent process that we wish to infer.</span>
    f <span class="pl-k">=</span> <span class="pl-c1">GP</span>(<span class="pl-c1">SEKernel</span>())

    <span class="pl-c"><span class="pl-c">#</span> Define the two noise processes described.</span>
    g <span class="pl-k">=</span> x<span class="pl-k">-&gt;</span><span class="pl-c1">sin</span>.(x) <span class="pl-k">.-</span> <span class="pl-c1">5.0</span> <span class="pl-k">.+</span> <span class="pl-c1">sqrt</span>.(<span class="pl-c1">abs</span>.(x))
    noise1 <span class="pl-k">=</span> <span class="pl-c1">sqrt</span>(<span class="pl-c1">1e-2</span>) <span class="pl-k">*</span> <span class="pl-c1">GP</span>(<span class="pl-c1">WhiteKernel</span>()) <span class="pl-k">+</span> g
    noise2 <span class="pl-k">=</span> <span class="pl-c1">sqrt</span>(<span class="pl-c1">1e-1</span>) <span class="pl-k">*</span> <span class="pl-c1">GP</span>(<span class="pl-c1">3.5</span>, <span class="pl-c1">WhiteKernel</span>())

    <span class="pl-c"><span class="pl-c">#</span> Define the processes that we get to observe.</span>
    y1 <span class="pl-k">=</span> f <span class="pl-k">+</span> noise1
    y2 <span class="pl-k">=</span> f <span class="pl-k">+</span> noise2
<span class="pl-k">end</span>;

<span class="pl-c"><span class="pl-c">#</span> Generate some toy observations of `y1` and `y2`.</span>
X1 <span class="pl-k">=</span> <span class="pl-c1">GPPPInput</span>(<span class="pl-c1">:y1</span>, <span class="pl-c1">rand</span>(rng, <span class="pl-c1">3</span>) <span class="pl-k">*</span> <span class="pl-c1">10</span>);
X2 <span class="pl-k">=</span> <span class="pl-c1">GPPPInput</span>(<span class="pl-c1">:y2</span>, <span class="pl-c1">rand</span>(rng, <span class="pl-c1">10</span>) <span class="pl-k">*</span> <span class="pl-c1">10</span>);
X <span class="pl-k">=</span> <span class="pl-c1">BlockData</span>(X1, X2);
y <span class="pl-k">=</span> <span class="pl-c1">rand</span>(rng, <span class="pl-c1">f</span>(X));
ŷ1, ŷ2 <span class="pl-k">=</span> <span class="pl-c1">split</span>(X, y);

<span class="pl-c"><span class="pl-c">#</span> Compute the posterior GPPP.</span>
f′ <span class="pl-k">=</span> <span class="pl-c1">posterior</span>(<span class="pl-c1">f</span>(X), y);

<span class="pl-c"><span class="pl-c">#</span> Sample jointly from the posterior processes.</span>
X_ <span class="pl-k">=</span> <span class="pl-c1">range</span>(<span class="pl-k">-</span><span class="pl-c1">2.5</span>, stop<span class="pl-k">=</span><span class="pl-c1">12.5</span>, length<span class="pl-k">=</span><span class="pl-c1">500</span>);
Xp_f <span class="pl-k">=</span> <span class="pl-c1">GPPPInput</span>(<span class="pl-c1">:f</span>, X_);
Xp_y1 <span class="pl-k">=</span> <span class="pl-c1">GPPPInput</span>(<span class="pl-c1">:y1</span>, X_);
Xp_y2 <span class="pl-k">=</span> <span class="pl-c1">GPPPInput</span>(<span class="pl-c1">:y2</span>, X_);
Xp <span class="pl-k">=</span> <span class="pl-c1">BlockData</span>(Xp_f, Xp_y1, Xp_y2);

<span class="pl-c"><span class="pl-c">#</span> Sample jointly from posterior over process, and split up the result.</span>
f′Xp, y1′Xp, y2′Xp <span class="pl-k">=</span> <span class="pl-c1">split</span>(Xp, <span class="pl-c1">rand</span>(rng, <span class="pl-c1">f′</span>(Xp, <span class="pl-c1">1e-9</span>), <span class="pl-c1">11</span>));

<span class="pl-c"><span class="pl-c">#</span> Compute and split up posterior marginals. We're not using the plotting</span>
<span class="pl-c"><span class="pl-c">#</span> recipes from AbstractGPs here, to make it clear how one might compute the</span>
<span class="pl-c"><span class="pl-c">#</span> posterior marginals manually.</span>
ms <span class="pl-k">=</span> <span class="pl-c1">marginals</span>(<span class="pl-c1">f′</span>(Xp, <span class="pl-c1">1e-9</span>));
μf′, μy1′, μy2′ <span class="pl-k">=</span> <span class="pl-c1">split</span>(Xp, <span class="pl-c1">mean</span>.(ms));
σf′, σy1′, σy2′ <span class="pl-k">=</span> <span class="pl-c1">split</span>(Xp, <span class="pl-c1">std</span>.(ms));

<span class="pl-c"><span class="pl-c">#</span> Instantiate plot and chose backend</span>
<span class="pl-c1">plotly</span>();
posterior_plot <span class="pl-k">=</span> <span class="pl-c1">plot</span>();

<span class="pl-c"><span class="pl-c">#</span> Plot posterior over y1.</span>
<span class="pl-c1">plot!</span>(posterior_plot, X_, μy1′; color<span class="pl-k">=</span><span class="pl-c1">:red</span>, ribbon<span class="pl-k">=</span><span class="pl-c1">3</span>σy1′, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>, fillalpha<span class="pl-k">=</span><span class="pl-c1">0.3</span>);
<span class="pl-c1">plot!</span>(posterior_plot, X_, y1′Xp; color<span class="pl-k">=</span><span class="pl-c1">:red</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>, alpha<span class="pl-k">=</span><span class="pl-c1">0.2</span>, linewidth<span class="pl-k">=</span><span class="pl-c1">1</span>);
<span class="pl-c1">scatter!</span>(posterior_plot, X1<span class="pl-k">.</span>x, ŷ1;
    markercolor<span class="pl-k">=</span><span class="pl-c1">:red</span>,
    markershape<span class="pl-k">=</span><span class="pl-c1">:circle</span>,
    markerstrokewidth<span class="pl-k">=</span><span class="pl-c1">0.0</span>,
    markersize<span class="pl-k">=</span><span class="pl-c1">4</span>,
    markeralpha<span class="pl-k">=</span><span class="pl-c1">0.8</span>,
    label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Sensor 1<span class="pl-pds">"</span></span>,
);

<span class="pl-c"><span class="pl-c">#</span> Plot posterior over y2.</span>
<span class="pl-c1">plot!</span>(posterior_plot, X_, μy2′; color<span class="pl-k">=</span><span class="pl-c1">:green</span>, ribbon<span class="pl-k">=</span><span class="pl-c1">3</span>σy2′, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>, fillalpha<span class="pl-k">=</span><span class="pl-c1">0.3</span>);
<span class="pl-c1">plot!</span>(posterior_plot, X_, y2′Xp; color<span class="pl-k">=</span><span class="pl-c1">:green</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>, alpha<span class="pl-k">=</span><span class="pl-c1">0.2</span>, linewidth<span class="pl-k">=</span><span class="pl-c1">1</span>);
<span class="pl-c1">scatter!</span>(posterior_plot, X2<span class="pl-k">.</span>x, ŷ2;
    markercolor<span class="pl-k">=</span><span class="pl-c1">:green</span>,
    markershape<span class="pl-k">=</span><span class="pl-c1">:circle</span>,
    markerstrokewidth<span class="pl-k">=</span><span class="pl-c1">0.0</span>,
    markersize<span class="pl-k">=</span><span class="pl-c1">4</span>,
    markeralpha<span class="pl-k">=</span><span class="pl-c1">0.8</span>,
    label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Sensor 2<span class="pl-pds">"</span></span>,
);

<span class="pl-c"><span class="pl-c">#</span> Plot posterior over f.</span>
<span class="pl-c1">plot!</span>(posterior_plot, X_, μf′; color<span class="pl-k">=</span><span class="pl-c1">:blue</span>, ribbon<span class="pl-k">=</span><span class="pl-c1">3</span>σf′, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>f<span class="pl-pds">"</span></span>, fillalpha<span class="pl-k">=</span><span class="pl-c1">0.3</span>);
<span class="pl-c1">plot!</span>(posterior_plot, X_, f′Xp; color<span class="pl-k">=</span><span class="pl-c1">:blue</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>, alpha<span class="pl-k">=</span><span class="pl-c1">0.2</span>, linewidth<span class="pl-k">=</span><span class="pl-c1">1</span>);

<span class="pl-c1">display</span>(posterior_plot);
</pre></div>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/willtebbutt/stheno_models/blob/master/exact/simple_sensor_fusion.png"><img src="https://github.com/willtebbutt/stheno_models/raw/master/exact/simple_sensor_fusion.png" alt="" style="max-width:100%;"></a></p>
<p>As before, we visualise the posterior distribution through its marginal statistics and joint samples. Note that the posterior samples over the unobserved process are (unsurprisingly) smooth, whereas the posterior samples over the noisy processes still look uncorrelated and noise-like.</p>
<p>As before, this example can also be found in <code>examples/basic_gppp/process_decomposition.jl</code>.</p>
<h2><a id="user-content-hyperparameter-learning-and-inference" class="anchor" aria-hidden="true" href="#hyperparameter-learning-and-inference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Hyperparameter learning and inference</h2>
<p>Fortunately, there is really no need for this package to explicitly provide support for hyperparameter optimisation as the functionality is already available elsewhere -- it's sufficient that it plays nicely with other standard packages in the ecosystem such as <a href="https://github.com/FluxML/Zygote.jl/">Zygote.jl</a> (reverse-mode algorithmic differentiation), <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> (non-linear optimisation), <a href="https://github.com/TuringLang/AdvancedHMC.jl/">AdvancedHMC.jl</a> (Hamiltonian Monte Carlo / NUTS), <a href="https://github.com/invenia/ParameterHandling.jl/">ParameterHandling.jl</a>, <a href="https://github.com/cscherrer/Soss.jl/">Soss.jl</a> / <a href="https://github.com/TuringLang/Turing.jl">Turing.jl</a>. For concrete examples of the use of each of these packages in conjunction with Stheno, see the <code>Getting Started</code> section of the <a href="https://juliagaussianprocesses.github.io/Stheno.jl/dev" rel="nofollow">(dev) docs</a>.</p>
<h2><a id="user-content-non-gaussian-problems" class="anchor" aria-hidden="true" href="#non-gaussian-problems"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Non-Gaussian problems</h2>
<p>As with hyperparmeter learning, Stheno doesn't support non-Gaussian likelihoods directly.
Rather, we expect users to obtain this functionality through the general functionality provided in <code>AbstractGPs</code>.
This part of the JuliaGaussianProcesses ecosystem is broadly under-developed, so please open issues on AbstractGPs if you're keen to help out!</p>
<h2><a id="user-content-gps--deep-learning" class="anchor" aria-hidden="true" href="#gps--deep-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>GPs + Deep Learning</h2>
<p>Again, explicit support not included. Rather just use Stheno in conjunction with <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> and related packages.</p>
</article></div>