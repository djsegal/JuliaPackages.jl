<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-diffeqgpu" class="anchor" aria-hidden="true" href="#diffeqgpu"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DiffEqGPU</h1>
<p dir="auto"><a href="https://julialang.zulipchat.com/#narrow/stream/279055-sciml-bridged" rel="nofollow"><img src="https://camo.githubusercontent.com/667867fc71b8b3c9ed350ce154a04d38adca002ecfa38edf519284e0365ee553/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d5a756c6970266d6573736167653d6368617426636f6c6f723d393535386232266c6162656c436f6c6f723d333839383236" alt="Join the chat at https://julialang.zulipchat.com #sciml-bridged" data-canonical-src="https://img.shields.io/static/v1?label=Zulip&amp;message=chat&amp;color=9558b2&amp;labelColor=389826" style="max-width: 100%;"></a>
<a href="https://docs.sciml.ai/DiffEqGPU/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/88037a523f970520933771e764f5abff55de9382efc91cd89dd43ef0bb49a85f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d5363694d4c2d626c75652e737667" alt="Global Docs" data-canonical-src="https://img.shields.io/badge/docs-SciML-blue.svg" style="max-width: 100%;"></a>
<a href="https://buildkite.com/julialang/diffeqgpu-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/fb98a6943c2a958db65405ed43cc848ff8d9a55a93fc8d904f075f7deeda6854/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f34303961623464383835303330303632363831613434343332383836386432653861643131376361646330613765313432342e737667" alt="Build status" data-canonical-src="https://badge.buildkite.com/409ab4d885030062681a444328868d2e8ad117cadc0a7e1424.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><a href="https://codecov.io/gh/SciML/DiffEqGPU.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/66ba0fc46008fe7dce153789a1c918cc7946309eabbeef6efc340e00d1b083ae/68747470733a2f2f636f6465636f762e696f2f67682f5363694d4c2f4469666645714750552e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/SciML/DiffEqGPU.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><a href="https://github.com/SciML/ColPrac"><img src="https://camo.githubusercontent.com/2496bdc13cbc9c458dfa19a108b1f333353f62917355a4cdee582bbdf8be43cf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f6c507261632d436f6e7472696275746f722532377325323047756964652d626c756576696f6c6574" alt="ColPrac: Contributor's Guide on Collaborative Practices for Community Packages" data-canonical-src="https://img.shields.io/badge/ColPrac-Contributor%27s%20Guide-blueviolet" style="max-width: 100%;"></a>
<a href="https://github.com/SciML/SciMLStyle"><img src="https://camo.githubusercontent.com/3e16f03bad047817fbc07f49307817ed7919ef79c339dc75ad4ce813012c3e0b/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d636f64652532307374796c65266d6573736167653d5363694d4c26636f6c6f723d393535386232266c6162656c436f6c6f723d333839383236" alt="SciML Code Style" data-canonical-src="https://img.shields.io/static/v1?label=code%20style&amp;message=SciML&amp;color=9558b2&amp;labelColor=389826" style="max-width: 100%;"></a></p>
<p dir="auto">This library is a component package of the DifferentialEquations.jl ecosystem. It includes
functionality for making use of GPUs in the differential equation solvers.</p>
<h2 dir="auto"><a id="user-content-the-two-ways-to-accelerate-ode-solvers-with-gpus" class="anchor" aria-hidden="true" href="#the-two-ways-to-accelerate-ode-solvers-with-gpus"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The two ways to accelerate ODE solvers with GPUs</h2>
<p dir="auto">There are two very different ways that one can
accelerate an ODE solution with GPUs. There is one case where <code>u</code> is very big and <code>f</code>
is very expensive but very structured, and you use GPUs to accelerate the computation
of said <code>f</code>. The other use case is where <code>u</code> is very small but you want to solve the ODE
<code>f</code> over many different initial conditions (<code>u0</code>) or parameters <code>p</code>. In that case, you can
use GPUs to parallelize over different parameters and initial conditions. In other words:</p>
<table>
<thead>
<tr>
<th align="left">Type of Problem</th>
<th align="left">SciML Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Accelerate a big ODE</td>
<td align="left">Use <a href="https://cuda.juliagpu.org/stable/" rel="nofollow">CUDA.jl's</a> CuArray as <code>u0</code></td>
</tr>
<tr>
<td align="left">Solve the same ODE with many <code>u0</code> and <code>p</code></td>
<td align="left">Use <a href="https://docs.sciml.ai/DiffEqGPU/stable/" rel="nofollow">DiffEqGPU.jl's</a> <code>EnsembleGPUArray</code> and <code>EnsembleGPUKernel</code></td>
</tr>
</tbody>
</table>
<h2 dir="auto"><a id="user-content-supported-gpus" class="anchor" aria-hidden="true" href="#supported-gpus"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Supported GPUs</h2>
<p dir="auto">SciML's GPU support extends to a wide array of hardware, including:</p>
<table>
<thead>
<tr>
<th align="left">GPU Manufacturer</th>
<th align="left">GPU Kernel Language</th>
<th align="left">Julia Support Package</th>
<th align="left">Backend Type</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">NVIDIA</td>
<td align="left">CUDA</td>
<td align="left"><a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a></td>
<td align="left"><code>CUDA.CUDABackend()</code></td>
</tr>
<tr>
<td align="left">AMD</td>
<td align="left">ROCm</td>
<td align="left"><a href="https://github.com/JuliaGPU/AMDGPU.jl">AMDGPU.jl</a></td>
<td align="left"><code>AMDGPU.ROCBackend()</code></td>
</tr>
<tr>
<td align="left">Intel</td>
<td align="left">OneAPI</td>
<td align="left"><a href="https://github.com/JuliaGPU/oneAPI.jl">OneAPI.jl</a></td>
<td align="left"><code>oneAPI.oneAPIBackend()</code></td>
</tr>
<tr>
<td align="left">Apple (M-Series)</td>
<td align="left">Metal</td>
<td align="left"><a href="https://github.com/JuliaGPU/Metal.jl">Metal.jl</a></td>
<td align="left"><code>Metal.MetalBackend()</code></td>
</tr>
</tbody>
</table>
<p dir="auto">For this tutorial we will demonstrate the CUDA backend for NVIDIA GPUs, though any of the other GPUs can be
used by simply swapping out the <code>backend</code> choice.</p>
<h2 dir="auto"><a id="user-content-example-of-within-method-gpu-parallelism" class="anchor" aria-hidden="true" href="#example-of-within-method-gpu-parallelism"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example of Within-Method GPU Parallelism</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using OrdinaryDiffEq, CUDA, LinearAlgebra
u0 = cu(rand(1000))
A = cu(randn(1000, 1000))
f(du, u, p, t) = mul!(du, A, u)
prob = ODEProblem(f, u0, (0.0f0, 1.0f0)) # Float32 is better on GPUs!
sol = solve(prob, Tsit5())"><pre><span class="pl-k">using</span> OrdinaryDiffEq, CUDA, LinearAlgebra
u0 <span class="pl-k">=</span> <span class="pl-c1">cu</span>(<span class="pl-c1">rand</span>(<span class="pl-c1">1000</span>))
A <span class="pl-k">=</span> <span class="pl-c1">cu</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">1000</span>, <span class="pl-c1">1000</span>))
<span class="pl-en">f</span>(du, u, p, t) <span class="pl-k">=</span> <span class="pl-c1">mul!</span>(du, A, u)
prob <span class="pl-k">=</span> <span class="pl-c1">ODEProblem</span>(f, u0, (<span class="pl-c1">0.0f0</span>, <span class="pl-c1">1.0f0</span>)) <span class="pl-c"><span class="pl-c">#</span> Float32 is better on GPUs!</span>
sol <span class="pl-k">=</span> <span class="pl-c1">solve</span>(prob, <span class="pl-c1">Tsit5</span>())</pre></div>
<h2 dir="auto"><a id="user-content-example-of-parameter-parallelism-with-gpu-ensemble-methods" class="anchor" aria-hidden="true" href="#example-of-parameter-parallelism-with-gpu-ensemble-methods"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example of Parameter-Parallelism with GPU Ensemble Methods</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using DiffEqGPU, CUDA, OrdinaryDiffEq, StaticArrays

function lorenz(u, p, t)
    σ = p[1]
    ρ = p[2]
    β = p[3]
    du1 = σ * (u[2] - u[1])
    du2 = u[1] * (ρ - u[3]) - u[2]
    du3 = u[1] * u[2] - β * u[3]
    return SVector{3}(du1, du2, du3)
end

u0 = @SVector [1.0f0; 0.0f0; 0.0f0]
tspan = (0.0f0, 10.0f0)
p = @SVector [10.0f0, 28.0f0, 8 / 3.0f0]
prob = ODEProblem{false}(lorenz, u0, tspan, p)
prob_func = (prob, i, repeat) -&gt; remake(prob, p = (@SVector rand(Float32, 3)) .* p)
monteprob = EnsembleProblem(prob, prob_func = prob_func, safetycopy = false)

@time sol = solve(monteprob, GPUTsit5(), EnsembleGPUKernel(CUDA.CUDABackend()),
                  trajectories = 10_000, adaptive = false, dt = 0.1f0)"><pre><span class="pl-k">using</span> DiffEqGPU, CUDA, OrdinaryDiffEq, StaticArrays

<span class="pl-k">function</span> <span class="pl-en">lorenz</span>(u, p, t)
    σ <span class="pl-k">=</span> p[<span class="pl-c1">1</span>]
    ρ <span class="pl-k">=</span> p[<span class="pl-c1">2</span>]
    β <span class="pl-k">=</span> p[<span class="pl-c1">3</span>]
    du1 <span class="pl-k">=</span> σ <span class="pl-k">*</span> (u[<span class="pl-c1">2</span>] <span class="pl-k">-</span> u[<span class="pl-c1">1</span>])
    du2 <span class="pl-k">=</span> u[<span class="pl-c1">1</span>] <span class="pl-k">*</span> (ρ <span class="pl-k">-</span> u[<span class="pl-c1">3</span>]) <span class="pl-k">-</span> u[<span class="pl-c1">2</span>]
    du3 <span class="pl-k">=</span> u[<span class="pl-c1">1</span>] <span class="pl-k">*</span> u[<span class="pl-c1">2</span>] <span class="pl-k">-</span> β <span class="pl-k">*</span> u[<span class="pl-c1">3</span>]
    <span class="pl-k">return</span> <span class="pl-c1">SVector</span><span class="pl-c1">{3}</span>(du1, du2, du3)
<span class="pl-k">end</span>

u0 <span class="pl-k">=</span> <span class="pl-c1">@SVector</span> [<span class="pl-c1">1.0f0</span>; <span class="pl-c1">0.0f0</span>; <span class="pl-c1">0.0f0</span>]
tspan <span class="pl-k">=</span> (<span class="pl-c1">0.0f0</span>, <span class="pl-c1">10.0f0</span>)
p <span class="pl-k">=</span> <span class="pl-c1">@SVector</span> [<span class="pl-c1">10.0f0</span>, <span class="pl-c1">28.0f0</span>, <span class="pl-c1">8</span> <span class="pl-k">/</span> <span class="pl-c1">3.0f0</span>]
prob <span class="pl-k">=</span> <span class="pl-c1">ODEProblem</span><span class="pl-c1">{false}</span>(lorenz, u0, tspan, p)
prob_func <span class="pl-k">=</span> (prob, i, repeat) <span class="pl-k">-&gt;</span> <span class="pl-c1">remake</span>(prob, p <span class="pl-k">=</span> (<span class="pl-c1">@SVector</span> <span class="pl-c1">rand</span>(Float32, <span class="pl-c1">3</span>)) <span class="pl-k">.*</span> p)
monteprob <span class="pl-k">=</span> <span class="pl-c1">EnsembleProblem</span>(prob, prob_func <span class="pl-k">=</span> prob_func, safetycopy <span class="pl-k">=</span> <span class="pl-c1">false</span>)

<span class="pl-c1">@time</span> sol <span class="pl-k">=</span> <span class="pl-c1">solve</span>(monteprob, <span class="pl-c1">GPUTsit5</span>(), <span class="pl-c1">EnsembleGPUKernel</span>(CUDA<span class="pl-k">.</span><span class="pl-c1">CUDABackend</span>()),
                  trajectories <span class="pl-k">=</span> <span class="pl-c1">10_000</span>, adaptive <span class="pl-k">=</span> <span class="pl-c1">false</span>, dt <span class="pl-k">=</span> <span class="pl-c1">0.1f0</span>)</pre></div>
</article></div>