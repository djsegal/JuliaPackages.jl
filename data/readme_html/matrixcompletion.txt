<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-matrixcompletionjl" class="anchor" aria-hidden="true" href="#matrixcompletionjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>MatrixCompletion.jl</h1>
<p dir="auto">MatrixCompletion.jl is Julia package for completion low rank matrices with missing entries. The problem of matrix completion has a wide range of applications, such as collaborative filtering, system identification, data imputation, and Internet of things localization.</p>
<p dir="auto">MatrixCompletion.jl by default uses algorithm proposed in Robust Matrix Completion with Mix Data Types, see <a href="">paper</a>, which is a convex algorithm that minimizes the joint likelihood reguluaized by both nuclear norm and max norm. It can complete low rank matrices with hetergenous data (columnwise or row wise) data types, which are in the exponential family such as:</p>
<ul dir="auto">
<li>Bernoulli (binary data)</li>
<li>Poisson (count data)</li>
<li>Gaussian (continuous data)</li>
<li>Negative Binomial (count)</li>
<li>Gamma (skewed continuous data)</li>
</ul>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">To install, simply type</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="Pkg.add(&quot;MatrixCompletion)"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>MatrixCompletion)</span></pre></div>
<p dir="auto">in the Julia REPL.</p>
<h2 dir="auto"><a id="user-content-minimal-working-example" class="anchor" aria-hidden="true" href="#minimal-working-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Minimal Working Example</h2>
<p dir="auto">For example, the following simulation snippet demonstrates how to complete a manually generated mixed-type low rank matrix.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using MatrixCompletion
import Distributions, Random
input_rank = 20
truth_matrix       = rand([(FixedRankMatrix(Distributions.Gaussian(0, 1),           rank = input_rank), 500, 100),
                           (FixedRankMatrix(Distributions.Bernoulli(0.5),           rank = input_rank), 500, 100),
                           (FixedRankMatrix(Distributions.Gamma(10, 0.5),           rank = input_rank), 500, 100),
                           (FixedRankMatrix(Distributions.Poisson(5),               rank = input_rank), 500, 100),
                           (FixedRankMatrix(Distributions.NegativeBinomial(6, 0.8), rank = input_rank), 500, 100)])
sample_model       = provide(Sampler{BernoulliModel}(), rate = 80 / 100)
input_matrix       = sample_model.draw(truth_matrix)
manual_type_matrix = Array{Symbol}(undef, 500, 500)
manual_type_matrix[:, 1:100]   .= :Gaussian
manual_type_matrix[:, 101:200] .= :Bernoulli
manual_type_matrix[:, 201:300] .= :Gamma
manual_type_matrix[:, 301:400] .= :Poisson
manual_type_matrix[:, 401:500] .= :NegativeBinomial
user_input_estimators = Dict(:NegativeBinomial=&gt; Dict(:r=&gt;6, :p=&gt;0.8))

completed_matrix, type_tracker, tracker = complete(A                     = input_matrix,
                                                    maxiter               = 200,
                                                    ρ                     = 0.3,
                                                    use_autodiff          = false,
                                                    gd_iter               = 3,
                                                    debug_mode            = false,
                                                    user_input_estimators = user_input_estimators,
                                                    project_rank          = input_rank * 10,
                                                    io                    = io,
                                                    type_assignment       = manual_type_matrix)


predicted_matrix = predict(MatrixCompletionModel(),
                            completed_matrix = completed_matrix,
                            type_tracker     = type_tracker,
                            estimators       = user_input_estimators)

summary_object   = summary(MatrixCompletionModel(),
                            predicted_matrix = predicted_matrix,
                            truth_matrix     = truth_matrix,
                            type_tracker     = type_tracker,
                            tracker          = tracker)"><pre class="notranslate"><code>using MatrixCompletion
import Distributions, Random
input_rank = 20
truth_matrix       = rand([(FixedRankMatrix(Distributions.Gaussian(0, 1),           rank = input_rank), 500, 100),
                           (FixedRankMatrix(Distributions.Bernoulli(0.5),           rank = input_rank), 500, 100),
                           (FixedRankMatrix(Distributions.Gamma(10, 0.5),           rank = input_rank), 500, 100),
                           (FixedRankMatrix(Distributions.Poisson(5),               rank = input_rank), 500, 100),
                           (FixedRankMatrix(Distributions.NegativeBinomial(6, 0.8), rank = input_rank), 500, 100)])
sample_model       = provide(Sampler{BernoulliModel}(), rate = 80 / 100)
input_matrix       = sample_model.draw(truth_matrix)
manual_type_matrix = Array{Symbol}(undef, 500, 500)
manual_type_matrix[:, 1:100]   .= :Gaussian
manual_type_matrix[:, 101:200] .= :Bernoulli
manual_type_matrix[:, 201:300] .= :Gamma
manual_type_matrix[:, 301:400] .= :Poisson
manual_type_matrix[:, 401:500] .= :NegativeBinomial
user_input_estimators = Dict(:NegativeBinomial=&gt; Dict(:r=&gt;6, :p=&gt;0.8))

completed_matrix, type_tracker, tracker = complete(A                     = input_matrix,
                                                    maxiter               = 200,
                                                    ρ                     = 0.3,
                                                    use_autodiff          = false,
                                                    gd_iter               = 3,
                                                    debug_mode            = false,
                                                    user_input_estimators = user_input_estimators,
                                                    project_rank          = input_rank * 10,
                                                    io                    = io,
                                                    type_assignment       = manual_type_matrix)


predicted_matrix = predict(MatrixCompletionModel(),
                            completed_matrix = completed_matrix,
                            type_tracker     = type_tracker,
                            estimators       = user_input_estimators)

summary_object   = summary(MatrixCompletionModel(),
                            predicted_matrix = predicted_matrix,
                            truth_matrix     = truth_matrix,
                            type_tracker     = type_tracker,
                            tracker          = tracker)
</code></pre></div>
<h2 dir="auto"><a id="user-content-automatic-data-type-detection" class="anchor" aria-hidden="true" href="#automatic-data-type-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Automatic data type detection</h2>
<p dir="auto">We note that in the MWE, the data type of the observed matrix was entered manually. Although doing so in most cases guarantees maximum recovery rate, in reality it is often unknown that what are the exact distributions of the underlying data. To address this issue, we provided an API that allows the algorithm to automatically detect the best fitting distributed within the supported range and after doing so, also acquire the MLE of the corresponding parameters. Traditional goodness-and-fit often has less power when the input data size are large. To address this problem, we adopted a different approach combining a simple trivial decision tree and comparing the empirical distribution to its exponential family candidates in the frequency domain, i.e. MGF. In order to use automatic data type detection, one simply need to not provide the <code>user_input_estimators</code> parameter in the <code>complete</code> function.</p>
<p dir="auto"><strong>Note.</strong> While useful, according to preliminary simulations results, using automatic data type detection often results in recovery rate loss when the underlying data is continuous and strongly skewed.</p>
<h2 dir="auto"><a id="user-content-simulation-utilities" class="anchor" aria-hidden="true" href="#simulation-utilities"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Simulation Utilities</h2>
<h3 dir="auto"><a id="user-content-different-fast-eigen-solvers" class="anchor" aria-hidden="true" href="#different-fast-eigen-solvers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Different Fast Eigen Solvers</h3>
<p dir="auto">Due to potential unforseen numerical instabilitis, multiple fast eigen libraries are shipped with MatrixCompletion.jl. Arpack is tested to be the fastest when using the MKL patched Julia 1.2. By default, this is not enabled due to licensing issues; and a Julia native Lancozs library is used by default.</p>
<h3 dir="auto"><a id="user-content-sampling-schemes" class="anchor" aria-hidden="true" href="#sampling-schemes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Sampling Schemes</h3>
<p dir="auto">MatrixCompletion.jl supports two sampling schemes, Uniform Sampling and Bernoulli Sampling. Researchers can use <code>x = provide(Sampler{BernoulliModel}(), rate = 80 / 100)</code> to get an instance of the corresponding sampler and bind it to <code>x</code>, and use <code>x.draw(M)</code> to draw a partially observed matrix from full input matrix <code>M</code>.</p>
<h3 dir="auto"><a id="user-content-random-fixed-rank-matrix-generator" class="anchor" aria-hidden="true" href="#random-fixed-rank-matrix-generator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Random Fixed Rank Matrix Generator</h3>
<p dir="auto">MatrixCompletion.jl also provides a random fixed rank matrix generator that supports generating low rank matrix of target rank and specified (combination of) distributions. For example,</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="input_rank = 10
M = rand([(FixedRankMatrix(Distributions.Gaussian(0, 1),           rank = input_rank), 500, 100),
          (FixedRankMatrix(Distributions.Bernoulli(0.5),           rank = input_rank), 500, 100),
          (FixedRankMatrix(Distributions.Gamma(10, 0.5),           rank = input_rank), 500, 100),
          (FixedRankMatrix(Distributions.Poisson(5),               rank = input_rank), 500, 100),
          (FixedRankMatrix(Distributions.NegativeBinomial(6, 0.8), rank = input_rank), 500, 100)])"><pre>input_rank <span class="pl-k">=</span> <span class="pl-c1">10</span>
M <span class="pl-k">=</span> <span class="pl-c1">rand</span>([(<span class="pl-c1">FixedRankMatrix</span>(Distributions<span class="pl-k">.</span><span class="pl-c1">Gaussian</span>(<span class="pl-c1">0</span>, <span class="pl-c1">1</span>),           rank <span class="pl-k">=</span> input_rank), <span class="pl-c1">500</span>, <span class="pl-c1">100</span>),
          (<span class="pl-c1">FixedRankMatrix</span>(Distributions<span class="pl-k">.</span><span class="pl-c1">Bernoulli</span>(<span class="pl-c1">0.5</span>),           rank <span class="pl-k">=</span> input_rank), <span class="pl-c1">500</span>, <span class="pl-c1">100</span>),
          (<span class="pl-c1">FixedRankMatrix</span>(Distributions<span class="pl-k">.</span><span class="pl-c1">Gamma</span>(<span class="pl-c1">10</span>, <span class="pl-c1">0.5</span>),           rank <span class="pl-k">=</span> input_rank), <span class="pl-c1">500</span>, <span class="pl-c1">100</span>),
          (<span class="pl-c1">FixedRankMatrix</span>(Distributions<span class="pl-k">.</span><span class="pl-c1">Poisson</span>(<span class="pl-c1">5</span>),               rank <span class="pl-k">=</span> input_rank), <span class="pl-c1">500</span>, <span class="pl-c1">100</span>),
          (<span class="pl-c1">FixedRankMatrix</span>(Distributions<span class="pl-k">.</span><span class="pl-c1">NegativeBinomial</span>(<span class="pl-c1">6</span>, <span class="pl-c1">0.8</span>), rank <span class="pl-k">=</span> input_rank), <span class="pl-c1">500</span>, <span class="pl-c1">100</span>)])</pre></div>
<p dir="auto">generates a 500*500 matrix <code>M</code> with target rank 50, with the five listed distribution divided according to the dimension parameters.</p>
<h1 dir="auto"><a id="user-content-on-going-work" class="anchor" aria-hidden="true" href="#on-going-work"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>On going work</h1>
<h2 dir="auto"><a id="user-content-gui-front-end" class="anchor" aria-hidden="true" href="#gui-front-end"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>GUI front end</h2>
<p dir="auto">A Gui front end is to be created using Genie to</p>
<ul dir="auto">
<li>provide interactive plotting of convergence path and regularization path.</li>
<li>provide a simple and easy to use interface for user to try to apply the algorithm to pictures of users' choice.</li>
</ul>
<h2 dir="auto"><a id="user-content-more-algorithms" class="anchor" aria-hidden="true" href="#more-algorithms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>More Algorithms</h2>
<p dir="auto">MatrixCompletion.jl aims to be the most comprehensive matrix completion algorithm library in Julia consisting of both popular non-convex and convex algorithms proposed in the past decade, including (on going work):</p>
<ul dir="auto">
<li>
<p dir="auto">LMaFit: Low-Rank Matrix Fitting <a href="http://link.springer.com/article/10.1007%2Fs12532-012-0044-1" rel="nofollow">(Wen et al. 2012)</a> <a href="http://lmafit.blogs.rice.edu/" rel="nofollow">website</a></p>
</li>
<li>
<p dir="auto">OptSpace: Matrix Completion from Noisy Entries  <a href="http://arxiv.org/pdf/0906.2027v1.pdf" rel="nofollow">(Keshavan et al. 2009)</a> <a href="http://web.engr.illinois.edu/~swoh/software/optspace/code.html" rel="nofollow">website</a></p>
</li>
<li>
<p dir="auto">OR1MP: Orthogonal rank-one matrix pursuit for low rank matrix completion <a href="https://arxiv.org/abs/1404.1377" rel="nofollow">(Wang et al. 2015)</a></p>
</li>
<li>
<p dir="auto">SVT: A singular value thresholding algorithm for matrix completion <a href="http://arxiv.org/pdf/0810.3286.pdf" rel="nofollow">(Cai et al. 2008)</a> <a href="http://svt.stanford.edu/" rel="nofollow">website</a></p>
</li>
</ul>
</article></div>