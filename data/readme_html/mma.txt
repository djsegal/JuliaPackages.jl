<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-mmajl" class="anchor" aria-hidden="true" href="#mmajl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>MMA.jl</h1>
<p><a href="https://travis-ci.org/KristofferC/MMA.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/a61928906ab074a6d3dc4cadb5adc4f96277aaa2dc7cc1786dddbbb81a8d0f07/68747470733a2f2f7472617669732d63692e6f72672f4b726973746f66666572432f4d4d412e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/KristofferC/MMA.jl.svg?branch=master" style="max-width:100%;"></a></p>
<p>This module implements the MMA Algorithm in Julia as described by Krister Svanberg in [1].</p>
<p>The code in this module was made for a course in Structural Optimization and should be seen as educational. For real use it is likely better to use a more mature code base, for example <a href="https://github.com/JuliaOpt/NLopt.jl">NLopt.jl</a> which contain a more modern MMA algorithm than the one implemented here.</p>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<p>áº€e will solve the nonlinear constrained minimization problem given <a href="http://ab-initio.mit.edu/wiki/index.php/NLopt_Tutorial" rel="nofollow">here</a></p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using MMA

# Define objective function
function f(x::Vector, grad::Vector)
    if length(grad) != 0
        grad[1] = 0.0
        grad[2] = 0.5/sqrt(x[2])
    end
    sqrt(x[2])
end

# Define a constraint function
function g(x::Vector, grad::Vector, a, b)
    if length(grad) != 0
        grad[1] = 3a * (a*x[1] + b)^2
        grad[2] = -1
    end
    (a*x[1] + b)^3 - x[2]
end

# Create the MMAModel with a relative tolerance on x
ndim = 2
m = MMAModel(ndim, f, xtol = 1e-6, store_trace=true)

# Add box constraints to the variables
box!(m, 1, 0.0, 100.0)
box!(m, 2, 0.0, 100.0)

# Add two nonlinear inequalities
ineq_constraint!(m, (x,grad) -&gt; g(x,grad,2,0))
ineq_constraint!(m, (x,grad) -&gt; g(x,grad,-1,1))

# Solve the problem
x0 = [1.234, 2.345]
results = optimize(m, x0)

# Print the results
print(results)

#Results of Optimization Algorithm
# * Algorithm: MMA._MMA
# * Starting Point: [1.234,2.345]
# * Minimizer: [0.3333332274782007,0.29629691337859027]
# * Minimum: 5.443316e-01
# * Iterations: 7
# * Convergence: true
#   * |x - x'| &lt; 1.0e-06: true
#     |x - x'| = 8.33e-08
#   * |f(x) - f(x')| / |f(x)| &lt; 1.5e-08: false
#     |f(x) - f(x')| / |f(x)| = 7.65e-08
#   * |g(x)| &lt; 1.5e-08: false
#     |g(x)| = 9.19e-01
#   * stopped by an increasing objective: true
#   * Reached Maximum Number of Iterations: false
# * Objective Calls: 8
# * Gradient Calls: 8

# Print the trace
#println(results.trace)
#Iter     Function value   Gradient norm
#------   --------------   --------------
#     1     3.948114e-01     1.266427e+00
#     2     1.799667e-01     2.778292e+00
#     3     4.353204e-01     1.148579e+00
#     4     5.338213e-01     9.366429e-01
#     5     5.442500e-01     9.186955e-01
#     6     5.443315e-01     9.185578e-01
#     7     5.443316e-01     9.185577e-01
"><pre><span class="pl-k">using</span> MMA

<span class="pl-c"><span class="pl-c">#</span> Define objective function</span>
<span class="pl-k">function</span> <span class="pl-en">f</span>(x<span class="pl-k">::</span><span class="pl-c1">Vector</span>, grad<span class="pl-k">::</span><span class="pl-c1">Vector</span>)
    <span class="pl-k">if</span> <span class="pl-c1">length</span>(grad) <span class="pl-k">!=</span> <span class="pl-c1">0</span>
        grad[<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">0.0</span>
        grad[<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">0.5</span><span class="pl-k">/</span><span class="pl-c1">sqrt</span>(x[<span class="pl-c1">2</span>])
    <span class="pl-k">end</span>
    <span class="pl-c1">sqrt</span>(x[<span class="pl-c1">2</span>])
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> Define a constraint function</span>
<span class="pl-k">function</span> <span class="pl-en">g</span>(x<span class="pl-k">::</span><span class="pl-c1">Vector</span>, grad<span class="pl-k">::</span><span class="pl-c1">Vector</span>, a, b)
    <span class="pl-k">if</span> <span class="pl-c1">length</span>(grad) <span class="pl-k">!=</span> <span class="pl-c1">0</span>
        grad[<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">3</span>a <span class="pl-k">*</span> (a<span class="pl-k">*</span>x[<span class="pl-c1">1</span>] <span class="pl-k">+</span> b)<span class="pl-k">^</span><span class="pl-c1">2</span>
        grad[<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1</span>
    <span class="pl-k">end</span>
    (a<span class="pl-k">*</span>x[<span class="pl-c1">1</span>] <span class="pl-k">+</span> b)<span class="pl-k">^</span><span class="pl-c1">3</span> <span class="pl-k">-</span> x[<span class="pl-c1">2</span>]
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> Create the MMAModel with a relative tolerance on x</span>
ndim <span class="pl-k">=</span> <span class="pl-c1">2</span>
m <span class="pl-k">=</span> <span class="pl-c1">MMAModel</span>(ndim, f, xtol <span class="pl-k">=</span> <span class="pl-c1">1e-6</span>, store_trace<span class="pl-k">=</span><span class="pl-c1">true</span>)

<span class="pl-c"><span class="pl-c">#</span> Add box constraints to the variables</span>
<span class="pl-c1">box!</span>(m, <span class="pl-c1">1</span>, <span class="pl-c1">0.0</span>, <span class="pl-c1">100.0</span>)
<span class="pl-c1">box!</span>(m, <span class="pl-c1">2</span>, <span class="pl-c1">0.0</span>, <span class="pl-c1">100.0</span>)

<span class="pl-c"><span class="pl-c">#</span> Add two nonlinear inequalities</span>
<span class="pl-c1">ineq_constraint!</span>(m, (x,grad) <span class="pl-k">-&gt;</span> <span class="pl-c1">g</span>(x,grad,<span class="pl-c1">2</span>,<span class="pl-c1">0</span>))
<span class="pl-c1">ineq_constraint!</span>(m, (x,grad) <span class="pl-k">-&gt;</span> <span class="pl-c1">g</span>(x,grad,<span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">1</span>))

<span class="pl-c"><span class="pl-c">#</span> Solve the problem</span>
x0 <span class="pl-k">=</span> [<span class="pl-c1">1.234</span>, <span class="pl-c1">2.345</span>]
results <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(m, x0)

<span class="pl-c"><span class="pl-c">#</span> Print the results</span>
<span class="pl-c1">print</span>(results)

<span class="pl-c"><span class="pl-c">#</span>Results of Optimization Algorithm</span>
<span class="pl-c"><span class="pl-c">#</span> * Algorithm: MMA._MMA</span>
<span class="pl-c"><span class="pl-c">#</span> * Starting Point: [1.234,2.345]</span>
<span class="pl-c"><span class="pl-c">#</span> * Minimizer: [0.3333332274782007,0.29629691337859027]</span>
<span class="pl-c"><span class="pl-c">#</span> * Minimum: 5.443316e-01</span>
<span class="pl-c"><span class="pl-c">#</span> * Iterations: 7</span>
<span class="pl-c"><span class="pl-c">#</span> * Convergence: true</span>
<span class="pl-c"><span class="pl-c">#</span>   * |x - x'| &lt; 1.0e-06: true</span>
<span class="pl-c"><span class="pl-c">#</span>     |x - x'| = 8.33e-08</span>
<span class="pl-c"><span class="pl-c">#</span>   * |f(x) - f(x')| / |f(x)| &lt; 1.5e-08: false</span>
<span class="pl-c"><span class="pl-c">#</span>     |f(x) - f(x')| / |f(x)| = 7.65e-08</span>
<span class="pl-c"><span class="pl-c">#</span>   * |g(x)| &lt; 1.5e-08: false</span>
<span class="pl-c"><span class="pl-c">#</span>     |g(x)| = 9.19e-01</span>
<span class="pl-c"><span class="pl-c">#</span>   * stopped by an increasing objective: true</span>
<span class="pl-c"><span class="pl-c">#</span>   * Reached Maximum Number of Iterations: false</span>
<span class="pl-c"><span class="pl-c">#</span> * Objective Calls: 8</span>
<span class="pl-c"><span class="pl-c">#</span> * Gradient Calls: 8</span>

<span class="pl-c"><span class="pl-c">#</span> Print the trace</span>
<span class="pl-c"><span class="pl-c">#</span>println(results.trace)</span>
<span class="pl-c"><span class="pl-c">#</span>Iter     Function value   Gradient norm</span>
<span class="pl-c"><span class="pl-c">#</span>------   --------------   --------------</span>
<span class="pl-c"><span class="pl-c">#</span>     1     3.948114e-01     1.266427e+00</span>
<span class="pl-c"><span class="pl-c">#</span>     2     1.799667e-01     2.778292e+00</span>
<span class="pl-c"><span class="pl-c">#</span>     3     4.353204e-01     1.148579e+00</span>
<span class="pl-c"><span class="pl-c">#</span>     4     5.338213e-01     9.366429e-01</span>
<span class="pl-c"><span class="pl-c">#</span>     5     5.442500e-01     9.186955e-01</span>
<span class="pl-c"><span class="pl-c">#</span>     6     5.443315e-01     9.185578e-01</span>
<span class="pl-c"><span class="pl-c">#</span>     7     5.443316e-01     9.185577e-01</span></pre></div>
<h2><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>References</h2>
<p>[1] <a href="http://www.researchgate.net/publication/227631828_The_method_of_moving_asymptotesa_new_method_for_structural_optimization" rel="nofollow">The method of moving asymptotes - a new method for structural optimization</a></p>
<h3><a id="user-content-author" class="anchor" aria-hidden="true" href="#author"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Author</h3>
<p>Kristoffer Carlsson - <a href="mailto:kristoffer.carlsson@chalmers.se">kristoffer.carlsson@chalmers.se</a></p>
</article></div>