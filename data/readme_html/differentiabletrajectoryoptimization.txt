<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-differentiabletrajectoryoptimizationjl-dito" class="anchor" aria-hidden="true" href="#differentiabletrajectoryoptimizationjl-dito"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DifferentiableTrajectoryOptimization.jl (Dito)</h1>
<p dir="auto"><a href="https://github.com/lassepe/DifferentiableTrajectoryOptimization.jl/actions/workflows/ci.yml"><img src="https://github.com/lassepe/DifferentiableTrajectoryOptimization.jl/actions/workflows/ci.yml/badge.svg" alt="CI" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/lassepe/DifferentiableTrajectoryOptimization.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/96e4190ccd4e17958d81ad068562c1b2ddb785d5f39684c68ce97861864d48fb/68747470733a2f2f636f6465636f762e696f2f67682f6c6173736570652f446966666572656e746961626c655472616a6563746f72794f7074696d697a6174696f6e2e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d69316737566635784f59" alt="codecov" data-canonical-src="https://codecov.io/gh/lassepe/DifferentiableTrajectoryOptimization.jl/branch/main/graph/badge.svg?token=i1g7Vf5xOY" style="max-width: 100%;"></a>
<a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/2bb630e2707a04100cd270fd944d22816241c37b68a5a1629257920c65e17891/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c7565" alt="License" data-canonical-src="https://img.shields.io/badge/license-MIT-blue" style="max-width: 100%;"></a></p>
<p dir="auto">DifferentiableTrajectoryOptimization.jl (Dito for short) is a package for <strong>Di</strong>fferentiable <strong>T</strong>rajetory <strong>O</strong>ptimization in Julia. It supports both forward and reverse mode differentiation via <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff.jl</a> and <a href="https://github.com/JuliaDiff/ChainRulesCore.jl">ChainRulesCore.jl</a> and therefore integrates seamlessly with machine learning frameworks such as <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a>.</p>
<hr>
<p dir="auto">A substantial part of machine learning (ML) algorithms relies upon the ability to propagate gradient signals through the entire learning pipeline.
Traditionally, such models have been mostly limited to artificial neural networks and "simple" analytic functions.
Recent work has focused on extending the class of admissible models for gradient-based learning by making all sorts of procedures differentiable.
These efforts range from <a href="https://arxiv.org/pdf/2103.16021.pdf" rel="nofollow">differentiable physics engines</a> over <a href="https://arxiv.org/pdf/2006.12057.pdf?ref=https://githubhelp.com" rel="nofollow">differentiable rendering</a> to <a href="https://arxiv.org/pdf/1703.00443.pdf" rel="nofollow">differentiable optimization</a>.</p>
<p dir="auto">Dito focuses on a special case of the latter category, differentiable trajectory optimization.
As such, Dito algorithmically provides a (local) answer to the question:</p>
<blockquote>
<p dir="auto"><em>"How does the optimal solution of an inequality constrained trajectory optimization problem change if the problem changes?"</em>.</p>
</blockquote>
<p dir="auto">This implementation was initially developed as part of our research on <a href="https://arxiv.org/pdf/2205.00291.pdf" rel="nofollow">Learning Mixed Strategies in Trajectory Games</a>.
There, Dito allowed us to efficiently train a neural network pipeline that rapidly generate feasible equilibrium trajectories in multi-player non-cooperative dynamic games.
Since this component has proven to be very useful in that context, we have since decided to factor it out into a stand-alone package.</p>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">To install Dito, simply add it via Julia's package manager from the REPL:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# hit `]` to enter &quot;pkg&quot;-mode of the REPL
pkg&gt; add DifferentiableTrajectoryOptimization"><pre><span class="pl-c"><span class="pl-c">#</span> hit `]` to enter "pkg"-mode of the REPL</span>
pkg<span class="pl-k">&gt;</span> add DifferentiableTrajectoryOptimization</pre></div>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">Below we construct a parametric optimization problem for a 2D integrator with 2 states, 2 inputs
over a horizon of 10 stages with box constraints on states and inputs.</p>
<p dir="auto">Please consult the documentation for each of the types below for further information. For example, just type <code>?ParametricTrajectoryOptimizationProblem</code> to learn more about the problem setup.
You can also consult the <a href="test/runtests.jl">tests</a> as an additional source of implicit documentation.</p>
<h3 dir="auto"><a id="user-content-1-problem-setup" class="anchor" aria-hidden="true" href="#1-problem-setup"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>1. Problem Setup</h3>
<p dir="auto">The entry-point for getting started with this package is to set up you problem of choice as an <code>ParametricTrajectoryOptimizationProblem</code>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using DifferentiableTrajectoryOptimization as Dito

horizon = 10
state_dim = control_dim = parameter_dim = 2
cost = (xs, us, params) -&gt; sum(sum((x - params).^2) + sum(u.^2) for (x, u) in zip(xs, us))
dynamics = (x, u, t) -&gt; x + u
inequality_constraints = let
    state_constraints = state -&gt; [state .+ 0.1; -state .+ 0.1]
    control_constraints = control -&gt; [control .+ 0.1; -control .+ 0.1]
    (xs, us, params) -&gt; [
        mapreduce(state_constraints, vcat, xs)
        mapreduce(control_constraints, vcat, us)
    ]
end

problem = ParametricTrajectoryOptimizationProblem(
    cost,
    dynamics,
    inequality_constraints,
    state_dim,
    control_dim,
    parameter_dim,
    horizon
)
"><pre><span class="pl-k">using</span> DifferentiableTrajectoryOptimization <span class="pl-k">as</span> Dito

horizon <span class="pl-k">=</span> <span class="pl-c1">10</span>
state_dim <span class="pl-k">=</span> control_dim <span class="pl-k">=</span> parameter_dim <span class="pl-k">=</span> <span class="pl-c1">2</span>
cost <span class="pl-k">=</span> (xs, us, params) <span class="pl-k">-&gt;</span> <span class="pl-c1">sum</span>(<span class="pl-c1">sum</span>((x <span class="pl-k">-</span> params)<span class="pl-k">.</span><span class="pl-k">^</span><span class="pl-c1">2</span>) <span class="pl-k">+</span> <span class="pl-c1">sum</span>(u<span class="pl-k">.^</span><span class="pl-c1">2</span>) <span class="pl-k">for</span> (x, u) <span class="pl-k">in</span> <span class="pl-c1">zip</span>(xs, us))
dynamics <span class="pl-k">=</span> (x, u, t) <span class="pl-k">-&gt;</span> x <span class="pl-k">+</span> u
inequality_constraints <span class="pl-k">=</span> <span class="pl-k">let</span>
    state_constraints <span class="pl-k">=</span> state <span class="pl-k">-&gt;</span> [state <span class="pl-k">.+</span> <span class="pl-c1">0.1</span>; <span class="pl-k">-</span>state <span class="pl-k">.+</span> <span class="pl-c1">0.1</span>]
    control_constraints <span class="pl-k">=</span> control <span class="pl-k">-&gt;</span> [control <span class="pl-k">.+</span> <span class="pl-c1">0.1</span>; <span class="pl-k">-</span>control <span class="pl-k">.+</span> <span class="pl-c1">0.1</span>]
    (xs, us, params) <span class="pl-k">-&gt;</span> [
        <span class="pl-c1">mapreduce</span>(state_constraints, vcat, xs)
        <span class="pl-c1">mapreduce</span>(control_constraints, vcat, us)
    ]
<span class="pl-k">end</span>

problem <span class="pl-k">=</span> <span class="pl-c1">ParametricTrajectoryOptimizationProblem</span>(
    cost,
    dynamics,
    inequality_constraints,
    state_dim,
    control_dim,
    parameter_dim,
    horizon
)
</pre></div>
<h3 dir="auto"><a id="user-content-2-optimizer-setup" class="anchor" aria-hidden="true" href="#2-optimizer-setup"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>2. Optimizer Setup</h3>
<p dir="auto">Given an instance of the <code>ParametricTrajectoryOptimizationProblem</code>, you can construct an <code>Optimizer</code> for the problem.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="backend = QPSolver()
optimizer = Optimizer(problem, backend)"><pre>backend <span class="pl-k">=</span> <span class="pl-c1">QPSolver</span>()
optimizer <span class="pl-k">=</span> <span class="pl-c1">Optimizer</span>(problem, backend)</pre></div>
<p dir="auto">Currently, Dito supports the following optimization backends:</p>
<ul dir="auto">
<li><code>MCPSolver</code>: Casts trajectory optimization problem as a mixed complementarity problem (MCP) and solves it via PATH.
<ul dir="auto">
<li>This is the best option for nonlinear, non-convex problems. Even for QPs this solver is often as fast as the specialized QP solver.</li>
<li>The PATH solver is not open source but provides a free license. Without setting a license key, this backend only works for small problems. Please consult the documentation of <a href="https://github.com/chkwon/PATHSolver.jl">PATHSolver.jl</a> to learn about loading the license key.</li>
</ul>
</li>
<li><code>QPSolver</code>: Treats the problem as convex QP by linearizing the constraints and quadraticizing the cost a priori.
<ul dir="auto">
<li>If the true problem is not a QP, this solution will not be exact.</li>
</ul>
</li>
<li><code>NLPSolver</code>: Solves the trajectory optimization problem as NLP using Ipopt.
<ul dir="auto">
<li>This solver is mostely here for historic reasons to provide a fully open-source backend for NLPs. However, for many problems the <code>MCPSolver</code> backend using PATH is <em>much</em> faster.</li>
</ul>
</li>
</ul>
<h3 dir="auto"><a id="user-content-3-solving-the-problem" class="anchor" aria-hidden="true" href="#3-solving-the-problem"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>3. Solving the Problem</h3>
<p dir="auto">Given an optimizer, we can solve a problem instance for a given initial state <code>x0</code> and parameter values <code>params</code>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="x0 = zeros(state_dim)
params = randn(2)
optimizer(x0, params)"><pre>x0 <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(state_dim)
params <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">2</span>)
<span class="pl-c1">optimizer</span>(x0, params)</pre></div>
<h2 dir="auto"><a id="user-content-background" class="anchor" aria-hidden="true" href="#background"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Background</h2>
<p dir="auto">Dito achieves differentiable trajectory optimization by augmenting existing optimization routines with custom derivative rules that apply the <a href="https://en.wikipedia.org/wiki/Implicit_function_theorem" rel="nofollow">implicit function theorem (IFT)</a> to the resulting KKT-system.
Through this formulation, Dito avoids differentiation of the entire (potentially iterative) algorithm, leading to substantially accelerated derivative computation and facilitating differentiation of optimization backends that are not written in pure Julia.</p>
<p dir="auto">The following body of work provides more information about this IFT-based differentiation approach:</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://link.springer.com/content/pdf/10.1007/BF01585934.pdf" rel="nofollow">Ralph, Daniel, and Stephan Dempe. "Directional derivatives of the solution of a parametric nonlinear program." Mathematical programming 70.1 (1995): 159-172.</a></p>
</li>
<li>
<p dir="auto"><a href="https://arxiv.org/pdf/1703.00443.pdf" rel="nofollow">Amos, Brandon, and J. Zico Kolter. "Optnet: Differentiable optimization as a layer in neural networks." International Conference on Machine Learning. PMLR, 2017.</a></p>
</li>
</ul>
</article></div>