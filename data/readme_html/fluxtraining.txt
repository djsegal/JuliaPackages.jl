<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-fluxtrainingjl" class="anchor" aria-hidden="true" href="#fluxtrainingjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>FluxTraining.jl</h1>
<p><a href="https://lorenzoh.github.io/FluxTraining.jl/dev" rel="nofollow">Docs (master)</a></p>
<p>A powerful, extensible neural net training library.</p>
<p><em>FluxTraining.jl</em> gives you an endlessly extensible training loop for deep learning inspired by <a href="https://docs.fast.ai" rel="nofollow">fastai</a>'s training loop. It is the training backend for <a href="https://github.com/FluxML/FastAI.jl">FastAI.jl</a>.</p>
<p>It exposes a small set of extensible interfaces and uses them to implement</p>
<ul>
<li>hyperparameter scheduling</li>
<li>metrics</li>
<li>logging</li>
<li>training history; and</li>
<li>model checkpointing</li>
</ul>
<p>Install using <code>]add FluxTraining</code>.</p>
<p>Read <a href="docs/getting_started.md">getting started</a> first and the <a href="docs/overview.md">user guide</a> if you want to know more.</p>
</article></div>