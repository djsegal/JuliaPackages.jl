<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-t-sne-t-stochastic-neighbor-embedding" class="anchor" aria-hidden="true" href="#t-sne-t-stochastic-neighbor-embedding"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>t-SNE (t-Stochastic Neighbor Embedding)</h1>
<p dir="auto"><a href="https://github.com/lejon/TSne.jl/actions?query=workflow%3ACI+branch%3Amaster"><img src="https://github.com/lejon/TSne.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://coveralls.io/github/lejon/TSne.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/cb998f2dfa93a656ef4e41e0fcee1597e9fef5cc45be46a3cc10a452a1aac107/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6c656a6f6e2f54536e652e6a6c2f62616467652e737667" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/lejon/TSne.jl/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">Julia implementation of L.J.P. van der Maaten and G.E. Hintons <a href="https://lvdmaaten.github.io/tsne/" rel="nofollow">t-SNE visualisation technique</a>.</p>
<p dir="auto">The scripts in the <code>examples</code> folder require <code>Plots</code>, <code>MLDatasets</code> and <code>RDatasets</code> Julia packages.</p>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto"><code>julia&gt; Pkg.add("TSne")</code></p>
<h2 dir="auto"><a id="user-content-basic-api-usage" class="anchor" aria-hidden="true" href="#basic-api-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basic API usage</h2>
<p dir="auto"><code>tsne(X, ndim, reduce_dims, max_iter, perplexit; [keyword arguments])</code></p>
<p dir="auto">Apply t-SNE (t-Distributed Stochastic Neighbor Embedding) to <code>X</code>,
i.e. embed its points (rows) into <code>ndims</code> dimensions preserving close neighbours.
Returns the points√ó<code>ndims</code> matrix of calculated embedded coordinates.</p>
<ul dir="auto">
<li><code>X</code>: AbstractMatrix or AbstractVector. If <code>X</code> is a matrix, then rows are observations and columns are features.</li>
<li><code>ndims</code>: Dimension of the embedded space.</li>
<li><code>reduce_dims</code> the number of the first dimensions of <code>X</code> PCA to use for t-SNE,
if 0, all available dimension are used</li>
<li><code>max_iter</code>: Maximum number of iterations for the optimization</li>
<li>`perplexity': The perplexity is related to the number of nearest neighbors that
is used in other manifold learning algorithms. Larger datasets
usually require a larger perplexity. Consider selecting a value
between 5 and 50. Different values can result in significantly
different results</li>
</ul>
<p dir="auto"><strong>Optional Arguments</strong></p>
<ul dir="auto">
<li><code>distance</code> if <code>true</code>, specifies that <code>X</code> is a distance matrix,
if of type <code>Function</code> or <code>Distances.SemiMetric</code>, specifies the function to
use for calculating the distances between the rows
(or elements, if <code>X</code> is a vector) of <code>X</code></li>
<li><code>pca_init</code> whether to use the first <code>ndims</code> of <code>X</code> PCA as the initial t-SNE layout,
if <code>false</code> (the default), the method is initialized with the random layout</li>
<li><code>max_iter</code> how many iterations of t-SNE to do</li>
<li><code>perplexity</code> the number of "effective neighbours" of a datapoint,
typical values are from 5 to 50, the default is 30</li>
<li><code>verbose</code> output informational and diagnostic messages</li>
<li><code>progress</code> display progress meter during t-SNE optimization</li>
<li><code>min_gain</code>, <code>eta</code>, <code>initial_momentum</code>, <code>final_momentum</code>, <code>momentum_switch_iter</code>,
<code>stop_cheat_iter</code>, <code>cheat_scale</code> low-level parameters of t-SNE optimization</li>
<li><code>extended_output</code> if <code>true</code>, returns a tuple of embedded coordinates matrix,
point perplexities and final Kullback-Leibler divergence</li>
</ul>
<h3 dir="auto"><a id="user-content-example-usage" class="anchor" aria-hidden="true" href="#example-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example usage</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using TSne, Statistics, MLDatasets

rescale(A; dims=1) = (A .- mean(A, dims=dims)) ./ max.(std(A, dims=dims), eps())

alldata, allabels = MNIST.traindata(Float64);
data = reshape(permutedims(alldata[:, :, 1:2500], (3, 1, 2)),
               2500, size(alldata, 1)*size(alldata, 2));
# Normalize the data, this should be done if there are large scale differences in the dataset
X = rescale(data, dims=1);

Y = tsne(X, 2, 50, 1000, 20.0);

using Plots
theplot = scatter(Y[:,1], Y[:,2], marker=(2,2,:auto,stroke(0)), color=Int.(allabels[1:size(Y,1)]))
Plots.pdf(theplot, &quot;myplot.pdf&quot;)"><pre><span class="pl-k">using</span> TSne, Statistics, MLDatasets

<span class="pl-en">rescale</span>(A; dims<span class="pl-k">=</span><span class="pl-c1">1</span>) <span class="pl-k">=</span> (A <span class="pl-k">.-</span> <span class="pl-c1">mean</span>(A, dims<span class="pl-k">=</span>dims)) <span class="pl-k">./</span> <span class="pl-c1">max</span>.(<span class="pl-c1">std</span>(A, dims<span class="pl-k">=</span>dims), <span class="pl-c1">eps</span>())

alldata, allabels <span class="pl-k">=</span> MNIST<span class="pl-k">.</span><span class="pl-c1">traindata</span>(Float64);
data <span class="pl-k">=</span> <span class="pl-c1">reshape</span>(<span class="pl-c1">permutedims</span>(alldata[:, :, <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2500</span>], (<span class="pl-c1">3</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>)),
               <span class="pl-c1">2500</span>, <span class="pl-c1">size</span>(alldata, <span class="pl-c1">1</span>)<span class="pl-k">*</span><span class="pl-c1">size</span>(alldata, <span class="pl-c1">2</span>));
<span class="pl-c"><span class="pl-c">#</span> Normalize the data, this should be done if there are large scale differences in the dataset</span>
X <span class="pl-k">=</span> <span class="pl-c1">rescale</span>(data, dims<span class="pl-k">=</span><span class="pl-c1">1</span>);

Y <span class="pl-k">=</span> <span class="pl-c1">tsne</span>(X, <span class="pl-c1">2</span>, <span class="pl-c1">50</span>, <span class="pl-c1">1000</span>, <span class="pl-c1">20.0</span>);

<span class="pl-k">using</span> Plots
theplot <span class="pl-k">=</span> <span class="pl-c1">scatter</span>(Y[:,<span class="pl-c1">1</span>], Y[:,<span class="pl-c1">2</span>], marker<span class="pl-k">=</span>(<span class="pl-c1">2</span>,<span class="pl-c1">2</span>,<span class="pl-c1">:auto</span>,<span class="pl-c1">stroke</span>(<span class="pl-c1">0</span>)), color<span class="pl-k">=</span><span class="pl-c1">Int</span>.(allabels[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">size</span>(Y,<span class="pl-c1">1</span>)]))
Plots<span class="pl-k">.</span><span class="pl-c1">pdf</span>(theplot, <span class="pl-s"><span class="pl-pds">"</span>myplot.pdf<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="example.png"><img src="example.png" alt="" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-command-line-usage" class="anchor" aria-hidden="true" href="#command-line-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Command line usage</h2>
<p dir="auto"><code>julia demo-csv.jl haveheader --labelcol=5 iris-headers.csv</code></p>
<p dir="auto">Creates <code>myplot.pdf</code> with t-SNE result visualized using <code>Gadfly.jl</code>.</p>
<h2 dir="auto"><a id="user-content-see-also" class="anchor" aria-hidden="true" href="#see-also"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>See also</h2>
<ul dir="auto">
<li><a href="http://lejon.github.io" rel="nofollow">Some tips working with t-SNE</a></li>
<li><a href="http://distill.pub/2016/misread-tsne/" rel="nofollow">How to Use t-SNE Effectively</a></li>
</ul>
</article></div>