<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-axisalgorithms" class="anchor" aria-hidden="true" href="#axisalgorithms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>AxisAlgorithms</h1>
<p dir="auto"><a href="https://travis-ci.org/timholy/AxisAlgorithms.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/d9e193209cdae6fbbb515475a5765556c4653264eb3ddceba91780626bf80ee8/68747470733a2f2f7472617669732d63692e6f72672f74696d686f6c792f41786973416c676f726974686d732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/timholy/AxisAlgorithms.jl.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/timholy/AxisAlgorithms.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/728faa91ddb103bf52677d32c1369327e98d9d32c4435bf128f40f3de66f2b17/68747470733a2f2f636f6465636f762e696f2f67682f74696d686f6c792f41786973416c676f726974686d732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/timholy/AxisAlgorithms.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">AxisAlgorithms is a collection of filtering and linear algebra algorithms for multidimensional arrays.
For algorithms that would typically apply along the columns of a matrix, you can instead pick an arbitrary axis (dimension).</p>
<p dir="auto">Note that all functions come in two variants, a <code>!</code> version that uses pre-allocated output (where the output is
the first argument) and a version that allocates the output. Below, the <code>!</code> versions will be described.</p>
<h3 dir="auto"><a id="user-content-tridiagonal-and-woodbury-inversion" class="anchor" aria-hidden="true" href="#tridiagonal-and-woodbury-inversion"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Tridiagonal and Woodbury inversion</h3>
<p dir="auto">If <code>F</code> is an LU-factorization of a tridiagonal matrix, or a <a href="WoodburyMatrices.jl">Woodbury matrix</a> created from such a factorization,
then <code>A_ldiv_B_md!(dest, F, src, axis)</code> will solve the equation <code>F\b</code> for 1-dimensional slices
along dimension <code>axis</code>.
Unlike many linear algebra algorithms, this one is safe to use as a mutating algorithm with <code>dest=src</code>.
The tridiagonal case does not create temporaries, and it has excellent cache behavior.</p>
<h3 dir="auto"><a id="user-content-matrix-multiplication" class="anchor" aria-hidden="true" href="#matrix-multiplication"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Matrix multiplication</h3>
<p dir="auto">Multiply a matrix <code>M</code> to all 1-dimensional slices along a particular dimension.
Here you have two algorithms to choose from:</p>
<ul dir="auto">
<li><code>A_mul_B_perm!(dest, M, src, axis)</code> uses <code>permutedims</code> and standard BLAS-accelerated routines; it allocates temporary storage.</li>
<li><code>A_mul_B_md!(dest, M, src, axis)</code> is a non-allocating naive routine. This also has optimized implementations for sparse <code>M</code> and 2x2 matrices.</li>
</ul>
<p dir="auto">In general it is very difficult to get efficient cache behavior for multidimensional multiplication, and often using <code>A_mul_B_perm!</code> is the best strategy.
However, there are cases where <code>A_mul_B_md!</code> is faster.
It's a good idea to time both and see which works better for your case.</p>
</article></div>