<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-gamjl" class="anchor" aria-hidden="true" href="#gamjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>GAM.jl</h1>
<p dir="auto">Fit, evaluate, and visualise generalised additive models (GAMs) in native Julia</p>
<h2 dir="auto"><a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Motivation</h2>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Generalized_additive_model" rel="nofollow">Generalised additive models</a> (GAMs) are an incredibly powerful modelling tool for regression practitioners. However, the functionality of the excellent R package <a href="https://cran.r-project.org/web/packages/mgcv/mgcv.pdf" rel="nofollow"><code>mgcv</code></a> is yet to be built in native Julia. This package aims to do just that, albeit at much less complexity given how sophisticated <code>mgcv</code> is.</p>
<h2 dir="auto"><a id="user-content-development-notes" class="anchor" aria-hidden="true" href="#development-notes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Development notes</h2>
<p dir="auto"><code>GAM.jl</code> is very much a work in progress. Please check back for updates and new features!</p>
<h2 dir="auto"><a id="user-content-model-structure" class="anchor" aria-hidden="true" href="#model-structure"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Model structure</h2>
<p dir="auto">Currently, <code>GAM.jl</code> fits the following model:</p>
<p dir="auto"><math-renderer class="js-display-math" style="display: block" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$$
y = \beta_0 + \sum_{j=1}^{p} f_j(x_j) + \epsilon ,
$$</math-renderer></p>
<p dir="auto">where <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$y$</math-renderer> is the response variable, <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$\beta_0$</math-renderer> is the intercept, <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$f_j$</math-renderer> is the smooth term for predictor <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$x_j$</math-renderer>, and <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$\epsilon$</math-renderer> is the error term.</p>
<p dir="auto">The smooth term <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$f_j$</math-renderer> is modeled using a spline basis expansion:</p>
<p dir="auto"><math-renderer class="js-display-math" style="display: block" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$$
f_j(x_j) = \sum_{k=1}^{K_j} \beta_{j,k} B_{k,j}(x_j) ,
$$</math-renderer></p>
<p dir="auto">where <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$K_j$</math-renderer> is the number of spline basis functions for predictor <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$x_j$</math-renderer>, <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$\beta_{j,k}$</math-renderer> is the coefficient for the <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$k$th spline basis function, and $B_{k,j}(x_j)$</math-renderer> is the <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$k$th spline basis function for predictor $x_j$</math-renderer>.</p>
<p dir="auto">The spline basis functions are defined as:</p>
<p dir="auto">$$
B_{k,j}(x_j) = \prod_{m=1}^{d} (x_j - \text{knots}<em>{k,m})^{[x_j \geq \text{knots}</em>{k,m}]} ,
$$</p>
<p dir="auto">where <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$d$</math-renderer> is the degree of the spline, <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$\text{knots}_{k,m}$</math-renderer> is the <em>m</em>th knot for the <em>k</em>th spline basis function, and <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$[\cdot]$</math-renderer> is the Iverson bracket.</p>
<p dir="auto">The spline basis functions are defined such that they are zero outside of the range of the knots. The coefficients <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$\beta$</math-renderer> are estimated by minimizing the negative log-likelihood:</p>
<p dir="auto"><math-renderer class="js-display-math" style="display: block" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$$
\mathcal{L} = -\sum_{i=1}^{n} \log p(y_i | f(x_i)) ,
$$</math-renderer></p>
<p dir="auto">where <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$p(y_i | f(x_i))$</math-renderer> is the probability density function of the likelihood distribution. The negative log-likelihood is regularised by adding a penalty term:</p>
<p dir="auto"><math-renderer class="js-display-math" style="display: block" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$$
\mathcal{L} = \frac{1}{2} \sum_{i=1}^{n} \left( y_i - \left( \beta_0 + \sum_{j=1}^{p} f_j(x_{i,j}) \right) \right)^2 + \lambda \beta^T P \beta ,
$$</math-renderer></p>
<p dir="auto">where <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$\lambda$</math-renderer> is the regularization strength and <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="cc42d72be9c55253485a3fbc2a65afdf">$P$</math-renderer> is the penalty matrix.</p>
</article></div>