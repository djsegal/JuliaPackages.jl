<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-galacticoptimjl" class="anchor" aria-hidden="true" href="#galacticoptimjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>GalacticOptim.jl</h1>
<p><a href="https://github.com/SciML/GalacticOptim.jl/actions?query=workflow%3ACI"><img src="https://github.com/SciML/GalacticOptim.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width:100%;"></a>
<a href="http://galacticoptim.sciml.ai/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a>
<a href="http://galacticoptim.sciml.ai/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a></p>
<p>GalacticOptim.jl is a package with a scope that is beyond your normal global optimization
package. GalacticOptim.jl seeks to bring together all of the optimization packages
it can find, local and global, into one unified Julia interface. This means, you
learn one package and you learn them all! GalacticOptim.jl adds a few high-level
features, such as integrating with automatic differentiation, to make its usage
fairly simple for most cases, while allowing all of the options in a single
unified interface.</p>
<h5><a id="user-content-note-this-package-is-still-in-active-development" class="anchor" aria-hidden="true" href="#note-this-package-is-still-in-active-development"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Note: This package is still in active development.</h5>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>Assuming that you already have Julia correctly installed, it suffices to import
GalacticOptim.jl in the standard way:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="import Pkg; Pkg.add(&quot;GalacticOptim&quot;)
"><pre><span class="pl-k">import</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>GalacticOptim<span class="pl-pds">"</span></span>)</pre></div>
<p>The packages relevant to the core functionality of GalacticOptim.jl will be imported
accordingly and, in most cases, you do not have to worry about the manual
installation of dependencies. Below is the list of packages that need to be
installed explicitly if you intend to use the specific optimization algorithms
offered by them:</p>
<ul>
<li><a href="https://github.com/robertfeldt/BlackBoxOptim.jl">BlackBoxOptim.jl</a> (solver: <code>BBO()</code>)</li>
<li><a href="https://github.com/JuliaOpt/NLopt.jl">NLopt.jl</a> (usage via the NLopt API;
see also the available <a href="https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/" rel="nofollow">algorithms</a>)</li>
<li><a href="https://github.com/tpapp/MultistartOptimization.jl">MultistartOptimization.jl</a>
(see also <a href="https://juliahub.com/docs/MultistartOptimization/cVZvi/0.1.0/" rel="nofollow">this documentation</a>)</li>
<li><a href="https://github.com/timholy/QuadDIRECT.jl">QuadDIRECT.jl</a></li>
<li><a href="https://github.com/wildart/Evolutionary.jl">Evolutionary.jl</a> (see also <a href="https://wildart.github.io/Evolutionary.jl/dev/" rel="nofollow">this documentation</a>)</li>
<li><a href="https://github.com/jbrea/CMAEvolutionStrategy.jl">CMAEvolutionStrategy.jl</a></li>
</ul>
<h2><a id="user-content-tutorials-and-documentation" class="anchor" aria-hidden="true" href="#tutorials-and-documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tutorials and Documentation</h2>
<p>For information on using the package,
<a href="https://galacticoptim.sciml.ai/stable/" rel="nofollow">see the stable documentation</a>. Use the
<a href="https://galacticoptim.sciml.ai/dev/" rel="nofollow">in-development documentation</a> for the version of
the documentation, which contains the unreleased features.</p>
<h2><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples</h2>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content=" using GalacticOptim, Optim
 rosenbrock(x,p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2
 x0 = zeros(2)
 p  = [1.0,100.0]

 prob = OptimizationProblem(rosenbrock,x0,p)
 sol = solve(prob,NelderMead())


 using BlackBoxOptim
 prob = OptimizationProblem(rosenbrock, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])
 sol = solve(prob,BBO())
"><pre> <span class="pl-k">using</span> GalacticOptim, Optim
 <span class="pl-en">rosenbrock</span>(x,p) <span class="pl-k">=</span>  (p[<span class="pl-c1">1</span>] <span class="pl-k">-</span> x[<span class="pl-c1">1</span>])<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> p[<span class="pl-c1">2</span>] <span class="pl-k">*</span> (x[<span class="pl-c1">2</span>] <span class="pl-k">-</span> x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>)<span class="pl-k">^</span><span class="pl-c1">2</span>
 x0 <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>)
 p  <span class="pl-k">=</span> [<span class="pl-c1">1.0</span>,<span class="pl-c1">100.0</span>]

 prob <span class="pl-k">=</span> <span class="pl-c1">OptimizationProblem</span>(rosenbrock,x0,p)
 sol <span class="pl-k">=</span> <span class="pl-c1">solve</span>(prob,<span class="pl-c1">NelderMead</span>())


 <span class="pl-k">using</span> BlackBoxOptim
 prob <span class="pl-k">=</span> <span class="pl-c1">OptimizationProblem</span>(rosenbrock, x0, p, lb <span class="pl-k">=</span> [<span class="pl-k">-</span><span class="pl-c1">1.0</span>,<span class="pl-k">-</span><span class="pl-c1">1.0</span>], ub <span class="pl-k">=</span> [<span class="pl-c1">1.0</span>,<span class="pl-c1">1.0</span>])
 sol <span class="pl-k">=</span> <span class="pl-c1">solve</span>(prob,<span class="pl-c1">BBO</span>())</pre></div>
<p>Note that Optim.jl is a core dependency of GalaticOptim.jl. However, BlackBoxOptim.jl
is not and must already be installed (see the list above).</p>
<p><em>Warning:</em> The output of the second optimization task (<code>BBO()</code>) is
currently misleading in the sense that it returns <code>Status: failure (reached maximum number of iterations)</code>. However, convergence is actually
reached and the confusing message stems from the reliance on the Optim.jl output
struct (where the situation of reaching the maximum number of iterations is
rightly regarded as a failure). The improved output struct will soon be
implemented.</p>
<p>The output of the first optimization task (with the <code>NelderMead()</code> algorithm)
is given below:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="* Status: success

* Candidate solution
   Final objective value:     3.525527e-09

* Found with
   Algorithm:     Nelder-Mead

* Convergence measures
   √(Σ(yᵢ-ȳ)²)/n ≤ 1.0e-08

* Work counters
   Seconds run:   0  (vs limit Inf)
   Iterations:    60
   f(x) calls:    118
"><pre><span class="pl-k">*</span> Status<span class="pl-k">:</span> success

<span class="pl-k">*</span> Candidate solution
   Final objective value<span class="pl-k">:</span>     <span class="pl-c1">3.525527e-09</span>

<span class="pl-k">*</span> Found with
   Algorithm<span class="pl-k">:</span>     Nelder<span class="pl-k">-</span>Mead

<span class="pl-k">*</span> Convergence measures
   <span class="pl-k">√</span>(<span class="pl-c1">Σ</span>(yᵢ<span class="pl-k">-</span>ȳ)²)<span class="pl-k">/</span>n <span class="pl-k">≤</span> <span class="pl-c1">1.0e-08</span>

<span class="pl-k">*</span> Work counters
   Seconds run<span class="pl-k">:</span>   <span class="pl-c1">0</span>  (vs limit <span class="pl-c1">Inf</span>)
   Iterations<span class="pl-k">:</span>    <span class="pl-c1">60</span>
   <span class="pl-c1">f</span>(x) calls<span class="pl-k">:</span>    <span class="pl-c1">118</span></pre></div>
<p>We can also explore other methods in a similar way:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content=" f = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())
 prob = OptimizationProblem(f, x0, p)
 sol = solve(prob,BFGS())
"><pre> f <span class="pl-k">=</span> <span class="pl-c1">OptimizationFunction</span>(rosenbrock, GalacticOptim<span class="pl-k">.</span><span class="pl-c1">AutoForwardDiff</span>())
 prob <span class="pl-k">=</span> <span class="pl-c1">OptimizationProblem</span>(f, x0, p)
 sol <span class="pl-k">=</span> <span class="pl-c1">solve</span>(prob,<span class="pl-c1">BFGS</span>())</pre></div>
<p>For instance, the above optimization task produces the following output:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="* Status: success

* Candidate solution
   Final objective value:     7.645684e-21

* Found with
   Algorithm:     BFGS

* Convergence measures
   |x - x'|               = 3.48e-07 ≰ 0.0e+00
   |x - x'|/|x'|          = 3.48e-07 ≰ 0.0e+00
   |f(x) - f(x')|         = 6.91e-14 ≰ 0.0e+00
   |f(x) - f(x')|/|f(x')| = 9.03e+06 ≰ 0.0e+00
   |g(x)|                 = 2.32e-09 ≤ 1.0e-08

* Work counters
   Seconds run:   0  (vs limit Inf)
   Iterations:    16
   f(x) calls:    53
   ∇f(x) calls:   53
"><pre><span class="pl-k">*</span> Status<span class="pl-k">:</span> success

<span class="pl-k">*</span> Candidate solution
   Final objective value<span class="pl-k">:</span>     <span class="pl-c1">7.645684e-21</span>

<span class="pl-k">*</span> Found with
   Algorithm<span class="pl-k">:</span>     BFGS

<span class="pl-k">*</span> Convergence measures
   <span class="pl-k">|</span>x <span class="pl-k">-</span> x<span class="pl-k">'</span><span class="pl-k">|</span>               <span class="pl-k">=</span> <span class="pl-c1">3.48e-07</span> ≰ <span class="pl-c1">0.0e+00</span>
   <span class="pl-k">|</span>x <span class="pl-k">-</span> x<span class="pl-k">'</span><span class="pl-k">|</span><span class="pl-k">/</span><span class="pl-k">|</span>x<span class="pl-k">'</span><span class="pl-k">|</span>          <span class="pl-k">=</span> <span class="pl-c1">3.48e-07</span> ≰ <span class="pl-c1">0.0e+00</span>
   <span class="pl-k">|</span><span class="pl-c1">f</span>(x) <span class="pl-k">-</span> <span class="pl-c1">f</span>(x<span class="pl-k">'</span>)<span class="pl-k">|</span>         <span class="pl-k">=</span> <span class="pl-c1">6.91e-14</span> ≰ <span class="pl-c1">0.0e+00</span>
   <span class="pl-k">|</span><span class="pl-c1">f</span>(x) <span class="pl-k">-</span> <span class="pl-c1">f</span>(x<span class="pl-k">'</span>)<span class="pl-k">|</span><span class="pl-k">/</span><span class="pl-k">|</span><span class="pl-c1">f</span>(x<span class="pl-k">'</span>)<span class="pl-k">|</span> <span class="pl-k">=</span> <span class="pl-c1">9.03e+06</span> ≰ <span class="pl-c1">0.0e+00</span>
   <span class="pl-k">|</span><span class="pl-c1">g</span>(x)<span class="pl-k">|</span>                 <span class="pl-k">=</span> <span class="pl-c1">2.32e-09</span> <span class="pl-k">≤</span> <span class="pl-c1">1.0e-08</span>

<span class="pl-k">*</span> Work counters
   Seconds run<span class="pl-k">:</span>   <span class="pl-c1">0</span>  (vs limit <span class="pl-c1">Inf</span>)
   Iterations<span class="pl-k">:</span>    <span class="pl-c1">16</span>
   <span class="pl-c1">f</span>(x) calls<span class="pl-k">:</span>    <span class="pl-c1">53</span>
   <span class="pl-c1">∇f</span>(x) calls<span class="pl-k">:</span>   <span class="pl-c1">53</span></pre></div>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content=" prob = OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])
 sol = solve(prob, Fminbox(GradientDescent()))
"><pre> prob <span class="pl-k">=</span> <span class="pl-c1">OptimizationProblem</span>(f, x0, p, lb <span class="pl-k">=</span> [<span class="pl-k">-</span><span class="pl-c1">1.0</span>,<span class="pl-k">-</span><span class="pl-c1">1.0</span>], ub <span class="pl-k">=</span> [<span class="pl-c1">1.0</span>,<span class="pl-c1">1.0</span>])
 sol <span class="pl-k">=</span> <span class="pl-c1">solve</span>(prob, <span class="pl-c1">Fminbox</span>(<span class="pl-c1">GradientDescent</span>()))</pre></div>
<p>The examples clearly demonstrate that GalacticOptim.jl provides an intuitive
way of specifying optimization tasks and offers a relatively
easy access to a wide range of optimization algorithms.</p>
</article></div>