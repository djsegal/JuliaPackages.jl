<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-strategicgamesjl" class="anchor" aria-hidden="true" href="#strategicgamesjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>StrategicGames.jl</h1>
<p dir="auto">A set of functions in pure Julia for analysing strategic generic N-players games using concepts and tools of Game Theory.</p>
<p dir="auto">While written in Julia, the library is easily accessible directly in Python or R using the <a href="https://github.com/JuliaPy/pyjulia"><code>PyJulia</code></a> and <a href="https://github.com/Non-Contradiction/JuliaCall"><code>JuliaCall</code></a> packages respectively (<a href="https://sylvaticus.github.io/StrategicGames.jl/dev/using_other_languages.html#using_other_languages" rel="nofollow">Python and R examples</a>).</p>
<p dir="auto">Check out the companion repository <a href="https://github.com/sylvaticus/GameTheoryNotes">GameTheoryNotes</a> for introductory notes on the Game Theory approach and the documentation at the links below for further information on the package and how to use it.</p>
<p dir="auto"><a href="https://sylvaticus.github.io/StrategicGames.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://sylvaticus.github.io/StrategicGames.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/sylvaticus/StrategicGames.jl/actions"><img src="https://github.com/sylvaticus/StrategicGames.jl/workflows/CI/badge.svg" alt="Build status (Github Actions)" style="max-width: 100%;"></a>
<a href="http://codecov.io/github/sylvaticus/StrategicGames.jl?branch=main" rel="nofollow"><img src="https://camo.githubusercontent.com/6fe9bf5689242ad335cbc0a1752de1100a989debfbfe38434e96954730e5e23f/687474703a2f2f636f6465636f762e696f2f6769746875622f73796c766174696375732f53747261746567696347616d65732e6a6c2f636f7665726167652e7376673f6272616e63683d6d61696e" alt="codecov.io" data-canonical-src="http://codecov.io/github/sylvaticus/StrategicGames.jl/coverage.svg?branch=main" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-basic-example" class="anchor" aria-hidden="true" href="#basic-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basic example</h2>
<p dir="auto">Other examples are available in the <a href="https://sylvaticus.github.io/StrategicGames.jl/dev/#examples" rel="nofollow"><code>Examples</code></a> section of the documentation.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; # Prisoner's dilemma (N players are also supported in all functions)
       payoff = [(-1,-1) (-3,  0);
                 ( 0,-3) (-2, -2)];
julia&gt; # From N-dimensional array of tuples to N+1 arrays of scalars    
       payoff_array = expand_dimensions(payoff);
julia&gt; # Find all the dominated strategies for the two players
       dominated_strategies(payoff_array)
2-element Vector{Vector{Int64}}:
 [1]
 [1]
julia&gt; # Compute one Nash Equilibrium of the Game using complementarity formulation
       eq = nash_cp(payoff_array).equilibrium_strategies
2-element Vector{Vector{Float64}}:
 [0.0, 0.9999999887780999]
 [0.0, 0.9999999887780999]
julia&gt; # Compute all isolated Nash equilibria using support enumeration
       eqs = nash_se(payoff_array,max_samples=Inf)
1-element Vector{NamedTuple{(:equilibrium_strategies, :expected_payoffs, :supports), Tuple{Vector{Vector{Float64}}, Vector{Float64}, Vector{Vector{Int64}}}}}:
 (equilibrium_strategies = [[0.0, 0.9999999999999999], [0.0, 0.9999999999999999]], expected_payoffs = [-1.9999999999999678, -1.9999999999999678], supports = [[2], [2]])
julia&gt; # Best response for player 2
       best_response(payoff_array,[[0.5,0.5],[0.5,0.5]],2).optimal_strategy
2-element Vector{Float64}:
 0.0
 1.0
julia&gt; # Expected payoffs given a specific strategy profile
       expected_payoff(payoff_array,[[1,0],[1,0]])
2-element Vector{Int64}:
 -1
 -1
julia&gt; # Is this strategy profile a Nash equilibrium ?
       is_nash(payoff_array,[[1,0],[1,0]]) 
false"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c"><span class="pl-c">#</span> Prisoner's dilemma (N players are also supported in all functions)</span>
       payoff <span class="pl-k">=</span> [(<span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-k">-</span><span class="pl-c1">1</span>) (<span class="pl-k">-</span><span class="pl-c1">3</span>,  <span class="pl-c1">0</span>);
                 ( <span class="pl-c1">0</span>,<span class="pl-k">-</span><span class="pl-c1">3</span>) (<span class="pl-k">-</span><span class="pl-c1">2</span>, <span class="pl-k">-</span><span class="pl-c1">2</span>)];
julia<span class="pl-k">&gt;</span> <span class="pl-c"><span class="pl-c">#</span> From N-dimensional array of tuples to N+1 arrays of scalars    </span>
       payoff_array <span class="pl-k">=</span> <span class="pl-c1">expand_dimensions</span>(payoff);
julia<span class="pl-k">&gt;</span> <span class="pl-c"><span class="pl-c">#</span> Find all the dominated strategies for the two players</span>
       <span class="pl-c1">dominated_strategies</span>(payoff_array)
<span class="pl-c1">2</span><span class="pl-k">-</span>element Vector{Vector{Int64}}<span class="pl-k">:</span>
 [<span class="pl-c1">1</span>]
 [<span class="pl-c1">1</span>]
julia<span class="pl-k">&gt;</span> <span class="pl-c"><span class="pl-c">#</span> Compute one Nash Equilibrium of the Game using complementarity formulation</span>
       eq <span class="pl-k">=</span> <span class="pl-c1">nash_cp</span>(payoff_array)<span class="pl-k">.</span>equilibrium_strategies
<span class="pl-c1">2</span><span class="pl-k">-</span>element Vector{Vector{Float64}}<span class="pl-k">:</span>
 [<span class="pl-c1">0.0</span>, <span class="pl-c1">0.9999999887780999</span>]
 [<span class="pl-c1">0.0</span>, <span class="pl-c1">0.9999999887780999</span>]
julia<span class="pl-k">&gt;</span> <span class="pl-c"><span class="pl-c">#</span> Compute all isolated Nash equilibria using support enumeration</span>
       eqs <span class="pl-k">=</span> <span class="pl-c1">nash_se</span>(payoff_array,max_samples<span class="pl-k">=</span><span class="pl-c1">Inf</span>)
<span class="pl-c1">1</span><span class="pl-k">-</span>element Vector{NamedTuple{(<span class="pl-c1">:equilibrium_strategies</span>, <span class="pl-c1">:expected_payoffs</span>, <span class="pl-c1">:supports</span>), Tuple{Vector{Vector{Float64}}, Vector{Float64}, Vector{Vector{Int64}}}}}<span class="pl-k">:</span>
 (equilibrium_strategies <span class="pl-k">=</span> [[<span class="pl-c1">0.0</span>, <span class="pl-c1">0.9999999999999999</span>], [<span class="pl-c1">0.0</span>, <span class="pl-c1">0.9999999999999999</span>]], expected_payoffs <span class="pl-k">=</span> [<span class="pl-k">-</span><span class="pl-c1">1.9999999999999678</span>, <span class="pl-k">-</span><span class="pl-c1">1.9999999999999678</span>], supports <span class="pl-k">=</span> [[<span class="pl-c1">2</span>], [<span class="pl-c1">2</span>]])
julia<span class="pl-k">&gt;</span> <span class="pl-c"><span class="pl-c">#</span> Best response for player 2</span>
       <span class="pl-c1">best_response</span>(payoff_array,[[<span class="pl-c1">0.5</span>,<span class="pl-c1">0.5</span>],[<span class="pl-c1">0.5</span>,<span class="pl-c1">0.5</span>]],<span class="pl-c1">2</span>)<span class="pl-k">.</span>optimal_strategy
<span class="pl-c1">2</span><span class="pl-k">-</span>element Vector{Float64}<span class="pl-k">:</span>
 <span class="pl-c1">0.0</span>
 <span class="pl-c1">1.0</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c"><span class="pl-c">#</span> Expected payoffs given a specific strategy profile</span>
       <span class="pl-c1">expected_payoff</span>(payoff_array,[[<span class="pl-c1">1</span>,<span class="pl-c1">0</span>],[<span class="pl-c1">1</span>,<span class="pl-c1">0</span>]])
<span class="pl-c1">2</span><span class="pl-k">-</span>element Vector{Int64}<span class="pl-k">:</span>
 <span class="pl-k">-</span><span class="pl-c1">1</span>
 <span class="pl-k">-</span><span class="pl-c1">1</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c"><span class="pl-c">#</span> Is this strategy profile a Nash equilibrium ?</span>
       <span class="pl-c1">is_nash</span>(payoff_array,[[<span class="pl-c1">1</span>,<span class="pl-c1">0</span>],[<span class="pl-c1">1</span>,<span class="pl-c1">0</span>]]) 
<span class="pl-c1">false</span></pre></div>
<h2 dir="auto"><a id="user-content-other-game-theory-libraries--benchmarks" class="anchor" aria-hidden="true" href="#other-game-theory-libraries--benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Other game-theory libraries &amp; benchmarks</h2>
<p dir="auto"><strong>Julia</strong></p>
<ul dir="auto">
<li><strong><a href="https://github.com/KrainskiL/Nash.jl">Nash.jl</a></strong> Has several functions to generate games in normal form, determine best response and if a strategy profile is a Nash Equilibrium (NE) but it doesn't provide a functionality to retrieve a NE, except for 2 players simmetric games</li>
<li><strong><a href="https://github.com/QuantEcon/GameTheory.jl">GameTheory.jl</a></strong> Inter alia, compute N-players pure strategy NE, 2-players mixed strategy games (<code>lrsnash</code>, using exact arithmetics) and N-players mixed strategies NE using a solver of the polynomial equation representation of the complementarity conditions (<code>hc_solve</code>). However this "generic" N-player solver is slow, as it doesn't seem to have a dominance check. Further, compilation times are huge.</li>
</ul>
<p dir="auto"><strong>Non-Julia</strong></p>
<ul dir="auto">
<li><a href="https://github.com/drvinceknight/Nashpy">Nashpy</a>: two players only</li>
<li><a href="http://www.gambit-project.org/" rel="nofollow">Gambit</a>: many algorithms require installation of gambit other than pygambit. No decimal/rational payoffs in Python</li>
<li><a href="https://doc.sagemath.org/html/en/reference/game_theory/sage/game_theory/normal_form_game.html" rel="nofollow">Sage Math</a>: two players only</li>
<li><a href="https://forgemia.inra.fr/game-theory-tools-group/gtnash/-/tree/main/" rel="nofollow">GtNash</a></li>
</ul>
<h3 dir="auto"><a id="user-content-benchmarks" class="anchor" aria-hidden="true" href="#benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Benchmarks</h3>
<p dir="auto">The following benchmarks have been run on a Intel Core 5 laptop on StrategicGames v0.0.4.
See <a href="/blob/main/benchmarks/benchmarks_other_libraries.jl">benchmarks/benchmarks_other_libraries.jl</a> for details.</p>
<table>
<thead>
<tr>
<th>benchmark_name</th>
<th>library</th>
<th>method</th>
<th>time (ms)</th>
<th>memory (MB)</th>
<th>alloc</th>
<th>n eqs</th>
<th>notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>small_3x2</td>
<td>StrategicGames</td>
<td>nash_se</td>
<td>3.43</td>
<td>0.55</td>
<td>17694</td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>small_3x2</td>
<td>GameTheory</td>
<td>hc_solve</td>
<td>15.85</td>
<td>2.73</td>
<td>38255</td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>small_3x2</td>
<td>nashpy</td>
<td>vertex_enumeration</td>
<td>21.78</td>
<td></td>
<td></td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>small_3x2</td>
<td>nashpy</td>
<td>lemke_howson_enumeration</td>
<td>1.66</td>
<td></td>
<td></td>
<td>5</td>
<td>repeated results</td>
</tr>
<tr>
<td>small_3x2</td>
<td>nashpy</td>
<td>support_enumeration</td>
<td>2.68</td>
<td></td>
<td></td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>small_3x2</td>
<td>pygambit</td>
<td>lcp_solve</td>
<td>0.58</td>
<td></td>
<td></td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>small_3x2</td>
<td>pygambit</td>
<td>ExternalEnumPolySolver</td>
<td>2.84</td>
<td></td>
<td></td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>rand_6x7</td>
<td>StrategicGames</td>
<td>nash_se</td>
<td>223.78</td>
<td>346.44</td>
<td>7113996</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>rand_6x7</td>
<td>GameTheory</td>
<td>hc_solve</td>
<td>24319.04</td>
<td>219.29</td>
<td>6639449</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>rand_6x7</td>
<td>nashpy</td>
<td>vertex_enumeration</td>
<td>483.39</td>
<td></td>
<td></td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>rand_6x7</td>
<td>nashpy</td>
<td>lemke_howson_enumeration</td>
<td>10.20</td>
<td></td>
<td></td>
<td>13</td>
<td>repeated results</td>
</tr>
<tr>
<td>rand_6x7</td>
<td>nashpy</td>
<td>support_enumeration</td>
<td>1002.63</td>
<td></td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>rand_6x7</td>
<td>pygambit</td>
<td>lcp_solve</td>
<td>8.61</td>
<td></td>
<td></td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>rand_6x7</td>
<td>pygambit</td>
<td>ExternalEnumPolySolver</td>
<td>466356.13</td>
<td></td>
<td></td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>rand_dec_6x5</td>
<td>StrategicGames</td>
<td>nash_se</td>
<td>61.64</td>
<td>61.19</td>
<td>1383871</td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>rand_dec_6x5</td>
<td>GameTheory</td>
<td>hc_solve</td>
<td>2891.12</td>
<td>12.38</td>
<td>129350</td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>rand_dec_6x5</td>
<td>nashpy</td>
<td>vertex_enumeration</td>
<td>115.39</td>
<td></td>
<td></td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>rand_dec_6x5</td>
<td>nashpy</td>
<td>lemke_howson_enumeration</td>
<td>4.75</td>
<td></td>
<td></td>
<td>11</td>
<td>repeated results</td>
</tr>
<tr>
<td>rand_dec_6x5</td>
<td>nashpy</td>
<td>support_enumeration</td>
<td>247.32</td>
<td></td>
<td></td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>rand_4x4x2</td>
<td>StrategicGames</td>
<td>nash_se</td>
<td>2990.28</td>
<td>68.61</td>
<td>1243570</td>
<td>7</td>
<td>1 eq repeated</td>
</tr>
<tr>
<td>rand_4x4x2</td>
<td>GameTheory</td>
<td>hc_solve</td>
<td>5085.48</td>
<td>14.03</td>
<td>163760</td>
<td>4</td>
<td>2 eq missing</td>
</tr>
<tr>
<td>rand_4x4x2</td>
<td>pygambit</td>
<td>ExternalEnumPolySolver</td>
<td>924.56</td>
<td></td>
<td></td>
<td>5</td>
<td>1 eq missed</td>
</tr>
<tr>
<td>rand_6x7_1st_eq</td>
<td>StrategicGames</td>
<td>nash_se</td>
<td>7.90</td>
<td>3.70</td>
<td>81730</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>rand_6x7_1st_eq</td>
<td>GameTheory</td>
<td>hc_solve</td>
<td>20529.34</td>
<td>193.50</td>
<td>5212846</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>rand_6x7_1st_eq</td>
<td>nashpy</td>
<td>vertex_enumeration</td>
<td>221.68</td>
<td></td>
<td></td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>rand_6x7_1st_eq</td>
<td>nashpy</td>
<td>lemke_howson_enumeration</td>
<td>0.83</td>
<td></td>
<td></td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>rand_6x7_1st_eq</td>
<td>nashpy</td>
<td>support_enumeration</td>
<td>(0.00)</td>
<td></td>
<td></td>
<td>0</td>
<td>no eq reported</td>
</tr>
</tbody>
</table>
<h2 dir="auto"><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Acknowledgements</h2>
<p dir="auto">The development of this package at the <em>Bureau d'Economie Théorique et Appliquée</em> (BETA, Nancy) was supported by the French National Research Agency through the <a href="http://mycor.nancy.inra.fr/ARBRE/" rel="nofollow">Laboratory of Excellence ARBRE</a>, a part of the “Investissements d'Avenir” Program (ANR 11 – LABX-0002-01).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="assets/logos_betaumr.png"><img src="assets/logos_betaumr.png" alt="BLogos" style="max-width: 100%;"></a></p>
</article></div>