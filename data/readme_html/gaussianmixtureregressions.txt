<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-gaussianmixtureregressions" class="anchor" aria-hidden="true" href="#gaussianmixtureregressions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>GaussianMixtureRegressions</h1>
<p dir="auto"><a href="https://yuehhua.github.io/GaussianMixtureRegressions.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://yuehhua.github.io/GaussianMixtureRegressions.jl/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/yuehhua/GaussianMixtureRegressions.jl/actions/workflows/CI.yml?query=branch%3Amain"><img src="https://github.com/yuehhua/GaussianMixtureRegressions.jl/actions/workflows/CI.yml/badge.svg?branch=main" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/yuehhua/GaussianMixtureRegressions.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/0b63465a6e79410ef4816771108bed90480cb9bbb357954a934eae67ea041306/68747470733a2f2f636f6465636f762e696f2f67682f797565686875612f476175737369616e4d69787475726552656772657373696f6e732e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/yuehhua/GaussianMixtureRegressions.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">GaussianMixtureRegressions provides implementation of Gaussian mixture regression model<sup>1</sup> in Julia.</p>
<h2 dir="auto"><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using GaussianMixtureRegressions

julia&gt; n = 100;

julia&gt; d = 3;

julia&gt; w = [1., 2., 3.];

julia&gt; b = -1.0;

julia&gt; σ = 2.0;

julia&gt; X = randn(n, d);

julia&gt; y = X*w .+ b .+ randn(n)*σ;

julia&gt; X = hcat(X, y);

julia&gt; K = 3;

julia&gt; model = fit(GMR{K}, X)
[ Info: Initializing GMM, 3 Gaussians diag covariance 4 dimensions using 100 data points
K-means converged with 5 iterations (objv = 496.2564299844352)
┌ Info: K-means with 100 data points using 5 iterations
└ 6.7 data points per parameter
GMR{3, MixtureModel{Multivariate, Continuous, FullNormal, Categorical{Float64, Vector{Float64}}}}(MixtureModel{FullNormal}(K = 3)
components[1] (prior = 0.3146): FullNormal(
dim: 4
μ: [0.26776175162691485, 0.2509249295364129, 0.9660834976335448, 3.532775397209546]
Σ: [0.7115861947660863 -0.1944775509058701 -0.20333074136580565 -0.13206921117259834; -0.1944775509058701 0.8514434620519014 0.011086817365474606 1.2602845902443185; -0.20333074136580565 0.011086817365474606 0.2348133924977131 0.3688123774069542; -0.13206921117259834 1.2602845902443185 0.3688123774069542 5.354242427805917]
)
..."><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> GaussianMixtureRegressions

julia<span class="pl-k">&gt;</span> n <span class="pl-k">=</span> <span class="pl-c1">100</span>;

julia<span class="pl-k">&gt;</span> d <span class="pl-k">=</span> <span class="pl-c1">3</span>;

julia<span class="pl-k">&gt;</span> w <span class="pl-k">=</span> [<span class="pl-c1">1.</span>, <span class="pl-c1">2.</span>, <span class="pl-c1">3.</span>];

julia<span class="pl-k">&gt;</span> b <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1.0</span>;

julia<span class="pl-k">&gt;</span> σ <span class="pl-k">=</span> <span class="pl-c1">2.0</span>;

julia<span class="pl-k">&gt;</span> X <span class="pl-k">=</span> <span class="pl-c1">randn</span>(n, d);

julia<span class="pl-k">&gt;</span> y <span class="pl-k">=</span> X<span class="pl-k">*</span>w <span class="pl-k">.+</span> b <span class="pl-k">.+</span> <span class="pl-c1">randn</span>(n)<span class="pl-k">*</span>σ;

julia<span class="pl-k">&gt;</span> X <span class="pl-k">=</span> <span class="pl-c1">hcat</span>(X, y);

julia<span class="pl-k">&gt;</span> K <span class="pl-k">=</span> <span class="pl-c1">3</span>;

julia<span class="pl-k">&gt;</span> model <span class="pl-k">=</span> <span class="pl-c1">fit</span>(GMR{K}, X)
[ Info<span class="pl-k">:</span> Initializing GMM, <span class="pl-c1">3</span> Gaussians diag covariance <span class="pl-c1">4</span> dimensions <span class="pl-k">using</span> <span class="pl-c1">100</span> data points
K<span class="pl-k">-</span>means converged with <span class="pl-c1">5</span> iterations (objv <span class="pl-k">=</span> <span class="pl-c1">496.2564299844352</span>)
┌ Info<span class="pl-k">:</span> K<span class="pl-k">-</span>means with <span class="pl-c1">100</span> data points <span class="pl-k">using</span> <span class="pl-c1">5</span> iterations
└ <span class="pl-c1">6.7</span> data points per parameter
GMR{<span class="pl-c1">3</span>, MixtureModel{Multivariate, Continuous, FullNormal, Categorical{Float64, Vector{Float64}}}}(<span class="pl-c1">MixtureModel</span><span class="pl-c1">{FullNormal}</span>(K <span class="pl-k">=</span> <span class="pl-c1">3</span>)
components[<span class="pl-c1">1</span>] (prior <span class="pl-k">=</span> <span class="pl-c1">0.3146</span>)<span class="pl-k">:</span> <span class="pl-c1">FullNormal</span>(
dim<span class="pl-k">:</span> <span class="pl-c1">4</span>
μ: [<span class="pl-c1">0.26776175162691485</span>, <span class="pl-c1">0.2509249295364129</span>, <span class="pl-c1">0.9660834976335448</span>, <span class="pl-c1">3.532775397209546</span>]
Σ: [<span class="pl-c1">0.7115861947660863</span> <span class="pl-k">-</span><span class="pl-c1">0.1944775509058701</span> <span class="pl-k">-</span><span class="pl-c1">0.20333074136580565</span> <span class="pl-k">-</span><span class="pl-c1">0.13206921117259834</span>; <span class="pl-k">-</span><span class="pl-c1">0.1944775509058701</span> <span class="pl-c1">0.8514434620519014</span> <span class="pl-c1">0.011086817365474606</span> <span class="pl-c1">1.2602845902443185</span>; <span class="pl-k">-</span><span class="pl-c1">0.20333074136580565</span> <span class="pl-c1">0.011086817365474606</span> <span class="pl-c1">0.2348133924977131</span> <span class="pl-c1">0.3688123774069542</span>; <span class="pl-k">-</span><span class="pl-c1">0.13206921117259834</span> <span class="pl-c1">1.2602845902443185</span> <span class="pl-c1">0.3688123774069542</span> <span class="pl-c1">5.354242427805917</span>]
)
<span class="pl-k">...</span></pre></div>
<h2 dir="auto"><a id="user-content-save-and-load-model" class="anchor" aria-hidden="true" href="#save-and-load-model"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Save and load model</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="GaussianMixtureRegressions.save(model, &quot;model.bson&quot;)

gmr = GaussianMixtureRegressions.load(&quot;model.bson&quot;)"><pre>GaussianMixtureRegressions<span class="pl-k">.</span><span class="pl-c1">save</span>(model, <span class="pl-s"><span class="pl-pds">"</span>model.bson<span class="pl-pds">"</span></span>)

gmr <span class="pl-k">=</span> GaussianMixtureRegressions<span class="pl-k">.</span><span class="pl-c1">load</span>(<span class="pl-s"><span class="pl-pds">"</span>model.bson<span class="pl-pds">"</span></span>)</pre></div>
<h2 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<ol dir="auto">
<li><a href="https://proceedings.neurips.cc/paper/1993/file/f2201f5191c4e92cc5af043eebfd0946-Paper.pdf" rel="nofollow">Ghahramani, Z., &amp; Jordan, M. (1994). Supervised learning from incomplete data via an EM approach. In J. Cowan, G. Tesauro, &amp; J. Alspector (Eds.), <em>Advances in neural information processing systems</em> (Vol. 6, pp. 120–127). Morgan-Kaufmann.</a></li>
<li>
<div dir="auto">Fabisch, A. (2021). gmr: Gaussian Mixture Regression. <i>Journal of Open Source Software</i>, <i>6</i>(62), 3054. <a href="https://doi.org/10.21105/joss.03054" rel="nofollow">https://doi.org/10.21105/joss.03054</a></div>
</li>
</ol>
</article></div>