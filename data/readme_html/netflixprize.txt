<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-netflixprizejl" class="anchor" aria-hidden="true" href="#netflixprizejl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>NetflixPrize.jl</h1>
<p>Julia package for handling the Netflix Prize data set of 2006</p>
<p>This package does NOT provide the actual data itself. However, you may download it elsewhere, e.g. from
<a href="http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a" rel="nofollow">Academic Torrents</a>.
Please note that the data set itself comes with a separate license agreement.</p>
<h2><a id="user-content-how-to-use" class="anchor" aria-hidden="true" href="#how-to-use"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How to use</h2>
<ol>
<li>
<p>Place the downloaded training set tarball <code>nf_prize_dataset.tar.gz</code> in
<code>~/Downloads</code> or in the <code>data/</code> subdirectory under the package name.</p>
</li>
<li>
<p>(Optional but recommended) Fire up some Julia workers on the current node, e.g.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">addprocs</span>(<span class="pl-c1">4</span>)</pre></div>
<p>These extra workers will be used in the next step to speed up data processing.</p>
</li>
<li>
<p>Load the package:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">@everywhere</span> <span class="pl-k">using</span> NetflixPrize</pre></div>
<p>If you are not using multiple workers, just run</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> NetflixPrize</pre></div>
</li>
<li>
<p>To return the data set as a sparse matrix, run</p>
<div class="highlight highlight-source-julia"><pre>NetflixPrize<span class="pl-k">.</span><span class="pl-c1">training_set</span>()</pre></div>
<p>Where needed, the function will copy the tarball into the package subtree,
unpack the tarball, parse all the text files belonging to the training set,
and save the resulting sparse matrix in a local JLD (Julia data) file.</p>
<p>The output is a sparse matrix containing ratings, with rows indexed by movie
ID and columns indexed by user ID.
(Note: the raw data also contains dates, which are not saved.)
Parsing the entire training set can take some time.</p>
<pre><code>17770x2649429 sparse matrix with 100480507 UInt8 entries:
        [30     ,       6]  =  0x03
...
</code></pre>
</li>
</ol>
<p>Once the file <code>data/training_set.jld</code> has been created, the original tarball
and its unpacked contents can be deleted from <code>data/</code> without adversely
affecting the functionality of this package.</p>
<h2><a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Citation</h2>
<p>The Netflix Prize data set can be cited by</p>
<p>James Bennett, Charles Elkan, Bing Liu, Padhraic Smyth, and Domonkos Tikk,
"KDD Cup and Workshop 2007",
ACM SiGKDD Explorations Newletter, Vol 9, Iss 2, Dec 2007, pp. 51-52,
<a href="http://dx.doi.org/10.1145/1345448.1345459" rel="nofollow">doi:10.1145/1345448.1345459</a></p>
</article></div>