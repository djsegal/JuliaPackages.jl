<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-nearestneighbordescentjl" class="anchor" aria-hidden="true" href="#nearestneighbordescentjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>NearestNeighborDescent.jl</h1>
<table>
<thead>
<tr>
<th align="center"><strong>Documentation</strong></th>
<th align="center"><strong>Build Status</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://dillondaudert.github.io/NearestNeighborDescent.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/f7b92a177c912c1cc007fc9b40f17ff3ee3bb414/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a> <a href="https://dillondaudert.github.io/NearestNeighborDescent.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/3e353c26ddfe819150acbc732248f4f2a37f5175/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a></td>
<td align="center"><a href="https://travis-ci.com/dillondaudert/NearestNeighborDescent.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/3b830f6d71bc17051d0fa5caeededfb40054f893/68747470733a2f2f7472617669732d63692e636f6d2f64696c6c6f6e646175646572742f4e6561726573744e65696768626f7244657363656e742e6a6c2e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://travis-ci.com/dillondaudert/NearestNeighborDescent.jl.svg?branch=master" style="max-width:100%;"></a> <a href="https://ci.appveyor.com/project/dillondaudert/nearestneighbordescent-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/196d54df610d0f8d21a5ef85f9bd8c65e9250e24/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6c723439703976786b723861337576303f7376673d74727565" alt="" data-canonical-src="https://ci.appveyor.com/api/projects/status/lr49p9vxkr8a3uv0?svg=true" style="max-width:100%;"></a> <a href="https://codecov.io/gh/dillondaudert/NearestNeighborDescent.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/91f68a0c3814d4a692e1faeec86f15b27855e48a/68747470733a2f2f636f6465636f762e696f2f67682f64696c6c6f6e646175646572742f4e6561726573744e65696768626f7244657363656e742e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="" data-canonical-src="https://codecov.io/gh/dillondaudert/NearestNeighborDescent.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a> <a href="https://coveralls.io/github/dillondaudert/NearestNeighborDescent.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/f12e8361eaadf12ee921f0caaf471570b957ccc1/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f64696c6c6f6e646175646572742f4e6561726573744e65696768626f7244657363656e742e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://coveralls.io/repos/github/dillondaudert/NearestNeighborDescent.jl/badge.svg?branch=master" style="max-width:100%;"></a></td>
</tr>
</tbody>
</table>
<p>A Julia implementation of Nearest Neighbor Descent.</p>
<blockquote>
<p>Dong, Wei <em>et al.</em> Efficient K-Nearest Neighbor Graph Construction for Generic Similarity Measures. <em>WWW</em> (2011).</p>
</blockquote>
<h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Overview</h2>
<p>Nearest Neighbor Descent (NNDescent) is an approximate K-nearest neighbor graph construction algorithm that has
several useful properties:</p>
<ul>
<li><strong>general</strong>: works with arbitrary dissimilarity functions</li>
<li><strong>scalable</strong>: has an empirical complexity of O(n^1.14) pairwise comparisons for a dataset of size n</li>
<li><strong>space efficient</strong>: the only data structure required is an approximate KNN graph which is operated on in-place and is also the final output</li>
<li><strong>accurate</strong>: converges to above 90% recall while only comparing each data point to a small percentage of the whole dataset on average</li>
</ul>
<p>NNDescent is based on the heuristic argument that <em>a neighbor of a neighbor is also likely to be a neighbor</em>. That is,
given a list of approximate nearest neighbors to a point, we can improve that list by exploring the neighbors of each
point in the list. The algorithm is in essence the repeated application of this principle.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<div class="highlight highlight-source-julia"><pre>]add NearestNeighborDescent</pre></div>
<h2><a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Basic Usage</h2>
<p>Approximate kNN graph construction on a dataset:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> NearestNeighborDescent
<span class="pl-k">using</span> Distances
data <span class="pl-k">=</span> [<span class="pl-c1">rand</span>(<span class="pl-c1">20</span>) <span class="pl-k">for</span> _ <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">1000</span>]
n_neighbors <span class="pl-k">=</span> <span class="pl-c1">10</span>
metric <span class="pl-k">=</span> <span class="pl-c1">Euclidean</span>()
graph <span class="pl-k">=</span> <span class="pl-c1">nndescent</span>(data, n_neighbors, metric)</pre></div>
<p>The approximate KNNs of the original dataset can be retrieved from the resulting graph with</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span> return the approximate knns as KxN matrices of indexes and distances, where</span>
<span class="pl-c"><span class="pl-c">#</span> indices[j, i] and distances[j, i] are the index of and distance to node i's jth</span>
<span class="pl-c"><span class="pl-c">#</span> nearest neighbor, respectively.</span>
indices, distances <span class="pl-k">=</span> <span class="pl-c1">knn_matrices</span>(graph)</pre></div>
<p>To find the approximate neighbors for new points with respect to an already constructed graph:</p>
<div class="highlight highlight-source-julia"><pre>queries <span class="pl-k">=</span> [<span class="pl-c1">rand</span>(<span class="pl-c1">20</span>) <span class="pl-k">for</span> _ <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">20</span>]
n_neighbors <span class="pl-k">=</span> <span class="pl-c1">5</span>
indices, distances <span class="pl-k">=</span> <span class="pl-c1">search</span>(graph, queries, n_neighbors)</pre></div>
</article></div>