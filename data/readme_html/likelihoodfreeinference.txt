<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-likelihoodfreeinferencejl" class="anchor" aria-hidden="true" href="#likelihoodfreeinferencejl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>LikelihoodfreeInference.jl</h1>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/0058ce9713cb93a553c2f23207afbb49b1b852a70a4a24de20e2e816c58b299e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6966656379636c652d6578706572696d656e74616c2d6f72616e67652e737667"><img src="https://camo.githubusercontent.com/0058ce9713cb93a553c2f23207afbb49b1b852a70a4a24de20e2e816c58b299e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6966656379636c652d6578706572696d656e74616c2d6f72616e67652e737667" alt="Lifecycle" data-canonical-src="https://img.shields.io/badge/lifecycle-experimental-orange.svg" style="max-width: 100%;"></a></p>

<p dir="auto"><a href="https://juliaapproxinference.github.io/LikelihoodfreeInference.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/4fbf1a0e9af715d83da2c6cb134932756a9f0a25d715cecf4c83b1437b7996eb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6d61737465722d626c75652e737667" alt="Documentation" data-canonical-src="https://img.shields.io/badge/docs-master-blue.svg" style="max-width: 100%;"></a></p>
<p dir="auto">Given some measured data <code>y0</code> and a potentially stochastic model <code>model(x)</code>
that takes parameters <code>x</code> and returns simulated data <code>y</code>,
<code>LikelihoodfreeInference.jl</code> allows to find approximate posterior distributions
over <code>x</code> or approximate maximum likelihood (ML) and maximum a posteriori (MAP)
point estimates, by runnning</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="run!(method, model, y0)"><pre><span class="pl-c1">run!</span>(method, model, y0)</pre></div>
<p dir="auto">where <code>method</code> can be an Approximate Bayesian Computation (ABC) method
<code>PMC</code>, <code>AdaptiveSMC</code>, <code>K2ABC</code>, <code>KernelABC</code>
(<code>subtypes(LikelihoodfreeInference.AbstractABC)</code>) or
<code>PointEstimator</code>, <code>KernelRecursiveABC</code>
(<code>subtypes(LikelihoodfreeInference.AbstractPointABC)</code>).</p>
<h2 dir="auto"><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LikelihoodfreeInference, StatsPlots, Distributions
model(x) = randn() .+ x
data = [2.]
method = KernelABC(delta = eps(),
                   K = 10^4,
                   kernel = Kernel(),
                   prior = TruncatedMultivariateNormal([0.], [5.],
                                                       lower = [-5.],
                                                       upper = [5.]))
result = run!(method, model, data)
println(&quot;Approximate posterior mean = $(mean(method))&quot;)
figure = histogram(method, normalize = true, xlims = (-5, 5))
plot!(figure, -1:.01:5, pdf.(Normal.(-1:.01:5, 26/25), 25/26*2.0))"><pre><span class="pl-k">using</span> LikelihoodfreeInference, StatsPlots, Distributions
<span class="pl-en">model</span>(x) <span class="pl-k">=</span> <span class="pl-c1">randn</span>() <span class="pl-k">.+</span> x
data <span class="pl-k">=</span> [<span class="pl-c1">2.</span>]
method <span class="pl-k">=</span> <span class="pl-c1">KernelABC</span>(delta <span class="pl-k">=</span> <span class="pl-c1">eps</span>(),
                   K <span class="pl-k">=</span> <span class="pl-c1">10</span><span class="pl-k">^</span><span class="pl-c1">4</span>,
                   kernel <span class="pl-k">=</span> <span class="pl-c1">Kernel</span>(),
                   prior <span class="pl-k">=</span> <span class="pl-c1">TruncatedMultivariateNormal</span>([<span class="pl-c1">0.</span>], [<span class="pl-c1">5.</span>],
                                                       lower <span class="pl-k">=</span> [<span class="pl-k">-</span><span class="pl-c1">5.</span>],
                                                       upper <span class="pl-k">=</span> [<span class="pl-c1">5.</span>]))
result <span class="pl-k">=</span> <span class="pl-c1">run!</span>(method, model, data)
<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span>Approximate posterior mean = <span class="pl-v">$(<span class="pl-c1">mean</span>(method))</span><span class="pl-pds">"</span></span>)
figure <span class="pl-k">=</span> <span class="pl-c1">histogram</span>(method, normalize <span class="pl-k">=</span> <span class="pl-c1">true</span>, xlims <span class="pl-k">=</span> (<span class="pl-k">-</span><span class="pl-c1">5</span>, <span class="pl-c1">5</span>))
<span class="pl-c1">plot!</span>(figure, <span class="pl-k">-</span><span class="pl-c1">1</span><span class="pl-k">:</span>.<span class="pl-c1">01</span><span class="pl-k">:</span><span class="pl-c1">5</span>, <span class="pl-c1">pdf</span>.(<span class="pl-c1">Normal</span>.(<span class="pl-k">-</span><span class="pl-c1">1</span><span class="pl-k">:</span>.<span class="pl-c1">01</span><span class="pl-k">:</span><span class="pl-c1">5</span>, <span class="pl-c1">26</span><span class="pl-k">/</span><span class="pl-c1">25</span>), <span class="pl-c1">25</span><span class="pl-k">/</span><span class="pl-c1">26</span><span class="pl-k">*</span><span class="pl-c1">2.0</span>))</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="example.png"><img src="example.png" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">See <a href="https://juliaapproxinference.github.io/LikelihoodfreeInference.jl/dev" rel="nofollow">documentation</a>
or example notebooks <a href="https://github.com/jbrea/LikelihoodfreeInference.jl/blob/gh-pages/dev/generated/toyexample.ipynb">Gaussian model</a> and <a href="https://github.com/jbrea/LikelihoodfreeInference.jl/blob/gh-pages/dev/generated/blowfly.ipynb">Blowfly model</a>.</p>
</article></div>