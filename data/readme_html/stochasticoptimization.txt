<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-stochasticoptimization" class="anchor" aria-hidden="true" href="#stochasticoptimization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>StochasticOptimization</h1>
<p><a href="https://travis-ci.org/JuliaML/StochasticOptimization.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/53aeddc964da19c5050c5802afea8ce99e22ad12fa948da73ac3af4f93b2ff02/68747470733a2f2f7472617669732d63692e6f72672f4a756c69614d4c2f53746f636861737469634f7074696d697a6174696f6e2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/JuliaML/StochasticOptimization.jl.svg?branch=master" style="max-width:100%;"></a>  <a href="https://gitter.im/JuliaML/chat" rel="nofollow"><img src="https://camo.githubusercontent.com/fbdb61b4b11b1a4ffa20aeacd32c914d81c6c484830fefe55a9d4330063fffef/68747470733a2f2f6261646765732e6769747465722e696d2f4a756c69614d4c2f636861742e706e67" alt="Gitter chat" data-canonical-src="https://badges.gitter.im/JuliaML/chat.png" style="max-width:100%;"></a></p>
<p>Utilizing the JuliaML ecosystem, StochasticOptimization is a framework for iteration-based optimizers.  Below is a complete example, from creating transformations, losses, penalties, and the combined objective function, to building custom sub-learners for the optimization, to constructing and running a stochastic gradient descent learner.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using StochasticOptimization
using ObjectiveFunctions
using CatViews

# Build our objective. Note this is LASSO regression.
# The objective method constucts a RegularizedObjective composed
#   of a Transformation, a Loss, and an optional Penalty.
nin, nout = 10, 1
obj = objective(
    Affine(nin,nout),
    L2DistLoss(),
    L1Penalty(1e-8)
)

# Create some fake data... affine transform plus noise
τ = 1000
w = randn(nout, nin)
b = randn(nout)
inputs = randn(nin, τ)
noise = 0.1rand(nout, τ)
targets = w * inputs + repmat(b, 1, τ) + noise

# Create a view of w and b which looks like a single vector
θ = CatView(w,b)

# The MetaLearner has a bunch of specialized sub-learners.
# Our core learning strategy is Adamax with a fixed learning rate.
# The `maxiter` and `converged` keywords will add `MaxIter`
#   and `ConvergenceFunction` sub-learners to the MetaLearner.
learner = make_learner(
    GradientLearner(5e-3, Adamax()),
    maxiter = 5000,
    converged = (model,i) -&gt; begin
        if mod1(i,100) == 100
            if norm(θ - params(model)) &lt; 0.1
                info(&quot;Converged after $i iterations&quot;)
                return true
            end
        end
        false
    end
)

# Everything is set up... learn the parameters by iterating through
#   random minibatches forever until convergence, or until the max iterations.
learn!(obj, learner, infinite_batches(inputs, targets, size=20))
"><pre><span class="pl-k">using</span> StochasticOptimization
<span class="pl-k">using</span> ObjectiveFunctions
<span class="pl-k">using</span> CatViews

<span class="pl-c"><span class="pl-c">#</span> Build our objective. Note this is LASSO regression.</span>
<span class="pl-c"><span class="pl-c">#</span> The objective method constucts a RegularizedObjective composed</span>
<span class="pl-c"><span class="pl-c">#</span>   of a Transformation, a Loss, and an optional Penalty.</span>
nin, nout <span class="pl-k">=</span> <span class="pl-c1">10</span>, <span class="pl-c1">1</span>
obj <span class="pl-k">=</span> <span class="pl-c1">objective</span>(
    <span class="pl-c1">Affine</span>(nin,nout),
    <span class="pl-c1">L2DistLoss</span>(),
    <span class="pl-c1">L1Penalty</span>(<span class="pl-c1">1e-8</span>)
)

<span class="pl-c"><span class="pl-c">#</span> Create some fake data... affine transform plus noise</span>
τ <span class="pl-k">=</span> <span class="pl-c1">1000</span>
w <span class="pl-k">=</span> <span class="pl-c1">randn</span>(nout, nin)
b <span class="pl-k">=</span> <span class="pl-c1">randn</span>(nout)
inputs <span class="pl-k">=</span> <span class="pl-c1">randn</span>(nin, τ)
noise <span class="pl-k">=</span> <span class="pl-c1">0.1</span><span class="pl-c1">rand</span>(nout, τ)
targets <span class="pl-k">=</span> w <span class="pl-k">*</span> inputs <span class="pl-k">+</span> <span class="pl-c1">repmat</span>(b, <span class="pl-c1">1</span>, τ) <span class="pl-k">+</span> noise

<span class="pl-c"><span class="pl-c">#</span> Create a view of w and b which looks like a single vector</span>
θ <span class="pl-k">=</span> <span class="pl-c1">CatView</span>(w,b)

<span class="pl-c"><span class="pl-c">#</span> The MetaLearner has a bunch of specialized sub-learners.</span>
<span class="pl-c"><span class="pl-c">#</span> Our core learning strategy is Adamax with a fixed learning rate.</span>
<span class="pl-c"><span class="pl-c">#</span> The `maxiter` and `converged` keywords will add `MaxIter`</span>
<span class="pl-c"><span class="pl-c">#</span>   and `ConvergenceFunction` sub-learners to the MetaLearner.</span>
learner <span class="pl-k">=</span> <span class="pl-c1">make_learner</span>(
    <span class="pl-c1">GradientLearner</span>(<span class="pl-c1">5e-3</span>, <span class="pl-c1">Adamax</span>()),
    maxiter <span class="pl-k">=</span> <span class="pl-c1">5000</span>,
    converged <span class="pl-k">=</span> (model,i) <span class="pl-k">-&gt;</span> <span class="pl-k">begin</span>
        <span class="pl-k">if</span> <span class="pl-c1">mod1</span>(i,<span class="pl-c1">100</span>) <span class="pl-k">==</span> <span class="pl-c1">100</span>
            <span class="pl-k">if</span> <span class="pl-c1">norm</span>(θ <span class="pl-k">-</span> <span class="pl-c1">params</span>(model)) <span class="pl-k">&lt;</span> <span class="pl-c1">0.1</span>
                <span class="pl-c1">info</span>(<span class="pl-s"><span class="pl-pds">"</span>Converged after <span class="pl-v">$i</span> iterations<span class="pl-pds">"</span></span>)
                <span class="pl-k">return</span> <span class="pl-c1">true</span>
            <span class="pl-k">end</span>
        <span class="pl-k">end</span>
        <span class="pl-c1">false</span>
    <span class="pl-k">end</span>
)

<span class="pl-c"><span class="pl-c">#</span> Everything is set up... learn the parameters by iterating through</span>
<span class="pl-c"><span class="pl-c">#</span>   random minibatches forever until convergence, or until the max iterations.</span>
<span class="pl-c1">learn!</span>(obj, learner, <span class="pl-c1">infinite_batches</span>(inputs, targets, size<span class="pl-k">=</span><span class="pl-c1">20</span>))</pre></div>
<p>With any luck, you'll see something like:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="INFO: Converged after 800 iterations
"><pre><code>INFO: Converged after 800 iterations
</code></pre></div>
<h3><a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Notes:</h3>
<p>Each sub-learner might only implement a subset of the iteration API:</p>
<ul>
<li><code>pre_hook(learner, model)</code></li>
<li><code>learn!(model, learner, data)</code></li>
<li><code>iter_hook(learner, model, i)</code></li>
<li><code>finished(learner, model, i)</code></li>
<li><code>post_hook(learner, model)</code></li>
</ul>
</article></div>