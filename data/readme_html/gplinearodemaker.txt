<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-gplinearodemakerjl" class="anchor" aria-hidden="true" href="#gplinearodemakerjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>GPLinearODEMaker.jl</h1>
<p><a href="https://arxiv.org/abs/2009.01085" rel="nofollow"><img src="https://camo.githubusercontent.com/9f413b6681c962ac12724b21ab1ddf4d0b122502d52ce122905a3e8a85a0d4e9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61725869762d323030392e30313038352d6f72616e67652e737667" alt="arXiv" data-canonical-src="https://img.shields.io/badge/arXiv-2009.01085-orange.svg" style="max-width:100%;"></a>
<a href="https://zenodo.org/badge/latestdoi/256533350" rel="nofollow"><img src="https://camo.githubusercontent.com/cb7773f274a0291a9700ab285d1d96448d5a3b68c571a3f9dee111405fb0ac86/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3235363533333335302e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/256533350.svg" style="max-width:100%;"></a></p>
<p>GPLinearODEMaker (GLOM) is a package for finding the likelihood (and derivatives thereof) of multivariate Gaussian processes (GP) that are composed of a linear combination of a univariate GP and its derivatives.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://render.githubusercontent.com/render/math?math=q_0(t)%20%3D%20m_0(t)%20%2B%20a_%7B00%7DX(t)%20%2B%20a_%7B01%7D%5Cdot%7BX%7D(t)%20%2B%20a_%7B02%7D%5Cddot%7BX%7D(t)"><img src="https://render.githubusercontent.com/render/math?math=q_0(t)%20%3D%20m_0(t)%20%2B%20a_%7B00%7DX(t)%20%2B%20a_%7B01%7D%5Cdot%7BX%7D(t)%20%2B%20a_%7B02%7D%5Cddot%7BX%7D(t)" alt="q_0(t) = m_0(t) + a_{00}X(t) + a_{01}\dot{X}(t) + a_{02}\ddot{X}(t)" style="max-width:100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://render.githubusercontent.com/render/math?math=q_1(t)%20%3D%20m_1(t)%20%2B%20a_%7B10%7DX(t)%20%2B%20a_%7B11%7D%5Cdot%7BX%7D(t)%20%2B%20a_%7B12%7D%5Cddot%7BX%7D(t)"><img src="https://render.githubusercontent.com/render/math?math=q_1(t)%20%3D%20m_1(t)%20%2B%20a_%7B10%7DX(t)%20%2B%20a_%7B11%7D%5Cdot%7BX%7D(t)%20%2B%20a_%7B12%7D%5Cddot%7BX%7D(t)" alt="q_1(t) = m_1(t) + a_{10}X(t) + a_{11}\dot{X}(t) + a_{12}\ddot{X}(t)" style="max-width:100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://render.githubusercontent.com/render/math?math=%5Cvdots"><img src="https://render.githubusercontent.com/render/math?math=%5Cvdots" alt="\vdots" style="max-width:100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://render.githubusercontent.com/render/math?math=q_l(t)%20%3D%20m_l(t)%20%2B%20a_%7Bl0%7DX(t)%20%2B%20a_%7Bl1%7D%5Cdot%7BX%7D(t)%20%2B%20a_%7Bl2%7D%5Cddot%7BX%7D(t)"><img src="https://render.githubusercontent.com/render/math?math=q_l(t)%20%3D%20m_l(t)%20%2B%20a_%7Bl0%7DX(t)%20%2B%20a_%7Bl1%7D%5Cdot%7BX%7D(t)%20%2B%20a_%7Bl2%7D%5Cddot%7BX%7D(t)" alt="q_l(t) = m_l(t) + a_{l0}X(t) + a_{l1}\dot{X}(t) + a_{l2}\ddot{X}(t)" style="max-width:100%;"></a></p>
<p>where each X(t) is the latent GP and the qs are the time series of the outputs.</p>
<p>Here's an example using sine and cosines as the outputs to be modelled. The f, g!, and h! functions at the end give the likelihood, gradient, and Hessian, respectively.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="import GPLinearODEMaker; GLOM = GPLinearODEMaker

kernel, n_kern_hyper = GLOM.include_kernel(&quot;se&quot;)

n = 100
xs = 20 .* sort(rand(n))
noise1 = 0.1 .* ones(n)
noise2 = 0.2 .* ones(n)
y1 = sin.(xs) .+ (noise1 .* randn(n))
y2 = cos.(xs) .+ (noise2 .* randn(n))

ys = collect(Iterators.flatten(zip(y1, y2)))
noise = collect(Iterators.flatten(zip(noise1, noise2)))

glo = GLOM.GLO(kernel, n_kern_hyper, 2, 2, xs, ys; noise = noise, a=[[1. 0.1];[0.1 1]])
total_hyperparameters = append!(collect(Iterators.flatten(glo.a)), [10])
workspace = GLOM.nlogL_matrix_workspace(glo, total_hyperparameters)

function f(non_zero_hyper::Vector{T} where T&lt;:Real) = GLOM.nlogL_GLOM!(workspace, glo, non_zero_hyper)  # feel free to add priors here to optimize on the posterior!
function g!(G::Vector{T}, non_zero_hyper::Vector{T}) where T&lt;:Real
    G[:] = GLOM.∇nlogL_GLOM!(workspace, glo, non_zero_hyper)  # feel free to add priors here to optimize on the posterior!
end
function h!(H::Matrix{T}, non_zero_hyper::Vector{T}) where T&lt;:Real
    H[:, :] = GLOM.∇∇nlogL_GLOM!(workspace, glo, non_zero_hyper)  # feel free to add priors here to optimize on the posterior!
end
"><pre><span class="pl-k">import</span> GPLinearODEMaker; GLOM <span class="pl-k">=</span> GPLinearODEMaker

kernel, n_kern_hyper <span class="pl-k">=</span> GLOM<span class="pl-k">.</span><span class="pl-c1">include_kernel</span>(<span class="pl-s"><span class="pl-pds">"</span>se<span class="pl-pds">"</span></span>)

n <span class="pl-k">=</span> <span class="pl-c1">100</span>
xs <span class="pl-k">=</span> <span class="pl-c1">20</span> <span class="pl-k">.*</span> <span class="pl-c1">sort</span>(<span class="pl-c1">rand</span>(n))
noise1 <span class="pl-k">=</span> <span class="pl-c1">0.1</span> <span class="pl-k">.*</span> <span class="pl-c1">ones</span>(n)
noise2 <span class="pl-k">=</span> <span class="pl-c1">0.2</span> <span class="pl-k">.*</span> <span class="pl-c1">ones</span>(n)
y1 <span class="pl-k">=</span> <span class="pl-c1">sin</span>.(xs) <span class="pl-k">.+</span> (noise1 <span class="pl-k">.*</span> <span class="pl-c1">randn</span>(n))
y2 <span class="pl-k">=</span> <span class="pl-c1">cos</span>.(xs) <span class="pl-k">.+</span> (noise2 <span class="pl-k">.*</span> <span class="pl-c1">randn</span>(n))

ys <span class="pl-k">=</span> <span class="pl-c1">collect</span>(Iterators<span class="pl-k">.</span><span class="pl-c1">flatten</span>(<span class="pl-c1">zip</span>(y1, y2)))
noise <span class="pl-k">=</span> <span class="pl-c1">collect</span>(Iterators<span class="pl-k">.</span><span class="pl-c1">flatten</span>(<span class="pl-c1">zip</span>(noise1, noise2)))

glo <span class="pl-k">=</span> GLOM<span class="pl-k">.</span><span class="pl-c1">GLO</span>(kernel, n_kern_hyper, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, xs, ys; noise <span class="pl-k">=</span> noise, a<span class="pl-k">=</span>[[<span class="pl-c1">1.</span> <span class="pl-c1">0.1</span>];[<span class="pl-c1">0.1</span> <span class="pl-c1">1</span>]])
total_hyperparameters <span class="pl-k">=</span> <span class="pl-c1">append!</span>(<span class="pl-c1">collect</span>(Iterators<span class="pl-k">.</span><span class="pl-c1">flatten</span>(glo<span class="pl-k">.</span>a)), [<span class="pl-c1">10</span>])
workspace <span class="pl-k">=</span> GLOM<span class="pl-k">.</span><span class="pl-c1">nlogL_matrix_workspace</span>(glo, total_hyperparameters)

<span class="pl-k">function</span> <span class="pl-en">f</span>(non_zero_hyper<span class="pl-k">::</span><span class="pl-c1">Vector{T}</span> <span class="pl-k">where</span> T<span class="pl-k">&lt;:</span><span class="pl-c1">Real</span>) <span class="pl-k">=</span> GLOM<span class="pl-k">.</span><span class="pl-c1">nlogL_GLOM!</span>(workspace, glo, non_zero_hyper)  <span class="pl-c"><span class="pl-c">#</span> feel free to add priors here to optimize on the posterior!</span>
<span class="pl-k">function</span> <span class="pl-en">g!</span>(G<span class="pl-k">::</span><span class="pl-c1">Vector{T}</span>, non_zero_hyper<span class="pl-k">::</span><span class="pl-c1">Vector{T}</span>) <span class="pl-k">where</span> T<span class="pl-k">&lt;:</span><span class="pl-c1">Real</span>
    G[:] <span class="pl-k">=</span> GLOM.<span class="pl-c1">∇nlogL_GLOM!</span>(workspace, glo, non_zero_hyper)  <span class="pl-c"><span class="pl-c">#</span> feel free to add priors here to optimize on the posterior!</span>
<span class="pl-k">end</span>
<span class="pl-k">function</span> <span class="pl-en">h!</span>(H<span class="pl-k">::</span><span class="pl-c1">Matrix{T}</span>, non_zero_hyper<span class="pl-k">::</span><span class="pl-c1">Vector{T}</span>) <span class="pl-k">where</span> T<span class="pl-k">&lt;:</span><span class="pl-c1">Real</span>
    H[:, :] <span class="pl-k">=</span> GLOM.<span class="pl-c1">∇∇nlogL_GLOM!</span>(workspace, glo, non_zero_hyper)  <span class="pl-c"><span class="pl-c">#</span> feel free to add priors here to optimize on the posterior!</span>
<span class="pl-k">end</span></pre></div>
<p>You can use f, g!, and h! to optimize the GP hyperparameters with external packages like <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> or <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a></p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="initial_x = GLOM.remove_zeros(total_hyperparameters)

using Optim

# @time result = optimize(f, initial_x, NelderMead())  # slow or wrong
# @time result = optimize(f, g!, initial_x, LBFGS())  # faster and usually right
@time result = optimize(f, g!, h!, initial_x, NewtonTrustRegion())  # fastest and usually right

fit_total_hyperparameters = GLOM.reconstruct_total_hyperparameters(glo, result.minimizer)
"><pre>initial_x <span class="pl-k">=</span> GLOM<span class="pl-k">.</span><span class="pl-c1">remove_zeros</span>(total_hyperparameters)

<span class="pl-k">using</span> Optim

<span class="pl-c"><span class="pl-c">#</span> @time result = optimize(f, initial_x, NelderMead())  # slow or wrong</span>
<span class="pl-c"><span class="pl-c">#</span> @time result = optimize(f, g!, initial_x, LBFGS())  # faster and usually right</span>
<span class="pl-c1">@time</span> result <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(f, g!, h!, initial_x, <span class="pl-c1">NewtonTrustRegion</span>())  <span class="pl-c"><span class="pl-c">#</span> fastest and usually right</span>

fit_total_hyperparameters <span class="pl-k">=</span> GLOM<span class="pl-k">.</span><span class="pl-c1">reconstruct_total_hyperparameters</span>(glo, result<span class="pl-k">.</span>minimizer)</pre></div>
<p>Once you have the best fit hyperparameters, you can easily calculate the GP conditioned on the data (i.e. the GP posterior)</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="n_samp_points = convert(Int64, max(500, round(2 * sqrt(2) * length(glo.x_obs))))
x_samp = collect(range(minimum(glo.x_obs); stop=maximum(glo.x_obs), length=n_samp_points))
n_total_samp_points = n_samp_points * glo.n_out
n_meas = length(glo.x_obs)

mean_GP, σ, mean_GP_obs, Σ = GLOM.GP_posteriors(glo, x_samp, fit_total_hyperparameters; return_mean_obs=true)
"><pre>n_samp_points <span class="pl-k">=</span> <span class="pl-c1">convert</span>(Int64, <span class="pl-c1">max</span>(<span class="pl-c1">500</span>, <span class="pl-c1">round</span>(<span class="pl-c1">2</span> <span class="pl-k">*</span> <span class="pl-c1">sqrt</span>(<span class="pl-c1">2</span>) <span class="pl-k">*</span> <span class="pl-c1">length</span>(glo<span class="pl-k">.</span>x_obs))))
x_samp <span class="pl-k">=</span> <span class="pl-c1">collect</span>(<span class="pl-c1">range</span>(<span class="pl-c1">minimum</span>(glo<span class="pl-k">.</span>x_obs); stop<span class="pl-k">=</span><span class="pl-c1">maximum</span>(glo<span class="pl-k">.</span>x_obs), length<span class="pl-k">=</span>n_samp_points))
n_total_samp_points <span class="pl-k">=</span> n_samp_points <span class="pl-k">*</span> glo<span class="pl-k">.</span>n_out
n_meas <span class="pl-k">=</span> <span class="pl-c1">length</span>(glo<span class="pl-k">.</span>x_obs)

mean_GP, σ, mean_GP_obs, Σ <span class="pl-k">=</span> GLOM<span class="pl-k">.</span><span class="pl-c1">GP_posteriors</span>(glo, x_samp, fit_total_hyperparameters; return_mean_obs<span class="pl-k">=</span><span class="pl-c1">true</span>)</pre></div>
<p>and use Plots to visualize the results</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using Plots

function make_plot(output::Integer, label::String)
    sample_output_indices = output:glo.n_out:n_total_samp_points
    obs_output_indices = output:glo.n_out:length(ys)
    p = scatter(xs, ys[obs_output_indices], yerror=noise1, label=label)
    plot!(x_samp, mean_GP[sample_output_indices]; ribbon=σ[sample_output_indices], alpha=0.3, label=&quot;GP&quot;)
    return p
end

plot(make_plot(1, &quot;Sin&quot;), make_plot(2, &quot;Cos&quot;), layout=(2,1), size=(960,540))

"><pre><span class="pl-k">using</span> Plots

<span class="pl-k">function</span> <span class="pl-en">make_plot</span>(output<span class="pl-k">::</span><span class="pl-c1">Integer</span>, label<span class="pl-k">::</span><span class="pl-c1">String</span>)
    sample_output_indices <span class="pl-k">=</span> output<span class="pl-k">:</span>glo<span class="pl-k">.</span>n_out<span class="pl-k">:</span>n_total_samp_points
    obs_output_indices <span class="pl-k">=</span> output<span class="pl-k">:</span>glo<span class="pl-k">.</span>n_out<span class="pl-k">:</span><span class="pl-c1">length</span>(ys)
    p <span class="pl-k">=</span> <span class="pl-c1">scatter</span>(xs, ys[obs_output_indices], yerror<span class="pl-k">=</span>noise1, label<span class="pl-k">=</span>label)
    <span class="pl-c1">plot!</span>(x_samp, mean_GP[sample_output_indices]; ribbon<span class="pl-k">=</span>σ[sample_output_indices], alpha<span class="pl-k">=</span><span class="pl-c1">0.3</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>GP<span class="pl-pds">"</span></span>)
    <span class="pl-k">return</span> p
<span class="pl-k">end</span>

<span class="pl-c1">plot</span>(<span class="pl-c1">make_plot</span>(<span class="pl-c1">1</span>, <span class="pl-s"><span class="pl-pds">"</span>Sin<span class="pl-pds">"</span></span>), <span class="pl-c1">make_plot</span>(<span class="pl-c1">2</span>, <span class="pl-s"><span class="pl-pds">"</span>Cos<span class="pl-pds">"</span></span>), layout<span class="pl-k">=</span>(<span class="pl-c1">2</span>,<span class="pl-c1">1</span>), size<span class="pl-k">=</span>(<span class="pl-c1">960</span>,<span class="pl-c1">540</span>))
</pre></div>
<h1><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Documentation</h1>
<p>For more details and options, see the <a href="https://christiangil.github.io/GPLinearODEMaker.jl/dev" rel="nofollow">documentation</a></p>
<p>You can read about the first usage of this package in <a href="https://arxiv.org/abs/2009.01085" rel="nofollow">our paper</a></p>
<h1><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h1>
<p>The most current, tagged version of <a href="https://github.com/christiangil/GPLinearODEMaker.jl">GPLinearODEMaker.jl</a> can be easily installed using Julia's Pkg</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="Pkg.add(&quot;GPLinearODEMaker&quot;)
"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>GPLinearODEMaker<span class="pl-pds">"</span></span>)</pre></div>
<p>If you would like to contribute to the package, or just want to run the latest (untagged) version, you can use the following</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="Pkg.develop(&quot;GPLinearODEMaker&quot;)
"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">develop</span>(<span class="pl-s"><span class="pl-pds">"</span>GPLinearODEMaker<span class="pl-pds">"</span></span>)</pre></div>
<h1><a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Citation</h1>
<p>If you use <code>GPLinearODEMaker.jl</code> in your work, please cite the BibTeX entry given in CITATION.bib</p>
<p>The formula images in this README created with <a href="https://tex-image-link-generator.herokuapp.com/" rel="nofollow">this website</a></p>
</article></div>