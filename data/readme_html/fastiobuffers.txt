<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-fastiobuffers" class="anchor" aria-hidden="true" href="#fastiobuffers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>FastIOBuffers</h1>
<p><a href="https://travis-ci.org/tkoolen/FastIOBuffers.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/6d1ed46114a1c219052c75895d8f0a8f8d2a5e30/68747470733a2f2f7472617669732d63692e6f72672f746b6f6f6c656e2f46617374494f427566666572732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/tkoolen/FastIOBuffers.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="http://codecov.io/github/tkoolen/FastIOBuffers.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/d615992d2d180432b577f531cdda1224d264444b/687474703a2f2f636f6465636f762e696f2f6769746875622f746b6f6f6c656e2f46617374494f427566666572732e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/tkoolen/FastIOBuffers.jl/coverage.svg?branch=master" style="max-width:100%;"></a></p>
<p>FastIOBuffers aims to provide faster alternatives to <code>Base.IOBuffer</code>, which as of time of writing allocates memory even when e.g. a <code>Float64</code> is written to or read from it.</p>
<h3><a id="user-content-fastwritebuffer" class="anchor" aria-hidden="true" href="#fastwritebuffer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>FastWriteBuffer</h3>
<p><code>FastWriteBuffer</code> solves the allocation problem for the write use case. On 1.1.0, using <code>IOBuffer</code>:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> BenchmarkTools
<span class="pl-k">const</span> N <span class="pl-k">=</span> <span class="pl-c1">1000</span>
<span class="pl-c1">@btime</span> <span class="pl-c1">write</span>(buf, x) evals <span class="pl-k">=</span> N setup <span class="pl-k">=</span> <span class="pl-k">begin</span>
    x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float64)
    buf <span class="pl-k">=</span> <span class="pl-c1">IOBuffer</span>(<span class="pl-c1">Vector</span><span class="pl-c1">{UInt8}</span>(undef, N <span class="pl-k">*</span> Core<span class="pl-k">.</span><span class="pl-c1">sizeof</span>(x)), read<span class="pl-k">=</span><span class="pl-c1">false</span>, write<span class="pl-k">=</span><span class="pl-c1">true</span>)
<span class="pl-k">end</span></pre></div>
<p>results in <code>15.582 ns (1 allocation: 16 bytes)</code>, while</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> BenchmarkTools
<span class="pl-k">using</span> FastIOBuffers
<span class="pl-k">const</span> N <span class="pl-k">=</span> <span class="pl-c1">1000</span>
<span class="pl-c1">@btime</span> <span class="pl-c1">write</span>(buf, x) evals <span class="pl-k">=</span> N setup <span class="pl-k">=</span> <span class="pl-k">begin</span>
    x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float64)
    buf <span class="pl-k">=</span> <span class="pl-c1">FastWriteBuffer</span>(<span class="pl-c1">Vector</span><span class="pl-c1">{UInt8}</span>(undef, N <span class="pl-k">*</span> Core<span class="pl-k">.</span><span class="pl-c1">sizeof</span>(x)))
<span class="pl-k">end</span></pre></div>
<p>results in <code>10.759 ns (0 allocations: 0 bytes)</code></p>
<h3><a id="user-content-fastreadbuffer" class="anchor" aria-hidden="true" href="#fastreadbuffer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>FastReadBuffer</h3>
<p>Similarly, <code>FastReadBuffer</code> can be used in place of <code>IOBuffer</code> for reading. On 1.1.0, using <code>IOBuffer</code>:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> BenchmarkTools, Random
<span class="pl-k">const</span> N <span class="pl-k">=</span> <span class="pl-c1">1000</span>
<span class="pl-c1">@btime</span> <span class="pl-c1">read</span>(buf, Float64) evals <span class="pl-k">=</span> N setup <span class="pl-k">=</span> <span class="pl-k">begin</span>
    rng <span class="pl-k">=</span> <span class="pl-c1">MersenneTwister</span>(<span class="pl-c1">1</span>)
    writebuf <span class="pl-k">=</span> <span class="pl-c1">IOBuffer</span>()
    <span class="pl-c1">map</span>(<span class="pl-c1">1</span> : N) <span class="pl-k">do</span> _
        <span class="pl-c1">write</span>(writebuf, <span class="pl-c1">rand</span>(rng, Float64))
    <span class="pl-k">end</span>
    buf <span class="pl-k">=</span> <span class="pl-c1">IOBuffer</span>(<span class="pl-c1">take!</span>(writebuf))
<span class="pl-k">end</span></pre></div>
<p>results in <code>3.368 ns (0 allocations: 0 bytes)</code>, while replacing <code>IOBuffer</code> with <code>FastReadBuffer</code> results in <code>1.344 ns (0 allocations: 0 bytes)</code>.</p>
</article></div>