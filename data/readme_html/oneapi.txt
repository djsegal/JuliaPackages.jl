<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-oneapijl" class="anchor" aria-hidden="true" href="#oneapijl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>oneAPI.jl</h1>
<p dir="auto"><em>Julia support for the oneAPI programming toolkit.</em></p>
<p dir="auto"><a href="https://zenodo.org/badge/latestdoi/252466420" rel="nofollow"><img src="https://camo.githubusercontent.com/f39c6f94f6dc74e64dd0cebc623ea76b22bc52b3d5fbd5ff29a711c6b912bc32/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3235323436363432302e737667" alt="" data-canonical-src="https://zenodo.org/badge/252466420.svg" style="max-width: 100%;"></a> <a href="https://buildkite.com/julialang/oneapi-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/e6da2d32b109e5655c726b3317bfddaae624ff7de00ed402c97e5760fbeca9fa/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f30306666663031666434643663646439303565363165326365376564306637323033626132323764663962353735343236632e737667" alt="" data-canonical-src="https://badge.buildkite.com/00fff01fd4d6cdd905e61e2ce7ed0f7203ba227df9b575426c.svg" style="max-width: 100%;"></a> <a href="https://codecov.io/gh/JuliaGPU/oneAPI.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/7afa973960d009be77da6400d5b8e88bb41719c38c6371e1c606092da7f81d14/68747470733a2f2f636f6465636f762e696f2f67682f4a756c69614750552f6f6e654150492e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="" data-canonical-src="https://codecov.io/gh/JuliaGPU/oneAPI.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">oneAPI.jl provides support for working with the <a href="https://software.intel.com/en-us/oneapi" rel="nofollow">oneAPI unified programming
model</a>. The package is verified to work with the
(currently) only implementation of this interface <a href="https://github.com/intel/compute-runtime">that is part of the Intel Compute
Runtime</a>, only available on Linux.</p>
<p dir="auto">This package is still under significant development, so expect bugs and missing features.</p>
<h2 dir="auto"><a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick start</h2>
<p dir="auto">You need to use Julia 1.6 or higher, and it is strongly advised to use <a href="https://julialang.org/downloads/" rel="nofollow">the official
binaries</a>. For now, only Linux is supported.
On Windows, you need to use the second generation Windows Subsystem for Linux (WSL2).
<strong>If you're using Alchemist hardware, you need to use at least Linux 6.2.</strong> For other
hardware, any recent Linux distribution should work.</p>
<p dir="auto">Once you have installed Julia, proceed by entering the package manager REPL mode by pressing
<code>]</code> and adding theoneAPI package:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; add oneAPI"><pre class="notranslate"><code>pkg&gt; add oneAPI
</code></pre></div>
<p dir="auto">This installation will take a couple of minutes to download necessary binaries, such as the
oneAPI loader, several SPIR-V tools, etc. For now, the oneAPI.jl package also depends on
<a href="https://github.com/intel/compute-runtime">the Intel implementation</a> of the oneAPI spec.
That means you need compatible hardware; refer to the Intel documentation for more details.</p>
<p dir="auto">Once you have oneAPI.jl installed, perform a smoke test by calling the <code>versioninfo()</code> function:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using oneAPI

julia&gt; oneAPI.versioninfo()
Binary dependencies:
- NEO_jll: 22.43.24595+0
- libigc_jll: 1.0.12504+0
- gmmlib_jll: 22.3.0+0
- SPIRV_LLVM_Translator_unified_jll: 0.2.0+0
- SPIRV_Tools_jll: 2022.1.0+0

Toolchain:
- Julia: 1.8.5
- LLVM: 13.0.1

1 driver:
- 00000000-0000-0000-173d-d94201036013 (v1.3.24595, API v1.3.0)

2 devices:
- Intel(R) Graphics [0x56a0]
- Intel(R) HD Graphics P630 [0x591d]"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> oneAPI

julia<span class="pl-k">&gt;</span> oneAPI<span class="pl-k">.</span><span class="pl-c1">versioninfo</span>()
Binary dependencies<span class="pl-k">:</span>
<span class="pl-k">-</span> NEO_jll<span class="pl-k">:</span> <span class="pl-c1">22.43</span>.<span class="pl-c1">24595</span><span class="pl-k">+</span><span class="pl-c1">0</span>
<span class="pl-k">-</span> libigc_jll<span class="pl-k">:</span> <span class="pl-c1">1.0</span>.<span class="pl-c1">12504</span><span class="pl-k">+</span><span class="pl-c1">0</span>
<span class="pl-k">-</span> gmmlib_jll<span class="pl-k">:</span> <span class="pl-c1">22.3</span>.<span class="pl-c1">0</span><span class="pl-k">+</span><span class="pl-c1">0</span>
<span class="pl-k">-</span> SPIRV_LLVM_Translator_unified_jll<span class="pl-k">:</span> <span class="pl-c1">0.2</span>.<span class="pl-c1">0</span><span class="pl-k">+</span><span class="pl-c1">0</span>
<span class="pl-k">-</span> SPIRV_Tools_jll<span class="pl-k">:</span> <span class="pl-c1">2022.1</span>.<span class="pl-c1">0</span><span class="pl-k">+</span><span class="pl-c1">0</span>

Toolchain<span class="pl-k">:</span>
<span class="pl-k">-</span> Julia<span class="pl-k">:</span> <span class="pl-c1">1.8</span>.<span class="pl-c1">5</span>
<span class="pl-k">-</span> LLVM<span class="pl-k">:</span> <span class="pl-c1">13.0</span>.<span class="pl-c1">1</span>

<span class="pl-c1">1</span> driver<span class="pl-k">:</span>
<span class="pl-k">-</span> <span class="pl-c1">00000000</span><span class="pl-k">-</span><span class="pl-c1">0000</span><span class="pl-k">-</span><span class="pl-c1">0000</span><span class="pl-k">-</span><span class="pl-c1">173</span>d<span class="pl-k">-</span>d94201036013 (v1.<span class="pl-c1">3.24595</span>, API v1.<span class="pl-c1">3.0</span>)

<span class="pl-c1">2</span> devices<span class="pl-k">:</span>
<span class="pl-k">-</span> <span class="pl-c1">Intel</span>(R) Graphics [<span class="pl-c1">0x56a0</span>]
<span class="pl-k">-</span> <span class="pl-c1">Intel</span>(R) HD Graphics P630 [<span class="pl-c1">0x591d</span>]</pre></div>
<p dir="auto">If you have multiple compatible drivers or devices, use the <code>driver!</code> and <code>device!</code>
functions to configure which one to use in the current task:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; devices()
ZeDevice iterator for 2 devices:
1. Intel(R) Graphics [0x56a0]
2. Intel(R) HD Graphics P630 [0x591d]

julia&gt; device()
ZeDevice(GPU, vendor 0x8086, device 0x56a0): Intel(R) Graphics [0x56a0]

julia&gt; device!(2)
ZeDevice(GPU, vendor 0x8086, device 0x591d): Intel(R) HD Graphics P630 [0x591d]"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">devices</span>()
ZeDevice iterator <span class="pl-k">for</span> <span class="pl-c1">2</span> devices<span class="pl-k">:</span>
<span class="pl-c1">1.</span> <span class="pl-c1">Intel</span>(R) Graphics [<span class="pl-c1">0x56a0</span>]
<span class="pl-c1">2.</span> <span class="pl-c1">Intel</span>(R) HD Graphics P630 [<span class="pl-c1">0x591d</span>]

julia<span class="pl-k">&gt;</span> <span class="pl-c1">device</span>()
<span class="pl-c1">ZeDevice</span>(GPU, vendor <span class="pl-c1">0x8086</span>, device <span class="pl-c1">0x56a0</span>)<span class="pl-k">:</span> <span class="pl-c1">Intel</span>(R) Graphics [<span class="pl-c1">0x56a0</span>]

julia<span class="pl-k">&gt;</span> <span class="pl-c1">device!</span>(<span class="pl-c1">2</span>)
<span class="pl-c1">ZeDevice</span>(GPU, vendor <span class="pl-c1">0x8086</span>, device <span class="pl-c1">0x591d</span>)<span class="pl-k">:</span> <span class="pl-c1">Intel</span>(R) HD Graphics P630 [<span class="pl-c1">0x591d</span>]</pre></div>
<p dir="auto">To ensure other functionality works as expected, you can run the test suite from the package
manager REPL mode. Note that this will pull and run the test suite for
<a href="https://github.com/JuliaGPU/GPUArrays.jl">GPUArrays</a>, which takes quite some time:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; test oneAPI
...
Testing finished in 16 minutes, 27 seconds, 506 milliseconds

Test Summary: | Pass  Total  Time
  Overall     | 4945   4945
    SUCCESS
     Testing oneAPI tests passed"><pre class="notranslate"><code>pkg&gt; test oneAPI
...
Testing finished in 16 minutes, 27 seconds, 506 milliseconds

Test Summary: | Pass  Total  Time
  Overall     | 4945   4945
    SUCCESS
     Testing oneAPI tests passed
</code></pre></div>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">The functionality of oneAPI.jl is organized as follows:</p>
<ul dir="auto">
<li>low-level wrappers for the Level Zero library</li>
<li>kernel programming capabilities</li>
<li>abstractions for high-level array programming</li>
</ul>
<p dir="auto">The level zero wrappers are available in the <code>oneL0</code> submodule, and expose all flexibility
of the underlying APIs with user-friendly wrappers:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using oneAPI, oneAPI.oneL0

julia&gt; drv = first(drivers());

julia&gt; ctx = ZeContext(drv);

julia&gt; dev = first(devices(drv))
ZeDevice(GPU, vendor 0x8086, device 0x1912): Intel(R) Gen9

julia&gt; compute_properties(dev)
(maxTotalGroupSize = 256, maxGroupSizeX = 256, maxGroupSizeY = 256, maxGroupSizeZ = 256, maxGroupCountX = 4294967295, maxGroupCountY = 4294967295, maxGroupCountZ = 4294967295, maxSharedLocalMemory = 65536, subGroupSizes = (8, 16, 32))

julia&gt; queue = ZeCommandQueue(ctx, dev);

julia&gt; execute!(queue) do list
         append_barrier!(list)
       end"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> oneAPI, oneAPI<span class="pl-k">.</span>oneL0

julia<span class="pl-k">&gt;</span> drv <span class="pl-k">=</span> <span class="pl-c1">first</span>(<span class="pl-c1">drivers</span>());

julia<span class="pl-k">&gt;</span> ctx <span class="pl-k">=</span> <span class="pl-c1">ZeContext</span>(drv);

julia<span class="pl-k">&gt;</span> dev <span class="pl-k">=</span> <span class="pl-c1">first</span>(<span class="pl-c1">devices</span>(drv))
<span class="pl-c1">ZeDevice</span>(GPU, vendor <span class="pl-c1">0x8086</span>, device <span class="pl-c1">0x1912</span>)<span class="pl-k">:</span> <span class="pl-c1">Intel</span>(R) Gen9

julia<span class="pl-k">&gt;</span> <span class="pl-c1">compute_properties</span>(dev)
(maxTotalGroupSize <span class="pl-k">=</span> <span class="pl-c1">256</span>, maxGroupSizeX <span class="pl-k">=</span> <span class="pl-c1">256</span>, maxGroupSizeY <span class="pl-k">=</span> <span class="pl-c1">256</span>, maxGroupSizeZ <span class="pl-k">=</span> <span class="pl-c1">256</span>, maxGroupCountX <span class="pl-k">=</span> <span class="pl-c1">4294967295</span>, maxGroupCountY <span class="pl-k">=</span> <span class="pl-c1">4294967295</span>, maxGroupCountZ <span class="pl-k">=</span> <span class="pl-c1">4294967295</span>, maxSharedLocalMemory <span class="pl-k">=</span> <span class="pl-c1">65536</span>, subGroupSizes <span class="pl-k">=</span> (<span class="pl-c1">8</span>, <span class="pl-c1">16</span>, <span class="pl-c1">32</span>))

julia<span class="pl-k">&gt;</span> queue <span class="pl-k">=</span> <span class="pl-c1">ZeCommandQueue</span>(ctx, dev);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">execute!</span>(queue) <span class="pl-k">do</span> list
         <span class="pl-c1">append_barrier!</span>(list)
       <span class="pl-k">end</span></pre></div>
<p dir="auto">Built on top of that, are kernel programming capabilities for executing Julia code on oneAPI
accelerators. For now, we reuse OpenCL intrinsics, and compile to SPIR-V using <a href="https://github.com/KhronosGroup/SPIRV-LLVM-Translator">Khronos'
translator</a>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; function kernel()
         barrier()
         return
       end

julia&gt; @oneapi items=1 kernel()"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">function</span> <span class="pl-en">kernel</span>()
         <span class="pl-c1">barrier</span>()
         <span class="pl-k">return</span>
       <span class="pl-k">end</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@oneapi</span> items<span class="pl-k">=</span><span class="pl-c1">1</span> <span class="pl-c1">kernel</span>()</pre></div>
<p dir="auto">Code reflection macros are available to see the generated code:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; @device_code_llvm @oneapi items=1 kernel()"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">@device_code_llvm</span> <span class="pl-c1">@oneapi</span> items<span class="pl-k">=</span><span class="pl-c1">1</span> <span class="pl-c1">kernel</span>()</pre></div>
<div class="highlight highlight-source-llvm notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content=";  @ REPL[18]:1 within `kernel'
define dso_local spir_kernel void @_Z17julia_kernel_3053() local_unnamed_addr {
top:
;  @ REPL[18]:2 within `kernel'
; ┌ @ oneAPI.jl/src/device/opencl/synchronization.jl:9 within `barrier' @ oneAPI.jl/src/device/opencl/synchronization.jl:9
; │┌ @ oneAPI.jl/src/device/opencl/utils.jl:34 within `macro expansion'
    call void @_Z7barrierj(i32 0)
; └└
;  @ REPL[18]:3 within `kernel'
  ret void
}"><pre><span class="pl-c">;  @ REPL[18]:1 within `kernel'</span>
<span class="pl-k">define</span> dso_local spir_kernel <span class="pl-k">void</span> <span class="pl-c1">@_Z17julia_kernel_3053</span>() <span class="pl-k">local_unnamed_addr</span> {
top:
<span class="pl-c">;  @ REPL[18]:2 within `kernel'</span>
<span class="pl-c">; ┌ @ oneAPI.jl/src/device/opencl/synchronization.jl:9 within `barrier' @ oneAPI.jl/src/device/opencl/synchronization.jl:9</span>
<span class="pl-c">; │┌ @ oneAPI.jl/src/device/opencl/utils.jl:34 within `macro expansion'</span>
    <span class="pl-k">call</span> <span class="pl-k">void</span> <span class="pl-c1">@_Z7barrierj</span>(<span class="pl-k">i32</span> <span class="pl-c1">0</span>)
<span class="pl-c">; └└</span>
<span class="pl-c">;  @ REPL[18]:3 within `kernel'</span>
  <span class="pl-k">ret</span> <span class="pl-k">void</span>
}</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; @device_code_spirv @oneapi items=1 kernel()"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">@device_code_spirv</span> <span class="pl-c1">@oneapi</span> items<span class="pl-k">=</span><span class="pl-c1">1</span> <span class="pl-c1">kernel</span>()</pre></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="; SPIR-V
; Version: 1.0
; Generator: Khronos LLVM/SPIR-V Translator; 14
; Bound: 9
; Schema: 0
               OpCapability Addresses
               OpCapability Kernel
          %1 = OpExtInstImport &quot;OpenCL.std&quot;
               OpMemoryModel Physical64 OpenCL
               OpEntryPoint Kernel %4 &quot;_Z17julia_kernel_3067&quot;
               OpSource OpenCL_C 200000
               OpName %top &quot;top&quot;
       %uint = OpTypeInt 32 0
     %uint_2 = OpConstant %uint 2
     %uint_0 = OpConstant %uint 0
       %void = OpTypeVoid
          %3 = OpTypeFunction %void
          %4 = OpFunction %void None %3
        %top = OpLabel
               OpControlBarrier %uint_2 %uint_2 %uint_0
               OpReturn
               OpFunctionEnd
"><pre lang="spirv" class="notranslate"><code>; SPIR-V
; Version: 1.0
; Generator: Khronos LLVM/SPIR-V Translator; 14
; Bound: 9
; Schema: 0
               OpCapability Addresses
               OpCapability Kernel
          %1 = OpExtInstImport "OpenCL.std"
               OpMemoryModel Physical64 OpenCL
               OpEntryPoint Kernel %4 "_Z17julia_kernel_3067"
               OpSource OpenCL_C 200000
               OpName %top "top"
       %uint = OpTypeInt 32 0
     %uint_2 = OpConstant %uint 2
     %uint_0 = OpConstant %uint 0
       %void = OpTypeVoid
          %3 = OpTypeFunction %void
          %4 = OpFunction %void None %3
        %top = OpLabel
               OpControlBarrier %uint_2 %uint_2 %uint_0
               OpReturn
               OpFunctionEnd

</code></pre></div>
<p dir="auto">Finally, the <code>oneArray</code> type makes it possible to use your oneAPI accelerator without the
need to write custom kernels, thanks to Julia's high-level array abstractions:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; a = oneArray(rand(Float32, 2,2))
2×2 oneArray{Float32,2}:
 0.592979  0.996154
 0.874364  0.232854

julia&gt; a .+ 1
2×2 oneArray{Float32,2}:
 1.59298  1.99615
 1.87436  1.23285"><pre>julia<span class="pl-k">&gt;</span> a <span class="pl-k">=</span> <span class="pl-c1">oneArray</span>(<span class="pl-c1">rand</span>(Float32, <span class="pl-c1">2</span>,<span class="pl-c1">2</span>))
<span class="pl-c1">2</span><span class="pl-k">×</span><span class="pl-c1">2</span> oneArray{Float32,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-c1">0.592979</span>  <span class="pl-c1">0.996154</span>
 <span class="pl-c1">0.874364</span>  <span class="pl-c1">0.232854</span>

julia<span class="pl-k">&gt;</span> a <span class="pl-k">.+</span> <span class="pl-c1">1</span>
<span class="pl-c1">2</span><span class="pl-k">×</span><span class="pl-c1">2</span> oneArray{Float32,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-c1">1.59298</span>  <span class="pl-c1">1.99615</span>
 <span class="pl-c1">1.87436</span>  <span class="pl-c1">1.23285</span></pre></div>
<h2 dir="auto"><a id="user-content-status" class="anchor" aria-hidden="true" href="#status"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Status</h2>
<p dir="auto">The current version of oneAPI.jl supports most of oneAPI Level Zero interface, has good
kernel programming capabilties, and as a demonstration of that it fully implements the
GPUArrays.jl array interfaces. This results in a full-featured GPU array type.</p>
<p dir="auto">However, the package has not been extensively tested, and performance issues might be
present. The integration with vendor libraries like oneMKL or oneDNN is still in
development, and as result certain operations (like matrix multiplication) may be
unavailable or slow.</p>
<h2 dir="auto"><a id="user-content-using-a-local-toolchain" class="anchor" aria-hidden="true" href="#using-a-local-toolchain"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Using a local toolchain</h2>
<p dir="auto">For debugging issues with the underlying toolchain (NEO, IGC, etc), you may want the
package to use your local installation of these components instead of downloading the
prebuilt Julia binaries from Yggdrasil. This can be done using Preferences.jl, overriding
the paths to resources provided by the various JLLs that oneAPI.jl uses. A helpful script
to automate this is provided in the <code>res</code> folder of this repository:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="$ julia res/local.jl

Trying to find local IGC...
- found libigc at /usr/local/lib/libigc.so
- found libiga64 at /usr/local/lib/libiga64.so
- found libigdfcl at /usr/local/lib/libigdfcl.so
- found libopencl-clang at /usr/local/lib/libopencl-clang.so.11

Trying to find local gmmlib...
- found libigdgmm at /usr/local/lib/libigdgmm.so

Trying to find local NEO...
- found libze_intel_gpu.so.1 at /usr/local/lib/libze_intel_gpu.so.1
- found libigdrcl at /usr/local/lib/intel-opencl/libigdrcl.so

Trying to find local oneAPI loader...
- found libze_loader at /lib/x86_64-linux-gnu/libze_loader.so
- found libze_validation_layer at /lib/x86_64-linux-gnu/libze_validation_layer.so

Writing preferences..."><pre class="notranslate"><code>$ julia res/local.jl

Trying to find local IGC...
- found libigc at /usr/local/lib/libigc.so
- found libiga64 at /usr/local/lib/libiga64.so
- found libigdfcl at /usr/local/lib/libigdfcl.so
- found libopencl-clang at /usr/local/lib/libopencl-clang.so.11

Trying to find local gmmlib...
- found libigdgmm at /usr/local/lib/libigdgmm.so

Trying to find local NEO...
- found libze_intel_gpu.so.1 at /usr/local/lib/libze_intel_gpu.so.1
- found libigdrcl at /usr/local/lib/intel-opencl/libigdrcl.so

Trying to find local oneAPI loader...
- found libze_loader at /lib/x86_64-linux-gnu/libze_loader.so
- found libze_validation_layer at /lib/x86_64-linux-gnu/libze_validation_layer.so

Writing preferences...
</code></pre></div>
<p dir="auto">The discovered paths will be written to a global file with preferences, typically
<code>$HOME/.julia/environments/vX.Y/LocalPreferences.toml</code> (where <code>vX.Y</code> refers to the Julia
version you are using). You can modify this file, or remove it when you want to revert to
default set of binaries.</p>
<h2 dir="auto"><a id="user-content-float64-support" class="anchor" aria-hidden="true" href="#float64-support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>Float64</code> support</h2>
<p dir="auto">Not all oneAPI GPUs support Float64 datatypes. You can test if your GPU does using
the following code:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using oneAPI
julia&gt; oneL0.module_properties(device()).fp64flags &amp; oneL0.ZE_DEVICE_MODULE_FLAG_FP64 == oneL0.ZE_DEVICE_MODULE_FLAG_FP64
false"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> oneAPI
julia<span class="pl-k">&gt;</span> oneL0<span class="pl-k">.</span><span class="pl-c1">module_properties</span>(<span class="pl-c1">device</span>())<span class="pl-k">.</span>fp64flags <span class="pl-k">&amp;</span> oneL0<span class="pl-k">.</span>ZE_DEVICE_MODULE_FLAG_FP64 <span class="pl-k">==</span> oneL0<span class="pl-k">.</span>ZE_DEVICE_MODULE_FLAG_FP64
<span class="pl-c1">false</span></pre></div>
<p dir="auto">If your GPU doesn't, executing code that relies on Float64 values will result in an error:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; oneArray([1.]) .+ 1
┌ Error: Module compilation failed:
│
│ error: Double type is not supported on this platform."><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">oneArray</span>([<span class="pl-c1">1.</span>]) <span class="pl-k">.+</span> <span class="pl-c1">1</span>
┌ Error<span class="pl-k">:</span> Module compilation failed<span class="pl-k">:</span>
│
│ error<span class="pl-k">:</span> Double type is not supported on this platform.</pre></div>
</article></div>