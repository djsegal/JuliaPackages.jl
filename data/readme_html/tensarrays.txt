<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-tensarraysjl" class="anchor" aria-hidden="true" href="#tensarraysjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>TensArrays.jl</h1>
<p dir="auto">Kronecker product matrices that remember their tensor shape.</p>
<p dir="auto">This a minimal package, to be included in other packages so that they can interoperate with <code>Tensars</code>.  For example Jacobian shapes.</p>
<p dir="auto">Logic: if an operation is consistent with the tensor shapes, it returns a TensArray.  Otherwise, it lowers everything to Matrix.</p>
<p dir="auto">Think about TensArray<em>vector and adjoint</em>TensArray.  In the unilinear case, the lowered vectors and matrices construct the same Tensars as their TensArrays do, so don't think too hard.</p>
<p dir="auto">If Tensar stored a matrix, it could have the same in-memory layout as TensArray.  This would make conversion trivial.  In particular, Tensar can use the operations defined for TensArray, so there is no need to redefine broadcasting.  Except that Tensars should broadcast differently: an (xâŠ—y) tensar should broadcast along the y axis, but the TensArray is a column vector that should only broadcast over the whole plane.</p>
</article></div>