<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-blobtracking" class="anchor" aria-hidden="true" href="#blobtracking"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>BlobTracking</h1>
<p dir="auto"><a href="https://github.com/baggepinnen/BlobTracking.jl/actions"><img src="https://github.com/baggepinnen/BlobTracking.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/baggepinnen/BlobTracking.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/4112a7fabd16a067437aafd66fc4d093caf693b3756ec59d071884096273e710/68747470733a2f2f636f6465636f762e696f2f67682f626167676570696e6e656e2f426c6f62547261636b696e672e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Codecov" data-canonical-src="https://codecov.io/gh/baggepinnen/BlobTracking.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">Detect and track <a href="https://en.wikipedia.org/wiki/Blob_detection" rel="nofollow">blobs</a> (like birds or bugs) moving around in an image. Blobs are detected using simple <a href="https://en.wikipedia.org/wiki/Blob_detection" rel="nofollow">Laplacian-of-Gaussian filtering</a> (from <a href="https://juliaimages.org/latest/function_reference/#Images.blob_LoG" rel="nofollow">Images.jl</a>) and tracked using a Kalman filter from <a href="https://github.com/baggepinnen/LowLevelParticleFilters.jl">LowLevelParticleFilters.jl</a>.</p>
<p dir="auto">This package contains some facilities for the aforementioned detection and tracking, as well as some utilities for background removal etc.</p>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">In the example below, we are tracking birds that fly around a tree.</p>
<h3 dir="auto"><a id="user-content-load-a-video" class="anchor" aria-hidden="true" href="#load-a-video"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Load a video</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using BlobTracking, Images, VideoIO
path = &quot;/home/fredrikb/Video/2_small.MP4&quot;
io   = VideoIO.open(path)
vid  = VideoIO.openvideo(io)
img  = first(vid)"><pre><span class="pl-k">using</span> BlobTracking, Images, VideoIO
path <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>/home/fredrikb/Video/2_small.MP4<span class="pl-pds">"</span></span>
io   <span class="pl-k">=</span> VideoIO<span class="pl-k">.</span><span class="pl-c1">open</span>(path)
vid  <span class="pl-k">=</span> VideoIO<span class="pl-k">.</span><span class="pl-c1">openvideo</span>(io)
img  <span class="pl-k">=</span> <span class="pl-c1">first</span>(vid)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="figs/img.jpg"><img src="figs/img.jpg" alt="window" style="max-width: 100%;"></a></p>
<p dir="auto"><em>this package implements an iterator for VideoIO videos. It only iterates black and white images, even if the original video is in color.</em></p>
<h3 dir="auto"><a id="user-content-create-a-background-image" class="anchor" aria-hidden="true" href="#create-a-background-image"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Create a background image</h3>
<p dir="auto">We create a background image to subtract from each image</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="medbg = MedianBackground(Float32.(img), 4) # A buffer of 4 frames
foreach(1:4) do i # Populate the buffer
    update!(medbg,Float32.(first(vid)))
end
bg = background(medbg)"><pre>medbg <span class="pl-k">=</span> <span class="pl-c1">MedianBackground</span>(<span class="pl-c1">Float32</span>.(img), <span class="pl-c1">4</span>) <span class="pl-c"><span class="pl-c">#</span> A buffer of 4 frames</span>
<span class="pl-c1">foreach</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">4</span>) <span class="pl-k">do</span> i <span class="pl-c"><span class="pl-c">#</span> Populate the buffer</span>
    <span class="pl-c1">update!</span>(medbg,<span class="pl-c1">Float32</span>.(<span class="pl-c1">first</span>(vid)))
<span class="pl-k">end</span>
bg <span class="pl-k">=</span> <span class="pl-c1">background</span>(medbg)</pre></div>
<h3 dir="auto"><a id="user-content-create-a-mask" class="anchor" aria-hidden="true" href="#create-a-mask"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Create a mask</h3>
<p dir="auto">If you want to detect birds (blobs) in the entire image, you can skip this step.</p>
<p dir="auto">A mask is a binary image that is true where you want to be able to detect blobs and false where you want to ignore.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="mask = (bg .&gt; 0.4) |&gt; reduce(∘, fill(erode, 30)) |&gt; reduce(∘, fill(dilate, 20))
mask[:,1190:end] .= 0
mask[end-50:end,:] .= 0"><pre>mask <span class="pl-k">=</span> (bg <span class="pl-k">.&gt;</span> <span class="pl-c1">0.4</span>) <span class="pl-k">|&gt;</span> <span class="pl-c1">reduce</span>(<span class="pl-k">∘</span>, <span class="pl-c1">fill</span>(erode, <span class="pl-c1">30</span>)) <span class="pl-k">|&gt;</span> <span class="pl-c1">reduce</span>(<span class="pl-k">∘</span>, <span class="pl-c1">fill</span>(dilate, <span class="pl-c1">20</span>))
mask[:,<span class="pl-c1">1190</span><span class="pl-k">:</span><span class="pl-c1">end</span>] <span class="pl-k">.=</span> <span class="pl-c1">0</span>
mask[<span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">50</span><span class="pl-k">:</span><span class="pl-c1">end</span>,:] <span class="pl-k">.=</span> <span class="pl-c1">0</span></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="figs/mask.png"><img src="figs/mask.png" alt="window" style="max-width: 100%;"></a></p>
<h3 dir="auto"><a id="user-content-preprocessing" class="anchor" aria-hidden="true" href="#preprocessing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Preprocessing</h3>
<p dir="auto">For the tracking to work well, it's important that we feed the tracker nice and clean images. An example of a pre-processing function looks like this, it takes a storage array you can operate on in-place and the image to pre-process.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="function preprocessor(storage, img)
    storage .= Float32.(img)
    update!(medbg, storage) # update the background model
    storage .= Float32.(abs.(storage .- background(medbg)) .&gt; 0.4) # You can save some computation by not calculating a new background image every sample
end"><pre><span class="pl-k">function</span> <span class="pl-en">preprocessor</span>(storage, img)
    storage <span class="pl-k">.=</span> <span class="pl-c1">Float32</span>.(img)
    <span class="pl-c1">update!</span>(medbg, storage) <span class="pl-c"><span class="pl-c">#</span> update the background model</span>
    storage <span class="pl-k">.=</span> <span class="pl-c1">Float32</span>.(<span class="pl-c1">abs</span>.(storage <span class="pl-k">.-</span> <span class="pl-c1">background</span>(medbg)) <span class="pl-k">.&gt;</span> <span class="pl-c1">0.4</span>) <span class="pl-c"><span class="pl-c">#</span> You can save some computation by not calculating a new background image every sample</span>
<span class="pl-k">end</span></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="figs/pre.png"><img src="figs/pre.png" alt="window" style="max-width: 100%;"></a>
Notice how the tree contours are still present in this image? This is okay since that is behind the mask we created above. The mask was created by dilating the tree slightly so that the mask covers slightly more than the tree. However, in this image you can also see two small spots to the right of the tree, representing birds.</p>
<h3 dir="auto"><a id="user-content-run-tracking" class="anchor" aria-hidden="true" href="#run-tracking"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Run tracking</h3>
<p dir="auto">We now create the <code>BlobTracker</code> and run the tracking. If we don't know an appropriate value for the <code>sizes</code> vector that determines the size scales of the blobs, we may call the function <code>tune_sizes</code> to get a small GUI with a slider to help us out (works in Juno and IJulia). The length of <code>sizes</code> has a large impact on the time it takes to process each frame since the majority of the processing time is taken up by the blob detection.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="bt = BlobTracker(3:3, #sizes 
                2.0, # σw Dynamics noise std.
                10.0,  # σe Measurement noise std. (pixels)
                mask=mask,
                preprocessor = preprocessor,
                amplitude_th = 0.05,
                correspondence = HungarianCorrespondence(p=1.0, dist_th=2), # dist_th is the number of sigmas away from a predicted location a measurement is accepted.
)
tune_sizes(bt, img)

result = track_blobs(bt, vid,
                         display = Base.display, # use nothing to omit displaying.
                         recorder = Recorder()) # records result to video on disk"><pre>bt <span class="pl-k">=</span> <span class="pl-c1">BlobTracker</span>(<span class="pl-c1">3</span><span class="pl-k">:</span><span class="pl-c1">3</span>, <span class="pl-c"><span class="pl-c">#</span>sizes </span>
                <span class="pl-c1">2.0</span>, <span class="pl-c"><span class="pl-c">#</span> σw Dynamics noise std.</span>
                <span class="pl-c1">10.0</span>,  <span class="pl-c"><span class="pl-c">#</span> σe Measurement noise std. (pixels)</span>
                mask<span class="pl-k">=</span>mask,
                preprocessor <span class="pl-k">=</span> preprocessor,
                amplitude_th <span class="pl-k">=</span> <span class="pl-c1">0.05</span>,
                correspondence <span class="pl-k">=</span> <span class="pl-c1">HungarianCorrespondence</span>(p<span class="pl-k">=</span><span class="pl-c1">1.0</span>, dist_th<span class="pl-k">=</span><span class="pl-c1">2</span>), <span class="pl-c"><span class="pl-c">#</span> dist_th is the number of sigmas away from a predicted location a measurement is accepted.</span>
)
<span class="pl-c1">tune_sizes</span>(bt, img)

result <span class="pl-k">=</span> <span class="pl-c1">track_blobs</span>(bt, vid,
                         display <span class="pl-k">=</span> Base<span class="pl-k">.</span>display, <span class="pl-c"><span class="pl-c">#</span> use nothing to omit displaying.</span>
                         recorder <span class="pl-k">=</span> <span class="pl-c1">Recorder</span>()) <span class="pl-c"><span class="pl-c">#</span> records result to video on disk</span></pre></div>
<p dir="auto">To display images in a standalone window with okay performance, consider</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ImageView
c = imshow(img)
displayfun = img -&gt; imshow!(c[&quot;gui&quot;][&quot;canvas&quot;],img);
track_blobs(...; display = displayfun)"><pre><span class="pl-k">using</span> ImageView
c <span class="pl-k">=</span> <span class="pl-c1">imshow</span>(img)
displayfun <span class="pl-k">=</span> img <span class="pl-k">-&gt;</span> <span class="pl-c1">imshow!</span>(c[<span class="pl-s"><span class="pl-pds">"</span>gui<span class="pl-pds">"</span></span>][<span class="pl-s"><span class="pl-pds">"</span>canvas<span class="pl-pds">"</span></span>],img);
<span class="pl-c1">track_blobs</span>(<span class="pl-k">...</span>; display <span class="pl-k">=</span> displayfun)</pre></div>
<p dir="auto">Blobs are shown in blue, newly spawned blobs are show in green and measurements are shown in red.If everything is working well, most blue dots should have a red dot inside or very nearby. If the blue blobs are lagging behind the red dots, the filter needs tuning by either decreasing the measurement variance or increasing the dynamics variance. If blue dots shoot off rapidly whenever measurements are lost, the dynamics variance should be decreased.</p>
<p dir="auto">If you do not want to run the tracking and instead only collect all coordinates of detected blobs, you may call</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="coords = get_coordiantes(bt, vid)"><pre>coords <span class="pl-k">=</span> <span class="pl-c1">get_coordiantes</span>(bt, vid)</pre></div>
<p dir="auto">you can then later call the tracking function like <code>result = track_blobs(bt,coords)</code>, but if invoked like this, you do not have the option to display or record images.</p>
<h3 dir="auto"><a id="user-content-visualization-etc" class="anchor" aria-hidden="true" href="#visualization-etc"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Visualization etc.</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="traces = trace(result, minlife=5) # Filter minimum lifetime of 5
measurement_traces = tracem(result, minlife=5)
drawimg = RGB.(img)
draw!(drawimg, traces, c=RGB(0,0,0.5))
draw!(drawimg, measurement_traces, c=RGB(0.5,0,0))"><pre>traces <span class="pl-k">=</span> <span class="pl-c1">trace</span>(result, minlife<span class="pl-k">=</span><span class="pl-c1">5</span>) <span class="pl-c"><span class="pl-c">#</span> Filter minimum lifetime of 5</span>
measurement_traces <span class="pl-k">=</span> <span class="pl-c1">tracem</span>(result, minlife<span class="pl-k">=</span><span class="pl-c1">5</span>)
drawimg <span class="pl-k">=</span> <span class="pl-c1">RGB</span>.(img)
<span class="pl-c1">draw!</span>(drawimg, traces, c<span class="pl-k">=</span><span class="pl-c1">RGB</span>(<span class="pl-c1">0</span>,<span class="pl-c1">0</span>,<span class="pl-c1">0.5</span>))
<span class="pl-c1">draw!</span>(drawimg, measurement_traces, c<span class="pl-k">=</span><span class="pl-c1">RGB</span>(<span class="pl-c1">0.5</span>,<span class="pl-c1">0</span>,<span class="pl-c1">0</span>))</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="figs/traces.jpg"><img src="figs/traces.jpg" alt="window" style="max-width: 100%;"></a></p>
<p dir="auto">In the image, green dots represent spawning positions and red dots the last obtained measurement for a blob in case of the red measurement traces, and the point at which the blob was killed in case of the blue location traces.</p>
<p dir="auto">Below is a youtube video showing how it looks
<a href="https://www.youtube.com/watch?v=uKAURHYEWRs" rel="nofollow"><img src="https://camo.githubusercontent.com/7084c7efdec0a35f2ebc1bb231126443913ba81bf1fafbdeee3e46fa89c6f77f/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f754b4155524859455752732f302e6a7067" alt="Video illustration" data-canonical-src="https://img.youtube.com/vi/uKAURHYEWRs/0.jpg" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-further-documentation" class="anchor" aria-hidden="true" href="#further-documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Further documentation</h2>
<p dir="auto">Most functions have docstrings. Docstrings of types hint at what functions you can call on instances of the type. The types present in this package are</p>
<ul dir="auto">
<li><code>Blob</code> represents a Blob, contains traces of locations and measurements as well as the Kalman filter</li>
<li><code>BlobTracker</code> contains parameters for the tracking and correspondence matching</li>
<li><code>KalmanParams</code> stores the variance parameters for the KalmanFilter.</li>
<li><code>AbstractCorrespondence</code>
<ul dir="auto">
<li><code>HungarianCorrespondence</code> matches blobs to measurements using the Hungarian algorithm</li>
<li><code>NearestNeighborCorrespondence</code> matches blobs to the nearest measurement</li>
<li><code>MCCorrespondence</code> uses Monte Carlo integration over the filtering distribution of the blobs and matches blobs to measurements several times using the chosen inner <code>AbstractCorrespondence</code>.</li>
</ul>
</li>
<li><code>TrackingResult</code> contains lists of dead and alive blobs</li>
<li><code>Trace</code> is a list of coordinates</li>
<li><code>Recorder</code> records movies and saves them on disk</li>
<li><code>FrameBuffer</code> stores frames for temporal processing</li>
<li><code>BackgroundExtractor</code>
<ul dir="auto">
<li><code>MedianBackground</code> models the background of an image</li>
<li><code>DiffBackground</code> models the background of an image</li>
</ul>
</li>
<li><code>Workspace</code> is used internally</li>
</ul>
</article></div>