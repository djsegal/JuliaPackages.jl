<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-facedatasets" class="anchor" aria-hidden="true" href="#facedatasets"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>FaceDatasets</h1>
<p><a href="https://travis-ci.org/dfdx/FaceDatasets.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/b3c24ea9e4ede64b4ec6ff96209aa177fd3e3452/68747470733a2f2f7472617669732d63692e6f72672f646664782f4661636544617461736574732e6a6c2e737667" alt="Build Status" data-canonical-src="https://travis-ci.org/dfdx/FaceDatasets.jl.svg" style="max-width:100%;"></a></p>
<p>Package for making access to popular face datasets easier.</p>
<h2><a id="user-content-general-usage" class="anchor" aria-hidden="true" href="#general-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>General usage</h2>
<pre><code>load_images(&lt;dataset_name&gt;, &lt;dataset_params&gt;...)  # faces
load_shapes(&lt;dataset_name&gt;, &lt;dataset_params&gt;...)  # face landmarks
load_labels(&lt;dataset_name&gt;, &lt;dataset_params&gt;...)  # provided labels
</code></pre>
<p>For example, to load <code>CootesDataset</code>, enter:</p>
<pre><code>load_images(CootesDataset)
</code></pre>
<p>Note, that all methods return iterable objects: for small datasets they are just arrays, for larger iterators are returned instead. You can always materialize them using:</p>
<pre><code>collect(load_images(...))
</code></pre>
<h2><a id="user-content-available-datasets" class="anchor" aria-hidden="true" href="#available-datasets"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Available datasets</h2>
<h3><a id="user-content-cootes-images" class="anchor" aria-hidden="true" href="#cootes-images"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Cootes images</h3>
<p><code>CootesDataset</code> contains images from Tim Cootes' work on active appearance models. These images come prepacked, so you can use them for testing.</p>
<p>Supported functions:</p>
<ul>
<li><code>load_images(CootesDataset)</code></li>
<li><code>load_shapes(CootesDataset)</code></li>
</ul>
<h3><a id="user-content-cohn-kanade-dataset" class="anchor" aria-hidden="true" href="#cohn-kanade-dataset"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Cohn-Kanade+ dataset</h3>
<p><code>CKDataset</code> contains images from <a href="http://www.pitt.edu/~emotion/ck-spread.htm" rel="nofollow">Cohn-Kanade+ Expression Database</a>. To install this dataset, download it from <a href="http://www.consortium.ri.cmu.edu/ckagree/" rel="nofollow">this page</a> and unpack into a directory of your choice. Example of expected directory layout:</p>
<pre><code>$ tree -L 2
.
├── cohn-kanade-images
│   ├── S005
│   ├── S010
│   ├── S011
│   ...
│   └── S999
├── Emotion
│   ├── S005
│   ├── S010
│   ├── S011
│   ...
│   └── S999
└── Landmarks
    ├── S005
    ├── S010
    ├── S011
    ...
    └── S999
</code></pre>
<p>Supported functions:</p>
<ul>
<li><code>load_images(CKDataset, datadir, opts...)</code></li>
<li><code>load_shapes(CKDataset, datadir, opts...)</code></li>
<li><code>load_labels(CKDataset, datadir, opts...)</code></li>
</ul>
<p>where <code>datadir</code> is base dir for CK dataset and labels are numbers representing 6 basic emotions + neutral facial expression.</p>
<p>Options:</p>
<ul>
<li><code>start</code> - image index to start with</li>
<li><code>count</code> - number of images to return</li>
<li><code>indexes</code> - concrete indexes to return (<code>start</code> and <code>count</code> are ignored)</li>
<li><code>resizeratio</code> - resize image by this value</li>
</ul>
<h3><a id="user-content-cohn-kanade-max-only-dataset" class="anchor" aria-hidden="true" href="#cohn-kanade-max-only-dataset"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Cohn-Kanade+ (max only) dataset</h3>
<p><code>CKMaxDataset</code> - same as Cohn-Kanade+ dataset, but contains only images with maximally expressed emotion (~500 images). Only <code>resizeration</code> option is supported, though.</p>
<p>TODO: <code>KaggleFERDataset</code>
TODO: <code>PutFrontalDataset</code></p>
</article></div>