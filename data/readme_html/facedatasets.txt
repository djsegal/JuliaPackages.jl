<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-facedatasets" class="anchor" aria-hidden="true" href="#facedatasets"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>FaceDatasets</h1>
<p dir="auto"><a href="https://travis-ci.org/dfdx/FaceDatasets.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/a255a8b6fb425dcf514d48e34461f7895108406da69c27fec3972ce0c4290f34/68747470733a2f2f7472617669732d63692e6f72672f646664782f4661636544617461736574732e6a6c2e737667" alt="Build Status" data-canonical-src="https://travis-ci.org/dfdx/FaceDatasets.jl.svg" style="max-width: 100%;"></a></p>
<p dir="auto">Package for making access to popular face datasets easier.</p>
<h2 dir="auto"><a id="user-content-general-usage" class="anchor" aria-hidden="true" href="#general-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>General usage</h2>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="load_images(&lt;dataset_name&gt;, &lt;dataset_params&gt;...)  # faces
load_shapes(&lt;dataset_name&gt;, &lt;dataset_params&gt;...)  # face landmarks
load_labels(&lt;dataset_name&gt;, &lt;dataset_params&gt;...)  # provided labels"><pre class="notranslate"><code>load_images(&lt;dataset_name&gt;, &lt;dataset_params&gt;...)  # faces
load_shapes(&lt;dataset_name&gt;, &lt;dataset_params&gt;...)  # face landmarks
load_labels(&lt;dataset_name&gt;, &lt;dataset_params&gt;...)  # provided labels
</code></pre></div>
<p dir="auto">For example, to load <code>CootesDataset</code>, enter:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="load_images(CootesDataset)"><pre class="notranslate"><code>load_images(CootesDataset)
</code></pre></div>
<p dir="auto">Note, that all methods return iterable objects: for small datasets they are just arrays, for larger iterators are returned instead. You can always materialize them using:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="collect(load_images(...))"><pre class="notranslate"><code>collect(load_images(...))
</code></pre></div>
<h2 dir="auto"><a id="user-content-available-datasets" class="anchor" aria-hidden="true" href="#available-datasets"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Available datasets</h2>
<h3 dir="auto"><a id="user-content-cootes-images" class="anchor" aria-hidden="true" href="#cootes-images"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Cootes images</h3>
<p dir="auto"><code>CootesDataset</code> contains images from Tim Cootes' work on active appearance models. These images come prepacked, so you can use them for testing.</p>
<p dir="auto">Supported functions:</p>
<ul dir="auto">
<li><code>load_images(CootesDataset)</code></li>
<li><code>load_shapes(CootesDataset)</code></li>
</ul>
<h3 dir="auto"><a id="user-content-cohn-kanade-dataset" class="anchor" aria-hidden="true" href="#cohn-kanade-dataset"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Cohn-Kanade+ dataset</h3>
<p dir="auto"><code>CKDataset</code> contains images from <a href="http://www.pitt.edu/~emotion/ck-spread.htm" rel="nofollow">Cohn-Kanade+ Expression Database</a>. To install this dataset, download it from <a href="http://www.consortium.ri.cmu.edu/ckagree/" rel="nofollow">this page</a> and unpack into a directory of your choice. Example of expected directory layout:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="$ tree -L 2
.
├── cohn-kanade-images
│   ├── S005
│   ├── S010
│   ├── S011
│   ...
│   └── S999
├── Emotion
│   ├── S005
│   ├── S010
│   ├── S011
│   ...
│   └── S999
└── Landmarks
    ├── S005
    ├── S010
    ├── S011
    ...
    └── S999"><pre class="notranslate"><code>$ tree -L 2
.
├── cohn-kanade-images
│   ├── S005
│   ├── S010
│   ├── S011
│   ...
│   └── S999
├── Emotion
│   ├── S005
│   ├── S010
│   ├── S011
│   ...
│   └── S999
└── Landmarks
    ├── S005
    ├── S010
    ├── S011
    ...
    └── S999
</code></pre></div>
<p dir="auto">Supported functions:</p>
<ul dir="auto">
<li><code>load_images(CKDataset, datadir, opts...)</code></li>
<li><code>load_shapes(CKDataset, datadir, opts...)</code></li>
<li><code>load_labels(CKDataset, datadir, opts...)</code></li>
</ul>
<p dir="auto">where <code>datadir</code> is base dir for CK dataset and labels are numbers representing 6 basic emotions + neutral facial expression.</p>
<p dir="auto">Options:</p>
<ul dir="auto">
<li><code>start</code> - image index to start with</li>
<li><code>count</code> - number of images to return</li>
<li><code>indexes</code> - concrete indexes to return (<code>start</code> and <code>count</code> are ignored)</li>
<li><code>resizeratio</code> - resize image by this value</li>
</ul>
<h3 dir="auto"><a id="user-content-cohn-kanade-max-only-dataset" class="anchor" aria-hidden="true" href="#cohn-kanade-max-only-dataset"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Cohn-Kanade+ (max only) dataset</h3>
<p dir="auto"><code>CKMaxDataset</code> - same as Cohn-Kanade+ dataset, but contains only images with maximally expressed emotion (~500 images). Only <code>resizeration</code> option is supported, though.</p>
<p dir="auto">TODO: <code>KaggleFERDataset</code>
TODO: <code>PutFrontalDataset</code></p>
</article></div>