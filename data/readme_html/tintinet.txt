<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-tintinetjl" class="anchor" aria-hidden="true" href="#tintinetjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>TintiNet.jl</h1>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="./logo_TintiNet.png"><img src="./logo_TintiNet.png" alt="" title="TintiNet.jl Logo" style="max-width: 100%;"></a></p>
<p dir="auto">TintiNet.jl is the package that implements the Topological Inference by Neural Transformer-Inceptor Network architecture, as developed and described by G. Bottino and L. Mart√≠nez in the manuscript <em><strong>Estimation of protein topological properties from single sequences using a fast language model</strong></em> (in preparation)</p>
<p dir="auto">This repository is a work in progress and lacks some relevant functionality, but contains a working example for training and running inference on a TintiNet if the user has access to a CUDA-capable GPU with 5 GB or more.</p>
<hr>
<h2 dir="auto"><a id="user-content-setting-up" class="anchor" aria-hidden="true" href="#setting-up"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Setting up</h2>
<p dir="auto">In order to follow this tutorial, you will first need to ensure you have CUDA (major version 11 - we used 11.4) and CUDNN (major version 8 - we used 8.2) installed in your system. CUDA and CUDNN are proprietary software and can be downloaded from <a href="https://developer.nvidia.com/" rel="nofollow">https://developer.nvidia.com/</a></p>
<p dir="auto">You will also need a Julia language installation. We recommend version 1.6. To obtain Julia, visit <a href="https://julialang.org/downloads/" rel="nofollow">https://julialang.org/downloads/</a> and follow the instructions.</p>
<h3 dir="auto"><a id="user-content-installing-packages" class="anchor" aria-hidden="true" href="#installing-packages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installing packages</h3>
<p dir="auto">If you are new to Julia, there is a package manager included that will help you install TintiNet.jl. in the REPL, you can type <code>]</code> to bring up the package command-line and simply install the <code>TintiNet</code> package by typing <code>$julia&gt; ]add https://github.com/Hugemiler/TintiNet.jl.git</code>. It should install any dependencies, provided you have already set up CUDA and CUDNN adequately.</p>
<hr>
<h2 dir="auto"><a id="user-content-running-the-example" class="anchor" aria-hidden="true" href="#running-the-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Running the Example</h2>
<p dir="auto">In this repository, we provide an example script that allows you to build a specific version of the IGBT TintiNet. The script will allow you to tinker with this specific architecture and train it on over 30k protein sequences, saving model and optimizer checkpoints.</p>
<h3 dir="auto"><a id="user-content-tutorial" class="anchor" aria-hidden="true" href="#tutorial"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Tutorial</h3>
<ol dir="auto">
<li>Setting up:</li>
</ol>
<ul dir="auto">
<li>Clone this repository</li>
<li>Unzip the file <code>datasets.tar.gz</code> in the same folder.</li>
<li>(optional) Edit the header structures <code>hyperpar</code> and <code>config</code> in the <code>examples/train_TintiNet_IGBT_classifier.jl</code> file to alter the network size if necessary.</li>
</ul>
<ol start="2" dir="auto">
<li>Predicting 1D properties on protein samples using the pretrained models</li>
</ol>
<ul dir="auto">
<li>Ensure Julia is in our <code>PATH</code></li>
<li>Navigate to the exmples directory and run the prediction script with <code>$&gt; julia predict_TintiNet_IGBT.jl inputfile outputdir</code>. Argument <code>inputfile</code> receives a FASTA document with a list of proteins (refer to <code>example_samples.fasta</code> for structure), and argument <code>outputdir</code>receives the path to a director where the prediction outputs will be written. We provide an example inputfile comprised of the first 200 entries of CATH-S40. To use this inputfile, run command <code>$&gt; julia predict_TintiNet_IGBT.jl example_samples.fasta example_outputs</code></li>
</ul>
<ol start="3" dir="auto">
<li>Training the Classifier network and using your model for inference</li>
</ol>
<ul dir="auto">
<li>Uncomment the last line of <code>examples/train_TintiNet_IGBT_classifier.jl</code> and run the file using <code>$julia&gt; include("train_TintiNet_IGBT_classifier.jl")</code> from the REPL.</li>
<li>The generated model files will be stored in the examples folder. Take note of the training log and select a checkpoint.</li>
<li>To run prediction using your own trained model, edit line <code>@load "./example_classifier_model.bson" checkpoint_model</code> in <code>predict_TintiNet_IGBT.jl</code> to point to your checkpoint.</li>
</ul>
<ol start="4" dir="auto">
<li>Training the Regressor network and using your model for inference</li>
</ol>
<ul dir="auto">
<li>Uncomment the last line of <code>examples/train_TintiNet_IGBT_regressor.jl</code> and run the file using <code>$julia&gt; include("train_TintiNet_IGBT_regressor.jl")</code> from the REPL.</li>
<li>The generated model files will be stored in the examples folder. Take note of the training log and select a checkpoint.</li>
<li>To run prediction using your own trained model, edit line <code>@load "./example_regressor_model.bson" checkpoint_model</code> in <code>predict_TintiNet_IGBT.jl</code> to point to your checkpoint.</li>
</ul>
</article></div>