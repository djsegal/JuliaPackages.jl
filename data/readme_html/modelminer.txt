<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-modelminerjl" class="anchor" aria-hidden="true" href="#modelminerjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ModelMiner.jl</h1>
<p dir="auto"><em>One package to train them all.</em></p>
<p dir="auto">ModelMiner.jl aims to provide an easy use interface to train multiple machine learning
models with a single function all. It provides a <code>mine(...)</code> interface through
which users can train multiple classification and regression models easily. The goal
is to quickly verify which models performs better on data without much effort.</p>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<h3 dir="auto"><a id="user-content-classification-example" class="anchor" aria-hidden="true" href="#classification-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Classification example</h3>
<ol dir="auto">
<li>Prepare your data</li>
</ol>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using MLJ, RDatasets
data = dataset(&quot;datasets&quot;, &quot;iris&quot;)
y, X = MLJ.unpack(data, ==(:Species))"><pre><span class="pl-k">using</span> MLJ, RDatasets
data <span class="pl-k">=</span> <span class="pl-c1">dataset</span>(<span class="pl-s"><span class="pl-pds">"</span>datasets<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>iris<span class="pl-pds">"</span></span>)
y, X <span class="pl-k">=</span> MLJ<span class="pl-k">.</span><span class="pl-c1">unpack</span>(data, <span class="pl-k">==</span>(<span class="pl-c1">:Species</span>))</pre></div>
<ol start="2" dir="auto">
<li>Call <code>mine(...)</code> to train and evaluate models</li>
</ol>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ModelMiner
results = mine(X, y)"><pre><span class="pl-k">using</span> ModelMiner
results <span class="pl-k">=</span> <span class="pl-c1">mine</span>(X, y)</pre></div>
<p dir="auto">The output will a dataframe with performance measures according to the data</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="7×3 DataFrame
 Row │ name                             Accuracy  MulticlassFScore 
     │ String                           Float64   Float64          
─────┼─────────────────────────────────────────────────────────────
   1 │ AdaBoostStumpClassifier          0.94              0.927209
   2 │ ConstantClassifier               0.266667          0.140233
   3 │ DecisionTreeClassifier           0.966667          0.965303
   4 │ DecisionTreeClassifier           0.92              0.918642
   5 │ DeterministicConstantClassifier  0.266667          0.140063
   6 │ KernelPerceptron                 0.94              0.937882
   7 │ LinearPerceptron                 0.813333          0.771626
   8 │ LinearSVC                        0.96              0.963594
   9 │ LogisticClassifier               0.973333          0.968547
  10 │ MultinomialClassifier            0.953333          0.952808
  11 │ NeuralNetworkClassifier          0.533333          0.405575
  12 │ NuSVC                            0.966667          0.96627
  13 │ Pegasos                          0.6               0.484509
  14 │ RandomForestClassifier           0.953333          0.957148
  15 │ RandomForestClassifier           0.953333          0.948225
  16 │ SVC                              0.96              0.957057
  17 │ XGBoostClassifier                0.94              0.939973"><pre class="notranslate"><code>7×3 DataFrame
 Row │ name                             Accuracy  MulticlassFScore 
     │ String                           Float64   Float64          
─────┼─────────────────────────────────────────────────────────────
   1 │ AdaBoostStumpClassifier          0.94              0.927209
   2 │ ConstantClassifier               0.266667          0.140233
   3 │ DecisionTreeClassifier           0.966667          0.965303
   4 │ DecisionTreeClassifier           0.92              0.918642
   5 │ DeterministicConstantClassifier  0.266667          0.140063
   6 │ KernelPerceptron                 0.94              0.937882
   7 │ LinearPerceptron                 0.813333          0.771626
   8 │ LinearSVC                        0.96              0.963594
   9 │ LogisticClassifier               0.973333          0.968547
  10 │ MultinomialClassifier            0.953333          0.952808
  11 │ NeuralNetworkClassifier          0.533333          0.405575
  12 │ NuSVC                            0.966667          0.96627
  13 │ Pegasos                          0.6               0.484509
  14 │ RandomForestClassifier           0.953333          0.957148
  15 │ RandomForestClassifier           0.953333          0.948225
  16 │ SVC                              0.96              0.957057
  17 │ XGBoostClassifier                0.94              0.939973
</code></pre></div>
<h3 dir="auto"><a id="user-content-regression-example" class="anchor" aria-hidden="true" href="#regression-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Regression example</h3>
<ol dir="auto">
<li>Prepare your data</li>
</ol>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="data = dataset(&quot;MASS&quot;, &quot;Boston&quot;)
y, X = MLJ.unpack(data, ==(:MedV))"><pre>data <span class="pl-k">=</span> <span class="pl-c1">dataset</span>(<span class="pl-s"><span class="pl-pds">"</span>MASS<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Boston<span class="pl-pds">"</span></span>)
y, X <span class="pl-k">=</span> MLJ<span class="pl-k">.</span><span class="pl-c1">unpack</span>(data, <span class="pl-k">==</span>(<span class="pl-c1">:MedV</span>))</pre></div>
<ol start="2" dir="auto">
<li>Train models and evaluate models</li>
</ol>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ModelMiner
results = mine(X, y)"><pre><span class="pl-k">using</span> ModelMiner
results <span class="pl-k">=</span> <span class="pl-c1">mine</span>(X, y)</pre></div>
<p dir="auto">Results:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="8×2 DataFrame
 Row │ name                            RootMeanSquaredError 
     │ String                          Float64              
─────┼──────────────────────────────────────────────────────
   1 │ ConstantRegressor                            9.22236
   2 │ DecisionTreeRegressor                        5.0619
   3 │ DecisionTreeRegressor                        4.51225
   4 │ DeterministicConstantRegressor               9.19367
   5 │ GaussianMixtureRegressor                     8.18446
   6 │ NeuralNetworkRegressor                      20.2011
   7 │ RandomForestRegressor                        3.98226
   8 │ RandomForestRegressor                        3.38003"><pre class="notranslate"><code>8×2 DataFrame
 Row │ name                            RootMeanSquaredError 
     │ String                          Float64              
─────┼──────────────────────────────────────────────────────
   1 │ ConstantRegressor                            9.22236
   2 │ DecisionTreeRegressor                        5.0619
   3 │ DecisionTreeRegressor                        4.51225
   4 │ DeterministicConstantRegressor               9.19367
   5 │ GaussianMixtureRegressor                     8.18446
   6 │ NeuralNetworkRegressor                      20.2011
   7 │ RandomForestRegressor                        3.98226
   8 │ RandomForestRegressor                        3.38003
</code></pre></div>
<h2 dir="auto"><a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>TODO</h2>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> Automated Feature scaling</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> Hyperparameter Tuning</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> Reporting performance statistics from Cross Validations</li>
</ul>
<h2 dir="auto"><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Acknowledgements</h2>
<p dir="auto">Thanks to the developers of <a href="https://github.com/shankarpandala/lazypredict">LazyPredict</a>
for inspiration and <a href="https://github.com/ablaom">@ablaom</a> for helping me overcome
<a href="https://discourse.julialang.org/t/using-load-from-mlj-inside-a-package/93413" rel="nofollow">some challenges</a> in developing.</p>
</article></div>