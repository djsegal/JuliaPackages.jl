<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p align="center" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/ADCME.gif?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/ADCME.gif?raw=true" alt="ADCME" data-animated-image="" style="max-width: 100%;"></a>
</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a42c7dcd1a96d925359888ead7931cc5a595ed11140d98fcee1d1108e3a958b4/68747470733a2f2f7472617669732d63692e6f72672f6b61696c6169782f4144434d452e6a6c2e7376673f6272616e63683d6d6173746572"><img src="https://camo.githubusercontent.com/a42c7dcd1a96d925359888ead7931cc5a595ed11140d98fcee1d1108e3a958b4/68747470733a2f2f7472617669732d63692e6f72672f6b61696c6169782f4144434d452e6a6c2e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://travis-ci.org/kailaix/ADCME.jl.svg?branch=master" style="max-width: 100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/kailaix/ADCME.jl/workflows/Documentation/badge.svg"><img src="https://github.com/kailaix/ADCME.jl/workflows/Documentation/badge.svg" alt="" style="max-width: 100%;"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/d89a4ddf3a471918de630ad5079ebc89eab9710b0c11d16f07b5e8156c15457b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6b61696c6169782f4144434d452e6a6c2f62616467652e7376673f6272616e63683d6d6173746572"><img src="https://camo.githubusercontent.com/d89a4ddf3a471918de630ad5079ebc89eab9710b0c11d16f07b5e8156c15457b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6b61696c6169782f4144434d452e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/kailaix/ADCME.jl/badge.svg?branch=master" style="max-width: 100%;"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/demo.png?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/demo.png?raw=true" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">The ADCME library (<strong>A</strong>utomatic <strong>D</strong>ifferentiation Library for <strong>C</strong>omputational and <strong>M</strong>athematical <strong>E</strong>ngineering) aims at general and scalable inverse modeling in scientific computing with gradient-based optimization techniques. It is built on the deep learning framework, <strong>graph-mode <a href="https://www.tensorflow.org/" rel="nofollow">TensorFlow</a></strong>, which provides the automatic differentiation and parallel computing backend. The dataflow model adopted by the framework makes it suitable for high performance computing and inverse modeling in scientific computing. The design principles and methodologies are summarized in the <a href="https://kailaix.github.io/ADCMESlides/ADCME.pdf" rel="nofollow">slides</a>.</p>
<p dir="auto">Check out more about <a href="https://kailaix.github.io/ADCME.jl/dev/videos_and_slides/" rel="nofollow">slides and videos on ADCME</a>!</p>
<table>
<thead>
<tr>
<th><a href="https://www.youtube.com/playlist?list=PLKBz8ohiA3IlrCI0VO4cRYZp2S6SYG1Ww" rel="nofollow">Install ADCME and Get Started (Windows, Mac, and Linux)</a></th>
<th><a href="https://www.youtube.com/playlist?list=PLKBz8ohiA3In-ZlvBKbvj_TIQEaboGC9_" rel="nofollow">Scientific Machine Learning for Inverse Modeling</a></th>
<th><a href="https://www.youtube.com/playlist?list=PLKBz8ohiA3ImaNykOv56ONnCofEQMg3B8" rel="nofollow">Solving Inverse Modeling Problems with ADCME</a></th>
<th>...<strong>more</strong> on <a href="https://www.youtube.com/channel/UCeaZFluNatYpkIYcq2TTklw/playlists" rel="nofollow">ADCME Youtube Channel</a>!</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.youtube.com/playlist?list=PLKBz8ohiA3IlrCI0VO4cRYZp2S6SYG1Ww" rel="nofollow"><img src="https://camo.githubusercontent.com/eddee6f54151ffd598ce784d2d7d05dd1d28d2cdda1beb9ca741ee24e90c976f/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f664830517271677a55656f2f302e6a7067" alt="Alt text" data-canonical-src="https://img.youtube.com/vi/fH0QrqgzUeo/0.jpg" style="max-width: 100%;"></a></td>
<td><a href="https://www.youtube.com/playlist?list=PLKBz8ohiA3In-ZlvBKbvj_TIQEaboGC9_" rel="nofollow"><img src="https://camo.githubusercontent.com/6433ac014ea5b776d9531c460e9fd3a94eb680c362242d732fcaf4027d358b07/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f744e6a37486f6f5536656b2f302e6a7067" alt="Alt text" data-canonical-src="https://img.youtube.com/vi/tNj7HooU6ek/0.jpg" style="max-width: 100%;"></a></td>
<td><a href="https://www.youtube.com/playlist?list=PLKBz8ohiA3ImaNykOv56ONnCofEQMg3B8" rel="nofollow"><img src="https://camo.githubusercontent.com/f68e8f29f90327a253ecec931ad7f5cc881ae371267684dc7e227e49f0357beb/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f775033396f4e68495868382f302e6a7067" alt="Alt text" data-canonical-src="https://img.youtube.com/vi/wP39oNhIXh8/0.jpg" style="max-width: 100%;"></a></td>
<td><a href="https://www.youtube.com/channel/UCeaZFluNatYpkIYcq2TTklw/playlists" rel="nofollow"><img src="https://camo.githubusercontent.com/18417ea9118c524f0d4210695dac9b1eedbb8ff37b81bdf0534b3904c404b174/68747470733a2f2f7974332e67677068742e636f6d2f612d2f414f683134476a4e75625a534f5a616d657550726c4b6c6143564e5765323655484f314d7a587462493372503d733238382d632d6b2d63307866666666666666662d6e6f2d726a2d6d6f" alt="" data-canonical-src="https://yt3.ggpht.com/a-/AOh14GjNubZSOZameuPrlKlaCVNWe26UHO1MzXtbI3rP=s288-c-k-c0xffffffff-no-rj-mo" style="max-width: 100%;"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">Several features of the library are</p>
<ul dir="auto">
<li><strong>MATLAB-style Syntax</strong>. Write <code>A*B</code> for matrix production instead of <code>tf.matmul(A,B)</code>.</li>
<li><strong>Custom Operators</strong>. Implement operators in C/C++ for performance critical parts; incorporate legacy code or specially designed C/C++ code in <code>ADCME</code>; automatic differentiation through implicit schemes and iterative solvers.</li>
<li><strong>Numerical Scheme</strong>. Easy to implement numerical schemes for solving PDEs.</li>
<li><strong>Physics Constrained Learning</strong>. Embed neural network into PDEs and solve with any numerical schemes, including implicit and iterative schemes.</li>
<li><strong>Static Graphs</strong>. Compilation time computational graph optimization; automatic parallelism for your simulation codes.</li>
<li><strong>Parallel Computing</strong>. <a href="https://kailaix.github.io/ADCME.jl/dev/multithreading/" rel="nofollow">Concurrent execution</a> and model/data parallel <a href="https://kailaix.github.io/ADCME.jl/dev/mpi/" rel="nofollow">distributed optimization</a>.</li>
<li><strong>Custom Optimizers</strong>. Large scale constrained optimization? Use <code>CustomOptimizer</code> to integrate your favorite optimizer. Try out prebuilt <a href="https://kailaix.github.io/ADCME.jl/dev/customopt/#Dropin-substitute-of-BFGS!-1" rel="nofollow">Ipopt and NLopt</a> optimizers.</li>
<li><strong>Sparse Linear Algebra</strong>. Sparse linear algebra library tailored for scientific computing.</li>
<li><strong>Inverse Modeling</strong>. Many inverse modeling algorithms have been developed and implemented in ADCME, with wide applications in solid mechanics, fluid dynamics, geophysics, and stochastic processes.</li>
<li><a href="https://github.com/kailaix/AdFem.jl"><img src="https://raw.githubusercontent.com/ADCMEMarket/ADCMEImages/a82f1ae2c686e2c2a9eb2bc940540afb004c6503/ADCME/newrelease.svg" alt="" style="max-width: 100%;"></a><strong>Finite Element Method</strong>. Get <a href="https://github.com/kailaix/AdFem.jl">AdFem.jl</a> today for finite element simulation and inverse modeling!</li>
</ul>
<p dir="auto">Start building your forward and inverse modeling using ADCME today!</p>
<table>
<thead>
<tr>
<th>Documentation</th>
<th>Tutorial</th>
<th>Applications</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://kailaix.github.io/ADCME.jl/latest/" rel="nofollow"><img src="https://camo.githubusercontent.com/7bf375d106b452da9b4a8f08727ebec51c0b9435835b07197332ee5bd8bc22a5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d446f63756d656e746174696f6e2d626c7565" alt="" data-canonical-src="https://img.shields.io/badge/-Documentation-blue" style="max-width: 100%;"></a></td>
<td><a href="https://kailaix.github.io/ADCME.jl/dev/tutorial/" rel="nofollow"><img src="https://camo.githubusercontent.com/239cc700e1d379517b466d1214e3fb85986d8923b2c6af06b7f4fe1892317595/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d5475746f7269616c2d677265656e" alt="" data-canonical-src="https://img.shields.io/badge/-Tutorial-green" style="max-width: 100%;"></a></td>
<td><a href="https://kailaix.github.io/ADCME.jl/dev/apps" rel="nofollow"><img src="https://camo.githubusercontent.com/ea3a3a5b42d659010acfe2898e4220aa6794d17a0157832664aa5bef7627e687/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d4170706c69636174696f6e732d6f72616e6765" alt="" data-canonical-src="https://img.shields.io/badge/-Applications-orange" style="max-width: 100%;"></a></td>
</tr>
</tbody>
</table>
<h2 dir="auto"><a id="user-content-graph-mode-tensorflow-for-high-performance-scientific-computing" class="anchor" aria-hidden="true" href="#graph-mode-tensorflow-for-high-performance-scientific-computing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Graph-mode TensorFlow for High Performance Scientific Computing</h2>
<p dir="auto">Static computational graph (graph-mode AD) enables compilation time optimization. Below is a benchmark of common AD software from <a href="https://github.com/microsoft/ADBench">here</a>. In inverse modeling, we usually have a scalar-valued objective function, so the left panel is most relevant for ADCME.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/microsoft/ADBench/master/Documents/figs/2020_Jan.png"><img src="https://raw.githubusercontent.com/microsoft/ADBench/master/Documents/figs/2020_Jan.png" alt="" style="max-width: 100%;"></a></p>
<h1 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h1>
<ol dir="auto">
<li>Install <a href="https://julialang.org/" rel="nofollow">Julia</a>.</li>
</ol>
<p dir="auto"><g-emoji class="g-emoji" alias="tada" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png">🎉</g-emoji> Support Matrix</p>
<table>
<thead>
<tr>
<th></th>
<th>Julia≧1.3</th>
<th>GPU</th>
<th>Custom Operator</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linux</td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔</g-emoji></td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔</g-emoji></td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔</g-emoji></td>
</tr>
<tr>
<td>MacOS</td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔</g-emoji></td>
<td>✕</td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔</g-emoji></td>
</tr>
<tr>
<td>Windows</td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔</g-emoji></td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔</g-emoji></td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔</g-emoji></td>
</tr>
</tbody>
</table>
<ol dir="auto">
<li>Install <code>ADCME</code></li>
</ol>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using Pkg
Pkg.add(&quot;ADCME&quot;)"><pre class="notranslate"><code>using Pkg
Pkg.add("ADCME")
</code></pre></div>
<p dir="auto"><g-emoji class="g-emoji" alias="exclamation" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2757.png">❗</g-emoji> FOR WINDOWS USERS: See <a href="https://kailaix.github.io/ADCME.jl/dev/windows_installation/" rel="nofollow">the instruction</a> or <a href="https://www.youtube.com/playlist?list=PLKBz8ohiA3IlrCI0VO4cRYZp2S6SYG1Ww" rel="nofollow">the video</a> for installation details.</p>
<p dir="auto"><g-emoji class="g-emoji" alias="exclamation" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2757.png">❗</g-emoji> FOR MACOS USERS: See this <a href="https://kailaix.github.io/ADCME.jl/dev/#Troubleshooting-for-MacOS" rel="nofollow">troubleshooting list</a> for potential installation and compilation problems on Mac.</p>
<ol start="2" dir="auto">
<li>(Optional) Test <code>ADCME.jl</code></li>
</ol>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Pkg
Pkg.test(&quot;ADCME&quot;)"><pre><span class="pl-k">using</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">test</span>(<span class="pl-s"><span class="pl-pds">"</span>ADCME<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">See <a href="https://kailaix.github.io/ADCME.jl/dev/tu_customop/#Troubleshooting-1" rel="nofollow">Troubleshooting</a> if you encounter any compilation problems.</p>
<ol start="3" dir="auto">
<li>(Optional) To enable GPU support, make sure <code>nvcc</code> is available from your environment (e.g., type <code>nvcc</code> in your shell and you should get the location of the executable binary file), and then type</li>
</ol>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="ENV[&quot;GPU&quot;] = 1
Pkg.build(&quot;ADCME&quot;)"><pre><span class="pl-c1">ENV</span>[<span class="pl-s"><span class="pl-pds">"</span>GPU<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-c1">1</span>
Pkg<span class="pl-k">.</span><span class="pl-c1">build</span>(<span class="pl-s"><span class="pl-pds">"</span>ADCME<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">You can check the status with <code>using ADCME; gpu_info()</code>.</p>
<ol start="4" dir="auto">
<li>(Optional) Check the health of your installed ADCME and install missing dependencies or fixing incorrect paths.</li>
</ol>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ADCME 
doctor()"><pre><span class="pl-k">using</span> ADCME 
<span class="pl-c1">doctor</span>()</pre></div>
<p dir="auto">For manual installation without access to the internet, see <a href="https://kailaix.github.io/ADCME.jl/dev/" rel="nofollow">here</a>.</p>
<h2 dir="auto"><a id="user-content-install-via-docker" class="anchor" aria-hidden="true" href="#install-via-docker"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Install via Docker</h2>
<p dir="auto">If you have Docker installed on your system, you can try the no-hassle way to install ADCME (you don't even have to install Julia!):</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="docker run -ti kailaix/adcme"><pre>docker run -ti kailaix/adcme</pre></div>
<p dir="auto">For GPU-enabled ADCME, use</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="docker run -ti --gpus all kailaix/adcme:gpu"><pre>docker run -ti --gpus all kailaix/adcme:gpu</pre></div>
<p dir="auto">See <a href="https://kailaix.github.io/ADCME.jl/latest/docker/" rel="nofollow">this guide</a> for details. The docker images are hosted <a href="https://hub.docker.com/repository/docker/kailaix/adcme" rel="nofollow">here</a>.</p>
<h1 dir="auto"><a id="user-content-tutorial" class="anchor" aria-hidden="true" href="#tutorial"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Tutorial</h1>
<p dir="auto">Here we present three inverse problem examples. The first one is a parameter estimation problem, the second one is a function inverse problem where the unknown function does not depend on the state variables, and the third one is also a function inverse problem, but the unknown function depends on the state variables.</p>
<h3 dir="auto"><a id="user-content-parameter-inverse-problem" class="anchor" aria-hidden="true" href="#parameter-inverse-problem"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Parameter Inverse Problem</h3>
<p dir="auto">Consider solving the following problem</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/readme-eq1.svg?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/readme-eq1.svg?raw=true" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">where</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/readme-eq2.svg?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/readme-eq2.svg?raw=true" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">Assume that we have observed <code>u(0.5)=1</code>, we want to estimate <code>b</code>.  In this case, he true value should be <code>b=1</code>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LinearAlgebra
using ADCME

n = 101 # number of grid nodes in [0,1]
h = 1/(n-1)
x = LinRange(0,1,n)[2:end-1]

b = Variable(10.0) # we use Variable keyword to mark the unknowns
A = diagm(0=&gt;2/h^2*ones(n-2), -1=&gt;-1/h^2*ones(n-3), 1=&gt;-1/h^2*ones(n-3)) 
B = b*A + I  # I stands for the identity matrix
f = @. 4*(2 + x - x^2) 
u = B\f # solve the equation using built-in linear solver
ue = u[div(n+1,2)] # extract values at x=0.5

loss = (ue-1.0)^2 

# Optimization
sess = Session(); init(sess) 
BFGS!(sess, loss)

println(&quot;Estimated b = &quot;, run(sess, b))"><pre><span class="pl-k">using</span> LinearAlgebra
<span class="pl-k">using</span> ADCME

n <span class="pl-k">=</span> <span class="pl-c1">101</span> <span class="pl-c"><span class="pl-c">#</span> number of grid nodes in [0,1]</span>
h <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">/</span>(n<span class="pl-k">-</span><span class="pl-c1">1</span>)
x <span class="pl-k">=</span> <span class="pl-c1">LinRange</span>(<span class="pl-c1">0</span>,<span class="pl-c1">1</span>,n)[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>]

b <span class="pl-k">=</span> <span class="pl-c1">Variable</span>(<span class="pl-c1">10.0</span>) <span class="pl-c"><span class="pl-c">#</span> we use Variable keyword to mark the unknowns</span>
A <span class="pl-k">=</span> <span class="pl-c1">diagm</span>(<span class="pl-c1">0</span><span class="pl-k">=&gt;</span><span class="pl-c1">2</span><span class="pl-k">/</span>h<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">*</span><span class="pl-c1">ones</span>(n<span class="pl-k">-</span><span class="pl-c1">2</span>), <span class="pl-k">-</span><span class="pl-c1">1</span><span class="pl-k">=&gt;</span><span class="pl-k">-</span><span class="pl-c1">1</span><span class="pl-k">/</span>h<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">*</span><span class="pl-c1">ones</span>(n<span class="pl-k">-</span><span class="pl-c1">3</span>), <span class="pl-c1">1</span><span class="pl-k">=&gt;</span><span class="pl-k">-</span><span class="pl-c1">1</span><span class="pl-k">/</span>h<span class="pl-k">^</span><span class="pl-c1">2</span><span class="pl-k">*</span><span class="pl-c1">ones</span>(n<span class="pl-k">-</span><span class="pl-c1">3</span>)) 
B <span class="pl-k">=</span> b<span class="pl-k">*</span>A <span class="pl-k">+</span> I  <span class="pl-c"><span class="pl-c">#</span> I stands for the identity matrix</span>
f <span class="pl-k">=</span> <span class="pl-c1">@.</span> <span class="pl-c1">4</span><span class="pl-k">*</span>(<span class="pl-c1">2</span> <span class="pl-k">+</span> x <span class="pl-k">-</span> x<span class="pl-k">^</span><span class="pl-c1">2</span>) 
u <span class="pl-k">=</span> B<span class="pl-k">\</span>f <span class="pl-c"><span class="pl-c">#</span> solve the equation using built-in linear solver</span>
ue <span class="pl-k">=</span> u[<span class="pl-c1">div</span>(n<span class="pl-k">+</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span>)] <span class="pl-c"><span class="pl-c">#</span> extract values at x=0.5</span>

loss <span class="pl-k">=</span> (ue<span class="pl-k">-</span><span class="pl-c1">1.0</span>)<span class="pl-k">^</span><span class="pl-c1">2</span> 

<span class="pl-c"><span class="pl-c">#</span> Optimization</span>
sess <span class="pl-k">=</span> <span class="pl-c1">Session</span>(); <span class="pl-c1">init</span>(sess) 
<span class="pl-c1">BFGS!</span>(sess, loss)

<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span>Estimated b = <span class="pl-pds">"</span></span>, <span class="pl-c1">run</span>(sess, b))</pre></div>
<p dir="auto">Expected output</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="Estimated b = 0.9995582304494237"><pre class="notranslate"><code>Estimated b = 0.9995582304494237
</code></pre></div>
<p dir="auto">The gradients can be obtained very easily. For example, if we want the gradients of <code>loss</code> with respect to <code>b</code>, the following code will create a Tensor for the gradient</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="julia&gt; gradients(loss, b)
PyObject &lt;tf.Tensor 'gradients_1/Mul_grad/Reshape:0' shape=() dtype=float64&gt;"><pre class="notranslate"><code>julia&gt; gradients(loss, b)
PyObject &lt;tf.Tensor 'gradients_1/Mul_grad/Reshape:0' shape=() dtype=float64&gt;
</code></pre></div>
<h3 dir="auto"><a id="user-content-function-inverse-problem-full-field-data" class="anchor" aria-hidden="true" href="#function-inverse-problem-full-field-data"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Function Inverse Problem: Full Field Data</h3>
<p dir="auto">Consider a nonlinear PDE,</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/readme-eq3.svg?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/readme-eq3.svg?raw=true" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">where</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/readme-eq4.svg?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/readme-eq4.svg?raw=true" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">Here <code>f(x)</code> can be computed from an analytical solution</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/readme-eq5.svg?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/readme-eq5.svg?raw=true" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">In this problem, we are given the full field data of <code>u(x)</code> (the discrete value of <code>u(x)</code> is given on a very fine grid) and want to estimate the nonparametric function <code>b(u)</code>. We approximate <code>b(u)</code> using a neural network and use the <a href="https://kailaix.github.io/ADCME.jl/dev/tu_nn/" rel="nofollow">residual minimization method</a> to find the optimal weights and biases of the neural network. The minimization problem is given by</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/readme-eq6.svg?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/readme-eq6.svg?raw=true" alt="" style="max-width: 100%;"></a></p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LinearAlgebra
using ADCME
using PyPlot

n = 101 
h = 1/(n-1)
x = LinRange(0,1,n)|&gt;collect

u = sin.(π*x)
f = @. (1+u^2)/(1+2u^2) * π^2 * u + u 
# `fc` is short for fully connected neural network. 
# Here we create a neural network with 2 hidden layers, and 20 neuron per layer. 
# The default activation function is tanh.
b = squeeze(fc(u[2:end-1], [20,20,1])) 

residual = -b.*(u[3:end]+u[1:end-2]-2u[2:end-1])/h^2 + u[2:end-1] - f[2:end-1]
loss = sum(residual^2)

sess = Session(); init(sess)
BFGS!(sess, loss)

plot(x, (@. (1+x^2)/(1+2*x^2)), label=&quot;Reference&quot;)
plot(u[2:end-1], run(sess, b), &quot;o&quot;, markersize=5., label=&quot;Estimated&quot;)
legend(); xlabel(&quot;\$u\$&quot;); ylabel(&quot;\$b(u)\$&quot;); grid(&quot;on&quot;)"><pre><span class="pl-k">using</span> LinearAlgebra
<span class="pl-k">using</span> ADCME
<span class="pl-k">using</span> PyPlot

n <span class="pl-k">=</span> <span class="pl-c1">101</span> 
h <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">/</span>(n<span class="pl-k">-</span><span class="pl-c1">1</span>)
x <span class="pl-k">=</span> <span class="pl-c1">LinRange</span>(<span class="pl-c1">0</span>,<span class="pl-c1">1</span>,n)<span class="pl-k">|&gt;</span>collect

u <span class="pl-k">=</span> <span class="pl-c1">sin</span>.(π<span class="pl-k">*</span>x)
f <span class="pl-k">=</span> <span class="pl-c1">@.</span> (<span class="pl-c1">1</span><span class="pl-k">+</span>u<span class="pl-k">^</span><span class="pl-c1">2</span>)<span class="pl-k">/</span>(<span class="pl-c1">1</span><span class="pl-k">+</span><span class="pl-c1">2</span>u<span class="pl-k">^</span><span class="pl-c1">2</span>) <span class="pl-k">*</span> π<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">*</span> u <span class="pl-k">+</span> u 
<span class="pl-c"><span class="pl-c">#</span> `fc` is short for fully connected neural network. </span>
<span class="pl-c"><span class="pl-c">#</span> Here we create a neural network with 2 hidden layers, and 20 neuron per layer. </span>
<span class="pl-c"><span class="pl-c">#</span> The default activation function is tanh.</span>
b <span class="pl-k">=</span> <span class="pl-c1">squeeze</span>(<span class="pl-c1">fc</span>(u[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>], [<span class="pl-c1">20</span>,<span class="pl-c1">20</span>,<span class="pl-c1">1</span>])) 

residual <span class="pl-k">=</span> <span class="pl-k">-</span>b<span class="pl-k">.*</span>(u[<span class="pl-c1">3</span><span class="pl-k">:</span><span class="pl-c1">end</span>]<span class="pl-k">+</span>u[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">2</span>]<span class="pl-k">-</span><span class="pl-c1">2</span>u[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>])<span class="pl-k">/</span>h<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> u[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-k">-</span> f[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>]
loss <span class="pl-k">=</span> <span class="pl-c1">sum</span>(residual<span class="pl-k">^</span><span class="pl-c1">2</span>)

sess <span class="pl-k">=</span> <span class="pl-c1">Session</span>(); <span class="pl-c1">init</span>(sess)
<span class="pl-c1">BFGS!</span>(sess, loss)

<span class="pl-c1">plot</span>(x, (<span class="pl-c1">@.</span> (<span class="pl-c1">1</span><span class="pl-k">+</span>x<span class="pl-k">^</span><span class="pl-c1">2</span>)<span class="pl-k">/</span>(<span class="pl-c1">1</span><span class="pl-k">+</span><span class="pl-c1">2</span><span class="pl-k">*</span>x<span class="pl-k">^</span><span class="pl-c1">2</span>)), label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Reference<span class="pl-pds">"</span></span>)
<span class="pl-c1">plot</span>(u[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>], <span class="pl-c1">run</span>(sess, b), <span class="pl-s"><span class="pl-pds">"</span>o<span class="pl-pds">"</span></span>, markersize<span class="pl-k">=</span><span class="pl-c1">5.</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Estimated<span class="pl-pds">"</span></span>)
<span class="pl-c1">legend</span>(); <span class="pl-c1">xlabel</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\$</span>u<span class="pl-cce">\$</span><span class="pl-pds">"</span></span>); <span class="pl-c1">ylabel</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\$</span>b(u)<span class="pl-cce">\$</span><span class="pl-pds">"</span></span>); <span class="pl-c1">grid</span>(<span class="pl-s"><span class="pl-pds">"</span>on<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">Here we show the estimated coefficient function and the reference one:</p>
<p align="center" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/readmenn.png?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/readmenn.png?raw=true" style="max-width: 100%;"></a>
</p>
<h3 dir="auto"><a id="user-content-function-inverse-problem-sparse-data" class="anchor" aria-hidden="true" href="#function-inverse-problem-sparse-data"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Function Inverse Problem: Sparse Data</h3>
<p dir="auto">Now we consider the same problem as above, but only consider we have access to sparse observations. We assume that on the grid only the values of <code>u(x)</code> on every other 5th grid point are observable. We use the <a href="https://arxiv.org/pdf/2002.10521.pdf" rel="nofollow">physics constrained learning</a> technique and train a neural network surrogate for <code>b(u)</code> by minimizing</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/readme-eq7.svg?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/readme-eq7.svg?raw=true" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">Here <code>uᶿ</code> is the solution to the PDE with</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/readme-eq8.svg?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/readme-eq8.svg?raw=true" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">We add 1 to the neural network to ensure the initial guess does not result in a singular Jacobian matrix in the Newton Raphson solver.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LinearAlgebra
using ADCME
using PyPlot

n = 101 
h = 1/(n-1)
x = LinRange(0,1,n)|&gt;collect

u = sin.(π*x)
f = @. (1+u^2)/(1+2u^2) * π^2 * u + u 

# we use a Newton Raphson solver to solve the nonlinear PDE problem 
function residual_and_jac(θ, x)
    nn = squeeze(fc(reshape(x,:,1), [20,20,1], θ)) + 1.0
    u_full = vector(2:n-1, x, n)
    res = -nn.*(u_full[3:end]+u_full[1:end-2]-2u_full[2:end-1])/h^2 + u_full[2:end-1] - f[2:end-1]
    J = gradients(res, x)
    res, J
end
θ = Variable(fc_init([1,20,20,1]))
ADCME.options.newton_raphson.rtol = 1e-4 # relative tolerance
ADCME.options.newton_raphson.tol = 1e-4 # absolute tolerance
ADCME.options.newton_raphson.verbose = true # print details in newton_raphson
u_est = newton_raphson_with_grad(residual_and_jac, constant(zeros(n-2)),θ)
residual = u_est[1:5:end] - u[2:end-1][1:5:end]
loss = sum(residual^2)

b = squeeze(fc(reshape(x,:,1), [20,20,1], θ)) + 1.0
sess = Session(); init(sess)
BFGS!(sess, loss)

figure(figsize=(10,4))
subplot(121)
plot(x, (@. (1+x^2)/(1+2*x^2)), label=&quot;Reference&quot;)
plot(x, run(sess, b), &quot;o&quot;, markersize=5., label=&quot;Estimated&quot;)
legend(); xlabel(&quot;\$u\$&quot;); ylabel(&quot;\$b(u)\$&quot;); grid(&quot;on&quot;)
subplot(122)
plot(x, (@. sin(π*x)), label=&quot;Reference&quot;)
plot(x[2:end-1], run(sess, u_est), &quot;--&quot;, label=&quot;Estimated&quot;)
plot(x[2:end-1][1:5:end], run(sess, u_est)[1:5:end], &quot;x&quot;, markersize=5., label=&quot;Data&quot;)
legend(); xlabel(&quot;\$x\$&quot;); ylabel(&quot;\$u\$&quot;); grid(&quot;on&quot;)"><pre><span class="pl-k">using</span> LinearAlgebra
<span class="pl-k">using</span> ADCME
<span class="pl-k">using</span> PyPlot

n <span class="pl-k">=</span> <span class="pl-c1">101</span> 
h <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">/</span>(n<span class="pl-k">-</span><span class="pl-c1">1</span>)
x <span class="pl-k">=</span> <span class="pl-c1">LinRange</span>(<span class="pl-c1">0</span>,<span class="pl-c1">1</span>,n)<span class="pl-k">|&gt;</span>collect

u <span class="pl-k">=</span> <span class="pl-c1">sin</span>.(π<span class="pl-k">*</span>x)
f <span class="pl-k">=</span> <span class="pl-c1">@.</span> (<span class="pl-c1">1</span><span class="pl-k">+</span>u<span class="pl-k">^</span><span class="pl-c1">2</span>)<span class="pl-k">/</span>(<span class="pl-c1">1</span><span class="pl-k">+</span><span class="pl-c1">2</span>u<span class="pl-k">^</span><span class="pl-c1">2</span>) <span class="pl-k">*</span> π<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">*</span> u <span class="pl-k">+</span> u 

<span class="pl-c"><span class="pl-c">#</span> we use a Newton Raphson solver to solve the nonlinear PDE problem </span>
<span class="pl-k">function</span> <span class="pl-en">residual_and_jac</span>(θ, x)
    nn <span class="pl-k">=</span> <span class="pl-c1">squeeze</span>(<span class="pl-c1">fc</span>(<span class="pl-c1">reshape</span>(x,:,<span class="pl-c1">1</span>), [<span class="pl-c1">20</span>,<span class="pl-c1">20</span>,<span class="pl-c1">1</span>], θ)) <span class="pl-k">+</span> <span class="pl-c1">1.0</span>
    u_full <span class="pl-k">=</span> <span class="pl-c1">vector</span>(<span class="pl-c1">2</span><span class="pl-k">:</span>n<span class="pl-k">-</span><span class="pl-c1">1</span>, x, n)
    res <span class="pl-k">=</span> <span class="pl-k">-</span>nn<span class="pl-k">.*</span>(u_full[<span class="pl-c1">3</span><span class="pl-k">:</span><span class="pl-c1">end</span>]<span class="pl-k">+</span>u_full[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">2</span>]<span class="pl-k">-</span><span class="pl-c1">2</span>u_full[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>])<span class="pl-k">/</span>h<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> u_full[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-k">-</span> f[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>]
    J <span class="pl-k">=</span> <span class="pl-c1">gradients</span>(res, x)
    res, J
<span class="pl-k">end</span>
θ <span class="pl-k">=</span> <span class="pl-c1">Variable</span>(<span class="pl-c1">fc_init</span>([<span class="pl-c1">1</span>,<span class="pl-c1">20</span>,<span class="pl-c1">20</span>,<span class="pl-c1">1</span>]))
ADCME<span class="pl-k">.</span>options<span class="pl-k">.</span>newton_raphson<span class="pl-k">.</span>rtol <span class="pl-k">=</span> <span class="pl-c1">1e-4</span> <span class="pl-c"><span class="pl-c">#</span> relative tolerance</span>
ADCME<span class="pl-k">.</span>options<span class="pl-k">.</span>newton_raphson<span class="pl-k">.</span>tol <span class="pl-k">=</span> <span class="pl-c1">1e-4</span> <span class="pl-c"><span class="pl-c">#</span> absolute tolerance</span>
ADCME<span class="pl-k">.</span>options<span class="pl-k">.</span>newton_raphson<span class="pl-k">.</span>verbose <span class="pl-k">=</span> <span class="pl-c1">true</span> <span class="pl-c"><span class="pl-c">#</span> print details in newton_raphson</span>
u_est <span class="pl-k">=</span> <span class="pl-c1">newton_raphson_with_grad</span>(residual_and_jac, <span class="pl-c1">constant</span>(<span class="pl-c1">zeros</span>(n<span class="pl-k">-</span><span class="pl-c1">2</span>)),θ)
residual <span class="pl-k">=</span> u_est[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">5</span><span class="pl-k">:</span><span class="pl-c1">end</span>] <span class="pl-k">-</span> u[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>][<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">5</span><span class="pl-k">:</span><span class="pl-c1">end</span>]
loss <span class="pl-k">=</span> <span class="pl-c1">sum</span>(residual<span class="pl-k">^</span><span class="pl-c1">2</span>)

b <span class="pl-k">=</span> <span class="pl-c1">squeeze</span>(<span class="pl-c1">fc</span>(<span class="pl-c1">reshape</span>(x,:,<span class="pl-c1">1</span>), [<span class="pl-c1">20</span>,<span class="pl-c1">20</span>,<span class="pl-c1">1</span>], θ)) <span class="pl-k">+</span> <span class="pl-c1">1.0</span>
sess <span class="pl-k">=</span> <span class="pl-c1">Session</span>(); <span class="pl-c1">init</span>(sess)
<span class="pl-c1">BFGS!</span>(sess, loss)

<span class="pl-c1">figure</span>(figsize<span class="pl-k">=</span>(<span class="pl-c1">10</span>,<span class="pl-c1">4</span>))
<span class="pl-c1">subplot</span>(<span class="pl-c1">121</span>)
<span class="pl-c1">plot</span>(x, (<span class="pl-c1">@.</span> (<span class="pl-c1">1</span><span class="pl-k">+</span>x<span class="pl-k">^</span><span class="pl-c1">2</span>)<span class="pl-k">/</span>(<span class="pl-c1">1</span><span class="pl-k">+</span><span class="pl-c1">2</span><span class="pl-k">*</span>x<span class="pl-k">^</span><span class="pl-c1">2</span>)), label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Reference<span class="pl-pds">"</span></span>)
<span class="pl-c1">plot</span>(x, <span class="pl-c1">run</span>(sess, b), <span class="pl-s"><span class="pl-pds">"</span>o<span class="pl-pds">"</span></span>, markersize<span class="pl-k">=</span><span class="pl-c1">5.</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Estimated<span class="pl-pds">"</span></span>)
<span class="pl-c1">legend</span>(); <span class="pl-c1">xlabel</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\$</span>u<span class="pl-cce">\$</span><span class="pl-pds">"</span></span>); <span class="pl-c1">ylabel</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\$</span>b(u)<span class="pl-cce">\$</span><span class="pl-pds">"</span></span>); <span class="pl-c1">grid</span>(<span class="pl-s"><span class="pl-pds">"</span>on<span class="pl-pds">"</span></span>)
<span class="pl-c1">subplot</span>(<span class="pl-c1">122</span>)
<span class="pl-c1">plot</span>(x, (<span class="pl-c1">@.</span> <span class="pl-c1">sin</span>(π<span class="pl-k">*</span>x)), label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Reference<span class="pl-pds">"</span></span>)
<span class="pl-c1">plot</span>(x[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>], <span class="pl-c1">run</span>(sess, u_est), <span class="pl-s"><span class="pl-pds">"</span>--<span class="pl-pds">"</span></span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Estimated<span class="pl-pds">"</span></span>)
<span class="pl-c1">plot</span>(x[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>][<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">5</span><span class="pl-k">:</span><span class="pl-c1">end</span>], <span class="pl-c1">run</span>(sess, u_est)[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">5</span><span class="pl-k">:</span><span class="pl-c1">end</span>], <span class="pl-s"><span class="pl-pds">"</span>x<span class="pl-pds">"</span></span>, markersize<span class="pl-k">=</span><span class="pl-c1">5.</span>, label<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Data<span class="pl-pds">"</span></span>)
<span class="pl-c1">legend</span>(); <span class="pl-c1">xlabel</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\$</span>x<span class="pl-cce">\$</span><span class="pl-pds">"</span></span>); <span class="pl-c1">ylabel</span>(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\$</span>u<span class="pl-cce">\$</span><span class="pl-pds">"</span></span>); <span class="pl-c1">grid</span>(<span class="pl-s"><span class="pl-pds">"</span>on<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">We show the reconstructed <code>b(u)</code> and the solution <code>u</code> computed from <code>b(u)</code>. We see that even though the neural network model fits the data very well, <code>b(u)</code> is not the same as the true one. This problem is ubiquitous in inverse modeling, where the unknown may not be unique.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/buu.png?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/buu.png?raw=true" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">See <a href="https://kailaix.github.io/ADCME.jl/dev/tutorial/" rel="nofollow">Applications</a> for more inverse modeling techniques and examples.</p>
<h3 dir="auto"><a id="user-content-under-the-hood-computational-graph" class="anchor" aria-hidden="true" href="#under-the-hood-computational-graph"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Under the Hood: Computational Graph</h3>
<p dir="auto">A static computational graph is automatic constructed for your implementation. The computational graph guides the runtime execution, saves intermediate results, and records data flows dependencies for automatic differentiation. Here we show the computational graph in the parameter inverse problem:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/code.png?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/code.png?raw=true" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">See a detailed <a href="https://kailaix.github.io/ADCME.jl/dev/tutorial/" rel="nofollow">tutorial</a>, or a full <a href="https://kailaix.github.io/ADCME.jl/dev" rel="nofollow">documentation</a>.</p>
<h1 dir="auto"><a id="user-content-featured-applications" class="anchor" aria-hidden="true" href="#featured-applications"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Featured Applications</h1>
<table>
<thead>
<tr>
<th><a href="https://kailaix.github.io/ADCME.jl/dev/apps_constitutive_law/" rel="nofollow">Constitutive Modeling</a></th>
<th><a href="https://kailaix.github.io/ADCME.jl/dev/apps_adseismic" rel="nofollow">Seismic Inversion</a></th>
<th><a href="https://kailaix.github.io/ADCME.jl/dev/apps_ad/" rel="nofollow">Coupled Two-Phase Flow and Time-lapse FWI</a></th>
<th><a href="https://kailaix.github.io/ADCME.jl/dev/apps_levy/" rel="nofollow">Calibrating Jump Diffusion</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/law.png?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/law.png?raw=true" alt="law" style="max-width: 100%;"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/earthquake.png?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/earthquake.png?raw=true" alt="law" style="max-width: 100%;"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/geo.png?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/geo.png?raw=true" alt="law" style="max-width: 100%;"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/algo.png?raw=true"><img src="https://github.com/ADCMEMarket/ADCMEImages/raw/master/ADCME/algo.png?raw=true" alt="law" style="max-width: 100%;"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">Here are some research papers using ADCME:</p>
<ol dir="auto">
<li>
<p dir="auto">Li, Dongzhuo, Kailai Xu, Jerry M. Harris, and Eric Darve. "Coupled Time‐Lapse Full‐Waveform Inversion for Subsurface Flow Problems Using Intrusive Automatic Differentiation." Water Resources Research 56, no. 8 (2020): e2019WR027032.</p>
</li>
<li>
<p dir="auto">Xu, Kailai, Alexandre M. Tartakovsky, Jeff Burghardt, and Eric Darve. "Inverse Modeling of Viscoelasticity Materials using Physics Constrained Learning." arXiv preprint arXiv:2005.04384 (2020).</p>
</li>
<li>
<p dir="auto">Zhu, Weiqiang, Kailai Xu, Eric Darve, and Gregory C. Beroza. "A General Approach to Seismic Inversion with Automatic Differentiation." arXiv preprint arXiv:2003.06027 (2020).</p>
</li>
<li>
<p dir="auto">Xu, K. and Darve, E., 2019. Adversarial Numerical Analysis for Inverse Problems. arXiv preprint arXiv:1910.06936.</p>
</li>
<li>
<p dir="auto">Xu, Kailai, Weiqiang Zhu, and Eric Darve. "Distributed Machine Learning for Computational Engineering using MPI." arXiv preprint arXiv:2011.01349 (2020).</p>
</li>
<li>
<p dir="auto">Xu, Kailai, and Eric Darve. "Physics constrained learning for data-driven inverse modeling from sparse observations." arXiv preprint arXiv:2002.10521 (2020).</p>
</li>
<li>
<p dir="auto">Xu, Kailai, Daniel Z. Huang, and Eric Darve. "Learning constitutive relations using symmetric positive definite neural networks." arXiv preprint arXiv:2004.00265 (2020).</p>
</li>
<li>
<p dir="auto">Xu, Kailai, and Eric Darve. "The neural network approach to inverse problems in differential equations." arXiv preprint arXiv:1901.07758 (2019).</p>
</li>
<li>
<p dir="auto">Huang, D.Z., Xu, K., Farhat, C. and Darve, E., 2019. Predictive modeling with learned constitutive laws from indirect observations. arXiv preprint arXiv:1905.12530.</p>
</li>
</ol>
<p dir="auto"><strong>Domain specific software based on ADCME</strong></p>
<p dir="auto"><a href="https://github.com/kailaix/ADSeismic.jl">ADSeismic.jl</a>: Inverse Problems in Earthquake Location/Source-Time Function, FWI, Rupture Process</p>
<p dir="auto"><a href="https://github.com/lidongzh/FwiFlow.jl">FwiFlow.jl</a>: Seismic Inversion, Two-phase Flow, Coupled seismic and flow equations</p>
<p dir="auto"><a href="https://github.com/kailaix/AdFem.jl/">AdFem.jl</a>: Inverse Modeling with the Finite Element Method</p>
<h1 dir="auto"><a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Citation</h1>
<p dir="auto">Please cite this paper if you use this library:</p>
<p dir="auto"><a href="https://arxiv.org/abs/2011.11955" rel="nofollow">https://arxiv.org/abs/2011.11955</a></p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="@misc{xu2020adcme,
title={ADCME: Learning Spatially-varying Physical Fields using Deep Neural Networks},
author={Kailai Xu and Eric Darve},
year={2020},
eprint={2011.11955},
archivePrefix={arXiv},
primaryClass={math.NA}
}"><pre class="notranslate"><code>@misc{xu2020adcme,
title={ADCME: Learning Spatially-varying Physical Fields using Deep Neural Networks},
author={Kailai Xu and Eric Darve},
year={2020},
eprint={2011.11955},
archivePrefix={arXiv},
primaryClass={math.NA}
}
</code></pre></div>
<h1 dir="auto"><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>LICENSE</h1>
<p dir="auto">ADCME.jl is released under MIT License. See <a href="https://github.com/kailaix/ADCME.jl/tree/master/LICENSE">License</a> for details.</p>
</article></div>