<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-ptools" class="anchor" aria-hidden="true" href="#ptools"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>PTools</h1>
<p dir="auto">A collection of utilities for parallel computation in Julia</p>
<p dir="auto">Currently the following are available.</p>
<ul dir="auto">
<li>
<p dir="auto"><code>WorkerSet</code> - The ability to logically pool a set of workers for specific tasks.</p>
</li>
<li>
<p dir="auto"><code>pfork</code> - Parallelism using the UNIX <code>fork</code> system call.</p>
</li>
<li>
<p dir="auto">ServerTasks - These are long running tasks that simply processes incoming requests in a loop. Useful in situations where
state needs to be maintained across function calls. State can be maintained and retrieved using the task_local_storage methods.</p>
</li>
<li>
<p dir="auto">SharedMemory - Useful in the event of parallel procesing on a single large multi-core machine. Avoids the overhead associated
with sending/recieving large data sets.</p>
</li>
<li>
<p dir="auto"><a href="QUEUEDTASKS.md">QueuedTasks</a> - Schedule tasks to be executed by remote worker processes. Set/change priorities on the task to control order of execution.</p>
</li>
</ul>
<h1 dir="auto"><a id="user-content-platforms" class="anchor" aria-hidden="true" href="#platforms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Platforms</h1>
<ul dir="auto">
<li>Tested on Ubuntu 13.04</li>
<li>Should work on OSX</li>
<li>SharedMemory will not work on Windows. ServerTasks should.</li>
<li>pfork is a UNIX only implementation</li>
</ul>
<h1 dir="auto"><a id="user-content-workerset" class="anchor" aria-hidden="true" href="#workerset"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>WorkerSet</h1>
<ul dir="auto">
<li>
<p dir="auto">A WorkerSet is just an array of process ids</p>
</li>
<li>
<p dir="auto">A WorkerSet is created using <code>WorkerSet(w::Array{Integer}, mode)</code> where <code>mode</code> is either of
WS_MODE_RR or WS_MODE_FF where</p>
</li>
<li>
<p dir="auto">WS_MODE_RR enables the workers to be used in a round-robin fashion</p>
</li>
<li>
<p dir="auto">WS_MODE_FF tracks which of the workers are busy and sends the request only to a free one.
It queues the requests if all the workers in the set are busy.</p>
</li>
<li>
<p dir="auto">The <code>remotecall*</code> functions have been extended to support WorkerSet</p>
</li>
</ul>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="remotecall(ws::WorkerSet, f, args...) 
remotecall_fetch(ws::WorkerSet, f, args...) 
remotecall_wait(ws::WorkerSet, f, args...) "><pre class="notranslate"><code>remotecall(ws::WorkerSet, f, args...) 
remotecall_fetch(ws::WorkerSet, f, args...) 
remotecall_wait(ws::WorkerSet, f, args...) 
</code></pre></div>
<ul dir="auto">
<li>The behaviour is the same, except that the functions are executed only on the processes belonging to the
WorkerSet and follow the model as specified by <code>mode</code>.</li>
</ul>
<h1 dir="auto"><a id="user-content-pfork" class="anchor" aria-hidden="true" href="#pfork"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>pfork</h1>
<ul dir="auto">
<li>
<p dir="auto">It uses the UNIX <code>fork()</code> system call to execute a function in parallel.</p>
</li>
<li>
<p dir="auto"><code>pfork(nforks::Integer, f::Function, args...)</code> forks <code>nforks</code> times and executes <code>f</code> in each child.</p>
</li>
<li>
<p dir="auto">The first parameter to <code>f</code> is the forked child index.</p>
</li>
<li>
<p dir="auto"><code>pfork</code> returns an array of size <code>nforks</code>, where the nth element is the value returned by the nth forked child.</p>
</li>
<li>
<p dir="auto">Passing huge amounts of data to the function in the child process is a non-issue since it is a fork.</p>
</li>
<li>
<p dir="auto">In the event the parent process has a shared memory segment, the children have full visibility
into the same and can modify the segment in place. They don't have to bother with returning huge
amounts of data either.</p>
</li>
<li>
<p dir="auto">Currently can only be executed when nprocs() == 1, i.e., this model is incompatible with the worker model.</p>
</li>
<li>
<p dir="auto">Unpredictable behavior if the function to be executed in the forked children calls yield() AND other I/O tasks
are concurrently active. Can be used only where f is fully compute bound.</p>
</li>
</ul>
<h1 dir="auto"><a id="user-content-usage-of-server-tasks" class="anchor" aria-hidden="true" href="#usage-of-server-tasks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage of Server Tasks</h1>
<p dir="auto">Typical usage pattern will be</p>
<ul dir="auto">
<li>
<p dir="auto"><code>start_stasks</code> - Start Server Tasks, optionally with shared memory mappings.</p>
</li>
<li>
<p dir="auto">Execute a series of functions in parallel on these tasks using multiple invocations of <code>pmap_stasks</code></p>
</li>
<li>
<p dir="auto">SomeFunction</p>
</li>
<li>
<p dir="auto">SomeOtherFunction</p>
</li>
<li>
<p dir="auto">SomeOtherFunction
.
.
.</p>
</li>
<li>
<p dir="auto"><code>stop_stasks</code> - Stop all Server Tasks and free shared memory if required.</p>
</li>
</ul>
<p dir="auto">The user specified functions in pmap_stasks can store and retrieve state information using the task_local_storage functions.</p>
<h1 dir="auto"><a id="user-content-example-for-shared-memory-and-server-tasks" class="anchor" aria-hidden="true" href="#example-for-shared-memory-and-server-tasks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example for shared memory and server tasks</h1>
<p dir="auto">The best way to understand what is available is by example:</p>
<ul dir="auto">
<li>specify shared memory configuration.</li>
</ul>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using PTools

shmcfg = [ShmCfg(:svar1, Int32, 64*1024), ShmCfg(:svar2, Uint8, (100,100))]"><pre class="notranslate"><code>using PTools

shmcfg = [ShmCfg(:svar1, Int32, 64*1024), ShmCfg(:svar2, Uint8, (100,100))]
</code></pre></div>
<ul dir="auto">
<li>
<p dir="auto">the above line requests for a 64K Int32 array bound to <code>svar1</code>, and a 100x100 Uint8 array bound to <code>svar2</code></p>
</li>
<li>
<p dir="auto">Start tasks.</p>
</li>
</ul>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="h = start_stasks(shmcfg)
ntasks = count_stasks(h)"><pre class="notranslate"><code>h = start_stasks(shmcfg)
ntasks = count_stasks(h)
</code></pre></div>
<ul dir="auto">
<li>
<p dir="auto">The tasks are started and symbols pointing to shared memory segments are added as task local storage. A handle is returned.</p>
</li>
<li>
<p dir="auto">The shared memory segments are also mapped in the current tasks local storage.</p>
</li>
<li>
<p dir="auto">NOTE: If nprocs() &gt; 1, then only the Worker Julia processes are used to start the Server Tasks, i.e., if nprocs() == 5, then ntasks above would be 4.</p>
</li>
<li>
<p dir="auto">Prepare arguments for our pmap call</p>
</li>
</ul>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="offset_list = [i for i in 1:ntasks]
ntasks_list = [ntasks for i in 1:ntasks]"><pre class="notranslate"><code>offset_list = [i for i in 1:ntasks]
ntasks_list = [ntasks for i in 1:ntasks]
</code></pre></div>
<ul dir="auto">
<li>Execute our function in parallel.</li>
</ul>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="resp = pmap_stasks(h, (offset, ntasks) -&gt; begin
                        # get local refernces to shared memory mapped arrays
                        svar1 = task_local_storage(:svar1)
                        svar2 = task_local_storage(:svar2)
                        
                        mypid = myid()
                        for x in offset:ntasks:64*1024
                            svar1[x] = mypid
                        end
                        
                        true
                        
                    end,
                    
                    offset_list, ntasks_list)"><pre class="notranslate"><code>resp = pmap_stasks(h, (offset, ntasks) -&gt; begin
                        # get local refernces to shared memory mapped arrays
                        svar1 = task_local_storage(:svar1)
                        svar2 = task_local_storage(:svar2)
                        
                        mypid = myid()
                        for x in offset:ntasks:64*1024
                            svar1[x] = mypid
                        end
                        
                        true
                        
                    end,
                    
                    offset_list, ntasks_list)
</code></pre></div>
<ul dir="auto">
<li>Access shared memory segments and view changes</li>
</ul>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="svar1 = task_local_storage(:svar1)
println(svar1)"><pre class="notranslate"><code>svar1 = task_local_storage(:svar1)
println(svar1)
</code></pre></div>
<p dir="auto">svar1 will the values as updated by the Server Tasks.</p>
<ul dir="auto">
<li>Finally stop the tasks</li>
</ul>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="stop_stasks(h, shmcfg)"><pre class="notranslate"><code>stop_stasks(h, shmcfg)
</code></pre></div>
<p dir="auto">This causes all tasks to be stopped and the shared memory unmapped.</p>
<h1 dir="auto"><a id="user-content-exported-functions-for-servertasks" class="anchor" aria-hidden="true" href="#exported-functions-for-servertasks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Exported functions for ServerTasks</h1>
<p dir="auto"><code>start_stasks(shmcfg=false, shmpfx=false)</code> where shmcfg is an optional parameter. It is either a ShmCfg(name::Symbol, t::Type, d::dims) or Array{ShmCfg, 1}.
Returns a handle to the set of ServerTasks.</p>
<p dir="auto"><code>pmap_stasks(h::STasks, f::Function, lsts...)</code> is similar to pmap, except that the first parameter is the handle returned by start_tasks.
NOTE: that the length of <code>lsts</code> and number of ServerTasks must be identical.</p>
<p dir="auto"><code>stop_stasks(h::STasks, shmcfg=false, shmpfx=false)</code> stops all tasks and also frees the shared memory</p>
<p dir="auto"><code>count_stasks(h::STasks)</code> returns the number of ServerTasks - can be used to partition the compute job.</p>
<p dir="auto">NOTE: shmpfx should be set to a distinct string in case you are sharing the server with other users or have multiple self concurrent jobs active.</p>
<h1 dir="auto"><a id="user-content-exported-functions-for-shared-memory-support" class="anchor" aria-hidden="true" href="#exported-functions-for-shared-memory-support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Exported functions for Shared Memory support</h1>
<p dir="auto"><code>pmap_shm_create(shmcfg, shmpfx="")</code> - creates and maps the shared memory segments to global symbols in each Julia process. shmcfg
can be ShmCfg(name::Symbol, t::Type, d::dims) or Array{ShmCfg, 1}</p>
<p dir="auto"><code>unlink_shm(shmcfg, shmpfx="")</code> - frees the shared memory</p>
<p dir="auto">NOTE: For a single run, it is important that shmpfx is passed with same value to all the methods.</p>
<p dir="auto">Under Linux, you can view the shared memory mappings under /dev/shm
In the event of abnormal program termination, where unlink_shm has not been called it is important
to manually delete all segments allocated by the program. The name of the segments will be
of the form <code>/dev/julia_&lt;shmpfx&gt;_&lt;symbol_name&gt;</code></p>
</article></div>