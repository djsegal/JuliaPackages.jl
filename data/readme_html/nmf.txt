<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h2 dir="auto"><a id="user-content-nmfjl" class="anchor" aria-hidden="true" href="#nmfjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>NMF.jl</h2>
<p dir="auto">A Julia package for non-negative matrix factorization (NMF).</p>
<p dir="auto"><a href="https://github.com/JuliaStats/NMF.jl/actions/workflows/ci.yml"><img src="https://github.com/JuliaStats/NMF.jl/actions/workflows/ci.yml/badge.svg?branch=master" alt="CI" style="max-width: 100%;"></a>
<a href="https://codecov.io/github/JuliaStats/NMF.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/b000c444805885c7961f9cd68f39bcfc7eb4a32c06b533113decda992fcbafef/68747470733a2f2f636f6465636f762e696f2f6769746875622f4a756c696153746174732f4e4d462e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="CodeCov" data-canonical-src="https://codecov.io/github/JuliaStats/NMF.jl/badge.svg?branch=master" style="max-width: 100%;"></a></p>
<hr>
<h2 dir="auto"><a id="user-content-development-status" class="anchor" aria-hidden="true" href="#development-status"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Development Status</h2>
<p dir="auto"><strong>Note:</strong> Nonnegative Matrix Factorization is an area of active research. New algorithms are proposed every year. Contributions are very welcomed.</p>
<h4 dir="auto"><a id="user-content-done" class="anchor" aria-hidden="true" href="#done"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Done</h4>
<ul dir="auto">
<li>Lee &amp; Seung's Multiplicative Update (for both MSE &amp; Divergence objectives)</li>
<li>(Naive) Projected Alternate Least Squared</li>
<li>ALS Projected Gradient Methods</li>
<li>Coordinate Descent Methods</li>
<li>Random Initialization</li>
<li>NNDSVD Initialization</li>
<li>Sparse NMF</li>
<li>Separable NMF</li>
</ul>
<h4 dir="auto"><a id="user-content-to-do" class="anchor" aria-hidden="true" href="#to-do"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>To do</h4>
<ul dir="auto">
<li>Probabilistic NMF</li>
</ul>
<h2 dir="auto"><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Overview</h2>
<p dir="auto"><em>Non-negative Matrix Factorization (NMF)</em> generally refers to the techniques for factorizing a non-negative matrix <code>X</code> into the product of two lower rank matrices <code>W</code> and <code>H</code>, such that <code>WH</code> optimally approximates <code>X</code> in some sense. Such techniques are widely used in text mining, image analysis, and recommendation systems.</p>
<p dir="auto">This package provides two sets of tools, respectively for <em>initilization</em> and <em>optimization</em>. A typical NMF procedure consists of two steps: (1) use an initilization function that initialize <code>W</code> and <code>H</code>; and (2) use an optimization algorithm to pursue the optimal solution.</p>
<p dir="auto">Most types and functions (except the high-level function <code>nnmf</code>) in this package are not exported. Users are encouraged to use them with the prefix <code>NMF.</code>. This way allows us to use shorter names within the package and makes the codes more explicit and clear on the user side.</p>
<h2 dir="auto"><a id="user-content-high-level-interface" class="anchor" aria-hidden="true" href="#high-level-interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>High-Level Interface</h2>
<p dir="auto">The package provides a high-level function <code>nnmf</code> that runs the entire procedure (initialization + optimization):</p>
<p dir="auto"><strong>nnmf</strong>(X, k, ...)</p>
<p dir="auto">This function factorizes the input matrix <code>X</code> into the product of two non-negative matrices <code>W</code> and <code>H</code>.</p>
<p dir="auto">In general, it returns a result instance of type <code>NMF.Result</code>, which is defined as</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="struct Result
    W::Matrix{Float64}    # W matrix
    H::Matrix{Float64}    # H matrix
    niters::Int           # number of elapsed iterations
    converged::Bool       # whether the optimization procedure converges
    objvalue::Float64     # objective value of the last step
end"><pre><span class="pl-k">struct</span> Result
    W<span class="pl-k">::</span><span class="pl-c1">Matrix{Float64}</span>    <span class="pl-c"><span class="pl-c">#</span> W matrix</span>
    H<span class="pl-k">::</span><span class="pl-c1">Matrix{Float64}</span>    <span class="pl-c"><span class="pl-c">#</span> H matrix</span>
    niters<span class="pl-k">::</span><span class="pl-c1">Int</span>           <span class="pl-c"><span class="pl-c">#</span> number of elapsed iterations</span>
    converged<span class="pl-k">::</span><span class="pl-c1">Bool</span>       <span class="pl-c"><span class="pl-c">#</span> whether the optimization procedure converges</span>
    objvalue<span class="pl-k">::</span><span class="pl-c1">Float64</span>     <span class="pl-c"><span class="pl-c">#</span> objective value of the last step</span>
<span class="pl-k">end</span></pre></div>
<p dir="auto">The function supports the following keyword arguments:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>init</code>:  A symbol that indicates the initialization method (default = <code>:nndsvdar</code>).</p>
<p dir="auto">This argument accepts the following values:</p>
<ul dir="auto">
<li><code>random</code>:  matrices filled with uniformly random values</li>
<li><code>nndsvd</code>:  standard version of NNDSVD</li>
<li><code>nndsvda</code>:  NNDSVDa variant</li>
<li><code>nndsvdar</code>:  NNDSVDar variant</li>
<li><code>spa</code>: Successive Projection Algorithm</li>
<li><code>custom</code>: use custom matrices <code>W0</code> and <code>H0</code></li>
</ul>
<p dir="auto">With the <code>nndsvd</code> variants, you can optionally supply the SVD result via <code>initdata</code>, e.g., <code>initdata=svd(X)</code>. If not supplied, the factorization is computed using a randomized svd (<code>rsvd</code> from <a href="https://github.com/JuliaLinearAlgebra/RandomizedLinAlg.jl">RandomizedLinAlg</a>).</p>
</li>
<li>
<p dir="auto"><code>alg</code>:  A symbol that indicates the factorization algorithm (default = <code>:greedycd</code>).</p>
<p dir="auto">This argument accepts the following values:</p>
<ul dir="auto">
<li><code>multmse</code>:  Multiplicative update (using MSE as objective)</li>
<li><code>multdiv</code>:  Multiplicative update (using divergence as objective)</li>
<li><code>projals</code>:  (Naive) Projected Alternate Least Square</li>
<li><code>alspgrad</code>:  Alternate Least Square using Projected Gradient Descent</li>
<li><code>cd</code>: Coordinate Descent solver that uses Fast Hierarchical Alternating Least Squares (implemetation similar to scikit-learn)</li>
<li><code>greedycd</code>: Greedy Coordinate Descent</li>
<li><code>spa</code>: Successive Projection Algorithm</li>
</ul>
</li>
<li>
<p dir="auto"><code>maxiter</code>: Maximum number of iterations (default = <code>100</code>).</p>
</li>
<li>
<p dir="auto"><code>tol</code>: tolerance of changes upon convergence (default = <code>1.0e-6</code>).</p>
</li>
<li>
<p dir="auto"><code>replicates</code>: Number of times to perform factorization (default = <code>1</code>).</p>
</li>
<li>
<p dir="auto"><code>W0</code>: Option for custom initialization (default = <code>nothing</code>).</p>
</li>
<li>
<p dir="auto"><code>H0</code>: Option for custom initialization (default = <code>nothing</code>).</p>
<p dir="auto"><strong>Note:</strong> <code>W0</code> and <code>H0</code> may be overwritten. If one needs to avoid it, please pass in copies themselves.</p>
</li>
<li>
<p dir="auto"><code>update_H</code>: Option for specifying whether to update H (default = <code>true</code>).</p>
</li>
<li>
<p dir="auto"><code>verbose</code>: whether to show procedural information (default = <code>false</code>).</p>
</li>
</ul>
<h2 dir="auto"><a id="user-content-initialization" class="anchor" aria-hidden="true" href="#initialization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Initialization</h2>
<ul dir="auto">
<li>
<p dir="auto"><strong>NMF.randinit</strong>(X, k[; zeroh=false, normalize=false])</p>
<p dir="auto">Initialize <code>W</code> and <code>H</code> given the input matrix <code>X</code> and the rank <code>k</code>. This function returns a pair <code>(W, H)</code>.</p>
<p dir="auto">Suppose the size of <code>X</code> is <code>(p, n)</code>, then the size of <code>W</code> and <code>H</code> are respectively <code>(p, k)</code> and <code>(k, n)</code>.</p>
<p dir="auto">Usage:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="W, H = NMF.randinit(X, 3)"><pre>W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">randinit</span>(X, <span class="pl-c1">3</span>)</pre></div>
<p dir="auto">For some algorithms (<em>e.g.</em> ALS), only <code>W</code> needs to be initialized. For such cases, one may set the keyword argument <code>zeroh</code>to be <code>true</code>, then in the output <code>H</code> will be simply a zero matrix of size <code>(k, n)</code>.</p>
<p dir="auto">Another keyword argument is <code>normalize</code>. If <code>normalize</code> is set to <code>true</code>, columns of <code>W</code> will be normalized such that each column sum to one.</p>
</li>
<li>
<p dir="auto"><strong>NMF.nndsvd</strong>(X, k[; zeroh=false, variant=:std])</p>
<p dir="auto">Use the <em>Non-Negative Double Singular Value Decomposition (NNDSVD)</em> algorithm to initialize <code>W</code> and <code>H</code>.</p>
<p dir="auto">Reference: C. Boutsidis, and E. Gallopoulos. SVD based initialization: A head start for nonnegative matrix factorization. Pattern Recognition, 2007.</p>
<p dir="auto">Usage:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="W, H = NMF.nndsvd(X, k)"><pre>W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">nndsvd</span>(X, k)</pre></div>
<p dir="auto">This function has two keyword arguments:</p>
<ul dir="auto">
<li><code>zeroh</code>: have <code>H</code> initialized when it is set to <code>true</code>, or set <code>H</code> to all zeros when it is set to <code>false</code>.</li>
<li><code>variant</code>: the variant of the algorithm. Default is <code>std</code>, meaning to use the standard version, which would generate a rather sparse <code>W</code>. Other values are <code>a</code> and <code>ar</code>, respectively corresponding to the variants: <em>NNDSVDa</em> and <em>NNDSVDar</em>. Particularly, <code>ar</code> is recommended for dense NMF.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>NMF.spa</strong>(X, k)</p>
<p dir="auto">Use the <em>Successive Projection Algorithm (SPA)</em> to initialize <code>W</code> and <code>H</code>.</p>
<p dir="auto">Reference: N. Gillis and S. A. Vavasis, Fast and robust recursive algorithms for separable nonnegative matrix factorization, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 36, no. 4, pp. 698-714, 2013.</p>
<p dir="auto">Usage:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="W, H = NMF.spa(X, k)"><pre>W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">spa</span>(X, k)</pre></div>
</li>
</ul>
<h2 dir="auto"><a id="user-content-factorization-algorithms" class="anchor" aria-hidden="true" href="#factorization-algorithms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Factorization Algorithms</h2>
<p dir="auto">This package provides multiple factorization algorithms. Each algorithm corresponds to a type. One can create an algorithm <em>instance</em> by choosing a type and specifying the options, and run the algorithm using <code>NMF.solve!</code>:</p>
<h4 dir="auto"><a id="user-content-the-nmfsolve-function" class="anchor" aria-hidden="true" href="#the-nmfsolve-function"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>The NMF.solve! Function</h4>
<p dir="auto"><strong>NMF.solve!</strong>(alg, X, W, H)</p>
<p dir="auto">Use the algorithm <code>alg</code> to factorize <code>X</code> into <code>W</code> and <code>H</code>.</p>
<p dir="auto">Here, <code>W</code> and <code>H</code> must be pre-allocated matrices (respectively of size <code>(p, k)</code> and <code>(k, n)</code>). <code>W</code> and <code>H</code> must be appropriately initialized before this function is invoked. For some algorithms, both <code>W</code> and <code>H</code> must be initialized (<em>e.g.</em> multiplicative updating); while for others, only <code>W</code> needs to be initialized (<em>e.g.</em> ALS).</p>
<p dir="auto">The matrices <code>W</code> and <code>H</code> are updated in place.</p>
<h4 dir="auto"><a id="user-content-algorithms" class="anchor" aria-hidden="true" href="#algorithms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Algorithms</h4>
<ul dir="auto">
<li>
<p dir="auto"><strong>Multiplicative Updating</strong></p>
<p dir="auto">Reference: Daniel D. Lee and H. Sebastian Seung. Algorithms for Non-negative Matrix Factorization. Advances in NIPS, 2001.</p>
<p dir="auto">This algorithm has two different kind of objectives: minimizing mean-squared-error (<code>:mse</code>) and minimizing divergence (<code>:div</code>). Both <code>W</code> and <code>H</code> need to be initialized.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="MultUpdate(obj::Symbol=:mse,        # objective, either :mse or :div
           maxiter::Integer=100,    # maximum number of iterations
           verbose::Bool=false,     # whether to show procedural information
           tol::Real=1.0e-6,        # tolerance of changes on W and H upon convergence
           update_H::Bool=true,     # whether to update H
           lambda_w::Real=0.0,      # L1 regularization coefficient for W
           lambda_h::Real=0.0)      # L1 regularization coefficient for H"><pre><span class="pl-c1">MultUpdate</span>(obj<span class="pl-k">::</span><span class="pl-c1">Symbol</span><span class="pl-k">=</span><span class="pl-c1">:mse</span>,        <span class="pl-c"><span class="pl-c">#</span> objective, either :mse or :div</span>
           maxiter<span class="pl-k">::</span><span class="pl-c1">Integer</span><span class="pl-k">=</span><span class="pl-c1">100</span>,    <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations</span>
           verbose<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">false</span>,     <span class="pl-c"><span class="pl-c">#</span> whether to show procedural information</span>
           tol<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,        <span class="pl-c"><span class="pl-c">#</span> tolerance of changes on W and H upon convergence</span>
           update_H<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">true</span>,     <span class="pl-c"><span class="pl-c">#</span> whether to update H</span>
           lambda_w<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">0.0</span>,      <span class="pl-c"><span class="pl-c">#</span> L1 regularization coefficient for W</span>
           lambda_h<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">0.0</span>)      <span class="pl-c"><span class="pl-c">#</span> L1 regularization coefficient for H</span></pre></div>
<p dir="auto"><strong>Note:</strong> the values above are default values for the keyword arguments. One can override part (or all) of them.</p>
</li>
<li>
<p dir="auto"><strong>(Naive) Projected Alternate Least Square</strong></p>
<p dir="auto">This algorithm alternately updates <code>W</code> and <code>H</code> while holding the other fixed. Each update step solves <code>W</code> or <code>H</code> without enforcing the non-negativity constrait, and forces all negative entries to zeros afterwards. Only <code>W</code> needs to be initialized.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="ProjectedALS(maxiter::Integer=100,    # maximum number of iterations
             verbose::Bool=false,     # whether to show procedural information
             tol::Real=1.0e-6,        # tolerance of changes on W and H upon convergence
             update_H::Bool=true,     # whether to update H
             lambda_w::Real=1.0e-6,   # L2 regularization coefficient for W
             lambda_h::Real=1.0e-6)   # L2 regularization coefficient for H"><pre><span class="pl-c1">ProjectedALS</span>(maxiter<span class="pl-k">::</span><span class="pl-c1">Integer</span><span class="pl-k">=</span><span class="pl-c1">100</span>,    <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations</span>
             verbose<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">false</span>,     <span class="pl-c"><span class="pl-c">#</span> whether to show procedural information</span>
             tol<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,        <span class="pl-c"><span class="pl-c">#</span> tolerance of changes on W and H upon convergence</span>
             update_H<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">true</span>,     <span class="pl-c"><span class="pl-c">#</span> whether to update H</span>
             lambda_w<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,   <span class="pl-c"><span class="pl-c">#</span> L2 regularization coefficient for W</span>
             lambda_h<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>)   <span class="pl-c"><span class="pl-c">#</span> L2 regularization coefficient for H</span></pre></div>
</li>
<li>
<p dir="auto"><strong>Alternate Least Square Using Projected Gradient Descent</strong></p>
<p dir="auto">Reference: Chih-Jen Lin. Projected Gradient Methods for Non-negative Matrix Factorization. Neural Computing, 19 (2007).</p>
<p dir="auto">This algorithm adopts the alternate least square strategy. A efficient projected gradient descent method is used to solve each sub-problem. Both <code>W</code> and <code>H</code> need to be initialized.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="ALSPGrad(maxiter::Integer=100,      # maximum number of iterations (in main procedure)
         maxsubiter::Integer=200,   # maximum number of iterations in solving each sub-problem
         tol::Real=1.0e-6,          # tolerance of changes on W and H upon convergence
         tolg::Real=1.0e-4,         # tolerable gradient norm in sub-problem (first-order optimality)
         update_H::Bool=true,       # whether to update H
         verbose::Bool=false)       # whether to show procedural information"><pre><span class="pl-c1">ALSPGrad</span>(maxiter<span class="pl-k">::</span><span class="pl-c1">Integer</span><span class="pl-k">=</span><span class="pl-c1">100</span>,      <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations (in main procedure)</span>
         maxsubiter<span class="pl-k">::</span><span class="pl-c1">Integer</span><span class="pl-k">=</span><span class="pl-c1">200</span>,   <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations in solving each sub-problem</span>
         tol<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,          <span class="pl-c"><span class="pl-c">#</span> tolerance of changes on W and H upon convergence</span>
         tolg<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-4</span>,         <span class="pl-c"><span class="pl-c">#</span> tolerable gradient norm in sub-problem (first-order optimality)</span>
         update_H<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">true</span>,       <span class="pl-c"><span class="pl-c">#</span> whether to update H</span>
         verbose<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">false</span>)       <span class="pl-c"><span class="pl-c">#</span> whether to show procedural information</span></pre></div>
</li>
<li>
<p dir="auto"><strong>Coordinate Descent solver with Fast Hierarchical Alternating Least Squares</strong></p>
<p dir="auto">Reference: Cichocki, Andrzej, and P. H. A. N. Anh-Huy. Fast local algorithms for large scale nonnegative matrix and tensor factorizations. IEICE transactions on fundamentals of electronics, communications and computer sciences 92.3: 708-721 (2009).</p>
<p dir="auto">Sequential constrained minimization on a set of squared Euclidean distances over W and H matrices. Uses l_1 and l_2 penalties to enforce sparsity.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="CoordinateDescent(maxiter::Integer=100,      # maximum number of iterations (in main procedure)
                  verbose::Bool=false,       # whether to show procedural information
                  tol::Real=1.0e-6,          # tolerance of changes on W and H upon convergence
                  update_H::Bool=true,       # whether to update H
                  α::Real=0.0,               # constant that multiplies the regularization terms
                  regularization=:both,      # select whether the regularization affects the components (H), the transformation (W), both or none of them (:components, :transformation, :both, :none)
                  l₁ratio::Real=0.0,         # l1 / l2 regularization mixing parameter (in [0; 1])
                  shuffle::Bool=false)       # if true, randomize the order of coordinates in the CD solver"><pre><span class="pl-c1">CoordinateDescent</span>(maxiter<span class="pl-k">::</span><span class="pl-c1">Integer</span><span class="pl-k">=</span><span class="pl-c1">100</span>,      <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations (in main procedure)</span>
                  verbose<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">false</span>,       <span class="pl-c"><span class="pl-c">#</span> whether to show procedural information</span>
                  tol<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,          <span class="pl-c"><span class="pl-c">#</span> tolerance of changes on W and H upon convergence</span>
                  update_H<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">true</span>,       <span class="pl-c"><span class="pl-c">#</span> whether to update H</span>
                  α<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">0.0</span>,               <span class="pl-c"><span class="pl-c">#</span> constant that multiplies the regularization terms</span>
                  regularization<span class="pl-k">=</span><span class="pl-c1">:both</span>,      <span class="pl-c"><span class="pl-c">#</span> select whether the regularization affects the components (H), the transformation (W), both or none of them (:components, :transformation, :both, :none)</span>
                  l₁ratio<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">0.0</span>,         <span class="pl-c"><span class="pl-c">#</span> l1 / l2 regularization mixing parameter (in [0; 1])</span>
                  shuffle<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">false</span>)       <span class="pl-c"><span class="pl-c">#</span> if true, randomize the order of coordinates in the CD solver</span></pre></div>
</li>
<li>
<p dir="auto"><strong>Greedy Coordinate Descent</strong></p>
<p dir="auto">Reference: Cho-Jui Hsieh and Inderjit S. Dhillon. Fast coordinate descent methods with variable selection for non-negative matrix factorization. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1064–1072 (2011).</p>
<p dir="auto">This algorithm is a fast coordinate descent method with variable selection.
Both <code>W</code> and <code>H</code> need to be initialized.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="GreedyCD(maxiter::Integer=100,  # maximum number of iterations (in main procedure)
         verbose::Bool=false,   # whether to show procedural information
         tol::Real=1.0e-6,      # tolerance of changes on W and H upon convergence
         update_H::Bool=true,   # whether to update H
         lambda_w::Real=0.0,    # L1 regularization coefficient for W
         lambda_h::Real=0.0)    # L1 regularization coefficient for H"><pre><span class="pl-c1">GreedyCD</span>(maxiter<span class="pl-k">::</span><span class="pl-c1">Integer</span><span class="pl-k">=</span><span class="pl-c1">100</span>,  <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations (in main procedure)</span>
         verbose<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">false</span>,   <span class="pl-c"><span class="pl-c">#</span> whether to show procedural information</span>
         tol<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,      <span class="pl-c"><span class="pl-c">#</span> tolerance of changes on W and H upon convergence</span>
         update_H<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">true</span>,   <span class="pl-c"><span class="pl-c">#</span> whether to update H</span>
         lambda_w<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">0.0</span>,    <span class="pl-c"><span class="pl-c">#</span> L1 regularization coefficient for W</span>
         lambda_h<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">0.0</span>)    <span class="pl-c"><span class="pl-c">#</span> L1 regularization coefficient for H</span></pre></div>
</li>
<li>
<p dir="auto"><strong>Successive Projection Algorithm for Separable NMF</strong></p>
<p dir="auto">Reference: N. Gillis and S. A. Vavasis, "Fast and robust recursive algorithms for separable nonnegative matrix factorization," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 36, no. 4, pp. 698-714, 2013.</p>
<p dir="auto">A separable matrix X can be written as <code>X = WH = W[I V]P</code>, where <code>W</code> has rank <code>k</code>, <code>I</code> is the identity matrix, the sum of the entries of each column of <code>V</code> is at most one, and <code>P</code> is a permutation matrix to arange the columns of <code>[I V]</code> randomly. Separable NMF aims to decompose a separable matrix <code>X</code> into two nonnegative factor matrices <code>W</code> and <code>H</code>, so that <code>WH</code> is equal to <code>X</code>. This algorithm is used for separable NMF. Both <code>W</code> and <code>H</code> need to be initialized by <code>init=:spa</code>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="SPA(obj::Symbol=:mse)   # objective :mse or :div"><pre><span class="pl-c1">SPA</span>(obj<span class="pl-k">::</span><span class="pl-c1">Symbol</span><span class="pl-k">=</span><span class="pl-c1">:mse</span>)   <span class="pl-c"><span class="pl-c">#</span> objective :mse or :div</span></pre></div>
</li>
</ul>
<h2 dir="auto"><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h2>
<p dir="auto">Here are examples that demonstrate how to use this package to factorize a non-negative dense matrix.</p>
<h4 dir="auto"><a id="user-content-use-high-level-function-nnmf" class="anchor" aria-hidden="true" href="#use-high-level-function-nnmf"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Use High-level Function: nnmf</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="... # prepare input matrix X

r = nnmf(X, k; alg=:multmse, maxiter=30, tol=1.0e-4)

W = r.W
H = r.H"><pre><span class="pl-k">...</span> <span class="pl-c"><span class="pl-c">#</span> prepare input matrix X</span>

r <span class="pl-k">=</span> <span class="pl-c1">nnmf</span>(X, k; alg<span class="pl-k">=</span><span class="pl-c1">:multmse</span>, maxiter<span class="pl-k">=</span><span class="pl-c1">30</span>, tol<span class="pl-k">=</span><span class="pl-c1">1.0e-4</span>)

W <span class="pl-k">=</span> r<span class="pl-k">.</span>W
H <span class="pl-k">=</span> r<span class="pl-k">.</span>H</pre></div>
<h4 dir="auto"><a id="user-content-use-multiplicative-update" class="anchor" aria-hidden="true" href="#use-multiplicative-update"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Use Multiplicative Update</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import NMF

 # initialize
W, H = NMF.randinit(X, 5)

 # optimize
NMF.solve!(NMF.MultUpdate{Float64}(obj=:mse,maxiter=100), X, W, H)"><pre><span class="pl-k">import</span> NMF

 <span class="pl-c"><span class="pl-c">#</span> initialize</span>
W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">randinit</span>(X, <span class="pl-c1">5</span>)

 <span class="pl-c"><span class="pl-c">#</span> optimize</span>
NMF<span class="pl-k">.</span><span class="pl-c1">solve!</span>(NMF<span class="pl-k">.</span><span class="pl-c1">MultUpdate</span><span class="pl-c1">{Float64}</span>(obj<span class="pl-k">=</span><span class="pl-c1">:mse</span>,maxiter<span class="pl-k">=</span><span class="pl-c1">100</span>), X, W, H)</pre></div>
<h4 dir="auto"><a id="user-content-use-naive-als" class="anchor" aria-hidden="true" href="#use-naive-als"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Use Naive ALS</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import NMF

 # initialize
W, H = NMF.randinit(X, 5)

 # optimize
NMF.solve!(NMF.ProjectedALS{Float64}(maxiter=50), X, W, H)"><pre><span class="pl-k">import</span> NMF

 <span class="pl-c"><span class="pl-c">#</span> initialize</span>
W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">randinit</span>(X, <span class="pl-c1">5</span>)

 <span class="pl-c"><span class="pl-c">#</span> optimize</span>
NMF<span class="pl-k">.</span><span class="pl-c1">solve!</span>(NMF<span class="pl-k">.</span><span class="pl-c1">ProjectedALS</span><span class="pl-c1">{Float64}</span>(maxiter<span class="pl-k">=</span><span class="pl-c1">50</span>), X, W, H)</pre></div>
<h4 dir="auto"><a id="user-content-use-als-with-projected-gradient-descent" class="anchor" aria-hidden="true" href="#use-als-with-projected-gradient-descent"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Use ALS with Projected Gradient Descent</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import NMF

 # initialize
W, H = NMF.nndsvd(X, 5, variant=:ar)

 # optimize
NMF.solve!(NMF.ALSPGrad{Float64}(maxiter=50, tolg=1.0e-6), X, W, H)"><pre><span class="pl-k">import</span> NMF

 <span class="pl-c"><span class="pl-c">#</span> initialize</span>
W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">nndsvd</span>(X, <span class="pl-c1">5</span>, variant<span class="pl-k">=</span><span class="pl-c1">:ar</span>)

 <span class="pl-c"><span class="pl-c">#</span> optimize</span>
NMF<span class="pl-k">.</span><span class="pl-c1">solve!</span>(NMF<span class="pl-k">.</span><span class="pl-c1">ALSPGrad</span><span class="pl-c1">{Float64}</span>(maxiter<span class="pl-k">=</span><span class="pl-c1">50</span>, tolg<span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>), X, W, H)</pre></div>
<h4 dir="auto"><a id="user-content-use-coordinate-descent" class="anchor" aria-hidden="true" href="#use-coordinate-descent"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Use Coordinate Descent</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import NMF

 # initialize
W, H = NMF.nndsvd(X, 5, variant=:ar)

 # optimize
NMF.solve!(NMF.CoordinateDescent{Float64}(maxiter=50, α=0.5, l₁ratio=0.5), X, W, H)"><pre><span class="pl-k">import</span> NMF

 <span class="pl-c"><span class="pl-c">#</span> initialize</span>
W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">nndsvd</span>(X, <span class="pl-c1">5</span>, variant<span class="pl-k">=</span><span class="pl-c1">:ar</span>)

 <span class="pl-c"><span class="pl-c">#</span> optimize</span>
NMF<span class="pl-k">.</span><span class="pl-c1">solve!</span>(NMF<span class="pl-k">.</span><span class="pl-c1">CoordinateDescent</span><span class="pl-c1">{Float64}</span>(maxiter<span class="pl-k">=</span><span class="pl-c1">50</span>, α<span class="pl-k">=</span><span class="pl-c1">0.5</span>, l₁ratio<span class="pl-k">=</span><span class="pl-c1">0.5</span>), X, W, H)</pre></div>
<h4 dir="auto"><a id="user-content-use-greedy-coordinate-descent" class="anchor" aria-hidden="true" href="#use-greedy-coordinate-descent"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Use Greedy Coordinate Descent</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import NMF

 # initialize
W, H = NMF.nndsvd(X, 5, variant=:ar)

 # optimize
NMF.solve!(NMF.GreedyCD{Float64}(maxiter=50), X, W, H)"><pre><span class="pl-k">import</span> NMF

 <span class="pl-c"><span class="pl-c">#</span> initialize</span>
W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">nndsvd</span>(X, <span class="pl-c1">5</span>, variant<span class="pl-k">=</span><span class="pl-c1">:ar</span>)

 <span class="pl-c"><span class="pl-c">#</span> optimize</span>
NMF<span class="pl-k">.</span><span class="pl-c1">solve!</span>(NMF<span class="pl-k">.</span><span class="pl-c1">GreedyCD</span><span class="pl-c1">{Float64}</span>(maxiter<span class="pl-k">=</span><span class="pl-c1">50</span>), X, W, H)</pre></div>
<h4 dir="auto"><a id="user-content-use-successive-projection-algorithm-for-separable-nmf" class="anchor" aria-hidden="true" href="#use-successive-projection-algorithm-for-separable-nmf"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Use Successive Projection Algorithm for Separable NMF</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import NMF

 # initialize
W, H = NMF.spa(X, 5)

 # optimize
NMF.solve!(NMF.SPA{Float64}(obj=:mse), X, W, H)"><pre><span class="pl-k">import</span> NMF

 <span class="pl-c"><span class="pl-c">#</span> initialize</span>
W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">spa</span>(X, <span class="pl-c1">5</span>)

 <span class="pl-c"><span class="pl-c">#</span> optimize</span>
NMF<span class="pl-k">.</span><span class="pl-c1">solve!</span>(NMF<span class="pl-k">.</span><span class="pl-c1">SPA</span><span class="pl-c1">{Float64}</span>(obj<span class="pl-k">=</span><span class="pl-c1">:mse</span>), X, W, H)</pre></div>
</article></div>