<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h2><a id="user-content-nmfjl" class="anchor" aria-hidden="true" href="#nmfjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>NMF.jl</h2>
<p>A Julia package for non-negative matrix factorization (NMF).</p>
<p><a href="https://travis-ci.org/JuliaStats/NMF.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/01a901289a061190f2920b9a73d00c9048915520/68747470733a2f2f7472617669732d63692e6f72672f4a756c696153746174732f4e4d462e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/JuliaStats/NMF.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/JuliaStats/NMF.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/f15da6b07e04e5bc5aba5b02e664a691a9c00835/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4a756c696153746174732f4e4d462e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/JuliaStats/NMF.jl/badge.svg?branch=master" style="max-width:100%;"></a></p>
<hr>
<h2><a id="user-content-development-status" class="anchor" aria-hidden="true" href="#development-status"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Development Status</h2>
<p><strong>Note:</strong> Nonnegative Matrix Factorization is an area of active research. New algorithms are proposed every year. Contributions are very welcomed.</p>
<h4><a id="user-content-done" class="anchor" aria-hidden="true" href="#done"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Done</h4>
<ul>
<li>Lee &amp; Seung's Multiplicative Update (for both MSE &amp; Divergence objectives)</li>
<li>(Naive) Projected Alternate Least Squared</li>
<li>ALS Projected Gradient Methods</li>
<li>Random Initialization</li>
<li>NNDSVD Initialization</li>
<li>Sparse NMF</li>
</ul>
<h4><a id="user-content-to-do" class="anchor" aria-hidden="true" href="#to-do"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>To do</h4>
<ul>
<li>Probabilistic NMF</li>
</ul>
<h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Overview</h2>
<p><em>Non-negative Matrix Factorization (NMF)</em> generally refers to the techniques for factorizing a non-negative matrix <code>X</code> into the product of two lower rank matrices <code>W</code> and <code>H</code>, such that <code>WH</code> optimally approximates <code>X</code> in some sense. Such techniques are widely used in text mining, image analysis, and recommendation systems.</p>
<p>This package provides two sets of tools, respectively for <em>initilization</em> and <em>optimization</em>. A typical NMF procedure consists of two steps: (1) use an initilization function that initialize <code>W</code> and <code>H</code>; and (2) use an optimization algorithm to pursue the optimal solution.</p>
<p>Most types and functions (except the high-level function <code>nnmf</code>) in this package are not exported. Users are encouraged to use them with the prefix <code>NMF.</code>. This way allows us to use shorter names within the package and makes the codes more explicit and clear on the user side.</p>
<h2><a id="user-content-high-level-interface" class="anchor" aria-hidden="true" href="#high-level-interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>High-Level Interface</h2>
<p>The package provides a high-level function <code>nnmf</code> that runs the entire procedure (initialization + optimization):</p>
<p><strong>nnmf</strong>(X, k, ...)</p>
<p>This function factorizes the input matrix <code>X</code> into the product of two non-negative matrices <code>W</code> and <code>H</code>.</p>
<p>In general, it returns a result instance of type <code>NMF.Result</code>, which is defined as</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">struct</span> Result
    W<span class="pl-k">::</span><span class="pl-c1">Matrix{Float64}</span>    <span class="pl-c"><span class="pl-c">#</span> W matrix</span>
    H<span class="pl-k">::</span><span class="pl-c1">Matrix{Float64}</span>    <span class="pl-c"><span class="pl-c">#</span> H matrix</span>
    niters<span class="pl-k">::</span><span class="pl-c1">Int</span>           <span class="pl-c"><span class="pl-c">#</span> number of elapsed iterations</span>
    converged<span class="pl-k">::</span><span class="pl-c1">Bool</span>       <span class="pl-c"><span class="pl-c">#</span> whether the optimization procedure converges</span>
    objvalue<span class="pl-k">::</span><span class="pl-c1">Float64</span>     <span class="pl-c"><span class="pl-c">#</span> objective value of the last step</span>
<span class="pl-k">end</span></pre></div>
<p>The function supports the following keyword arguments:</p>
<ul>
<li>
<p><code>init</code>:  A symbol that indicates the initialization method (default = <code>:nndsvdar</code>).</p>
<p>This argument accepts the following values:</p>
<ul>
<li><code>random</code>:  matrices filled with uniformly random values</li>
<li><code>nndsvd</code>:  standard version of NNDSVD</li>
<li><code>nndsvda</code>:  NNDSVDa variant</li>
<li><code>nndsvdar</code>:  NNDSVDar variant</li>
</ul>
</li>
<li>
<p><code>alg</code>:  A symbol that indicates the factorization algorithm (default = <code>:alspgrad</code>).</p>
<p>This argument accepts the following values:</p>
<ul>
<li><code>multmse</code>:  Multiplicative update (using MSE as objective)</li>
<li><code>multdiv</code>:  Multiplicative update (using divergence as objective)</li>
<li><code>projals</code>:  (Naive) Projected Alternate Least Square</li>
<li><code>alspgrad</code>:  Alternate Least Square using Projected Gradient Descent</li>
<li><code>cd</code>: Coordinate Descent solver that uses Fast Hierarchical Alternating Least Squares (implemetation similar to scikit-learn)</li>
</ul>
</li>
<li>
<p><code>maxiter</code>: Maximum number of iterations (default = <code>100</code>).</p>
</li>
<li>
<p><code>tol</code>: tolerance of changes upon convergence (default = <code>1.0e-6</code>).</p>
</li>
<li>
<p><code>verbose</code>: whether to show procedural information (default = <code>false</code>).</p>
</li>
</ul>
<h2><a id="user-content-initialization" class="anchor" aria-hidden="true" href="#initialization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Initialization</h2>
<ul>
<li>
<p><strong>NMF.randinit</strong>(X, k[; zeroh=false, normalize=false])</p>
<p>Initialize <code>W</code> and <code>H</code> given the input matrix <code>X</code> and the rank <code>k</code>. This function returns a pair <code>(W, H)</code>.</p>
<p>Suppose the size of <code>X</code> is <code>(p, n)</code>, then the size of <code>W</code> and <code>H</code> are respectively <code>(p, k)</code> and <code>(k, n)</code>.</p>
<p>Usage:</p>
<div class="highlight highlight-source-julia"><pre>W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">randinit</span>(X, <span class="pl-c1">3</span>)</pre></div>
<p>For some algorithms (<em>e.g.</em> ALS), only <code>W</code> needs to be initialized. For such cases, one may set the keyword argument <code>zeroh</code>to be <code>true</code>, then in the output <code>H</code> will be simply a zero matrix of size <code>(k, n)</code>.</p>
<p>Another keyword argument is <code>normalize</code>. If <code>normalize</code> is set to <code>true</code>, columns of <code>W</code> will be normalized such that each column sum to one.</p>
</li>
<li>
<p><strong>NMF.nndsvd</strong>(X, k[; zeroh=false, variant=:std])</p>
<p>Use the <em>Non-Negative Double Singular Value Decomposition (NNDSVD)</em> algorithm to initialize <code>W</code> and <code>H</code>.</p>
<p>Reference: C. Boutsidis, and E. Gallopoulos. SVD based initialization: A head start for nonnegative matrix factorization. Pattern Recognition, 2007.</p>
<p>Usage:</p>
<div class="highlight highlight-source-julia"><pre>W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">nndsvd</span>(X, k)</pre></div>
<p>This function has two keyword arguments:</p>
<ul>
<li><code>zeroh</code>: have <code>H</code> initialized when it is set to <code>true</code>, or set <code>H</code> to all zeros when it is set to <code>false</code>.</li>
<li><code>variant</code>: the variant of the algorithm. Default is <code>std</code>, meaning to use the standard version, which would generate a rather sparse <code>W</code>. Other values are <code>a</code> and <code>ar</code>, respectively corresponding to the variants: <em>NNDSVDa</em> and <em>NNDSVDar</em>. Particularly, <code>ar</code> is recommended for dense NMF.</li>
</ul>
</li>
</ul>
<h2><a id="user-content-factorization-algorithms" class="anchor" aria-hidden="true" href="#factorization-algorithms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Factorization Algorithms</h2>
<p>This package provides multiple factorization algorithms. Each algorithm corresponds to a type. One can create an algorithm <em>instance</em> by choosing a type and specifying the options, and run the algorithm using <code>NMF.solve!</code>:</p>
<h4><a id="user-content-the-nmfsolve-function" class="anchor" aria-hidden="true" href="#the-nmfsolve-function"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>The NMF.solve! Function</h4>
<p><strong>NMF.solve!</strong>(alg, X, W, H)</p>
<p>Use the algorithm <code>alg</code> to factorize <code>X</code> into <code>W</code> and <code>H</code>.</p>
<p>Here, <code>W</code> and <code>H</code> must be pre-allocated matrices (respectively of size <code>(p, k)</code> and <code>(k, n)</code>). <code>W</code> and <code>H</code> must be appropriately initialized before this function is invoked. For some algorithms, both <code>W</code> and <code>H</code> must be initialized (<em>e.g.</em> multiplicative updating); while for others, only <code>W</code> needs to be initialized (<em>e.g.</em> ALS).</p>
<p>The matrices <code>W</code> and <code>H</code> are updated in place.</p>
<h4><a id="user-content-algorithms" class="anchor" aria-hidden="true" href="#algorithms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Algorithms</h4>
<ul>
<li>
<p><strong>Multiplicative Updating</strong></p>
<p>Reference: Daniel D. Lee and H. Sebastian Seung. Algorithms for Non-negative Matrix Factorization. Advances in NIPS, 2001.</p>
<p>This algorithm has two different kind of objectives: minimizing mean-squared-error (<code>:mse</code>) and minimizing divergence (<code>:div</code>). Both <code>W</code> and <code>H</code> need to be initialized.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">MultUpdate</span>(obj<span class="pl-k">=</span><span class="pl-c1">:mse</span>,        <span class="pl-c"><span class="pl-c">#</span> objective, either :mse or :div</span>
           maxiter<span class="pl-k">=</span><span class="pl-c1">100</span>,     <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations</span>
           verbose<span class="pl-k">=</span><span class="pl-c1">false</span>,   <span class="pl-c"><span class="pl-c">#</span> whether to show procedural information</span>
           tol<span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,      <span class="pl-c"><span class="pl-c">#</span> tolerance of changes on W and H upon convergence</span>
           lambda<span class="pl-k">=</span><span class="pl-c1">1.0e-9</span>)   <span class="pl-c"><span class="pl-c">#</span> regularization coefficients (added to the denominator)</span></pre></div>
<p><strong>Note:</strong> the values above are default values for the keyword arguments. One can override part (or all) of them.</p>
</li>
<li>
<p><strong>(Naive) Projected Alternate Least Square</strong></p>
<p>This algorithm alternately updates <code>W</code> and <code>H</code> while holding the other fixed. Each update step solves <code>W</code> or <code>H</code> without enforcing the non-negativity constrait, and forces all negative entries to zeros afterwards. Only <code>W</code> needs to be initialized.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">ProjectedALS</span>(maxiter<span class="pl-k">::</span><span class="pl-c1">Integer</span><span class="pl-k">=</span><span class="pl-c1">100</span>,    <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations</span>
             verbose<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">false</span>,     <span class="pl-c"><span class="pl-c">#</span> whether to show procedural information</span>
             tol<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,        <span class="pl-c"><span class="pl-c">#</span> tolerance of changes on W and H upon convergence</span>
             lambda_w<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,   <span class="pl-c"><span class="pl-c">#</span> L2 regularization coefficient for W</span>
             lambda_h<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>)   <span class="pl-c"><span class="pl-c">#</span> L2 regularization coefficient for H</span></pre></div>
</li>
<li>
<p><strong>Alternate Least Square Using Projected Gradient Descent</strong></p>
<p>Reference: Chih-Jen Lin. Projected Gradient Methods for Non-negative Matrix Factorization. Neural Computing, 19 (2007).</p>
<p>This algorithm adopts the alternate least square strategy. A efficient projected gradient descent method is used to solve each sub-problem. Both <code>W</code> and <code>H</code> need to be initialized.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">ALSPGrad</span>(maxiter<span class="pl-k">::</span><span class="pl-c1">Integer</span><span class="pl-k">=</span><span class="pl-c1">100</span>,      <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations (in main procedure)</span>
         maxsubiter<span class="pl-k">::</span><span class="pl-c1">Integer</span><span class="pl-k">=</span><span class="pl-c1">200</span>,   <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations in solving each sub-problem</span>
         tol<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,          <span class="pl-c"><span class="pl-c">#</span> tolerance of changes on W and H upon convergence</span>
         tolg<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-4</span>,         <span class="pl-c"><span class="pl-c">#</span> tolerable gradient norm in sub-problem (first-order optimality)</span>
         verbose<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">false</span>)       <span class="pl-c"><span class="pl-c">#</span> whether to show procedural information</span></pre></div>
</li>
<li>
<p><strong>Coordinate Descent solver with Fast Hierarchical Alternating Least Squares</strong></p>
<p>Reference: Cichocki, Andrzej, and P. H. A. N. Anh-Huy. Fast local algorithms for large scale nonnegative matrix and tensor factorizations. IEICE transactions on fundamentals of electronics, communications and computer sciences 92.3: 708-721 (2009).</p>
<p>Sequential constrained minimization on a set of squared Euclidean distances over W and H matrices. Uses l_1 and l_2 penalties to enforce sparsity.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">CoordinateDescent</span>(maxiter<span class="pl-k">::</span><span class="pl-c1">Integer</span><span class="pl-k">=</span><span class="pl-c1">100</span>,      <span class="pl-c"><span class="pl-c">#</span> maximum number of iterations (in main procedure)</span>
                  verbose<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">false</span>,       <span class="pl-c"><span class="pl-c">#</span> whether to show procedural information</span>
                  tol<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>,          <span class="pl-c"><span class="pl-c">#</span> tolerance of changes on W and H upon convergence</span>
                  α<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">0.0</span>,               <span class="pl-c"><span class="pl-c">#</span> constant that multiplies the regularization terms</span>
                  regularization<span class="pl-k">=</span><span class="pl-c1">:both</span>,      <span class="pl-c"><span class="pl-c">#</span> select whether the regularization affects the components (H), the transformation (W), both or none of them (:components, :transformation, :both, :none)</span>
                  l₁ratio<span class="pl-k">::</span><span class="pl-c1">Real</span><span class="pl-k">=</span><span class="pl-c1">0.0</span>,         <span class="pl-c"><span class="pl-c">#</span> l1 / l2 regularization mixing parameter (in [0; 1])</span>
                  shuffle<span class="pl-k">::</span><span class="pl-c1">Bool</span><span class="pl-k">=</span><span class="pl-c1">false</span>)       <span class="pl-c"><span class="pl-c">#</span> if true, randomize the order of coordinates in the CD solver</span></pre></div>
</li>
</ul>
<h2><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples</h2>
<p>Here are examples that demonstrate how to use this package to factorize a non-negative dense matrix.</p>
<h4><a id="user-content-use-high-level-function-nnmf" class="anchor" aria-hidden="true" href="#use-high-level-function-nnmf"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Use High-level Function: nnmf</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">...</span> <span class="pl-c"><span class="pl-c">#</span> prepare input matrix X</span>

r <span class="pl-k">=</span> <span class="pl-c1">nnmf</span>(X, k; alg<span class="pl-k">=</span><span class="pl-c1">:multmse</span>, maxiter<span class="pl-k">=</span><span class="pl-c1">30</span>, tol<span class="pl-k">=</span><span class="pl-c1">1.0e-4</span>)

W <span class="pl-k">=</span> r<span class="pl-k">.</span>W
H <span class="pl-k">=</span> r<span class="pl-k">.</span>H</pre></div>
<h4><a id="user-content-use-multiplicative-update" class="anchor" aria-hidden="true" href="#use-multiplicative-update"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Use Multiplicative Update</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> NMF

 <span class="pl-c"><span class="pl-c">#</span> initialize</span>
W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">randinit</span>(X, <span class="pl-c1">5</span>)

 <span class="pl-c"><span class="pl-c">#</span> optimize </span>
NMF<span class="pl-k">.</span><span class="pl-c1">solve!</span>(NMF<span class="pl-k">.</span><span class="pl-c1">MultUpdate</span><span class="pl-c1">{Float64}</span>(obj<span class="pl-k">=</span><span class="pl-c1">:mse</span>,maxiter<span class="pl-k">=</span><span class="pl-c1">100</span>), X, W, H)</pre></div>
<h4><a id="user-content-use-naive-als" class="anchor" aria-hidden="true" href="#use-naive-als"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Use Naive ALS</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> NMF

 <span class="pl-c"><span class="pl-c">#</span> initialize</span>
W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">randinit</span>(X, <span class="pl-c1">5</span>)

 <span class="pl-c"><span class="pl-c">#</span> optimize </span>
NMF<span class="pl-k">.</span><span class="pl-c1">solve!</span>(NMF<span class="pl-k">.</span><span class="pl-c1">ProjectedALS</span><span class="pl-c1">{Float64}</span>(maxiter<span class="pl-k">=</span><span class="pl-c1">50</span>), X, W, H)</pre></div>
<h4><a id="user-content-use-als-with-projected-gradient-descent" class="anchor" aria-hidden="true" href="#use-als-with-projected-gradient-descent"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Use ALS with Projected Gradient Descent</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> NMF

 <span class="pl-c"><span class="pl-c">#</span> initialize</span>
W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">nndsvdar</span>(X, <span class="pl-c1">5</span>)

 <span class="pl-c"><span class="pl-c">#</span> optimize </span>
NMF<span class="pl-k">.</span><span class="pl-c1">solve!</span>(NMF<span class="pl-k">.</span><span class="pl-c1">ALSPGrad</span><span class="pl-c1">{Float64}</span>(maxiter<span class="pl-k">=</span><span class="pl-c1">50</span>, tolg<span class="pl-k">=</span><span class="pl-c1">1.0e-6</span>), X, W, H)</pre></div>
<h4><a id="user-content-use-coordinate-descent" class="anchor" aria-hidden="true" href="#use-coordinate-descent"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Use Coordinate Descent</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> NMF

 <span class="pl-c"><span class="pl-c">#</span> initialize</span>
W, H <span class="pl-k">=</span> NMF<span class="pl-k">.</span><span class="pl-c1">nndsvdar</span>(X, <span class="pl-c1">5</span>)

 <span class="pl-c"><span class="pl-c">#</span> optimize </span>
NMF<span class="pl-k">.</span><span class="pl-c1">solve!</span>(NMF<span class="pl-k">.</span><span class="pl-c1">CoordinateDescent</span><span class="pl-c1">{Float64}</span>(maxiter<span class="pl-k">=</span><span class="pl-c1">50</span>, α<span class="pl-k">=</span><span class="pl-c1">0.5</span>, l₁ratio<span class="pl-k">=</span><span class="pl-c1">0.5</span>), X, W, H)</pre></div>
</article></div>