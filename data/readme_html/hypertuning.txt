<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/693e45ffa683c37fb7ed051ee719417f4578ce6f3bd39c7e6d77addeaf700c88/68747470733a2f2f6a6d656a6961382e6769746875622e696f2f487970657254756e696e672e6a6c2f6465762f6173736574732f6c6f676f2e737667"><img align="right" src="https://camo.githubusercontent.com/693e45ffa683c37fb7ed051ee719417f4578ce6f3bd39c7e6d77addeaf700c88/68747470733a2f2f6a6d656a6961382e6769746875622e696f2f487970657254756e696e672e6a6c2f6465762f6173736574732f6c6f676f2e737667" width="300" alt="HyperTuning.jl logo" data-canonical-src="https://jmejia8.github.io/HyperTuning.jl/dev/assets/logo.svg" style="max-width: 100%;"></a></p>
<h1 dir="auto"><a id="user-content-hypertuningjl" class="anchor" aria-hidden="true" href="#hypertuningjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>HyperTuning.jl</h1>
<p dir="auto"><a href="#installation">Installation</a> /
<a href="#quick-start">Quick Start</a> /
<a href="#features">Features</a> /
<a href="#examples">Examples</a> /
<a href="https://jmejia8.github.io/HyperTuning.jl/dev/" rel="nofollow">Documentation</a></p>
<p dir="auto">Automated hyperparameter tuning in Julia.
HyperTuning aims to be intuitive, capable of handling multiple problem instances, and providing easy parallelization.</p>
<p dir="auto"><a href="https://github.com/JuliaTesting/Aqua.jl"><img src="https://raw.githubusercontent.com/JuliaTesting/Aqua.jl/master/badge.svg" alt="Aqua QA" style="max-width: 100%;"></a>
<a href="https://jmejia8.github.io/HyperTuning.jl/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Doc" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a></p>
<hr>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">This package can be installed on Julia v1.7 and above. Use one of the following options.</p>
<p dir="auto">Via Pkg module:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; import Pkg; Pkg.add(&quot;HyperTuning&quot;)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">import</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>HyperTuning<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">Via the Julia package manager, type <code>]</code> and</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; add HyperTuning"><pre class="notranslate"><code>pkg&gt; add HyperTuning
</code></pre></div>
<h2 dir="auto"><a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick Start</h2>
<p dir="auto">Let's begin <code>using HyperTuning</code> to optimize <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="72fa9def2792d94b21b952ca89fd7ad8">$f(x,y)=(1-x)^2+(y-1)^2$</math-renderer>.
After that, the hyperparameters and budget are given in a new scenario.
Once the scenario and the objective function are defined, the optimization process begins.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using HyperTuning

julia&gt; function objective(trial)
           @unpack x, y = trial
           (1 - x)^2 + (y - 1)^2
       end
objective (generic function with 1 method)

julia&gt; scenario = Scenario(x = (-10.0..10.0),
                           y = (-10.0..10.0),
                           max_trials = 200);

julia&gt; HyperTuning.optimize(objective, scenario)
Scenario: evaluated 200 trials.
          parameters: x, y
   space cardinality: Huge!
           instances: 1
          batch_size: 8
             sampler: BCAPSampler{Random.Xoshiro}
              pruner: NeverPrune
          max_trials: 200
           max_evals: 200
         stop_reason: HyperTuning.BudgetExceeded(&quot;Due to max_trials&quot;)
          best_trial: 
┌───────────┬────────────┐
│     Trial │      Value │
│       198 │            │
├───────────┼────────────┤
│         x │   0.996266 │
│         y │    1.00086 │
│    Pruned │      false │
│   Success │      false │
│ Objective │ 1.46779e-5 │
└───────────┴────────────┘

julia&gt; @unpack x, y = scenario"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> HyperTuning

julia<span class="pl-k">&gt;</span> <span class="pl-k">function</span> <span class="pl-en">objective</span>(trial)
           <span class="pl-c1">@unpack</span> x, y <span class="pl-k">=</span> trial
           (<span class="pl-c1">1</span> <span class="pl-k">-</span> x)<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> (y <span class="pl-k">-</span> <span class="pl-c1">1</span>)<span class="pl-k">^</span><span class="pl-c1">2</span>
       <span class="pl-k">end</span>
objective (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> scenario <span class="pl-k">=</span> <span class="pl-c1">Scenario</span>(x <span class="pl-k">=</span> (<span class="pl-k">-</span><span class="pl-c1">10.0</span><span class="pl-k">..</span><span class="pl-c1">10.0</span>),
                           y <span class="pl-k">=</span> (<span class="pl-k">-</span><span class="pl-c1">10.0</span><span class="pl-k">..</span><span class="pl-c1">10.0</span>),
                           max_trials <span class="pl-k">=</span> <span class="pl-c1">200</span>);

julia<span class="pl-k">&gt;</span> HyperTuning<span class="pl-k">.</span><span class="pl-c1">optimize</span>(objective, scenario)
Scenario<span class="pl-k">:</span> evaluated <span class="pl-c1">200</span> trials.
          parameters<span class="pl-k">:</span> x, y
   space cardinality<span class="pl-k">:</span> Huge!
           instances<span class="pl-k">:</span> <span class="pl-c1">1</span>
          batch_size<span class="pl-k">:</span> <span class="pl-c1">8</span>
             sampler<span class="pl-k">:</span> BCAPSampler{Random<span class="pl-k">.</span>Xoshiro}
              pruner<span class="pl-k">:</span> NeverPrune
          max_trials<span class="pl-k">:</span> <span class="pl-c1">200</span>
           max_evals<span class="pl-k">:</span> <span class="pl-c1">200</span>
         stop_reason<span class="pl-k">:</span> HyperTuning<span class="pl-k">.</span><span class="pl-c1">BudgetExceeded</span>(<span class="pl-s"><span class="pl-pds">"</span>Due to max_trials<span class="pl-pds">"</span></span>)
          best_trial<span class="pl-k">:</span> 
┌───────────┬────────────┐
│     Trial │      Value │
│       <span class="pl-c1">198</span> │            │
├───────────┼────────────┤
│         x │   <span class="pl-c1">0.996266</span> │
│         y │    <span class="pl-c1">1.00086</span> │
│    Pruned │      <span class="pl-c1">false</span> │
│   Success │      <span class="pl-c1">false</span> │
│ Objective │ <span class="pl-c1">1.46779e-5</span> │
└───────────┴────────────┘

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@unpack</span> x, y <span class="pl-k">=</span> scenario</pre></div>
<p dir="auto">See <a href="https://github.com/jmejia8/hypertuning-examples">here</a> for more examples.</p>
<h2 dir="auto">
<a id="user-content-features" class="anchor" aria-hidden="true" href="#features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Features</h2>
<ul dir="auto">
<li>
<strong>Intuitive usage</strong>: Define easily the objective function, the hyperparameters, start optimization, and nothing more.</li>
<li>
<strong>Muti-instance</strong>: Find the best hyperparameters, not for a single application but multiple problem instances, datasets, etc.</li>
<li>
<strong>Parallelization</strong>: Don't worry, simply start <code>julia -t8</code> if you have 8 available threads or <code>julia -p4</code> if you want 4 distributed processes, and the HyperTuning does the rest.</li>
<li>
<strong>Parameters</strong>: This package is compatible with integer, float, boolean, and categorical parameters; however permutations and vectors of numerical values are compatible.</li>
<li>
<strong>Samplers</strong>: <code>BCAPSampler</code> for a heuristic search, <code>GridSampler</code> for brute force, and <code>RandomSampler</code> for an unbiased search.</li>
<li>
<strong>Pruner</strong>: <code>NeverPrune</code> to never prune a trial and <code>MedianPruner</code> for early-stopping the algorithm being configured.</li>
</ul>
<h2 dir="auto">
<a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h2>
<p dir="auto">Examples for different Julia packages.</p>
<ul dir="auto">
<li>Optimization
<ul dir="auto">
<li>
<a href="https://github.com/jmejia8/hypertuning-examples/blob/main/Metaheuristics/metaheuristics.jl">Metaheuristics</a>: The best parameters for a metaheuristic.</li>
<li>
<a href="https://github.com/jmejia8/hypertuning-examples/blob/main/Optim/optim.jl">Optim</a>: The best parameter for an exact optimizer.</li>
</ul>
</li>
<li>Machine Learning
<ul dir="auto">
<li>
<a href="https://github.com/jmejia8/hypertuning-examples/blob/main/MLJ/mlj.jl">MLJ</a>: The best hyperparameters for a Machine Learning method.</li>
<li>
<a href="https://github.com/jmejia8/hypertuning-examples/blob/main/Flux/flux.jl">Flux</a>: The best hyperparameters for an artificial neural network method.</li>
</ul>
</li>
</ul>
<p dir="auto">Further examples can be found at <a href="https://github.com/jmejia8/hypertuning-examples">https://github.com/jmejia8/hypertuning-examples</a></p>
<h2 dir="auto">
<a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Citation</h2>
<p dir="auto">Please, cite us if you use this package in your research work.</p>
<blockquote>
<p dir="auto">Mejía-de-Dios, JA., Mezura-Montes, E. &amp; Quiroz-Castellanos, M. Automated parameter tuning as a bilevel optimization problem solved by a surrogate-assisted population-based approach. Appl Intell 51, 5978–6000 (2021). <a href="https://doi.org/10.1007/s10489-020-02151-y" rel="nofollow">https://doi.org/10.1007/s10489-020-02151-y</a></p>
</blockquote>
<div class="highlight highlight-text-bibtex notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="@article{MejadeDios2021,
  author = {Jes{\'{u}}s-Adolfo Mej{\'{\i}}a-de-Dios and Efr{\'{e}}n Mezura-Montes and Marcela Quiroz-Castellanos},
  title = {Automated parameter tuning as a bilevel optimization problem solved by a surrogate-assisted population-based approach},
  journal = {Applied Intelligence}
  doi = {10.1007/s10489-020-02151-y},
  url = {https://doi.org/10.1007/s10489-020-02151-y},
  year = {2021},
  month = jan,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {51},
  number = {8},
  pages = {5978--6000},
}"><pre><span class="pl-k">@article</span>{<span class="pl-en">MejadeDios2021</span>,
  <span class="pl-s">author</span> = <span class="pl-s"><span class="pl-pds">{</span>Jes{\'{u}}s-Adolfo Mej{\'{\i}}a-de-Dios and Efr{\'{e}}n Mezura-Montes and Marcela Quiroz-Castellanos<span class="pl-pds">}</span></span>,
  <span class="pl-s">title</span> = <span class="pl-s"><span class="pl-pds">{</span>Automated parameter tuning as a bilevel optimization problem solved by a surrogate-assisted population-based approach<span class="pl-pds">}</span></span>,
  <span class="pl-s">journal</span> = <span class="pl-s"><span class="pl-pds">{</span>Applied Intelligence<span class="pl-pds">}</span></span>
  doi = <span class="pl-s"><span class="pl-pds">{</span>10.1007/s10489-020-02151-y<span class="pl-pds">}</span></span>,
  <span class="pl-s">url</span> = <span class="pl-s"><span class="pl-pds">{</span>https://doi.org/10.1007/s10489-020-02151-y<span class="pl-pds">}</span></span>,
  <span class="pl-s">year</span> = <span class="pl-s"><span class="pl-pds">{</span>2021<span class="pl-pds">}</span></span>,
  <span class="pl-s">month</span> = jan,
  <span class="pl-s">publisher</span> = <span class="pl-s"><span class="pl-pds">{</span>Springer Science and Business Media {LLC}<span class="pl-pds">}</span></span>,
  <span class="pl-s">volume</span> = <span class="pl-s"><span class="pl-pds">{</span>51<span class="pl-pds">}</span></span>,
  <span class="pl-s">number</span> = <span class="pl-s"><span class="pl-pds">{</span>8<span class="pl-pds">}</span></span>,
  <span class="pl-s">pages</span> = <span class="pl-s"><span class="pl-pds">{</span>5978--6000<span class="pl-pds">}</span></span>,
}</pre></div>
<h2 dir="auto">
<a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributing</h2>
<p dir="auto">To start contributing to the codebase, consider opening an issue describing the possible changes.
PRs fixing typos or grammar issues are always welcome.</p>
</article></div>