<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-knetlayers" class="anchor" aria-hidden="true" href="#knetlayers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>KnetLayers</h1>
<p dir="auto"><a href="https://ekinakyurek.github.io/KnetLayers.jl/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg" style="max-width: 100%;"></a>
<a href="https://gitlab.com/JuliaGPU/KnetLayers/pipelines" rel="nofollow"><img src="https://camo.githubusercontent.com/151a41771112825beb64ea124ca850af80162b4ca6d606416a08eafff7674e80/68747470733a2f2f6769746c61622e636f6d2f4a756c69614750552f4b6e65744c61796572732f6261646765732f6d61737465722f706970656c696e652e737667" alt="" data-canonical-src="https://gitlab.com/JuliaGPU/KnetLayers/badges/master/pipeline.svg" style="max-width: 100%;"></a>
<a href="https://travis-ci.org/ekinakyurek/KnetLayers.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/1df57a321c5e89557f2687c429acbb9715700e665003a1c5646bd998df8b44ba/68747470733a2f2f7472617669732d63692e6f72672f656b696e616b797572656b2f4b6e65744c61796572732e6a6c2e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://travis-ci.org/ekinakyurek/KnetLayers.jl.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/ekinakyurek/KnetLayers.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/745f0b6438a73da138d0a6d0f031f76c23a94e028dd7823912a3c6eb82908501/68747470733a2f2f636f6465636f762e696f2f67682f656b696e616b797572656b2f4b6e65744c61796572732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/ekinakyurek/KnetLayers.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">KnetLayers provides usefull deep learning layers for <a href="https://github.com/denizyuret/Knet.jl">Knet</a>, fostering your model development. You are able to use Knet and <a href="https://github.com/denizyuret/AutoGrad.jl">AutoGrad</a> functionalities without adding them to current workspace.</p>
<h2 dir="auto"><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Overview</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="model = Chain(Dense(input=768, output=128, activation=Sigm()),
	      Dense(input=128, output=10, activation=nothing))

loss(model, x, y) = nll(model(x), y)"><pre>model <span class="pl-k">=</span> <span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(input<span class="pl-k">=</span><span class="pl-c1">768</span>, output<span class="pl-k">=</span><span class="pl-c1">128</span>, activation<span class="pl-k">=</span><span class="pl-c1">Sigm</span>()),
	      <span class="pl-c1">Dense</span>(input<span class="pl-k">=</span><span class="pl-c1">128</span>, output<span class="pl-k">=</span><span class="pl-c1">10</span>, activation<span class="pl-k">=</span><span class="pl-c1">nothing</span>))

<span class="pl-en">loss</span>(model, x, y) <span class="pl-k">=</span> <span class="pl-c1">nll</span>(<span class="pl-c1">model</span>(x), y)</pre></div>
<h2 dir="auto"><a id="user-content-getting-started-train-an-mnist-model" class="anchor" aria-hidden="true" href="#getting-started-train-an-mnist-model"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Getting Started: Train an MNIST model</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Knet, KnetLayers
import Knet: Data
#Data
include(Knet.dir(&quot;data&quot;,&quot;mnist.jl&quot;))
dtrn,dtst = mnistdata(xsize=(784,:)); # dtrn and dtst = [ (x1,y1), (x2,y2), ... ] where xi,yi are

#Model
HIDDEN_SIZES = [100,50]
(m::MLP)(x,y) = nll(m(x),y)
(m::MLP)(d::Data) = mean(m(x,y) for (x,y) in d)
model = MLP(784,HIDDEN_SIZES...,10)

#Train
EPOCH=10
progress!(sgd(model,repeat(dtrn,EPOCH)))

#Test
@show 100accuracy(model, dtst)"><pre><span class="pl-k">using</span> Knet, KnetLayers
<span class="pl-k">import</span> Knet<span class="pl-k">:</span> Data
<span class="pl-c"><span class="pl-c">#</span>Data</span>
<span class="pl-c1">include</span>(Knet<span class="pl-k">.</span><span class="pl-c1">dir</span>(<span class="pl-s"><span class="pl-pds">"</span>data<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>mnist.jl<span class="pl-pds">"</span></span>))
dtrn,dtst <span class="pl-k">=</span> <span class="pl-c1">mnistdata</span>(xsize<span class="pl-k">=</span>(<span class="pl-c1">784</span>,:)); <span class="pl-c"><span class="pl-c">#</span> dtrn and dtst = [ (x1,y1), (x2,y2), ... ] where xi,yi are</span>

<span class="pl-c"><span class="pl-c">#</span>Model</span>
HIDDEN_SIZES <span class="pl-k">=</span> [<span class="pl-c1">100</span>,<span class="pl-c1">50</span>]
(m<span class="pl-k">::</span><span class="pl-c1">MLP</span>)(x,y) <span class="pl-k">=</span> <span class="pl-c1">nll</span>(<span class="pl-c1">m</span>(x),y)
(m<span class="pl-k">::</span><span class="pl-c1">MLP</span>)(d<span class="pl-k">::</span><span class="pl-c1">Data</span>) <span class="pl-k">=</span> <span class="pl-c1">mean</span>(<span class="pl-c1">m</span>(x,y) <span class="pl-k">for</span> (x,y) <span class="pl-k">in</span> d)
model <span class="pl-k">=</span> <span class="pl-c1">MLP</span>(<span class="pl-c1">784</span>,HIDDEN_SIZES<span class="pl-k">...</span>,<span class="pl-c1">10</span>)

<span class="pl-c"><span class="pl-c">#</span>Train</span>
EPOCH<span class="pl-k">=</span><span class="pl-c1">10</span>
<span class="pl-c1">progress!</span>(<span class="pl-c1">sgd</span>(model,<span class="pl-c1">repeat</span>(dtrn,EPOCH)))

<span class="pl-c"><span class="pl-c">#</span>Test</span>
<span class="pl-c1">@show</span> <span class="pl-c1">100</span><span class="pl-c1">accuracy</span>(model, dtst)</pre></div>
<h2 dir="auto"><a id="user-content-example-models" class="anchor" aria-hidden="true" href="#example-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example Models</h2>
<ol dir="auto">
<li>
<p dir="auto"><a href="./examples/mnist.jl">MNIST-MLP</a></p>
</li>
<li>
<p dir="auto"><a href="./examples/mnist-cnn.jl">MNIST-CNN</a></p>
</li>
<li>
<p dir="auto"><a href="./examples/gan-mlp.ipynb">GAN-MLP</a></p>
</li>
<li>
<p dir="auto"><a href="./examples/resnet.jl">ResNet: Residual Networks for Image Recognition</a></p>
</li>
<li>
<p dir="auto"><a href="./examples/s2smodel.jl">S2S: Sequence to Sequence Reccurent Model</a></p>
</li>
<li>
<p dir="auto"><a href="https://github.com/ekinakyurek/Morse.jl">Morse.jl: Morphological Analyzer+Lemmatizer</a></p>
</li>
<li>
<p dir="auto"><a href="https://github.com/ekinakyurek/Mac-Network">MAC Network: Memory-Attention-Composition Network for Visual Question Answering</a></p>
</li>
</ol>
<h2 dir="auto"><a id="user-content-exported-layers-refence" class="anchor" aria-hidden="true" href="#exported-layers-refence"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://ekinakyurek.github.io/KnetLayers.jl/latest/reference.html#Function-Index-1" rel="nofollow">Exported Layers Refence</a></h2>
<h2 dir="auto"><a id="user-content-example-layers-and-usage" class="anchor" aria-hidden="true" href="#example-layers-and-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example Layers and Usage</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using KnetLayers

#Instantiate an MLP model with random parameters
mlp = MLP(100,50,20; activation=Sigm()) # input size=100, hidden=50 and output=20

#Do a prediction with the mlp model
prediction = mlp(randn(Float32,100,1))

#Instantiate a convolutional layer with random parameters
cnn = Conv(height=3, width=3, inout=3=&gt;10, padding=1, stride=1) # A conv layer

#Filter your input with the convolutional layer
output = cnn(randn(Float32,224,224,3,1))

#Instantiate an LSTM model
lstm = LSTM(input=100, hidden=100, embed=50)

#You can use integers to represent one-hot vectors.
#Each integer corresponds to vocabulary index of corresponding element in your data.

#For example a pass over 5-Length sequence
rnnoutput = lstm([3,2,1,4,5];hy=true,cy=true)

#After you get the output, you may acces to hidden states and
#intermediate hidden states produced by the lstm model
rnnoutput.y
rnnoutput.hidden
rnnoutput.memory

#You can also use normal array inputs for low-level control
#One iteration of LSTM with a random input
rnnoutput = lstm(randn(100,1);hy=true,cy=true)

#Pass over a random 10-length sequence:
rnnoutput = lstm(randn(100,1,10);hy=true,cy=true)

#Pass over a mini-batch data which includes unequal length sequences
rnnoutput = lstm([[1,2,3,4],[5,6]];sorted=true,hy=true,cy=true)

#To see and modify rnn params in a structured view
lstm.gatesview"><pre><span class="pl-k">using</span> KnetLayers

<span class="pl-c"><span class="pl-c">#</span>Instantiate an MLP model with random parameters</span>
mlp <span class="pl-k">=</span> <span class="pl-c1">MLP</span>(<span class="pl-c1">100</span>,<span class="pl-c1">50</span>,<span class="pl-c1">20</span>; activation<span class="pl-k">=</span><span class="pl-c1">Sigm</span>()) <span class="pl-c"><span class="pl-c">#</span> input size=100, hidden=50 and output=20</span>

<span class="pl-c"><span class="pl-c">#</span>Do a prediction with the mlp model</span>
prediction <span class="pl-k">=</span> <span class="pl-c1">mlp</span>(<span class="pl-c1">randn</span>(Float32,<span class="pl-c1">100</span>,<span class="pl-c1">1</span>))

<span class="pl-c"><span class="pl-c">#</span>Instantiate a convolutional layer with random parameters</span>
cnn <span class="pl-k">=</span> <span class="pl-c1">Conv</span>(height<span class="pl-k">=</span><span class="pl-c1">3</span>, width<span class="pl-k">=</span><span class="pl-c1">3</span>, inout<span class="pl-k">=</span><span class="pl-c1">3</span><span class="pl-k">=&gt;</span><span class="pl-c1">10</span>, padding<span class="pl-k">=</span><span class="pl-c1">1</span>, stride<span class="pl-k">=</span><span class="pl-c1">1</span>) <span class="pl-c"><span class="pl-c">#</span> A conv layer</span>

<span class="pl-c"><span class="pl-c">#</span>Filter your input with the convolutional layer</span>
output <span class="pl-k">=</span> <span class="pl-c1">cnn</span>(<span class="pl-c1">randn</span>(Float32,<span class="pl-c1">224</span>,<span class="pl-c1">224</span>,<span class="pl-c1">3</span>,<span class="pl-c1">1</span>))

<span class="pl-c"><span class="pl-c">#</span>Instantiate an LSTM model</span>
lstm <span class="pl-k">=</span> <span class="pl-c1">LSTM</span>(input<span class="pl-k">=</span><span class="pl-c1">100</span>, hidden<span class="pl-k">=</span><span class="pl-c1">100</span>, embed<span class="pl-k">=</span><span class="pl-c1">50</span>)

<span class="pl-c"><span class="pl-c">#</span>You can use integers to represent one-hot vectors.</span>
<span class="pl-c"><span class="pl-c">#</span>Each integer corresponds to vocabulary index of corresponding element in your data.</span>

<span class="pl-c"><span class="pl-c">#</span>For example a pass over 5-Length sequence</span>
rnnoutput <span class="pl-k">=</span> <span class="pl-c1">lstm</span>([<span class="pl-c1">3</span>,<span class="pl-c1">2</span>,<span class="pl-c1">1</span>,<span class="pl-c1">4</span>,<span class="pl-c1">5</span>];hy<span class="pl-k">=</span><span class="pl-c1">true</span>,cy<span class="pl-k">=</span><span class="pl-c1">true</span>)

<span class="pl-c"><span class="pl-c">#</span>After you get the output, you may acces to hidden states and</span>
<span class="pl-c"><span class="pl-c">#</span>intermediate hidden states produced by the lstm model</span>
rnnoutput<span class="pl-k">.</span>y
rnnoutput<span class="pl-k">.</span>hidden
rnnoutput<span class="pl-k">.</span>memory

<span class="pl-c"><span class="pl-c">#</span>You can also use normal array inputs for low-level control</span>
<span class="pl-c"><span class="pl-c">#</span>One iteration of LSTM with a random input</span>
rnnoutput <span class="pl-k">=</span> <span class="pl-c1">lstm</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">100</span>,<span class="pl-c1">1</span>);hy<span class="pl-k">=</span><span class="pl-c1">true</span>,cy<span class="pl-k">=</span><span class="pl-c1">true</span>)

<span class="pl-c"><span class="pl-c">#</span>Pass over a random 10-length sequence:</span>
rnnoutput <span class="pl-k">=</span> <span class="pl-c1">lstm</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">100</span>,<span class="pl-c1">1</span>,<span class="pl-c1">10</span>);hy<span class="pl-k">=</span><span class="pl-c1">true</span>,cy<span class="pl-k">=</span><span class="pl-c1">true</span>)

<span class="pl-c"><span class="pl-c">#</span>Pass over a mini-batch data which includes unequal length sequences</span>
rnnoutput <span class="pl-k">=</span> <span class="pl-c1">lstm</span>([[<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>],[<span class="pl-c1">5</span>,<span class="pl-c1">6</span>]];sorted<span class="pl-k">=</span><span class="pl-c1">true</span>,hy<span class="pl-k">=</span><span class="pl-c1">true</span>,cy<span class="pl-k">=</span><span class="pl-c1">true</span>)

<span class="pl-c"><span class="pl-c">#</span>To see and modify rnn params in a structured view</span>
lstm<span class="pl-k">.</span>gatesview</pre></div>
<h2 dir="auto"><a id="user-content-to-do" class="anchor" aria-hidden="true" href="#to-do"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>TO-DO</h2>
<ol start="3" dir="auto">
<li>Examples</li>
<li>Special layers such Google's <code>inception</code></li>
<li>Known embeddings such <code>Gloove</code></li>
<li>Pretrained Models</li>
</ol>
</article></div>