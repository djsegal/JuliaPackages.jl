<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-amrvw-fast-and-backward-stable-computation-of-roots-of-polynomials" class="anchor" aria-hidden="true" href="#amrvw-fast-and-backward-stable-computation-of-roots-of-polynomials"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>AMRVW. Fast and backward stable computation of roots of polynomials</h1>
<p dir="auto"><a href="https://jverzani.github.io/AMRVW.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://jverzani.github.io/AMRVW.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/jverzani/AMRVW.jl/actions"><img src="https://github.com/jverzani/AMRVW.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/jverzani/AMRVW.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/b3dfb7cec59d83814d90e61a118e6be959e96518fc44d20334baaec18e724e77/68747470733a2f2f636f6465636f762e696f2f67682f6a7665727a616e692f414d5256572e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/jverzani/AMRVW.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">Implementation of core-chasing algorithms for finding eigenvalues of
factored matrices.  FORTRAN code for such methods is provided in the
<a href="https://github.com/eiscor/eiscor">eiscor</a> repository.</p>
<p dir="auto">This repository provides a <code>Julia</code> package implementing the methods,
as applied to the problem of finding the roots of polynomials through
the computation of the eigenvalues of a sparse factorization of the
companion matrix in:</p>
<ul dir="auto">
<li>
<p dir="auto">Fast and Backward Stable Computation of Roots of Polynomials.
Jared L. Aurentz, Thomas Mach, Raf Vandebril, and David S. Watkins
SIAM J. Matrix Anal. Appl., 36(3), 942â€“973. (2015)
<a href="https://doi.org/10.1137/140983434" rel="nofollow">https://doi.org/10.1137/140983434</a></p>
</li>
<li>
<p dir="auto">Fast and backward stable computation of roots of polynomials, Part
II: backward error analysis; companion matrix and companion pencil. By
Jared L. Aurentz, Thomas Mach, Leonardo Robol, Raf Vandebril, David
S. Watkins; arXiv:1611.02435</p>
</li>
</ul>
<p dir="auto">The methods are summarized in monograph format:</p>
<p dir="auto">Core-Chasing Algorithms for the Eigenvalue Problem; by Jared
L. Aurentz, Thomas Mach, Leonardo Robol, Raf Vandebril, and David
S. Watkins; <a href="https://doi.org/10.1137/1.9781611975345" rel="nofollow">https://doi.org/10.1137/1.9781611975345</a></p>
<p dir="auto">As well, the twisted algorithm from "A generalization of the
multishift QR algorithm" by Raf Vandebril and David S. Watkins;
<a href="https://doi.org/10.1137/11085219X" rel="nofollow">https://doi.org/10.1137/11085219X</a> is implemented here.</p>
<p dir="auto">The core-chasing algorithms utilize Francis's QR algorithm on sparse
factorizations of the respected companion matrix. For polynomials with
real coefficients, the storage requirements are O(n) and the algorithm
requires O(n) flops per iteration, or O(n^2) flops overall. The basic
QR algorithm applied to the full companion matrix would require O(n^2)
storage and O(n^3) flops overall.</p>
<h2 dir="auto"><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; import AMRVW; const A = AMRVW
julia&gt; p4 = [24.0, -50.0, 35.0, -10.0, 1.0]  # (x-1) * (x-2) * (x-3) * (x-4)

5-element Array{Float64,1}:
  24.0
 -50.0
  35.0
 -10.0
   1.0

julia&gt; A.roots(p4)
4-element Array{Complex{Float64},1}:
 0.9999999999999996 + 0.0im
 2.0000000000000027 + 0.0im
 2.9999999999999876 + 0.0im
 4.000000000000012 + 0.0im"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">import</span> AMRVW; <span class="pl-k">const</span> A <span class="pl-k">=</span> AMRVW
julia<span class="pl-k">&gt;</span> p4 <span class="pl-k">=</span> [<span class="pl-c1">24.0</span>, <span class="pl-k">-</span><span class="pl-c1">50.0</span>, <span class="pl-c1">35.0</span>, <span class="pl-k">-</span><span class="pl-c1">10.0</span>, <span class="pl-c1">1.0</span>]  <span class="pl-c"><span class="pl-c">#</span> (x-1) * (x-2) * (x-3) * (x-4)</span>

<span class="pl-c1">5</span><span class="pl-k">-</span>element Array{Float64,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
  <span class="pl-c1">24.0</span>
 <span class="pl-k">-</span><span class="pl-c1">50.0</span>
  <span class="pl-c1">35.0</span>
 <span class="pl-k">-</span><span class="pl-c1">10.0</span>
   <span class="pl-c1">1.0</span>

julia<span class="pl-k">&gt;</span> A<span class="pl-k">.</span><span class="pl-c1">roots</span>(p4)
<span class="pl-c1">4</span><span class="pl-k">-</span>element Array{Complex{Float64},<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-c1">0.9999999999999996</span> <span class="pl-k">+</span> <span class="pl-c1">0.0im</span>
 <span class="pl-c1">2.0000000000000027</span> <span class="pl-k">+</span> <span class="pl-c1">0.0im</span>
 <span class="pl-c1">2.9999999999999876</span> <span class="pl-k">+</span> <span class="pl-c1">0.0im</span>
 <span class="pl-c1">4.000000000000012</span> <span class="pl-k">+</span> <span class="pl-c1">0.0im</span></pre></div>
<p dir="auto">By means of comparison, using the <code>Polynomials</code> package:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Polynomials
julia&gt; roots(Polynomial(p4))

4-element Array{Float64,1}:
 1.000000000000002
 1.9999999999999805
 3.0000000000000386
 3.9999999999999822"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Polynomials
julia<span class="pl-k">&gt;</span> <span class="pl-c1">roots</span>(<span class="pl-c1">Polynomial</span>(p4))

<span class="pl-c1">4</span><span class="pl-k">-</span>element Array{Float64,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-c1">1.000000000000002</span>
 <span class="pl-c1">1.9999999999999805</span>
 <span class="pl-c1">3.0000000000000386</span>
 <span class="pl-c1">3.9999999999999822</span></pre></div>
<p dir="auto">The advantage of the methods comes from the fact that this algorithm
can be used for much larger polynomials.</p>
<ul dir="auto">
<li>
<p dir="auto">Compared to the <code>roots</code> function of the
<a href="https://github.com/JuliaMath/Polynomials.jl">Polynomials</a> package,
the methods are faster once the degree is around 75, and much faster
as this grows. These methods are O(n) in storage and O(n^2) in time,
whereas <code>roots</code> is O(n^2) in storage (the full companion matrix is
created) and O(n^3) in time (the running time of a generic
eigenvalue solver). As well, the <code>roots</code> function only computes over
<code>Float64</code> values, not generic floating point values.</p>
</li>
<li>
<p dir="auto">Compared to the <code>roots</code> function of the
<a href="https://github.com/giordano/PolynomialRoots.jl">PolynomialsRoots</a>
package, these methods are a bit slower, and perhaps a bit less
accurate. This <code>roots</code> function is O(n) in storage and also appears
to be O(n^2) in time. This <code>roots</code> function works over generic
floating point values. However, this <code>roots</code> method will run into
numeric issues for polynomials of degree n larger than 350 or so.</p>
</li>
</ul>
<p dir="auto">The backward stability of the methods is shown in the second paper to
grow linearly in the norm of the coefficients, so the following should
be quite accurate and is computable in a reasonable time:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="## by DOI:	10.1142/S0219199715500522, this should have expected value ~ 2/pi*log(n) + .625738072 + 2/(pi*n) ~ 6.48
julia&gt; rs = rand(Float64, 10_000) .- 1/2
julia&gt; @time rts  = A.roots(rs)
julia&gt; sum(isreal, rts)
 15.955615 seconds (35 allocations: 1017.297 KiB)
5"><pre><span class="pl-c"><span class="pl-c">#</span># by DOI:	10.1142/S0219199715500522, this should have expected value ~ 2/pi*log(n) + .625738072 + 2/(pi*n) ~ 6.48</span>
julia<span class="pl-k">&gt;</span> rs <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float64, <span class="pl-c1">10_000</span>) <span class="pl-k">.-</span> <span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">2</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@time</span> rts  <span class="pl-k">=</span> A<span class="pl-k">.</span><span class="pl-c1">roots</span>(rs)
julia<span class="pl-k">&gt;</span> <span class="pl-c1">sum</span>(isreal, rts)
 <span class="pl-c1">15.955615</span> seconds (<span class="pl-c1">35</span> allocations<span class="pl-k">:</span> <span class="pl-c1">1017.297</span> KiB)
<span class="pl-c1">5</span></pre></div>
<p dir="auto">As this is relatively speedy, statistics can be generated, albeit the following will take some time to finish:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; xs = [sum(isreal, A.roots(randn(3000))) for _ in 1:3000]
julia&gt; using StatsBase
julia&gt; xbar, s = mean_and_std(xs)
julia&gt; n = 3000
julia&gt; xbar .+ 1.96*s/sqrt(n) * [-1,1], 2/pi*log(n) + .625738072 + 2/(pi*n)
 ([5.67865426156726, 5.820012405099407], 5.7229621769994745)"><pre>julia<span class="pl-k">&gt;</span> xs <span class="pl-k">=</span> [<span class="pl-c1">sum</span>(isreal, A<span class="pl-k">.</span><span class="pl-c1">roots</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">3000</span>))) <span class="pl-k">for</span> _ <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">3000</span>]
julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> StatsBase
julia<span class="pl-k">&gt;</span> xbar, s <span class="pl-k">=</span> <span class="pl-c1">mean_and_std</span>(xs)
julia<span class="pl-k">&gt;</span> n <span class="pl-k">=</span> <span class="pl-c1">3000</span>
julia<span class="pl-k">&gt;</span> xbar <span class="pl-k">.+</span> <span class="pl-c1">1.96</span><span class="pl-k">*</span>s<span class="pl-k">/</span><span class="pl-c1">sqrt</span>(n) <span class="pl-k">*</span> [<span class="pl-k">-</span><span class="pl-c1">1</span>,<span class="pl-c1">1</span>], <span class="pl-c1">2</span><span class="pl-k">/</span><span class="pl-c1">pi</span><span class="pl-k">*</span><span class="pl-c1">log</span>(n) <span class="pl-k">+</span> .<span class="pl-c1">625738072</span> <span class="pl-k">+</span> <span class="pl-c1">2</span><span class="pl-k">/</span>(<span class="pl-c1">pi</span><span class="pl-k">*</span>n)
 ([<span class="pl-c1">5.67865426156726</span>, <span class="pl-c1">5.820012405099407</span>], <span class="pl-c1">5.7229621769994745</span>)</pre></div>
<hr>
<p dir="auto">There are no exported functions, as of now. But the internal functions may be of interest. For example, the paper <a href="http://etna.mcs.kent.edu/volumes/2011-2020/vol44/abstract.php?vol=44&amp;pages=327-341" rel="nofollow">Fast and stable unitary QR algorithm</a> discusses a situation where a matrix <code>A</code> is unitary Hessenberg, and so is factored in terms of a descending chain of rotators. To fit this matrix into the current framework, we have, for example:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using LinearAlgebra
T = Float64
const A =  AMRVW
Qs = A.random_rotator.(T, 1:10)
Q = A.DescendingChain(Qs)
QF = A.q_factorization(Q)
F = A.QRFactorization(QF)
eigvals(F)"><pre class="notranslate"><code>using LinearAlgebra
T = Float64
const A =  AMRVW
Qs = A.random_rotator.(T, 1:10)
Q = A.DescendingChain(Qs)
QF = A.q_factorization(Q)
F = A.QRFactorization(QF)
eigvals(F)
</code></pre></div>
<p dir="auto">Which can be compared with:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="MI = diagm(0 =&gt; ones(T, 11))
Qs * MI |&gt; eigvals"><pre class="notranslate"><code>MI = diagm(0 =&gt; ones(T, 11))
Qs * MI |&gt; eigvals
</code></pre></div>
</article></div>