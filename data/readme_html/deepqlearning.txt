<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-deepqlearningjl" class="anchor" aria-hidden="true" href="#deepqlearningjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DeepQLearning.jl</h1>
<p>Julia implementation of DeepMind's Deep Q-Learning algorithm as described in <a href="http://arxiv.org/abs/1312.5602" rel="nofollow">Playing Atari with Deep Reinforcement Learning</a>. This code only implements the base algorithm. It does not include the code for a convolutional network. However, this can be easily added using Mocha.jl. In lieu of this it uses a simpler single layer neural network. Information on the original <a href="http://cs.stanford.edu/people/karpathy/reinforcejs/waterworld.html" rel="nofollow">RecurrenJS DQN implementation can be found here</a></p>
<p><em>note: This library has been tested on various learning tasks and seems to be functioning correctly, but is not yet ready for public consumption.</em></p>
<h2><a id="user-content-example-code" class="anchor" aria-hidden="true" href="#example-code"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Example code</h2>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> DeepQLearning

<span class="pl-k">...</span> coming soon <span class="pl-k">...</span> I hope :)</pre></div>
<p>##Dependencies
This library requires <a href="https://github.com/Andy-P/NNGraph.jl">NNGraph.jl</a>.</p>
<p>##Credits
This library draws on the work of <a href="https://github.com/karpathy/reinforcejs">Andrej Karpathy</a></p>
<h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>License</h2>
<p>MIT</p>
</article></div>