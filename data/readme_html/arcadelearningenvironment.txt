<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p><a href="https://github.com/JuliaReinforcementLearning/ArcadeLearningEnvironment.jl/actions/workflows/ci.yml"><img src="https://github.com/JuliaReinforcementLearning/ArcadeLearningEnvironment.jl/actions/workflows/ci.yml/badge.svg" alt="CI" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/JuliaReinforcementLearning/ArcadeLearningEnvironment.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/ac2b6438559b0e1daed2bc3bc1cd61ca0e19e32c97d503d11f9d2e7527913be0/68747470733a2f2f636f6465636f762e696f2f67682f4a756c69615265696e666f7263656d656e744c6561726e696e672f4172636164654c6561726e696e67456e7669726f6e6d656e742e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/JuliaReinforcementLearning/ArcadeLearningEnvironment.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<h1><a id="user-content-arcadelearningenvironmentjl" class="anchor" aria-hidden="true" href="#arcadelearningenvironmentjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ArcadeLearningEnvironment.jl</h1>
<p>This package is a <a href="http://julialang.org/" rel="nofollow">Julia</a> wrapper for the
<a href="https://github.com/mgbellemare/Arcade-Learning-Environment">ArcadeLearningEnvironment</a> (ALE).</p>
<p><strong>This is the maintained fork that is in the official Julia registry.</strong></p>
<p>For a higher level access to ALE see <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironments.jl">ReinforcementLearningEnvironments</a>.</p>
<p>ALE is a modified emulator for the Atari 2600 that can emulate more than 50 games
with additional access to game state information and in-game rewards.
This is useful for learning and benchmarking artificial intelligence agents
playing computer games.</p>
<h2><a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Citation</h2>
<p>If you use this package for research publications, please cite the following
paper to acknowledge the work that went into ALE.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="@ARTICLE{bellemare13arcade,
	author = {{Bellemare}, M.~G. and {Naddaf}, Y. and {Veness}, J. and {Bowling}, M.},
	title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
	journal = {Journal of Artificial Intelligence Research},
	year = 2013,
	month = 06,
	volume = 47,
	pages = {253--279}
}
"><pre><code>@ARTICLE{bellemare13arcade,
	author = {{Bellemare}, M.~G. and {Naddaf}, Y. and {Veness}, J. and {Bowling}, M.},
	title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
	journal = {Journal of Artificial Intelligence Research},
	year = 2013,
	month = 06,
	volume = 47,
	pages = {253--279}
}
</code></pre></div>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>The package automatically downloads version 0.6.1 of the ArcadeLearningEnvironment
and the ROMS from <a href="http://www.atarimania.com" rel="nofollow">www.atarimania.com</a>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="Pkg.add(&quot;ArcadeLearningEnvironment&quot;)
"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>ArcadeLearningEnvironment<span class="pl-pds">"</span></span>)</pre></div>
<h2><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Example</h2>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using ArcadeLearningEnvironment

getROMList()

episodes = 50

ale = ALE_new()
loadROM(ale, &quot;seaquest&quot;)

S = zeros(Int64, episodes)
TR = zeros(episodes)
for ei = 1:episodes
    ctr = 0.0

    fc = 0
    while game_over(ale) == false
        actions = getLegalActionSet(ale)
        ctr += act(ale, actions[rand(1:length(actions))])
        fc += 1
    end
    reset_game(ale)
    println(&quot;Game $ei ended after $fc frames with total reward $(ctr).&quot;)

    S[ei] = fc
    TR[ei] = ctr
end
ALE_del(ale)
"><pre><span class="pl-k">using</span> ArcadeLearningEnvironment

<span class="pl-c1">getROMList</span>()

episodes <span class="pl-k">=</span> <span class="pl-c1">50</span>

ale <span class="pl-k">=</span> <span class="pl-c1">ALE_new</span>()
<span class="pl-c1">loadROM</span>(ale, <span class="pl-s"><span class="pl-pds">"</span>seaquest<span class="pl-pds">"</span></span>)

S <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(Int64, episodes)
TR <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(episodes)
<span class="pl-k">for</span> ei <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">:</span>episodes
    ctr <span class="pl-k">=</span> <span class="pl-c1">0.0</span>

    fc <span class="pl-k">=</span> <span class="pl-c1">0</span>
    <span class="pl-k">while</span> <span class="pl-c1">game_over</span>(ale) <span class="pl-k">==</span> <span class="pl-c1">false</span>
        actions <span class="pl-k">=</span> <span class="pl-c1">getLegalActionSet</span>(ale)
        ctr <span class="pl-k">+=</span> <span class="pl-c1">act</span>(ale, actions[<span class="pl-c1">rand</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">length</span>(actions))])
        fc <span class="pl-k">+=</span> <span class="pl-c1">1</span>
    <span class="pl-k">end</span>
    <span class="pl-c1">reset_game</span>(ale)
    <span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span>Game <span class="pl-v">$ei</span> ended after <span class="pl-v">$fc</span> frames with total reward <span class="pl-v">$(ctr)</span>.<span class="pl-pds">"</span></span>)

    S[ei] <span class="pl-k">=</span> fc
    TR[ei] <span class="pl-k">=</span> ctr
<span class="pl-k">end</span>
<span class="pl-c1">ALE_del</span>(ale)</pre></div>
</article></div>