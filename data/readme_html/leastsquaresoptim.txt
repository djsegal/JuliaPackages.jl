<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a href="https://github.com/matthieugomez/LeastSquaresOptim.jl/actions"><img src="https://github.com/matthieugomez/LeastSquaresOptim.jl/workflows/CI/badge.svg" alt="Build status" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Motivation</h2>
<p dir="auto">This package solves non linear least squares optimization problems.   This package is written with large scale problems in mind (in particular for sparse Jacobians).</p>
<h2 dir="auto"><a id="user-content-simple-syntax" class="anchor" aria-hidden="true" href="#simple-syntax"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Simple Syntax</h2>
<p dir="auto">The symple syntax mirrors the <code>Optim.jl</code> syntax</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LeastSquaresOptim
function rosenbrock(x)
	[1 - x[1], 100 * (x[2]-x[1]^2)]
end
x0 = zeros(2)
optimize(rosenbrock, x0, Dogleg())
optimize(rosenbrock, x0, LevenbergMarquardt())"><pre><span class="pl-k">using</span> LeastSquaresOptim
<span class="pl-k">function</span> <span class="pl-en">rosenbrock</span>(x)
	[<span class="pl-c1">1</span> <span class="pl-k">-</span> x[<span class="pl-c1">1</span>], <span class="pl-c1">100</span> <span class="pl-k">*</span> (x[<span class="pl-c1">2</span>]<span class="pl-k">-</span>x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>)]
<span class="pl-k">end</span>
x0 <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>)
<span class="pl-c1">optimize</span>(rosenbrock, x0, <span class="pl-c1">Dogleg</span>())
<span class="pl-c1">optimize</span>(rosenbrock, x0, <span class="pl-c1">LevenbergMarquardt</span>())</pre></div>
<p dir="auto">You can also add the options : <code>x_tol</code>, <code>f_tol</code>, <code>g_tol</code>, <code>iterations</code>, <code>Δ</code> (initial radius), <code>autodiff</code> (<code>:central</code> to use finite difference method or <code>:forward</code> to use ForwardDiff package) as well as <code>lower</code> / <code>upper</code> arguments to impose boundary constraints.</p>
<h2 dir="auto"><a id="user-content-choice-of-optimizer--least-square-solver" class="anchor" aria-hidden="true" href="#choice-of-optimizer--least-square-solver"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Choice of Optimizer / Least Square Solver</h2>
<ul dir="auto">
<li>You can specify two least squares optimizers, <code>Dogleg()</code> and <code>LevenbergMarquardt()</code></li>
<li>You can specify three least squares solvers (used within the optimizer)
<ul dir="auto">
<li>
<p dir="auto"><code>LeastSquaresOptim.QR()</code> or  <code>LeastSquaresOptim.Cholesky()</code> for dense jacobians</p>
</li>
<li>
<p dir="auto"><code>LeastSquaresOptim.LSMR()</code>. A conjugate gradient method (LSMR with diagonal preconditioner). Beyond <code>Matrix</code> and <code>SparseMatrixCSC</code>, the jacobian can be any type that defines the following interface:</p>
<ul dir="auto">
<li><code>mul!(y, A, x, α::Number, β::Number)</code> updates y to αAx + βy</li>
<li><code>mul!(x, A', y, α::Number, β::Number)</code> updates x to αA'y + βx</li>
<li><code>colsumabs2!(x, A)</code> updates x to the sum of squared elements of each column</li>
<li><code>size(A, d)</code> returns the nominal dimensions along the dth axis in the equivalent matrix representation of A.</li>
<li><code>eltype(A)</code> returns the element type implicit in the equivalent matrix representation of A.</li>
</ul>
<p dir="auto">Similarly, <code>x</code> or <code>f(x)</code> may be custom types. An example of the interface can be found in the package <a href="https://github.com/matthieugomez/SparseFactorModels.jl">SparseFactorModels.jl</a>.</p>
<p dir="auto">Moreover, you can optionally specifying a function <code>preconditioner!</code> and a matrix <code>P</code> such that <code>preconditioner!(P, x, J, λ)</code> updates <code>P</code> as a preconditioner for <code>J'J + λ</code>. The preconditioner can be any type that supports <code>A_ldiv_B!(x, P, y)</code>. By default, the preconditioner is chosen as the diagonal of the matrix <code>J'J + λ</code>.</p>
</li>
</ul>
</li>
</ul>
<p dir="auto">The optimizers and solvers are presented in more depth in the <a href="http://ceres-solver.org/nnls_solving.html" rel="nofollow">Ceres documentation</a>. For dense jacobians, the default option is <code>Doglel(QR())</code>. For sparse jacobians, the default option is  <code>LevenbergMarquardt(LSMR())</code></p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="optimize(rosenbrock, x0, Dogleg(LeastSquaresOptim.QR()))
optimize(rosenbrock, x0, LevenbergMarquardt(LeastSquaresOptim.LSMR()))"><pre><span class="pl-c1">optimize</span>(rosenbrock, x0, <span class="pl-c1">Dogleg</span>(LeastSquaresOptim<span class="pl-k">.</span><span class="pl-c1">QR</span>()))
<span class="pl-c1">optimize</span>(rosenbrock, x0, <span class="pl-c1">LevenbergMarquardt</span>(LeastSquaresOptim<span class="pl-k">.</span><span class="pl-c1">LSMR</span>()))</pre></div>
<h2 dir="auto"><a id="user-content-alternative-in-place-syntax" class="anchor" aria-hidden="true" href="#alternative-in-place-syntax"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Alternative in-place Syntax</h2>
<p dir="auto">The alternative syntax is useful when specifying in-place functions or the jacobian. Pass <code>optimize</code> a <code>LeastSquaresProblem</code> object with:</p>
<ul dir="auto">
<li><code>x</code> an initial set of parameters.</li>
<li><code>f!(out, x)</code> that writes <code>f(x)</code> in <code>out</code>.</li>
<li>the option <code>output_length</code> to specify the length of the output vector.</li>
<li>Optionally, <code>g!</code> a function such that <code>g!(out, x)</code> writes the jacobian at x in <code>out</code>. Otherwise, the jacobian will be computed following the <code>:autodiff</code> argument.</li>
</ul>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LeastSquaresOptim
function rosenbrock_f!(out, x)
 out[1] = 1 - x[1]
 out[2] = 100 * (x[2]-x[1]^2)
end
optimize!(LeastSquaresProblem(x = zeros(2), f! = rosenbrock_f!, output_length = 2, autodiff = :central), Dogleg())

# if you want to use gradient
function rosenbrock_g!(J, x)
    J[1, 1] = -1
    J[1, 2] = 0
    J[2, 1] = -200 * x[1]
    J[2, 2] = 100
end
optimize!(LeastSquaresProblem(x = zeros(2), f! = rosenbrock_f!, g! = rosenbrock_g!, output_length = 2), Dogleg())"><pre><span class="pl-k">using</span> LeastSquaresOptim
<span class="pl-k">function</span> <span class="pl-en">rosenbrock_f!</span>(out, x)
 out[<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">1</span> <span class="pl-k">-</span> x[<span class="pl-c1">1</span>]
 out[<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">100</span> <span class="pl-k">*</span> (x[<span class="pl-c1">2</span>]<span class="pl-k">-</span>x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>)
<span class="pl-k">end</span>
<span class="pl-c1">optimize!</span>(<span class="pl-c1">LeastSquaresProblem</span>(x <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>), f! <span class="pl-k">=</span> rosenbrock_f!, output_length <span class="pl-k">=</span> <span class="pl-c1">2</span>, autodiff <span class="pl-k">=</span> <span class="pl-c1">:central</span>), <span class="pl-c1">Dogleg</span>())

<span class="pl-c"><span class="pl-c">#</span> if you want to use gradient</span>
<span class="pl-k">function</span> <span class="pl-en">rosenbrock_g!</span>(J, x)
    J[<span class="pl-c1">1</span>, <span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1</span>
    J[<span class="pl-c1">1</span>, <span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">0</span>
    J[<span class="pl-c1">2</span>, <span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">200</span> <span class="pl-k">*</span> x[<span class="pl-c1">1</span>]
    J[<span class="pl-c1">2</span>, <span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">100</span>
<span class="pl-k">end</span>
<span class="pl-c1">optimize!</span>(<span class="pl-c1">LeastSquaresProblem</span>(x <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">2</span>), f! <span class="pl-k">=</span> rosenbrock_f!, g! <span class="pl-k">=</span> rosenbrock_g!, output_length <span class="pl-k">=</span> <span class="pl-c1">2</span>), <span class="pl-c1">Dogleg</span>())</pre></div>
<h2 dir="auto"><a id="user-content-related-packages" class="anchor" aria-hidden="true" href="#related-packages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Related packages</h2>
<p dir="auto">Related:</p>
<ul dir="auto">
<li><a href="https://github.com/sglyon/MINPACK.jl">MINPACK.jl</a>] solves least squares problem (without boundary constraints)</li>
<li><a href="https://github.com/JuliaOpt/Optim.jl">Optim.jl</a> solves general optimization problems.</li>
<li><a href="https://github.com/EconForge/NLsolve.jl">NLSolve.jl</a> solves non linear equations by least squares minimization.</li>
<li><a href="https://github.com/JuliaOpt/LsqFit.jl">LSqfit.jl</a> fits curves (i.e. models of the form y = f(x, β))</li>
</ul>
<h2 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<ul dir="auto">
<li>Nocedal, Jorge and Stephen Wright <em>An Inexact Levenberg-Marquardt method for Large Sparse Nonlinear Least Squares</em>  (1985) The Journal of the Australian Mathematical Society</li>
<li>Fong, DC. and Michael Saunders. (2011) <em>LSMR: An Iterative Algorithm for Sparse Least-Squares Problems</em>.  SIAM Journal on Scientific Computing</li>
<li>Agarwal, Sameer, Keir Mierle and Others. (2010) <em>Ceres Solver</em></li>
</ul>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">To install the package,</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Pkg
Pkg.add(&quot;LeastSquaresOptim&quot;)"><pre><span class="pl-k">using</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>LeastSquaresOptim<span class="pl-pds">"</span></span>)</pre></div>
</article></div>