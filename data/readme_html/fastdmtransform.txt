<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-fastdmtransform" class="anchor" aria-hidden="true" href="#fastdmtransform"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>FastDMTransform</h1>
<p dir="auto"><a href="https://kiranshila.github.io/FastDMTransform.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/kiranshila/FastDMTransform.jl/actions/workflows/CI.yml?query=branch%3Amain"><img src="https://github.com/kiranshila/FastDMTransform.jl/actions/workflows/CI.yml/badge.svg?branch=main" alt="Build Status" style="max-width: 100%;"></a></p>
<p dir="auto">A pure-julia implementation of the "Fast DM Transform" from:</p>
<p dir="auto"><a href="https://arxiv.org/abs/1411.5373" rel="nofollow">An accurate and efficient algorithm for detection of radio bursts with an unknown dispersion measure, for single dish telescopes and interferometers</a> - Zackay 2014, et. al.</p>
<h2 dir="auto"><a id="user-content-implementation-details" class="anchor" aria-hidden="true" href="#implementation-details"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Implementation Details</h2>
<p dir="auto">Here, we follow the Python implementation of provided by Vincent Morello, <a href="https://bitbucket.org/vmorello/pyfdmt/src/master/" rel="nofollow">pyfdmt</a>, as they implemented a very nice recursive version, a big improvement over the confusing nested loops from the source paper. In this code, we make the interface and abstractions more Julian, and heavily optimize for performance. This includes transforming the recursion into parallel sums</p>
<p dir="auto">In this code, we make heavy use of all available AVX extensions using <a href="https://github.com/JuliaSIMD/LoopVectorization.jl">LoopVectorization.jl</a>, so performance may be reasonably dependent on CPU, as Intel CPUs have AVX512.</p>
<h2 dir="auto"><a id="user-content-benchmarks" class="anchor" aria-hidden="true" href="#benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Benchmarks</h2>
<p dir="auto">Here we will try to FastDMTransform a synthetic pulse from a DM of 0 to 2000 with 4096 frequency channels, and 3000 1ms time samples.
These benchmarks are run on a machine with 64 GB of RAM and an i9-9900X</p>
<h3 dir="auto"><a id="user-content-canonical-matlab" class="anchor" aria-hidden="true" href="#canonical-matlab"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>"Canonical" MATLAB</h3>
<p dir="auto">Tested here was the original source from the author.
I only have Octave as I don't want to use nonfree software, and Octave doesn't have <code>timeit</code>, so I run it a few times with <code>tic</code> and <code>toc</code> and averaged around 1.3s</p>
<h3 dir="auto"><a id="user-content-pyfdmt" class="anchor" aria-hidden="true" href="#pyfdmt"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>pyfdmt</h3>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="%timeit -n 1 -r 10 pyfdmt.transform(pulse.T,1500,1200,1e-3,0,2000)
446 ms ± 2.19 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)"><pre><span class="pl-c1">%</span><span class="pl-s1">timeit</span> <span class="pl-c1">-</span><span class="pl-s1">n</span> <span class="pl-c1">1</span> <span class="pl-c1">-</span><span class="pl-s1">r</span> <span class="pl-c1">10</span> <span class="pl-s1">pyfdmt</span>.<span class="pl-en">transform</span>(<span class="pl-s1">pulse</span>.<span class="pl-v">T</span>,<span class="pl-c1">1500</span>,<span class="pl-c1">1200</span>,<span class="pl-c1">1e-3</span>,<span class="pl-c1">0</span>,<span class="pl-c1">2000</span>)
<span class="pl-c1">446</span> <span class="pl-s1">ms</span> ± <span class="pl-c1">2.19</span> <span class="pl-s1">ms</span> <span class="pl-s1">per</span> <span class="pl-en">loop</span> (<span class="pl-s1">mean</span> ± <span class="pl-s1">std</span>. <span class="pl-s1">dev</span>. <span class="pl-s1">of</span> <span class="pl-c1">10</span> <span class="pl-s1">runs</span>, <span class="pl-c1">1</span> <span class="pl-s1">loop</span> <span class="pl-s1">each</span>)</pre></div>
<h3 dir="auto"><a id="user-content-fastdmtransformjl" class="anchor" aria-hidden="true" href="#fastdmtransformjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>FastDMTransform.jl</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; @benchmark fdmt(pulse,1500,1200,1e-3,0,2000)
BenchmarkTools.Trial: 71 samples with 1 evaluation.
 Range (min … max):  50.494 ms … 150.447 ms  ┊ GC (min … max): 0.00% … 28.43%
 Time  (median):     55.299 ms               ┊ GC (median):    0.00%
 Time  (mean ± σ):   71.116 ms ±  30.091 ms  ┊ GC (mean ± σ):  9.60% ± 10.24%

  ▁█▁                                                           
  ███▄▅▅█▁▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▃▁▄▄▃▃▁▃▁▃▁▃▃▁▁▃▁▁▁▃▃ ▁
  50.5 ms         Histogram: frequency by time          144 ms &lt;

 Memory estimate: 479.17 MiB, allocs estimate: 281374."><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">fdmt</span>(pulse,<span class="pl-c1">1500</span>,<span class="pl-c1">1200</span>,<span class="pl-c1">1e-3</span>,<span class="pl-c1">0</span>,<span class="pl-c1">2000</span>)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">71</span> samples with <span class="pl-c1">1</span> evaluation.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">50.494</span> ms … <span class="pl-c1">150.447</span> ms  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">28.43</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">55.299</span> ms               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">71.116</span> ms ±  <span class="pl-c1">30.091</span> ms  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">9.60</span><span class="pl-k">%</span> ± <span class="pl-c1">10.24</span><span class="pl-k">%</span>

  ▁█▁                                                           
  ███▄▅▅█▁▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▃▁▄▄▃▃▁▃▁▃▁▃▃▁▁▃▁▁▁▃▃ ▁
  <span class="pl-c1">50.5</span> ms         Histogram<span class="pl-k">:</span> frequency by time          <span class="pl-c1">144</span> ms <span class="pl-k">&lt;</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">479.17</span> MiB, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">281374.</span></pre></div>
<h3 dir="auto"><a id="user-content-dedispjl" class="anchor" aria-hidden="true" href="#dedispjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/kiranshila/Dedisp.jl">Dedisp.jl</a></h3>
<p dir="auto">Here, I've been working on an "optimized" brute force approach</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="plan = plan_dedisp(range(;start=1500,stop=1200,length=4096),1500,range(;start=0,stop=2000,length=2076),1e-3)
julia&gt; @benchmark Dedisp.dedisp(pulse,plan)
BenchmarkTools.Trial: 1 sample with 1 evaluation.
 Single result which took 7.142 s (0.00% GC) to evaluate,
 with a memory estimate of 23.76 MiB, over 8 allocations."><pre>plan <span class="pl-k">=</span> <span class="pl-c1">plan_dedisp</span>(<span class="pl-c1">range</span>(;start<span class="pl-k">=</span><span class="pl-c1">1500</span>,stop<span class="pl-k">=</span><span class="pl-c1">1200</span>,length<span class="pl-k">=</span><span class="pl-c1">4096</span>),<span class="pl-c1">1500</span>,<span class="pl-c1">range</span>(;start<span class="pl-k">=</span><span class="pl-c1">0</span>,stop<span class="pl-k">=</span><span class="pl-c1">2000</span>,length<span class="pl-k">=</span><span class="pl-c1">2076</span>),<span class="pl-c1">1e-3</span>)
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> Dedisp<span class="pl-k">.</span><span class="pl-c1">dedisp</span>(pulse,plan)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">1</span> sample with <span class="pl-c1">1</span> evaluation.
 Single result which took <span class="pl-c1">7.142</span> s (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC) to evaluate,
 with a memory estimate of <span class="pl-c1">23.76</span> MiB, over <span class="pl-c1">8</span> allocations.</pre></div>
<p dir="auto">But, FDMT is still not as fast as the GPU-accelerated brute-force version, but reasonably close</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="output = CUDA.zeros(3000,2076)
plan = cu(plan)
pulse = cu(pulse)
julia&gt; @benchmark CUDA.@sync dedisp!(output,pulse,plan)
BenchmarkTools.Trial: 85 samples with 1 evaluation.
 Range (min … max):  55.555 ms … 71.742 ms  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     58.945 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   59.135 ms ±  1.516 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%

                                    ▃ █▆▆▄▄▄▃ ▁    ▃           
  ▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▆▄█▇███████▁█▇▇▇▆█▁▆▁▆▄▁▁▁▄ ▁
  55.6 ms         Histogram: frequency by time        60.5 ms &lt;

 Memory estimate: 8.72 KiB, allocs estimate: 150."><pre>output <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">zeros</span>(<span class="pl-c1">3000</span>,<span class="pl-c1">2076</span>)
plan <span class="pl-k">=</span> <span class="pl-c1">cu</span>(plan)
pulse <span class="pl-k">=</span> <span class="pl-c1">cu</span>(pulse)
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> CUDA<span class="pl-k">.</span><span class="pl-c1">@sync</span> <span class="pl-c1">dedisp!</span>(output,pulse,plan)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">85</span> samples with <span class="pl-c1">1</span> evaluation.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">55.555</span> ms … <span class="pl-c1">71.742</span> ms  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">58.945</span> ms              ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">59.135</span> ms ±  <span class="pl-c1">1.516</span> ms  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> ± <span class="pl-c1">0.00</span><span class="pl-k">%</span>

                                    ▃ █▆▆▄▄▄▃ ▁    ▃           
  ▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▆▄█▇███████▁█▇▇▇▆█▁▆▁▆▄▁▁▁▄ ▁
  <span class="pl-c1">55.6</span> ms         Histogram<span class="pl-k">:</span> frequency by time        <span class="pl-c1">60.5</span> ms <span class="pl-k">&lt;</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">8.72</span> KiB, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">150.</span></pre></div>
<p dir="auto">Our implementation here is the fastest (CPU version) among the lot - almost 10x faster than the reference python implementation, where we can cover every possible DM in a 3 second chunk in 50ms, that's 60x faster than realtime!</p>
</article></div>