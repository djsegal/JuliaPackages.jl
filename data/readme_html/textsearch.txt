<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-textsearchjl" class="anchor" aria-hidden="true" href="#textsearchjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>TextSearch.jl</h1>
<p><a href="https://travis-ci.org/sadit/TextSearch.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/a457289f18f5b446d7768f1b560d4d0c5926ab29/68747470733a2f2f7472617669732d63692e6f72672f73616469742f546578745365617263682e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/sadit/TextSearch.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/sadit/TextSearch.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/098db446c2b892127e2e6409725547a36e53d0a1/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f73616469742f546578745365617263682e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/sadit/TextSearch.jl/badge.svg?branch=master" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/sadit/TextSearch.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/1a2699dd49177eb5081fe51a85c6ba03cd4062b2/68747470733a2f2f636f6465636f762e696f2f67682f73616469742f546578745365617263682e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/sadit/TextSearch.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p><code>TextSearch.jl</code> is a package to create vector representations of text, mostly, independently of the language. It is intended to be used with <a href="https://github.com/sadit/SimilaritySearch.jl">SimilaritySearch.jl</a>, but can be used independetly if needed.
<code>TextSearch.jl</code> was renamed from <code>TextModel.jl</code> to reflect its capabilities and mission.</p>
<p>For generic text analysis you should use other packages like <a href="https://github.com/johnmyleswhite/TextAnalysis.jl">TextAnalysis.jl</a>.</p>
<p>It supports a number of simple text preprocessing functions, and three different kinds of tokenizers, i.e., word n-grams, character q-grams, and skip-grams. It supports creating multisets of tokens, commonly named bag of words (BOW).
<code>TextSearch.jl</code> can produce sparse vector representations based on term-weighting schemes like TF, IDF, and TFIDF. It also supports term-weighting schemes designed to cope text classification tasks, mostly based on distributional representations.</p>
<h1><a id="user-content-installing-similaritysearch" class="anchor" aria-hidden="true" href="#installing-similaritysearch"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installing SimilaritySearch</h1>
<p>You may install the package as follows</p>
<div class="highlight highlight-source-shell"><pre>julia -e <span class="pl-s"><span class="pl-pds">'</span>using Pkg; pkg"add https://github.com/sadit/TextSearch.jl"<span class="pl-pds">'</span></span></pre></div>
<p>also, you can run the set of tests as follows</p>
<div class="highlight highlight-source-shell"><pre>julia -e <span class="pl-s"><span class="pl-pds">'</span>using Pkg; pkg"test TextSearch"<span class="pl-pds">'</span></span></pre></div>
<h2><a id="user-content-using-the-library" class="anchor" aria-hidden="true" href="#using-the-library"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Using the library</h2>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> SimilaritySearch, TextSearch
julia<span class="pl-k">&gt;</span> url <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>http://ingeotec.mx/~sadit/emospace50k.json.gz<span class="pl-pds">"</span></span>
julia<span class="pl-k">&gt;</span> <span class="pl-k">!</span><span class="pl-c1">isfile</span>(<span class="pl-c1">basename</span>(url)) <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">download</span>(url, <span class="pl-c1">basename</span>(url))
julia<span class="pl-k">&gt;</span> db <span class="pl-k">=</span> <span class="pl-c1">loadtweets</span>(<span class="pl-c1">basename</span>(url))
<span class="pl-c"><span class="pl-c">#</span> you can use a number of tokenizers, here we use character q-grams to improve support for informal writing</span>
julia<span class="pl-k">&gt;</span> config <span class="pl-k">=</span> <span class="pl-c1">TextConfig</span>(qlist<span class="pl-k">=</span>[<span class="pl-c1">4</span>], nlist<span class="pl-k">=</span>[])
julia<span class="pl-k">&gt;</span> corpus <span class="pl-k">=</span> [t[<span class="pl-s"><span class="pl-pds">"</span>text<span class="pl-pds">"</span></span>] <span class="pl-k">for</span> t <span class="pl-k">in</span> db]
julia<span class="pl-k">&gt;</span> model <span class="pl-k">=</span> <span class="pl-c1">fit</span>(VectorModel, config, corpus)
julia<span class="pl-k">&gt;</span> invindex <span class="pl-k">=</span> <span class="pl-c1">InvIndex</span>()
julia<span class="pl-k">&gt;</span> invindex <span class="pl-k">=</span> <span class="pl-c1">fit</span>(InvIndex, [<span class="pl-c1">vectorize</span>(model, TfidfModel, text) <span class="pl-k">for</span> text <span class="pl-k">in</span> corpus])</pre></div>
<p>queries are made as follows</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> q <span class="pl-k">=</span> <span class="pl-c1">vectorize</span>(model, TfidfModel, <span class="pl-s"><span class="pl-pds">"</span>que chida musica!!!<span class="pl-pds">"</span></span>)
julia<span class="pl-k">&gt;</span> db[[p<span class="pl-k">.</span>objID <span class="pl-k">for</span> p <span class="pl-k">in</span> TextSearch<span class="pl-k">.</span><span class="pl-c1">search</span>(invindex, cosine_distance, q, <span class="pl-c1">KnnResult</span>(<span class="pl-c1">11</span>))]]</pre></div>
<p>you can save memory by pruning large lists, as follows</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> invindex <span class="pl-k">=</span> <span class="pl-c1">prune</span>(invindex, <span class="pl-c1">100</span>)
julia<span class="pl-k">&gt;</span> <span class="pl-k">for</span> p <span class="pl-k">in</span> <span class="pl-c1">search</span>(invindex, cosine_distance, <span class="pl-c1">vectorize</span>(model, TfidfModel, <span class="pl-s"><span class="pl-pds">"</span>que chida musica!!!<span class="pl-pds">"</span></span>), <span class="pl-c1">KnnResult</span>(<span class="pl-c1">11</span>))
    <span class="pl-c1">println</span>(db[p<span class="pl-k">.</span>objID][<span class="pl-s"><span class="pl-pds">"</span>klass<span class="pl-pds">"</span></span>], <span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span><span class="pl-pds">"</span></span>, db[p<span class="pl-k">.</span>objID][<span class="pl-s"><span class="pl-pds">"</span>text<span class="pl-pds">"</span></span>])
<span class="pl-k">end</span></pre></div>
<p>in some cases this prunning can improve results since it keeps the most weighted items per list.</p>
<p>TextSearch can also be used with SimilaritySearch methods. The initial code is identical to that needed by the inverted index</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> SimilaritySearch, TextSearch
julia<span class="pl-k">&gt;</span> url <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>http://ingeotec.mx/~sadit/emospace50k.json.gz<span class="pl-pds">"</span></span>
julia<span class="pl-k">&gt;</span> <span class="pl-k">!</span><span class="pl-c1">isfile</span>(<span class="pl-c1">basename</span>(url)) <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">download</span>(url, <span class="pl-c1">basename</span>(url))
julia<span class="pl-k">&gt;</span> db <span class="pl-k">=</span> <span class="pl-c1">loadtweets</span>(<span class="pl-c1">basename</span>(url))
<span class="pl-c"><span class="pl-c">#</span> you can use a number of tokenizers, here we use character q-grams to improve support for informal writing</span>
julia<span class="pl-k">&gt;</span> config <span class="pl-k">=</span> <span class="pl-c1">TextConfig</span>(qlist<span class="pl-k">=</span>[<span class="pl-c1">4</span>], nlist<span class="pl-k">=</span>[])
julia<span class="pl-k">&gt;</span> corpus <span class="pl-k">=</span> [t[<span class="pl-s"><span class="pl-pds">"</span>text<span class="pl-pds">"</span></span>] <span class="pl-k">for</span> t <span class="pl-k">in</span> db]
julia<span class="pl-k">&gt;</span> model <span class="pl-k">=</span> <span class="pl-c1">fit</span>(VectorModel, config, corpus)
julia<span class="pl-k">&gt;</span> db <span class="pl-k">=</span> [<span class="pl-c1">vectorize</span>(model, TfidfModel, text) <span class="pl-k">for</span> text <span class="pl-k">in</span> corpus]
julia<span class="pl-k">&gt;</span> invindex <span class="pl-k">=</span> <span class="pl-c1">fit</span>(InvIndex, db)</pre></div>
<p>now, the code to use SimilaritySearch methods along with a brief comparison with inverted indexes</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> SimilaritySearch, SimilaritySearch
julia<span class="pl-k">&gt;</span> perf <span class="pl-k">=</span> <span class="pl-c1">Performance</span>(db, cosine_distance)
julia<span class="pl-k">&gt;</span> seq <span class="pl-k">=</span> <span class="pl-c1">fit</span>(Sequential, db)
julia<span class="pl-k">&gt;</span> knr <span class="pl-k">=</span> <span class="pl-c1">fit</span>(Knr, cosine_distance, db, k<span class="pl-k">=</span><span class="pl-c1">7</span>, numrefs<span class="pl-k">=</span><span class="pl-c1">1024</span>)
julia<span class="pl-k">&gt;</span> graph <span class="pl-k">=</span> <span class="pl-c1">fit</span>(SearchGraph, cosine_distance, db)
julia<span class="pl-k">&gt;</span> pruned1000 <span class="pl-k">=</span> <span class="pl-c1">prune</span>(invindex, <span class="pl-c1">1000</span>)
julia<span class="pl-k">&gt;</span> pruned300 <span class="pl-k">=</span> <span class="pl-c1">prune</span>(invindex, <span class="pl-c1">300</span>)
julia<span class="pl-k">&gt;</span> pruned100 <span class="pl-k">=</span> <span class="pl-c1">prune</span>(invindex, <span class="pl-c1">100</span>)
julia<span class="pl-k">&gt;</span> pruned30 <span class="pl-k">=</span> <span class="pl-c1">prune</span>(invindex, <span class="pl-c1">30</span>)
julia<span class="pl-k">&gt;</span> P <span class="pl-k">=</span> [
        <span class="pl-c1">probe</span>(perf, seq, cosine_distance),
        <span class="pl-c1">probe</span>(perf, knr, cosine_distance),
        <span class="pl-c1">probe</span>(perf, graph, cosine_distance),
        <span class="pl-c1">probe</span>(perf, invindex, cosine_distance),
        <span class="pl-c1">probe</span>(perf, pruned1000, cosine_distance),
        <span class="pl-c1">probe</span>(perf, pruned300, cosine_distance),
        <span class="pl-c1">probe</span>(perf, pruned100, cosine_distance),
        <span class="pl-c1">probe</span>(perf, pruned30, cosine_distance),
    ]
julia<span class="pl-k">&gt;</span> M <span class="pl-k">=</span> <span class="pl-c1">Array</span><span class="pl-c1">{Any}</span>(undef, <span class="pl-c1">9</span>, <span class="pl-c1">5</span>)
julia<span class="pl-k">&gt;</span> M[<span class="pl-c1">1</span>, :] <span class="pl-k">.=</span> [<span class="pl-s"><span class="pl-pds">"</span>index<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>distances_sum<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>evaluations_ratio<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>queries_by_second<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>recall<span class="pl-pds">"</span></span>]
julia<span class="pl-k">&gt;</span> <span class="pl-k">for</span> (i, p) <span class="pl-k">in</span> <span class="pl-c1">zip</span>(
            [<span class="pl-s"><span class="pl-pds">"</span>seq<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>knr<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>graph<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>invindex<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>pruned1000<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>pruned300<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>pruned100<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>pruned30<span class="pl-pds">"</span></span>],
            [p<span class="pl-k">.</span>distances_sum<span class="pl-k">/</span>P[<span class="pl-c1">1</span>]<span class="pl-k">.</span>distances_sum <span class="pl-k">for</span> p <span class="pl-k">in</span> P],
            [p<span class="pl-k">.</span>evaluations<span class="pl-k">/</span>P[<span class="pl-c1">1</span>]<span class="pl-k">.</span>evaluations <span class="pl-k">for</span> p <span class="pl-k">in</span> P],
            [<span class="pl-c1">1</span><span class="pl-k">/</span>p<span class="pl-k">.</span>seconds <span class="pl-k">for</span> p <span class="pl-k">in</span> P],
            [p<span class="pl-k">.</span>recall <span class="pl-k">for</span> p <span class="pl-k">in</span> P]) <span class="pl-k">|&gt;</span> enumerate
       M[i<span class="pl-k">+</span><span class="pl-c1">1</span>, :] <span class="pl-k">.=</span> p
       <span class="pl-k">end</span>

julia<span class="pl-k">&gt;</span> M
<span class="pl-c1">9</span><span class="pl-k">×</span><span class="pl-c1">5</span> Array{Any,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-s"><span class="pl-pds">"</span>index<span class="pl-pds">"</span></span>        <span class="pl-s"><span class="pl-pds">"</span>distances_sum<span class="pl-pds">"</span></span>   <span class="pl-s"><span class="pl-pds">"</span>evaluations_ratio<span class="pl-pds">"</span></span>      <span class="pl-s"><span class="pl-pds">"</span>queries_by_second<span class="pl-pds">"</span></span>   <span class="pl-s"><span class="pl-pds">"</span>recall<span class="pl-pds">"</span></span>
 <span class="pl-s"><span class="pl-pds">"</span>seq<span class="pl-pds">"</span></span>         <span class="pl-c1">1.0</span>               <span class="pl-c1">1.0</span>                      <span class="pl-c1">9.86785</span>               <span class="pl-c1">1.0</span>      
 <span class="pl-s"><span class="pl-pds">"</span>knr<span class="pl-pds">"</span></span>         <span class="pl-c1">1.01337</span>           <span class="pl-c1">0.0863964</span>               <span class="pl-c1">80.5455</span>                <span class="pl-c1">0.809028</span> 
 <span class="pl-s"><span class="pl-pds">"</span>graph<span class="pl-pds">"</span></span>       <span class="pl-c1">1.0091</span>            <span class="pl-c1">0.0519419</span>              <span class="pl-c1">162.02</span>                  <span class="pl-c1">0.864583</span> 
 <span class="pl-s"><span class="pl-pds">"</span>invindex<span class="pl-pds">"</span></span>    <span class="pl-c1">1.0</span>               <span class="pl-c1">0.0</span>                     <span class="pl-c1">79.3421</span>                <span class="pl-c1">0.998264</span> 
 <span class="pl-s"><span class="pl-pds">"</span>pruned1000<span class="pl-pds">"</span></span>  <span class="pl-c1">1.00196</span>           <span class="pl-c1">0.0</span>                    <span class="pl-c1">354.288</span>                 <span class="pl-c1">0.942708</span> 
 <span class="pl-s"><span class="pl-pds">"</span>pruned300<span class="pl-pds">"</span></span>   <span class="pl-c1">1.00568</span>           <span class="pl-c1">0.0</span>                    <span class="pl-c1">703.035</span>                 <span class="pl-c1">0.875</span>    
 <span class="pl-s"><span class="pl-pds">"</span>pruned100<span class="pl-pds">"</span></span>   <span class="pl-c1">1.01031</span>           <span class="pl-c1">0.0</span>                   <span class="pl-c1">1608.57</span>                  <span class="pl-c1">0.762153</span> 
 <span class="pl-s"><span class="pl-pds">"</span>pruned30<span class="pl-pds">"</span></span>    <span class="pl-c1">1.01843</span>           <span class="pl-c1">0.0</span>                   <span class="pl-c1">5013.6</span>                   <span class="pl-c1">0.625868</span></pre></div>
<p>As you may see, prunning an inverted index improves the search speed significantly with
a small impact in the recall. The sum of distances is also barely impacted. The <code>�SearchGraph</code> and
<code>Knr</code> indexes perform relatively good, but inverted indexes are much better; that is why we need specialized methods like those provided in <code>TextSearch.jl</code> package. In any case, the approximation ratio is small, as indicated by the <code>distances_sum</code> ratio. Notice that it is possible to have a good distance approximation factor with bad recall, in this sense, recall is a more strict score.
In particular, the scalability of the pruned inverted index is almost independent of the size of the dataset, being dependent mostly in the number of tokens in the query; of course, it is also dependent of the size of the pruned posting list.</p>
</article></div>