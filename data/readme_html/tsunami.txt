<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/CarloLucibello/Tsunami.jl/main/docs/src/assets/the_great_wave.jpg"><img align="right" width="200px" src="https://raw.githubusercontent.com/CarloLucibello/Tsunami.jl/main/docs/src/assets/the_great_wave.jpg" style="max-width: 100%;"></a></p>
<h1 dir="auto"><a id="user-content-tsunamijl" class="anchor" aria-hidden="true" href="#tsunamijl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Tsunami.jl</h1>
<p dir="auto"><a href="https://CarloLucibello.github.io/Tsunami.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/CarloLucibello/Tsunami.jl/actions/workflows/ci.yml/badge.svg"><img src="https://github.com/CarloLucibello/Tsunami.jl/actions/workflows/ci.yml/badge.svg" alt="" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/CarloLucibello/Tsunami.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/fc7934740e4cae7cb959bc71a4e474f6d30a5ff298bb5d45a4f33593d4217281/68747470733a2f2f636f6465636f762e696f2f67682f4361726c6f4c75636962656c6c6f2f5473756e616d692e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d556867437a734871684d" alt="codecov" data-canonical-src="https://codecov.io/gh/CarloLucibello/Tsunami.jl/branch/main/graph/badge.svg?token=UhgCzsHqhM" style="max-width: 100%;"></a></p>
<p dir="auto">A high-level deep learning framework for the Julia language that helps you focus and organize the relevant part of your code while removing the boilerplate.</p>
<p dir="auto">Tsunami  is built on top of <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> and it is heavily inspired by <a href="https://pytorch-lightning.readthedocs.io/en/latest/" rel="nofollow">pytorch-lightning</a> (although <a href="https://www.pytorchlightning.ai/index.html" rel="nofollow">LightningAI</a> is not involved in this project).</p>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">Install Tsunami with</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="pkg&gt; add Tsunami"><pre>pkg<span class="pl-k">&gt;</span> add Tsunami</pre></div>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">Define your model subtyping the <code>FluxModule</code> abstract type, implement a few required methods, then let the <code>Trainer</code> train the model on your dataset with <code>Tsunami.fit</code>. Tsunami will handle all of the boilerplate (training loop, loggin, gpu movement, validation, ...).</p>
<p dir="auto">In the following script we train a Multilayer Perceptron on the FashionMNIST dataset using Tsunami:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Flux, Optimisers, Statistics, Tsunami, MLDatasets
using MLUtils: DataLoader, flatten, mapobs

## Define the model 

mutable struct MLP &lt;: FluxModule
    net
end

MLP() = MLP(Chain(flatten,
                Dense(28^2 =&gt; 512, relu), 
                Dense(512 =&gt; 10)))

(model::MLP)(x) = model.net(x)

function loss_and_accuracy(model::MLP, batch)
    x, y = batch
    ŷ = model(x)
    return Flux.logitcrossentropy(ŷ, y), Tsunami.accuracy(ŷ, y)
end

function Tsunami.train_step(model::MLP, trainer, batch)
    loss, acc = loss_and_accuracy(model, batch)
    Tsunami.log(trainer, &quot;loss/train&quot;, loss, prog_bar=true)
    Tsunami.log(trainer, &quot;accuracy/train&quot;, acc, prog_bar=true)
    return loss
end

function Tsunami.val_step(model::MLP, trainer, batch)
    loss, acc = loss_and_accuracy(model, batch)
    Tsunami.log(trainer, &quot;loss/val&quot;, loss)
    Tsunami.log(trainer, &quot;accuracy/val&quot;, acc)
end

Tsunami.configure_optimisers(model::MLP, trainer) = 
    Optimisers.setup(Optimisers.AdamW(1e-3), model)

## Prepare the data

function mnist_transform(batch)
    x, y = batch
    y = Flux.onehotbatch(y, 0:9)
    return (x, y)
end

train_data = FashionMNIST(split=:train)
train_data = mapobs(mnist_transform, train_data)[:]
train_loader = DataLoader(train_data, batchsize=128, shuffle=true)

test_data = FashionMNIST(split=:test)
test_data = mapobs(mnist_transform, test_data)[:]
test_loader = DataLoader(test_data, batchsize=128)

## Create and train the model

model = MLP()
trainer = Trainer(max_epochs=5)
model, fit_state = Tsunami.fit(model, trainer, train_loader, test_loader)"><pre><span class="pl-k">using</span> Flux, Optimisers, Statistics, Tsunami, MLDatasets
<span class="pl-k">using</span> MLUtils<span class="pl-k">:</span> DataLoader, flatten, mapobs

<span class="pl-c"><span class="pl-c">#</span># Define the model </span>

<span class="pl-k">mutable struct</span> MLP <span class="pl-k">&lt;:</span> <span class="pl-c1">FluxModule</span>
    net
<span class="pl-k">end</span>

<span class="pl-en">MLP</span>() <span class="pl-k">=</span> <span class="pl-c1">MLP</span>(<span class="pl-c1">Chain</span>(flatten,
                <span class="pl-c1">Dense</span>(<span class="pl-c1">28</span><span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">512</span>, relu), 
                <span class="pl-c1">Dense</span>(<span class="pl-c1">512</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">10</span>)))

(model<span class="pl-k">::</span><span class="pl-c1">MLP</span>)(x) <span class="pl-k">=</span> model<span class="pl-k">.</span><span class="pl-c1">net</span>(x)

<span class="pl-k">function</span> <span class="pl-en">loss_and_accuracy</span>(model<span class="pl-k">::</span><span class="pl-c1">MLP</span>, batch)
    x, y <span class="pl-k">=</span> batch
    ŷ <span class="pl-k">=</span> <span class="pl-c1">model</span>(x)
    <span class="pl-k">return</span> Flux<span class="pl-k">.</span><span class="pl-c1">logitcrossentropy</span>(ŷ, y), Tsunami<span class="pl-k">.</span><span class="pl-c1">accuracy</span>(ŷ, y)
<span class="pl-k">end</span>

<span class="pl-k">function</span> Tsunami<span class="pl-k">.</span><span class="pl-en">train_step</span>(model<span class="pl-k">::</span><span class="pl-c1">MLP</span>, trainer, batch)
    loss, acc <span class="pl-k">=</span> <span class="pl-c1">loss_and_accuracy</span>(model, batch)
    Tsunami<span class="pl-k">.</span><span class="pl-c1">log</span>(trainer, <span class="pl-s"><span class="pl-pds">"</span>loss/train<span class="pl-pds">"</span></span>, loss, prog_bar<span class="pl-k">=</span><span class="pl-c1">true</span>)
    Tsunami<span class="pl-k">.</span><span class="pl-c1">log</span>(trainer, <span class="pl-s"><span class="pl-pds">"</span>accuracy/train<span class="pl-pds">"</span></span>, acc, prog_bar<span class="pl-k">=</span><span class="pl-c1">true</span>)
    <span class="pl-k">return</span> loss
<span class="pl-k">end</span>

<span class="pl-k">function</span> Tsunami<span class="pl-k">.</span><span class="pl-en">val_step</span>(model<span class="pl-k">::</span><span class="pl-c1">MLP</span>, trainer, batch)
    loss, acc <span class="pl-k">=</span> <span class="pl-c1">loss_and_accuracy</span>(model, batch)
    Tsunami<span class="pl-k">.</span><span class="pl-c1">log</span>(trainer, <span class="pl-s"><span class="pl-pds">"</span>loss/val<span class="pl-pds">"</span></span>, loss)
    Tsunami<span class="pl-k">.</span><span class="pl-c1">log</span>(trainer, <span class="pl-s"><span class="pl-pds">"</span>accuracy/val<span class="pl-pds">"</span></span>, acc)
<span class="pl-k">end</span>

Tsunami<span class="pl-k">.</span><span class="pl-en">configure_optimisers</span>(model<span class="pl-k">::</span><span class="pl-c1">MLP</span>, trainer) <span class="pl-k">=</span> 
    Optimisers<span class="pl-k">.</span><span class="pl-c1">setup</span>(Optimisers<span class="pl-k">.</span><span class="pl-c1">AdamW</span>(<span class="pl-c1">1e-3</span>), model)

<span class="pl-c"><span class="pl-c">#</span># Prepare the data</span>

<span class="pl-k">function</span> <span class="pl-en">mnist_transform</span>(batch)
    x, y <span class="pl-k">=</span> batch
    y <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">onehotbatch</span>(y, <span class="pl-c1">0</span><span class="pl-k">:</span><span class="pl-c1">9</span>)
    <span class="pl-k">return</span> (x, y)
<span class="pl-k">end</span>

train_data <span class="pl-k">=</span> <span class="pl-c1">FashionMNIST</span>(split<span class="pl-k">=</span><span class="pl-c1">:train</span>)
train_data <span class="pl-k">=</span> <span class="pl-c1">mapobs</span>(mnist_transform, train_data)[:]
train_loader <span class="pl-k">=</span> <span class="pl-c1">DataLoader</span>(train_data, batchsize<span class="pl-k">=</span><span class="pl-c1">128</span>, shuffle<span class="pl-k">=</span><span class="pl-c1">true</span>)

test_data <span class="pl-k">=</span> <span class="pl-c1">FashionMNIST</span>(split<span class="pl-k">=</span><span class="pl-c1">:test</span>)
test_data <span class="pl-k">=</span> <span class="pl-c1">mapobs</span>(mnist_transform, test_data)[:]
test_loader <span class="pl-k">=</span> <span class="pl-c1">DataLoader</span>(test_data, batchsize<span class="pl-k">=</span><span class="pl-c1">128</span>)

<span class="pl-c"><span class="pl-c">#</span># Create and train the model</span>

model <span class="pl-k">=</span> <span class="pl-c1">MLP</span>()
trainer <span class="pl-k">=</span> <span class="pl-c1">Trainer</span>(max_epochs<span class="pl-k">=</span><span class="pl-c1">5</span>)
model, fit_state <span class="pl-k">=</span> Tsunami<span class="pl-k">.</span><span class="pl-c1">fit</span>(model, trainer, train_loader, test_loader)</pre></div>
<p dir="auto">What follows is the final output of the script. The script will train the model on CUDA gpus if available and will also write tensorboard logs and and model checkpoints on disk.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/CarloLucibello/Tsunami.jl/main/docs/src/assets/readme_output.png"><img src="https://raw.githubusercontent.com/CarloLucibello/Tsunami.jl/main/docs/src/assets/readme_output.png" style="max-width: 100%;"></a></p>
<p dir="auto">See the <a href="https://carlolucibello.github.io/Tsunami.jl/dev/" rel="nofollow">documentation</a> and check the <a href="https://github.com/CarloLucibello/Tsunami.jl/tree/main/examples">examples</a> folder to learn more.</p>
<h2 dir="auto"><a id="user-content-features" class="anchor" aria-hidden="true" href="#features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Features</h2>
<ul dir="auto">
<li>Use <code>Tsunami.fit</code> instead of implementing a training loop.</li>
<li>Logging (tensorboard).</li>
<li>Checkpoints (save and resume training).</li>
<li>Hyperparameters' schedulers.</li>
<li>GPU movement.</li>
</ul>
<h2 dir="auto"><a id="user-content-contributions-are-welcome" class="anchor" aria-hidden="true" href="#contributions-are-welcome"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributions are welcome!</h2>
<p dir="auto">If you want to contribute to Tsunami, please open an issue or a pull request.
Any help is appreciated!</p>
<h2 dir="auto"><a id="user-content-similar-julia-libraries" class="anchor" aria-hidden="true" href="#similar-julia-libraries"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Similar julia libraries</h2>
<ul dir="auto">
<li><a href="https://github.com/FluxML/FastAI.jl">FastAI.jl</a></li>
<li><a href="https://github.com/FluxML/FluxTraining.jl">FluxTraining.jl</a></li>
</ul>
</article></div>