<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-neural-arithmetic" class="anchor" aria-hidden="true" href="#neural-arithmetic"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Neural Arithmetic</h1>
<p><a href="https://travis-ci.com/nmheim/NeuralArithmetic.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/2124a46fc2f0ca9733d95ba1cfe2185f47771c1b/68747470733a2f2f7472617669732d63692e636f6d2f6e6d6865696d2f4e657572616c41726974686d657469632e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/nmheim/NeuralArithmetic.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/nmheim/NeuralArithmetic.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/05722f3bb1dec1a478a71c42fb8b06872e86ef03/68747470733a2f2f636f6465636f762e696f2f67682f6e6d6865696d2f4e657572616c41726974686d657469632e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/nmheim/NeuralArithmetic.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p>Collection of layers that can perform arithmetic operations such as addition,
subtraction, multiplication, and division in a single layer.  Implements
<a href="https://arxiv.org/abs/1808.00508" rel="nofollow">NALU</a>,
<a href="https://arxiv.org/abs/2003.07629" rel="nofollow">iNALU</a>,
<a href="https://openreview.net/forum?id=H1gNOeHKPS" rel="nofollow">NMU &amp; NAU</a>, and <a href="https://arxiv.org/abs/2006.01681" rel="nofollow">NPU</a>.</p>
<p>And additionally <code>FastNAU</code> and <code>FastNPU</code> for use with <a href="https://github.com/SciML/DiffEqFlux.jl">DiffEqFlux.jl</a>.</p>
<h1><a id="user-content-simple-neural-arithmetic" class="anchor" aria-hidden="true" href="#simple-neural-arithmetic"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Simple Neural Arithmetic</h1>
<p>As an example, we can train different layers to learn the function</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-en">f</span>(x,y) <span class="pl-k">=</span> (x<span class="pl-k">+</span>y, x<span class="pl-k">*</span>y, <span class="pl-c1">1</span><span class="pl-k">/</span>x, <span class="pl-c1">sqrt</span>(x))</pre></div>
<p>which has two inputs and four outputs. For mo.  The figure below plots the error
of each layer and arithmetic operation in <code>f</code> for training and testing datapoints.  All layers
were trained on the input range U(0.1,2). For more details take a look at <a href="https://arxiv.org/abs/2006.01681" rel="nofollow">our paper</a>.</p>
<p><a target="_blank" rel="noopener noreferrer" href="img/layers.png"><img src="img/layers.png" alt="layers" style="max-width:100%;"></a></p>
</article></div>