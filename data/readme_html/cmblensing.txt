<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-cmblensingjl" class="anchor" aria-hidden="true" href="#cmblensingjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>CMBLensing.jl</h1>
<p dir="auto"><a href="https://cosmicmar.com/CMBLensing.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a> <a href="https://gitter.im/CMBLensing-jl/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge" rel="nofollow"><img src="https://camo.githubusercontent.com/a7993aa72b0ca78af4191651e79e6fccacfeb241ce9807abc050c063d108f635/68747470733a2f2f6261646765732e6769747465722e696d2f434d424c656e73696e672d6a6c2f636f6d6d756e6974792e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/CMBLensing-jl/community.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><a href="https://github.com/marius311/CMBLensing.jl"><img src="https://camo.githubusercontent.com/4c4ff035af4488c96390ddc7b82358933015e6769459fa6a0b86602109f28d23/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736f757263652d6769746875622d626c7565" alt="" data-canonical-src="https://img.shields.io/badge/source-github-blue" style="max-width: 100%;"></a>  <a href="https://mybinder.org/v2/gh/marius311/CMBLensing.jl/gh-pages?urlpath=lab" rel="nofollow"><img src="https://camo.githubusercontent.com/581c077bdbc6ca6899c86d0acc6145ae85e9d80e6f805a1071793dbe48917982/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge_logo.svg" style="max-width: 100%;"></a>
<a href="https://github.com/marius311/CMBLensing.jl/actions?query=workflow%3Aruntests+branch%3Amaster"><img src="https://github.com/marius311/CMBLensing.jl/workflows/runtests/badge.svg" alt="" style="max-width: 100%;"></a> <a href="https://github.com/marius311/CMBLensing.jl/actions?query=workflow%3Adocbuild+branch%3Amaster"><img src="https://github.com/marius311/CMBLensing.jl/workflows/docbuild/badge.svg" alt="" style="max-width: 100%;"></a></p>
<p dir="auto">CMBLensing.jl is a next-generation tool for analysis of the lensed Cosmic Microwave Background. It is written in <a href="https://julialang.org/" rel="nofollow">Julia</a> and transparently callable from Python.</p>
<p dir="auto">At its heart, CMBLensing.jl maximizes, samples, or performs MUSE inference on the Bayesian posterior for the CMB lensing problem. It also contains tools to quickly manipulate and process CMB maps, set up modified posteriors with a probabilistic programming language, and take gradients using automatic differentiation.</p>
<h3 dir="auto"><a id="user-content-highlights" class="anchor" aria-hidden="true" href="#highlights"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Highlights</h3>
<ul dir="auto">
<li>Fully Nvidia GPU compatible (1-2 orders of magnitude speedups over CPU, depending on the problem size and hardware).</li>
<li>Automatic differentiation (via <a href="https://fluxml.ai/Zygote.jl/" rel="nofollow">Zygote.jl</a>) provides for-free gradients of your custom posteriors.</li>
<li>Includes the following algorithms to lense a map:
<ul dir="auto">
<li>
<code>LenseFlow</code> (<a href="https://arxiv.org/abs/1708.06753" rel="nofollow">Millea, Anderes, &amp; Wandelt 2017</a>)</li>
<li>
<code>Taylens</code> (<a href="https://arxiv.org/abs/1307.0719" rel="nofollow">NÃ¦ss &amp; Louis 2013</a>)</li>
<li>Taylor series expansion to any order</li>
<li>Bilinear interpolation</li>
</ul>
</li>
<li>Maximize and sample <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$\mathcal{P}(f,\phi,\theta,|,d)$</math-renderer>, the joint maximum a posteriori estimate of the lensing potential, <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$\phi$</math-renderer>, the  temperature and/or polarization fields, <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$f$</math-renderer>, and cosmological parameters, <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$\theta$</math-renderer> (<a href="https://arxiv.org/abs/1708.06753" rel="nofollow">Millea, Anderes, &amp; Wandelt 2017</a>, <a href="https://arxiv.org/abs/2002.00965" rel="nofollow">Millea, Anderes, &amp; Wandelt 2020</a>)</li>
<li>Maximize <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$\mathcal{P}(\phi,|,d,\theta)$</math-renderer>, i.e. the marginal maximum a posteriori estimate of the lensing potential, <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$\phi$</math-renderer>, at fixed cosmological parameters, <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$\theta$</math-renderer> (<a href="https://arxiv.org/abs/1704.08230" rel="nofollow">Carron &amp; Lewis 2017</a>)</li>
<li>Compute MUSE inferences of bandpowers of <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$\phi$</math-renderer> and unlensed <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$f$</math-renderer> via <a href="https://github.com/marius311/MuseInference.jl">MuseInference.jl</a> (<a href="https://arxiv.org/abs/2112.09354" rel="nofollow">Millea &amp; Seljak, 2021</a>).</li>
<li>Do basic quadratic estimation of <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$\phi$</math-renderer> (<a href="https://arxiv.org/abs/astro-ph/0111606" rel="nofollow">Hu &amp; Okamoto 2003</a>)</li>
</ul>
<h2 dir="auto">
<a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Documentation</h2>
<p dir="auto">The best place to get started is to read the <a href="https://cosmicmar.com/CMBLensing.jl/" rel="nofollow">documentation</a> (which is a work-in-progress, but contains many useful examples).</p>
<p dir="auto">Most of the pages in the documentation are Jupyter notebooks, and you can click the "launch binder" link at the top of each page to launch a Jupyterlab server running the notebook in your browser (courtesy of <a href="https://mybinder.org/" rel="nofollow">binder</a>).</p>
<p dir="auto">You can also clone the repository and open the notebooks in <a href="https://github.com/marius311/CMBLensing.jl/tree/master/docs/src">docs/src</a> if you want to run them locally (which will usually lead to higher performance). The notebooks are stored as <code>.md</code> files rather than <code>.ipynb</code> format. Its recommended to install <a href="jupytext">Jupytext</a> (<code>pip install jupytext</code>) and then you can run these <code>.md</code> directly from Jupyterlab by right-clicking on them and selecting <code>Open With -&gt; Notebook</code>. Otherwise, run the script <code>docs/make_notebooks.sh</code> to convert the <code>.md</code> files to <code>.ipynb</code> which you can then open as desired.</p>
<h2 dir="auto">
<a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<h3 dir="auto">
<a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Requirements</h3>
<ul dir="auto">
<li>Julia 1.7+</li>
<li>
<em>(recommended)</em> An Nvidia GPU and <a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a> for GPU support</li>
<li>
<em>(recommended)</em> Python 3 + matplotlib (used for plotting)</li>
<li>
<em>(recommended)</em> <a href="https://github.com/cmbant/CAMB">pycamb</a> to generate <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="8485e4f814ab10c25f59a18ab2e61dbf">$C_\ell$</math-renderer>'s (run <code>pip install --user camb</code>)</li>
<li>
<em>(recommended)</em> <a href="https://github.com/cormullion/juliamono/releases">JuliaMono</a> font to ensure characters like <code>fÌ, Ï, â, â</code>, etc... are rendered correctly</li>
</ul>
<h3 dir="auto">
<a id="user-content-native-installation" class="anchor" aria-hidden="true" href="#native-installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Native installation</h3>
<p dir="auto">To install the Julia package locally, run:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pkg&gt; add CMBLensing"><pre lang="juliapkg" class="notranslate"><code>pkg&gt; add CMBLensing
</code></pre></div>
<p dir="auto">(type <code>]</code> at the Julia REPL to reach the <code>pkg&gt;</code> prompt)</p>
<p dir="auto"><em>(recommended)</em> After installing, switch your Julia to use Intel MKL FFT libraries, which provide significantly faster FFTs when running on CPU. You can do so by running <code>using CMBLensing.FFTW; FFTW.set_provider!("mkl")</code> from the same environment in which you added CMBLensing. This only needs to be done once per-environment (see also <a href="https://github.com/JuliaMath/FFTW.jl#mkl">here</a>).</p>
<h3 dir="auto">
<a id="user-content-docker-installation" class="anchor" aria-hidden="true" href="#docker-installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Docker installation</h3>
<p dir="auto">Also provided is a Docker container which includes a Jupyterlab server and all the recommended and optional dependencies to run and use <code>CMBLensing.jl</code>. Launch this container with:</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/marius311/CMBLensing.jl.git
cd CMBLensing.jl
docker-compose pull main
docker-compose up main"><pre>git clone https://github.com/marius311/CMBLensing.jl.git
<span class="pl-c1">cd</span> CMBLensing.jl
docker-compose pull main
docker-compose up main</pre></div>
<p dir="auto">The first time you run this, it will automatically download the (~1Gb) container from the Docker hub. The command will prompt you with the URL which you should open in a browser to access the notebook.</p>
<p dir="auto">To run the notebook on a different port than the default <code>8888</code>, do <code>PORT=1234 docker-compose up main</code> where <code>1234</code> is whatever port number you want.</p>
<p dir="auto">You can also build the container locally by replacing <code>docker-compose pull main</code> with <code>docker-compose build main</code>.</p>
</article></div>