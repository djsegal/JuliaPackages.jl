<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-cmblensingjl" class="anchor" aria-hidden="true" href="#cmblensingjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>CMBLensing.jl</h1>
<p><a href="https://github.com/marius311/CMBLensing.jl"><img src="https://camo.githubusercontent.com/a5d203959accb117e9e1a28f87a9bb3d0aff941b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736f757263652d6769746875622d626c7565" alt="" data-canonical-src="https://img.shields.io/badge/source-github-blue" style="max-width:100%;"></a> <a href="https://cosmicmar.com/CMBLensing.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/f7b92a177c912c1cc007fc9b40f17ff3ee3bb414/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a> <a href="https://mybinder.org/v2/gh/marius311/CMBLensing.jl/gh-pages?urlpath=lab" rel="nofollow"><img src="https://camo.githubusercontent.com/483bae47a175c24dfbfc57390edd8b6982ac5fb3/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge_logo.svg" style="max-width:100%;"></a>
<a href="https://github.com/marius311/CMBLensing.jl/actions?query=workflow%3Aruntests+branch%3Amaster"><img src="https://github.com/marius311/CMBLensing.jl/workflows/runtests/badge.svg" alt="" style="max-width:100%;"></a> <a href="https://github.com/marius311/CMBLensing.jl/actions?query=workflow%3Adocbuild+branch%3Amaster"><img src="https://github.com/marius311/CMBLensing.jl/workflows/docbuild/badge.svg" alt="" style="max-width:100%;"></a></p>
<p>CMBLensing.jl is a next-generation tool for analysis of the lensed Cosmic Microwave Background. It is written in <a href="https://julialang.org/" rel="nofollow">Julia</a> and transparently callable from Python.</p>
<p>At its heart, CMBLensing.jl maximizes or samples the Bayesian posterior for the CMB lensing problem. It also contains tools to quickly manipulate and process CMB maps, set up modified posteriors, and take gradients using automatic differentation.</p>
<h3><a id="user-content-highlights" class="anchor" aria-hidden="true" href="#highlights"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Highlights</h3>
<ul>
<li>Fully Nvidia GPU compatible (speedups over CPU are currently 3x-10x, depending on the problem size and hardware).</li>
<li>Automatic differentation (via <a href="https://fluxml.ai/Zygote.jl/" rel="nofollow">Zygote.jl</a>) provides for-free gradients of your custom posteriors.</li>
<li>Includes the following algorithms to lense a map:
<ul>
<li><code>LenseFlow</code> (<a href="https://arxiv.org/abs/1708.06753" rel="nofollow">Millea, Anderes, &amp; Wandelt 2017</a>)</li>
<li><code>Taylens</code> (<a href="https://arxiv.org/abs/1307.0719" rel="nofollow">NÃ¦ss &amp; Louis 2013</a>)</li>
<li>Taylor series expansion to any order</li>
<li>Bilinear interpolation</li>
</ul>
</li>
<li>Maximize and sample $\mathcal{P}(f,\phi,\theta,|,d)$, the joint maximum a posteriori estimate of the lensing potential, $\phi$, the  temperature and/or polarization fields, $f$, and cosmological parameters, $\theta$ (<a href="https://arxiv.org/abs/1708.06753" rel="nofollow">Millea, Anderes, &amp; Wandelt 2017</a>, <a href="https://arxiv.org/abs/2002.00965" rel="nofollow">Millea, Anderes, &amp; Wandelt 2020</a>)</li>
<li>Maximize $\mathcal{P}(\phi,|,d,\theta)$, i.e. the marginal maximum a posteriori estimate of the lensing potential, $\phi$, at fixed cosmological parameters, $\theta$ (<a href="https://arxiv.org/abs/1704.08230" rel="nofollow">Carron &amp; Lewis 2017</a>)</li>
<li>Do basic quadratic estimation of $\phi$ (<a href="https://arxiv.org/abs/astro-ph/0111606" rel="nofollow">Hu &amp; Okamoto 2003</a>)</li>
</ul>
<h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Documentation</h2>
<p>The best place to get started is to read the <a href="https://cosmicmar.com/CMBLensing.jl/" rel="nofollow">documentation</a> (which is a work-in-progress, but contains many useful examples).</p>
<p>Most of the pages in the documentation are Jupyter notebooks, and you can click the "launch binder" link at the top of each page to launch a Jupyterlab server running the notebook in your browser (courtesy of <a href="https://mybinder.org/" rel="nofollow">binder</a>).</p>
<p>You can also clone the repostiory and open the notebooks in <a href="https://github.com/marius311/CMBLensing.jl/tree/master/docs/src">docs/src</a> if you want to run them locally (which will usually lead to higher performance). The notebooks are stored as <code>.md</code> files rather than <code>.ipynb</code> format. Its recommented to install <a href="jupytext">Jupytext</a> (<code>pip install jupytext</code>) and then you can run these <code>.md</code> directly from Jupyterlab by right-clicking on them and selecting <code>Open With -&gt; Notebook</code>. Otherwise, run the script <code>docs/make_notebooks.sh</code> to convert the <code>.md</code> files to <code>.ipynb</code> which you can then open as desired.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<h3><a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Requirements</h3>
<ul>
<li>Julia 1.3 or higher</li>
<li><em>(optional)</em> Python 3 + matplotlib (used for plotting)</li>
<li><em>(optional)</em> <a href="https://github.com/cmbant/CAMB">pycamb</a> to generate $C_\ell$'s</li>
<li><em>(optional)</em> An Nvidia GPU and <a href="https://github.com/JuliaGPU/CuArrays.jl">CuArrays</a> for GPU support</li>
<li><em>(optional)</em> <a href="https://github.com/healpy/healpy">healpy</a> for experimental curved sky support</li>
</ul>
<h3><a id="user-content-native-installation" class="anchor" aria-hidden="true" href="#native-installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Native installation</h3>
<p>To install the Julia package locally, run:</p>
<pre lang="juliapkg"><code>pkg&gt; add CMBLensing
</code></pre>
<p>(type <code>]</code> at the Julia REPL to reach the <code>pkg&gt;</code> prompt)</p>
<h3><a id="user-content-docker-installation" class="anchor" aria-hidden="true" href="#docker-installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Docker installation</h3>
<p>Also provided is a Docker container which includes a Jupyterlab server and all the recommended and optional dependencies to run and use <code>CMBLensing.jl</code>. Launch this container with:</p>
<div class="highlight highlight-source-shell"><pre>git clone https://github.com/marius311/CMBLensing.jl.git
<span class="pl-c1">cd</span> CMBLensing.jl
docker-compose pull
docker-compose up</pre></div>
<p>The first time you run this, it will automatically download the (~1Gb) container from the Docker hub. The command will prompt you with the URL which you should open in a browser to access the notebook.</p>
<p>To run the notebook on a different port than the default <code>8888</code>, do <code>PORT=1234 docker-compose up</code> where <code>1234</code> is whatever port number you want.</p>
<p>You can also build the container locally by replacing <code>docker-compose pull</code> with <code>docker-compose build</code> above.</p>
</article></div>