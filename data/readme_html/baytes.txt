<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-baytes" class="anchor" aria-hidden="true" href="#baytes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Baytes</h1>

<p dir="auto"><a href="https://paschermayr.github.io/Baytes.jl/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Documentation, Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/paschermayr/Baytes.jl/actions/workflows/CI.yml?query=branch%3Amain"><img src="https://github.com/paschermayr/Baytes.jl/actions/workflows/CI.yml/badge.svg?branch=main" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/paschermayr/Baytes.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/c1fac1082eea6e11db2240de5207e6df144aedc161a1b3ece274937be932b15f/68747470733a2f2f636f6465636f762e696f2f67682f706173636865726d6179722f4261797465732e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/paschermayr/Baytes.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a>
<a href="https://github.com/SciML/ColPrac"><img src="https://camo.githubusercontent.com/a6c1efcb19a957860ecb25966a730260b03d6e05380d0c27992ee7f9e3b1feb3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f6c507261632d436f6e7472696275746f72277325323047756964652d626c756576696f6c6574" alt="ColPrac: Contributor's Guide on Collaborative Practices for Community Packages" data-canonical-src="https://img.shields.io/badge/ColPrac-Contributor's%20Guide-blueviolet" style="max-width: 100%;"></a></p>
<p dir="auto">Baytes.jl is a sampling library to perform Monte Carlo proposal steps. It consists of several sub-libraries, such as <a href="https://github.com/paschermayr/BaytesMCMC.jl">BaytesMCMC.jl</a>, <a href="https://github.com/paschermayr/BaytesFilters.jl">BaytesFilters.jl</a>, <a href="https://github.com/paschermayr/BaytesPMCMC.jl">BaytesPMCMC.jl</a> and <a href="https://github.com/paschermayr/BaytesSMC.jl">BaytesSMC.jl</a>, and provides an interface to combine kernels from these libraries.</p>
<h2 dir="auto"><a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Introduction</h2>
<p dir="auto">In order to start, we have to define parameter and an objective function first. Let us use the model initially defined in the <a href="https://github.com/paschermayr/ModelWrappers.jl">ModelWrappers.jl</a> introduction:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ModelWrappers, Baytes
using Distributions, Random, UnPack
_rng = Random.GLOBAL_RNG

#Create initial model and data
myparameter = (μ = Param(Normal(), 2.0), σ = Param(Gamma(), 3.0))
mymodel = ModelWrapper(myparameter)
data = randn(1000)
#Create objective for both μ and σ and define a target function for it
myobjective = Objective(mymodel, data, (:μ, :σ))
function (objective::Objective{&lt;:ModelWrapper{BaseModel}})(θ::NamedTuple)
	@unpack data = objective
	lprior = Distributions.logpdf(Distributions.Normal(),θ.μ) + Distributions.logpdf(Distributions.Exponential(), θ.σ)
    llik = sum(Distributions.logpdf( Distributions.Normal(θ.μ, θ.σ), data[iter] ) for iter in eachindex(data))
	return lprior + llik
end"><pre><span class="pl-k">using</span> ModelWrappers, Baytes
<span class="pl-k">using</span> Distributions, Random, UnPack
_rng <span class="pl-k">=</span> Random<span class="pl-k">.</span>GLOBAL_RNG

<span class="pl-c"><span class="pl-c">#</span>Create initial model and data</span>
myparameter <span class="pl-k">=</span> (μ <span class="pl-k">=</span> <span class="pl-c1">Param</span>(<span class="pl-c1">Normal</span>(), <span class="pl-c1">2.0</span>), σ <span class="pl-k">=</span> <span class="pl-c1">Param</span>(<span class="pl-c1">Gamma</span>(), <span class="pl-c1">3.0</span>))
mymodel <span class="pl-k">=</span> <span class="pl-c1">ModelWrapper</span>(myparameter)
data <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">1000</span>)
<span class="pl-c"><span class="pl-c">#</span>Create objective for both μ and σ and define a target function for it</span>
myobjective <span class="pl-k">=</span> <span class="pl-c1">Objective</span>(mymodel, data, (<span class="pl-c1">:μ</span>, <span class="pl-c1">:σ</span>))
<span class="pl-k">function</span> (objective<span class="pl-k">::</span><span class="pl-c1">Objective{&lt;:ModelWrapper{BaseModel}}</span>)(θ<span class="pl-k">::</span><span class="pl-c1">NamedTuple</span>)
	<span class="pl-c1">@unpack</span> data <span class="pl-k">=</span> objective
	lprior <span class="pl-k">=</span> Distributions<span class="pl-k">.</span><span class="pl-c1">logpdf</span>(Distributions<span class="pl-k">.</span><span class="pl-c1">Normal</span>(),θ<span class="pl-k">.</span>μ) <span class="pl-k">+</span> Distributions<span class="pl-k">.</span><span class="pl-c1">logpdf</span>(Distributions<span class="pl-k">.</span><span class="pl-c1">Exponential</span>(), θ<span class="pl-k">.</span>σ)
    llik <span class="pl-k">=</span> <span class="pl-c1">sum</span>(Distributions<span class="pl-k">.</span><span class="pl-c1">logpdf</span>( Distributions<span class="pl-k">.</span><span class="pl-c1">Normal</span>(θ<span class="pl-k">.</span>μ, θ<span class="pl-k">.</span>σ), data[iter] ) <span class="pl-k">for</span> iter <span class="pl-k">in</span> <span class="pl-c1">eachindex</span>(data))
	<span class="pl-k">return</span> lprior <span class="pl-k">+</span> llik
<span class="pl-k">end</span></pre></div>
<p dir="auto">Sampling this model is straightforward. For instance, we can jointly estimate μ and σ via NUTS:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="trace1, algorithm1 = sample(_rng, mymodel, data, NUTS((:μ, :σ)))"><pre>trace1, algorithm1 <span class="pl-k">=</span> <span class="pl-c1">sample</span>(_rng, mymodel, data, <span class="pl-c1">NUTS</span>((<span class="pl-c1">:μ</span>, <span class="pl-c1">:σ</span>)))</pre></div>
<p dir="auto"><code>Trace.val</code> contains samples stored as <code>NamedTuple</code>. <code>Trace.diagnostics</code> contains diagnostics that were returned when sampling the corresponding parameter. <code>Trace.info</code> contains useful summary information printing and summarizing the parameter estimates. <code>Algorithm</code> returns the kernel that was used and tuned during the sampling process. Note that a new kernel is initiated for each chain separately.</p>
<p dir="auto">Alternatively, you might want to sample parameter with different kernels. This is usually useful when working with state space models.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="trace2, algorithm2 = sample(_rng, mymodel, data, NUTS((:μ, )), Metropolis( (:σ,) ))"><pre>trace2, algorithm2 <span class="pl-k">=</span> <span class="pl-c1">sample</span>(_rng, mymodel, data, <span class="pl-c1">NUTS</span>((<span class="pl-c1">:μ</span>, )), <span class="pl-c1">Metropolis</span>( (<span class="pl-c1">:σ</span>,) ))</pre></div>
<h2 dir="auto"><a id="user-content-advanced-usage" class="anchor" aria-hidden="true" href="#advanced-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Advanced usage</h2>
<p dir="auto">Similar to other Baytes packages, sampling arguments may be tweaked via a <code>Default</code> struct.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="sampledefault = SampleDefault(;
    dataformat=Batch(),
    tempering=IterationTempering(Float64, UpdateFalse(), 1.0, 1000),
    chains=4,
    iterations=2000,
    burnin=max(1, Int64(floor(2000/10))),
    thinning = 1,
    safeoutput=false,
    printoutput=true,
    printdefault=PrintDefault(),
    report=ProgressReport(),
)
trace3, algorithm3 = sample(_rng, mymodel, data, NUTS((:μ, :σ)); default = sampledefault)"><pre>sampledefault <span class="pl-k">=</span> <span class="pl-c1">SampleDefault</span>(;
    dataformat<span class="pl-k">=</span><span class="pl-c1">Batch</span>(),
    tempering<span class="pl-k">=</span><span class="pl-c1">IterationTempering</span>(Float64, <span class="pl-c1">UpdateFalse</span>(), <span class="pl-c1">1.0</span>, <span class="pl-c1">1000</span>),
    chains<span class="pl-k">=</span><span class="pl-c1">4</span>,
    iterations<span class="pl-k">=</span><span class="pl-c1">2000</span>,
    burnin<span class="pl-k">=</span><span class="pl-c1">max</span>(<span class="pl-c1">1</span>, <span class="pl-c1">Int64</span>(<span class="pl-c1">floor</span>(<span class="pl-c1">2000</span><span class="pl-k">/</span><span class="pl-c1">10</span>))),
    thinning <span class="pl-k">=</span> <span class="pl-c1">1</span>,
    safeoutput<span class="pl-k">=</span><span class="pl-c1">false</span>,
    printoutput<span class="pl-k">=</span><span class="pl-c1">true</span>,
    printdefault<span class="pl-k">=</span><span class="pl-c1">PrintDefault</span>(),
    report<span class="pl-k">=</span><span class="pl-c1">ProgressReport</span>(),
)
trace3, algorithm3 <span class="pl-k">=</span> <span class="pl-c1">sample</span>(_rng, mymodel, data, <span class="pl-c1">NUTS</span>((<span class="pl-c1">:μ</span>, <span class="pl-c1">:σ</span>)); default <span class="pl-k">=</span> sampledefault)</pre></div>
<p dir="auto">Note that hyperparameter that are specific to any kernel will have to be assigned in the MCMC constructor itself, i.e.:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="mcmc4 = HMC((:μ,); proposal = ConfigProposal(; metric = MDense()), GradientBackend = :ReverseDiff,)
trace4, algorithm4 = sample(_rng, mymodel, data, mcmc4; default = sampledefault)"><pre>mcmc4 <span class="pl-k">=</span> <span class="pl-c1">HMC</span>((<span class="pl-c1">:μ</span>,); proposal <span class="pl-k">=</span> <span class="pl-c1">ConfigProposal</span>(; metric <span class="pl-k">=</span> <span class="pl-c1">MDense</span>()), GradientBackend <span class="pl-k">=</span> <span class="pl-c1">:ReverseDiff</span>,)
trace4, algorithm4 <span class="pl-k">=</span> <span class="pl-c1">sample</span>(_rng, mymodel, data, mcmc4; default <span class="pl-k">=</span> sampledefault)</pre></div>
<p dir="auto">You can reuse returned <code>algorithm</code> container to sample again with the pre-tuned kernels. In this this case, on can call <code>sample!</code>. The information in <code>trace</code> will assure that sampling is continued with the correct specifications. After <code>sample!</code> is finished, a new trace is returned that contains sampling information.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="iterations = 10^3
trace5, algorithm4 = sample!(iterations, _rng, mymodel, data, trace4, algorithm4)"><pre>iterations <span class="pl-k">=</span> <span class="pl-c1">10</span><span class="pl-k">^</span><span class="pl-c1">3</span>
trace5, algorithm4 <span class="pl-k">=</span> <span class="pl-c1">sample!</span>(iterations, _rng, mymodel, data, trace4, algorithm4)</pre></div>
<h2 dir="auto"><a id="user-content-inference" class="anchor" aria-hidden="true" href="#inference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Inference</h2>
<p dir="auto">Per default, <code>sample</code> and <code>sample!</code> return summary information of the chain and diagnostics using MCMCDiagnosticTools.jl, unless <code>printdefault = false</code>. For further inference, one can manually convert <code>trace.val</code> into a 3D-array that is compatible with MCMCChains.jl:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="burnin = 0
thinning = 1
tagged = Tagged(mymodel, (:μ,:σ) )
tracetransform = TraceTransform(trace5, mymodel, tagged)
array_3dim = Baytes.trace_to_3DArray(trace5, tracetransform)

using MCMCChains
MCMCChains.Chains(array_3dim, trace5.info.sampling.paramnames)"><pre>burnin <span class="pl-k">=</span> <span class="pl-c1">0</span>
thinning <span class="pl-k">=</span> <span class="pl-c1">1</span>
tagged <span class="pl-k">=</span> <span class="pl-c1">Tagged</span>(mymodel, (<span class="pl-c1">:μ</span>,<span class="pl-c1">:σ</span>) )
tracetransform <span class="pl-k">=</span> <span class="pl-c1">TraceTransform</span>(trace5, mymodel, tagged)
array_3dim <span class="pl-k">=</span> Baytes<span class="pl-k">.</span><span class="pl-c1">trace_to_3DArray</span>(trace5, tracetransform)

<span class="pl-k">using</span> MCMCChains
MCMCChains<span class="pl-k">.</span><span class="pl-c1">Chains</span>(array_3dim, trace5<span class="pl-k">.</span>info<span class="pl-k">.</span>sampling<span class="pl-k">.</span>paramnames)</pre></div>
<h2 dir="auto"><a id="user-content-going-forward" class="anchor" aria-hidden="true" href="#going-forward"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Going Forward</h2>
<p dir="auto">This package is still highly experimental - suggestions and comments are always welcome!</p>

</article></div>