<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p><strong>Note: This functionality is now merged into Optim.jl</strong></p>
<h1><a id="user-content-constrainedoptim" class="anchor" aria-hidden="true" href="#constrainedoptim"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ConstrainedOptim</h1>
<p><a href="https://travis-ci.org/JuliaNLSolvers/ConstrainedOptim.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/1155bd1ab7e722b7cdd0140ddac9de81abcec67d9b56e84fadbd3060ac239335/68747470733a2f2f7472617669732d63692e6f72672f4a756c69614e4c536f6c766572732f436f6e73747261696e65644f7074696d2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/JuliaNLSolvers/ConstrainedOptim.jl.svg?branch=master" style="max-width:100%;"></a></p>
<p><a href="https://coveralls.io/github/JuliaNLSolvers/ConstrainedOptim.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/51e4d32a0df98c1acf9dbaeccd567720d93136da88e1fb43f0f2b5f7de889881/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c69614e4c536f6c766572732f436f6e73747261696e65644f7074696d2e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/JuliaNLSolvers/ConstrainedOptim.jl/badge.svg?branch=master&amp;service=github" style="max-width:100%;"></a></p>
<p><a href="http://codecov.io/github/JuliaNLSolvers/ConstrainedOptim.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/357a3efb5024f102ce2871e5a186f05fd8d178155687a8e358350da5a9ed39db/687474703a2f2f636f6465636f762e696f2f6769746875622f4a756c69614e4c536f6c766572732f436f6e73747261696e65644f7074696d2e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/JuliaNLSolvers/ConstrainedOptim.jl/coverage.svg?branch=master" style="max-width:100%;"></a></p>
<p>This package adds support for constrained optimization algorithms
to the package <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim</a>.
We intend to merge the code in <code>ConstrainedOptim</code> with <code>Optim</code> when
the interfaces and algorithms in this repository have been tested properly.
<strong>Feedback is very much appreciated, either via <a href="https://gitter.im/JuliaNLSolvers/Lobby" rel="nofollow">gitter</a>
or by creating an issue or PR on github.</strong></p>
<p>The nonlinear constrained optimization interface in <code>ConstrainedOptim</code> assumes that the user can write the optimization problem in the following way.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0ed7f44cc77719a67791e3b51ad05f25dcfc5d6f/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f706e672e6c617465783f2535436c61726765253230253543626567696e253742616c69676e2a2537442532302535436d696e5f25374278253543696e2535436d6174686262253742522537442535456e2537446625323878253239253236253543717561642532302535437465787425374273756368253230746861742537442535432535432532306c5f782532302535436c65712532302535437068616e746f6d25374263253238253744782535437068616e746f6d2537422532392537442532302532362532302535436c6571253230755f782535432535432532306c5f632532302535436c657125323063253238782532392532302532362532302535436c6571253230755f632e253230253543656e64253742616c69676e2a253744"><img src="https://camo.githubusercontent.com/0ed7f44cc77719a67791e3b51ad05f25dcfc5d6f/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f706e672e6c617465783f2535436c61726765253230253543626567696e253742616c69676e2a2537442532302535436d696e5f25374278253543696e2535436d6174686262253742522537442535456e2537446625323878253239253236253543717561642532302535437465787425374273756368253230746861742537442535432535432532306c5f782532302535436c65712532302535437068616e746f6d25374263253238253744782535437068616e746f6d2537422532392537442532302532362532302535436c6571253230755f782535432535432532306c5f632532302535436c657125323063253238782532392532302532362532302535436c6571253230755f632e253230253543656e64253742616c69676e2a253744" title="Constrained optimization problem" style="max-width:100%;"></a></p>
<p>Multiple nonlinear constraints can be set by considering <code>c(x)</code> as a
vector. An equality constraint <code>g(x) = 0</code> is then defined by setting,
say, <code>c(x)_1 = g(x)</code>, <code>l_{c,1}= u_{c,1} = 0</code>.</p>
<h2><a id="user-content-example-usage" class="anchor" aria-hidden="true" href="#example-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Example usage</h2>
<p>We will go through examples of how to use <code>ConstrainedOptim</code> and
illustrate how to use the constraints interface with an interior-point
Newton optimization algorithm.
Throughout these examples we work with the standard Rosenbrock function.
The objective and its derivatives are given by</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="fun(x) =  (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2

function fun_grad!(g, x)
g[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]
g[2] = 200.0 * (x[2] - x[1]^2)
end

function fun_hess!(h, x)
h[1, 1] = 2.0 - 400.0 * x[2] + 1200.0 * x[1]^2
h[1, 2] = -400.0 * x[1]
h[2, 1] = -400.0 * x[1]
h[2, 2] = 200.0
end
"><pre><span class="pl-en">fun</span>(x) <span class="pl-k">=</span>  (<span class="pl-c1">1.0</span> <span class="pl-k">-</span> x[<span class="pl-c1">1</span>])<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> <span class="pl-c1">100.0</span> <span class="pl-k">*</span> (x[<span class="pl-c1">2</span>] <span class="pl-k">-</span> x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>)<span class="pl-k">^</span><span class="pl-c1">2</span>

<span class="pl-k">function</span> <span class="pl-en">fun_grad!</span>(g, x)
g[<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">2.0</span> <span class="pl-k">*</span> (<span class="pl-c1">1.0</span> <span class="pl-k">-</span> x[<span class="pl-c1">1</span>]) <span class="pl-k">-</span> <span class="pl-c1">400.0</span> <span class="pl-k">*</span> (x[<span class="pl-c1">2</span>] <span class="pl-k">-</span> x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>) <span class="pl-k">*</span> x[<span class="pl-c1">1</span>]
g[<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">200.0</span> <span class="pl-k">*</span> (x[<span class="pl-c1">2</span>] <span class="pl-k">-</span> x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>)
<span class="pl-k">end</span>

<span class="pl-k">function</span> <span class="pl-en">fun_hess!</span>(h, x)
h[<span class="pl-c1">1</span>, <span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">2.0</span> <span class="pl-k">-</span> <span class="pl-c1">400.0</span> <span class="pl-k">*</span> x[<span class="pl-c1">2</span>] <span class="pl-k">+</span> <span class="pl-c1">1200.0</span> <span class="pl-k">*</span> x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>
h[<span class="pl-c1">1</span>, <span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">400.0</span> <span class="pl-k">*</span> x[<span class="pl-c1">1</span>]
h[<span class="pl-c1">2</span>, <span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">400.0</span> <span class="pl-k">*</span> x[<span class="pl-c1">1</span>]
h[<span class="pl-c1">2</span>, <span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">200.0</span>
<span class="pl-k">end</span></pre></div>
<h3><a id="user-content-optimization-interface" class="anchor" aria-hidden="true" href="#optimization-interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optimization interface</h3>
<p>To solve a constrained optimization problem we call the <code>optimize</code>
method</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="optimize(d::AbstractObjective, constraints::AbstractConstraints, initial_x::Tx, method::ConstrainedOptimizer, options::Options)
"><pre><span class="pl-c1">optimize</span>(d<span class="pl-k">::</span><span class="pl-c1">AbstractObjective</span>, constraints<span class="pl-k">::</span><span class="pl-c1">AbstractConstraints</span>, initial_x<span class="pl-k">::</span><span class="pl-c1">Tx</span>, method<span class="pl-k">::</span><span class="pl-c1">ConstrainedOptimizer</span>, options<span class="pl-k">::</span><span class="pl-c1">Options</span>)</pre></div>
<p>We can create instances of <code>AbstractObjective</code> and
<code>AbstractConstraints</code> using the types <code>TwiceDifferentiable</code> and
<code>TwiceDifferentiableConstraints</code> from the package <code>NLSolversBase.jl</code>.</p>
<p>This package contains one <code>ConstrainedOptimizer</code> method called <code>IPNewton</code>.
To get information on the keywords used to construct method instances, use the Julia REPL help prompt (<code>?</code>).</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="help?&gt; IPNewton
search: IPNewton

Interior-point Newton
≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡

Constructor
=============

IPNewton(; linesearch::Function = ConstrainedOptim.backtrack_constrained_grad,
μ0::Union{Symbol,Number} = :auto,
show_linesearch::Bool = false)

The initial barrier penalty coefficient μ0 can be chosen as a number, or set to :auto to let the
algorithm decide its value, see initialize_μ_λ!.

*Note*: For constrained optimization problems, we recommend
always enabling `allow_f_increases` and `successive_f_tol` in the options passed to `optimize`.
The default is set to `Optim.Options(allow_f_increases = true, successive_f_tol = 2)`.

As of February 2018, the line search algorithm is specialised for constrained interior-point
methods. In future we hope to support more algorithms from LineSearches.jl.

Description
=============

The IPNewton method implements an interior-point primal-dual Newton algorithm for solving nonlinear,
constrained optimization problems. See Nocedal and Wright (Ch. 19, 2006) for a discussion of
interior-point methods for constrained optimization.

References
============

The algorithm was originally written by Tim Holy (@timholy, tim.holy@gmail.com).

•    J Nocedal, SJ Wright (2006), Numerical optimization, second edition. Springer.

•    A Wächter, LT Biegler (2006), On the implementation of an interior-point filter
line-search algorithm for large-scale nonlinear programming. Mathematical Programming 106
(1), 25-57.
"><pre><code>help?&gt; IPNewton
search: IPNewton

Interior-point Newton
≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡

Constructor
=============

IPNewton(; linesearch::Function = ConstrainedOptim.backtrack_constrained_grad,
μ0::Union{Symbol,Number} = :auto,
show_linesearch::Bool = false)

The initial barrier penalty coefficient μ0 can be chosen as a number, or set to :auto to let the
algorithm decide its value, see initialize_μ_λ!.

*Note*: For constrained optimization problems, we recommend
always enabling `allow_f_increases` and `successive_f_tol` in the options passed to `optimize`.
The default is set to `Optim.Options(allow_f_increases = true, successive_f_tol = 2)`.

As of February 2018, the line search algorithm is specialised for constrained interior-point
methods. In future we hope to support more algorithms from LineSearches.jl.

Description
=============

The IPNewton method implements an interior-point primal-dual Newton algorithm for solving nonlinear,
constrained optimization problems. See Nocedal and Wright (Ch. 19, 2006) for a discussion of
interior-point methods for constrained optimization.

References
============

The algorithm was originally written by Tim Holy (@timholy, tim.holy@gmail.com).

•    J Nocedal, SJ Wright (2006), Numerical optimization, second edition. Springer.

•    A Wächter, LT Biegler (2006), On the implementation of an interior-point filter
line-search algorithm for large-scale nonlinear programming. Mathematical Programming 106
(1), 25-57.
</code></pre></div>
<h3><a id="user-content-box-minimzation" class="anchor" aria-hidden="true" href="#box-minimzation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Box minimzation</h3>
<p>We want to optimize the Rosenbrock function in the box
<code>-0.5 ≤ x ≤ 0.5</code>, starting from the point <code>x0=zeros(2)</code>.
Box constraints are defined using, for example,
<code>TwiceDifferentiableConstraints(lx, ux)</code>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="x0 = [0.0, 0.0]
df = TwiceDifferentiable(fun, fun_grad!, fun_hess!, x0)

lx = [-0.5, -0.5]; ux = [1.0, 1.0]
dfc = TwiceDifferentiableConstraints(lx, ux)

res = optimize(df, dfc, x0, IPNewton())
"><pre>x0 <span class="pl-k">=</span> [<span class="pl-c1">0.0</span>, <span class="pl-c1">0.0</span>]
df <span class="pl-k">=</span> <span class="pl-c1">TwiceDifferentiable</span>(fun, fun_grad!, fun_hess!, x0)

lx <span class="pl-k">=</span> [<span class="pl-k">-</span><span class="pl-c1">0.5</span>, <span class="pl-k">-</span><span class="pl-c1">0.5</span>]; ux <span class="pl-k">=</span> [<span class="pl-c1">1.0</span>, <span class="pl-c1">1.0</span>]
dfc <span class="pl-k">=</span> <span class="pl-c1">TwiceDifferentiableConstraints</span>(lx, ux)

res <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(df, dfc, x0, <span class="pl-c1">IPNewton</span>())</pre></div>
<p>The output from <code>res</code> is</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Results of Optimization Algorithm
 * Algorithm: Interior Point Newton
 * Starting Point: [0.0,0.0]
 * Minimizer: [0.5,0.2500000000000883]
 * Minimum: 2.500000e-01
 * Iterations: 41
 * Convergence: true
   * |x - x'| ≤ 1.0e-32: false
     |x - x'| = 8.88e-14
   * |f(x) - f(x')| ≤ 1.0e-32 |f(x)|: true
     |f(x) - f(x')| = 0.00e+00 |f(x)|
   * |g(x)| ≤ 1.0e-08: false
     |g(x)| = 1.00e+00
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 63
 * Gradient Calls: 63
"><pre><code>Results of Optimization Algorithm
 * Algorithm: Interior Point Newton
 * Starting Point: [0.0,0.0]
 * Minimizer: [0.5,0.2500000000000883]
 * Minimum: 2.500000e-01
 * Iterations: 41
 * Convergence: true
   * |x - x'| ≤ 1.0e-32: false
     |x - x'| = 8.88e-14
   * |f(x) - f(x')| ≤ 1.0e-32 |f(x)|: true
     |f(x) - f(x')| = 0.00e+00 |f(x)|
   * |g(x)| ≤ 1.0e-08: false
     |g(x)| = 1.00e+00
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 63
 * Gradient Calls: 63
</code></pre></div>
<p>If we only want to set lower bounds, use <code>ux = fill(Inf, 2)</code></p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="ux = fill(Inf, 2)
dfc = TwiceDifferentiableConstraints(lx, ux)

clear!(df)
res = optimize(df, dfc, x0, IPNewton())
"><pre>ux <span class="pl-k">=</span> <span class="pl-c1">fill</span>(<span class="pl-c1">Inf</span>, <span class="pl-c1">2</span>)
dfc <span class="pl-k">=</span> <span class="pl-c1">TwiceDifferentiableConstraints</span>(lx, ux)

<span class="pl-c1">clear!</span>(df)
res <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(df, dfc, x0, <span class="pl-c1">IPNewton</span>())</pre></div>
<p>The output from <code>res</code> is now</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Results of Optimization Algorithm
 * Algorithm: Interior Point Newton
 * Starting Point: [0.0,0.0]
 * Minimizer: [0.9999999998342594,0.9999999996456271]
 * Minimum: 7.987239e-20
 * Iterations: 35
 * Convergence: true
   * |x - x'| ≤ 1.0e-32: false
     |x - x'| = 3.54e-10
   * |f(x) - f(x')| ≤ 1.0e-32 |f(x)|: false
     |f(x) - f(x')| = 3.00e+00 |f(x)|
   * |g(x)| ≤ 1.0e-08: true
     |g(x)| = 8.83e-09
   * Stopped by an increasing objective: true
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 63
 * Gradient Calls: 63
"><pre><code>Results of Optimization Algorithm
 * Algorithm: Interior Point Newton
 * Starting Point: [0.0,0.0]
 * Minimizer: [0.9999999998342594,0.9999999996456271]
 * Minimum: 7.987239e-20
 * Iterations: 35
 * Convergence: true
   * |x - x'| ≤ 1.0e-32: false
     |x - x'| = 3.54e-10
   * |f(x) - f(x')| ≤ 1.0e-32 |f(x)|: false
     |f(x) - f(x')| = 3.00e+00 |f(x)|
   * |g(x)| ≤ 1.0e-08: true
     |g(x)| = 8.83e-09
   * Stopped by an increasing objective: true
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 63
 * Gradient Calls: 63
</code></pre></div>
<h3><a id="user-content-defining-unconstrained-problems" class="anchor" aria-hidden="true" href="#defining-unconstrained-problems"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Defining "unconstrained" problems</h3>
<p>An unconstrained problem can be defined either by passing
<code>Inf</code> bounds or empty arrays.
<strong>Note that we must pass the correct type information to the empty <code>lx</code> and <code>ux</code></strong></p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="lx = fill(-Inf, 2); ux = fill(Inf, 2)
dfc = TwiceDifferentiableConstraints(lx, ux)

clear!(df)
res = optimize(df, dfc, x0, IPNewton())

lx = Float64[]; ux = Float64[]
dfc = TwiceDifferentiableConstraints(lx, ux)

clear!(df)
res = optimize(df, dfc, x0, IPNewton())
"><pre>lx <span class="pl-k">=</span> <span class="pl-c1">fill</span>(<span class="pl-k">-</span><span class="pl-c1">Inf</span>, <span class="pl-c1">2</span>); ux <span class="pl-k">=</span> <span class="pl-c1">fill</span>(<span class="pl-c1">Inf</span>, <span class="pl-c1">2</span>)
dfc <span class="pl-k">=</span> <span class="pl-c1">TwiceDifferentiableConstraints</span>(lx, ux)

<span class="pl-c1">clear!</span>(df)
res <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(df, dfc, x0, <span class="pl-c1">IPNewton</span>())

lx <span class="pl-k">=</span> Float64[]; ux <span class="pl-k">=</span> Float64[]
dfc <span class="pl-k">=</span> <span class="pl-c1">TwiceDifferentiableConstraints</span>(lx, ux)

<span class="pl-c1">clear!</span>(df)
res <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(df, dfc, x0, <span class="pl-c1">IPNewton</span>())</pre></div>
<h3><a id="user-content-generic-nonlinear-constraints" class="anchor" aria-hidden="true" href="#generic-nonlinear-constraints"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Generic nonlinear constraints</h3>
<p>We now consider the Rosenbrock problem with a constraint on
<code>x[1]^2 + x[2]^2</code>.</p>
<p>We pass the information about the constraints to the <code>optimize</code>
by defining a vector function <code>c(x)</code> and its Jacobian <code>J(x)</code>.</p>
<p>The Hessian information is treated differently, by considering the
Lagrangian of the corresponding slack-variable transformed
optimization problem. This is similar to how the CUTEst library works.
Let <code>H_j(x)</code> represent the Hessian of the <code>j</code>th component of
<code>c(x)</code>, and <code>λ_j</code> the corresponding dual variable in the
Lagrangian. Then we want the <code>constraint</code> object to
add the values of the <code>H_j(x)</code> to the Hessian of the objective,
weighted by <code>lambda_j</code>.</p>
<p>The Julian form for the supplied function <code>c(x)</code> and the derivative
information is then added in the following way.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="con_c!(c, x) = (c[1] = x[1]^2 + x[2]^2; c)
function con_jacobian!(J, x)
    J[1,1] = 2*x[1]
    J[1,2] = 2*x[2]
    J
end
function con_h!(h, x, λ)
    h[1,1] += λ[1]*2
    h[2,2] += λ[1]*2
end
"><pre><span class="pl-en">con_c!</span>(c, x) <span class="pl-k">=</span> (c[<span class="pl-c1">1</span>] <span class="pl-k">=</span> x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>; c)
<span class="pl-k">function</span> <span class="pl-en">con_jacobian!</span>(J, x)
    J[<span class="pl-c1">1</span>,<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">1</span>]
    J[<span class="pl-c1">1</span>,<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">2</span>]
    J
<span class="pl-k">end</span>
<span class="pl-k">function</span> <span class="pl-en">con_h!</span>(h, x, λ)
    h[<span class="pl-c1">1</span>,<span class="pl-c1">1</span>] <span class="pl-k">+=</span> λ[<span class="pl-c1">1</span>]<span class="pl-k">*</span><span class="pl-c1">2</span>
    h[<span class="pl-c1">2</span>,<span class="pl-c1">2</span>] <span class="pl-k">+=</span> λ[<span class="pl-c1">1</span>]<span class="pl-k">*</span><span class="pl-c1">2</span>
<span class="pl-k">end</span></pre></div>
<p><strong>Note that <code>con_h!</code> adds the <code>λ</code>-weighted Hessian value of each element of <code>c(x)</code> to the Hessian of <code>fun</code>.</strong></p>
<p>We can then optimize the Rosenbrock function inside the ball of radius
<code>0.5</code>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="lx = Float64[]; ux = Float64[]
lc = [-Inf]; uc = [0.5^2]
dfc = TwiceDifferentiableConstraints(con_c!, con_jacobian!, con_h!,
                                     lx, ux, lc, uc)
res = optimize(df, dfc, x0, IPNewton())
"><pre>lx <span class="pl-k">=</span> Float64[]; ux <span class="pl-k">=</span> Float64[]
lc <span class="pl-k">=</span> [<span class="pl-k">-</span><span class="pl-c1">Inf</span>]; uc <span class="pl-k">=</span> [<span class="pl-c1">0.5</span><span class="pl-k">^</span><span class="pl-c1">2</span>]
dfc <span class="pl-k">=</span> <span class="pl-c1">TwiceDifferentiableConstraints</span>(con_c!, con_jacobian!, con_h!,
                                     lx, ux, lc, uc)
res <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(df, dfc, x0, <span class="pl-c1">IPNewton</span>())</pre></div>
<p>The output from the optimization is</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="Results of Optimization Algorithm
 * Algorithm: Interior Point Newton
 * Starting Point: [0.0,0.0]
 * Minimizer: [0.45564896414551875,0.2058737998704899]
 * Minimum: 2.966216e-01
 * Iterations: 28
 * Convergence: true
   * |x - x'| ≤ 1.0e-32: true
     |x - x'| = 0.00e+00
   * |f(x) - f(x')| ≤ 1.0e-32 |f(x)|: false
     |f(x) - f(x')| = 0.00e+00 |f(x)|
   * |g(x)| ≤ 1.0e-08: false
     |g(x)| = 7.71e-01
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 109
 * Gradient Calls: 109
"><pre><code>Results of Optimization Algorithm
 * Algorithm: Interior Point Newton
 * Starting Point: [0.0,0.0]
 * Minimizer: [0.45564896414551875,0.2058737998704899]
 * Minimum: 2.966216e-01
 * Iterations: 28
 * Convergence: true
   * |x - x'| ≤ 1.0e-32: true
     |x - x'| = 0.00e+00
   * |f(x) - f(x')| ≤ 1.0e-32 |f(x)|: false
     |f(x) - f(x')| = 0.00e+00 |f(x)|
   * |g(x)| ≤ 1.0e-08: false
     |g(x)| = 7.71e-01
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 109
 * Gradient Calls: 109
</code></pre></div>
<p>We can add a lower bound on the constraint, and thus
optimize the objective on the annulus with
inner and outer radii <code>0.1</code> and <code>0.5</code> respectively.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="lc = [0.1^2]
dfc = TwiceDifferentiableConstraints(con_c!, con_jacobian!, con_h!,
                                     lx, ux, lc, uc)
res = optimize(df, dfc, x0, IPNewton())
"><pre>lc <span class="pl-k">=</span> [<span class="pl-c1">0.1</span><span class="pl-k">^</span><span class="pl-c1">2</span>]
dfc <span class="pl-k">=</span> <span class="pl-c1">TwiceDifferentiableConstraints</span>(con_c!, con_jacobian!, con_h!,
                                     lx, ux, lc, uc)
res <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(df, dfc, x0, <span class="pl-c1">IPNewton</span>())</pre></div>
<p><strong>Note that the algorithm warns that the Initial guess is not an
interior point.</strong> <code>IPNewton</code> can often handle this, however, if the
initial guess is such that <code>c(x) = u_c</code>, then the algorithm currently
fails. We hope to fix this in the future.</p>
<h4><a id="user-content-multiple-constraints" class="anchor" aria-hidden="true" href="#multiple-constraints"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Multiple constraints</h4>
<p>The following example illustrates how to add an additional constraint.
In particular, we add a constraint <code>c_2(x) = x[2]*sin(x[1])-x[1]</code>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="function con_c!(c, x)
    c[1] = x[1]^2 + x[2]^2     # First constraint
    c[2] = x[2]*sin(x[1])-x[1] # Second constraint
    c
end
function con_jacobian!(J, x)
    # First constraint
    J[1,1] = 2*x[1]
    J[1,2] = 2*x[2]
    # Second constraint
    J[2,1] = x[2]*cos(x[1])-1.0
    J[2,2] = sin(x[1])
    J
end
function con_h!(h, x, λ)
    # First constraint
    h[1,1] += λ[1]*2
    h[2,2] += λ[1]*2
    # Second constraint
    h[1,1] += λ[2]*x[2]*-sin(x[1])
    h[1,2] += λ[2]*cos(x[1])
    # Symmetrize h
    h[2,1]  = h[1,2]
    h
end
"><pre><span class="pl-k">function</span> <span class="pl-en">con_c!</span>(c, x)
    c[<span class="pl-c1">1</span>] <span class="pl-k">=</span> x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>     <span class="pl-c"><span class="pl-c">#</span> First constraint</span>
    c[<span class="pl-c1">2</span>] <span class="pl-k">=</span> x[<span class="pl-c1">2</span>]<span class="pl-k">*</span><span class="pl-c1">sin</span>(x[<span class="pl-c1">1</span>])<span class="pl-k">-</span>x[<span class="pl-c1">1</span>] <span class="pl-c"><span class="pl-c">#</span> Second constraint</span>
    c
<span class="pl-k">end</span>
<span class="pl-k">function</span> <span class="pl-en">con_jacobian!</span>(J, x)
    <span class="pl-c"><span class="pl-c">#</span> First constraint</span>
    J[<span class="pl-c1">1</span>,<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">1</span>]
    J[<span class="pl-c1">1</span>,<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">2</span><span class="pl-k">*</span>x[<span class="pl-c1">2</span>]
    <span class="pl-c"><span class="pl-c">#</span> Second constraint</span>
    J[<span class="pl-c1">2</span>,<span class="pl-c1">1</span>] <span class="pl-k">=</span> x[<span class="pl-c1">2</span>]<span class="pl-k">*</span><span class="pl-c1">cos</span>(x[<span class="pl-c1">1</span>])<span class="pl-k">-</span><span class="pl-c1">1.0</span>
    J[<span class="pl-c1">2</span>,<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">sin</span>(x[<span class="pl-c1">1</span>])
    J
<span class="pl-k">end</span>
<span class="pl-k">function</span> <span class="pl-en">con_h!</span>(h, x, λ)
    <span class="pl-c"><span class="pl-c">#</span> First constraint</span>
    h[<span class="pl-c1">1</span>,<span class="pl-c1">1</span>] <span class="pl-k">+=</span> λ[<span class="pl-c1">1</span>]<span class="pl-k">*</span><span class="pl-c1">2</span>
    h[<span class="pl-c1">2</span>,<span class="pl-c1">2</span>] <span class="pl-k">+=</span> λ[<span class="pl-c1">1</span>]<span class="pl-k">*</span><span class="pl-c1">2</span>
    <span class="pl-c"><span class="pl-c">#</span> Second constraint</span>
    h[<span class="pl-c1">1</span>,<span class="pl-c1">1</span>] <span class="pl-k">+=</span> λ[<span class="pl-c1">2</span>]<span class="pl-k">*</span>x[<span class="pl-c1">2</span>]<span class="pl-k">*-</span><span class="pl-c1">sin</span>(x[<span class="pl-c1">1</span>])
    h[<span class="pl-c1">1</span>,<span class="pl-c1">2</span>] <span class="pl-k">+=</span> λ[<span class="pl-c1">2</span>]<span class="pl-k">*</span><span class="pl-c1">cos</span>(x[<span class="pl-c1">1</span>])
    <span class="pl-c"><span class="pl-c">#</span> Symmetrize h</span>
    h[<span class="pl-c1">2</span>,<span class="pl-c1">1</span>]  <span class="pl-k">=</span> h[<span class="pl-c1">1</span>,<span class="pl-c1">2</span>]
    h
<span class="pl-k">end</span></pre></div>
<p>We generate the constraint objects and call <code>IPNewton</code> with
initial guess <code>x0 = [0.25,0.25]</code>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="x0 = [0.25, 0.25]
lc = [-Inf, 0.0]; uc = [0.5^2, 0.0]
dfc = TwiceDifferentiableConstraints(con_c!, con_jacobian!, con_h!,
                                     lx, ux, lc, uc)
res = optimize(df, dfc, x0, IPNewton())
"><pre>x0 <span class="pl-k">=</span> [<span class="pl-c1">0.25</span>, <span class="pl-c1">0.25</span>]
lc <span class="pl-k">=</span> [<span class="pl-k">-</span><span class="pl-c1">Inf</span>, <span class="pl-c1">0.0</span>]; uc <span class="pl-k">=</span> [<span class="pl-c1">0.5</span><span class="pl-k">^</span><span class="pl-c1">2</span>, <span class="pl-c1">0.0</span>]
dfc <span class="pl-k">=</span> <span class="pl-c1">TwiceDifferentiableConstraints</span>(con_c!, con_jacobian!, con_h!,
                                     lx, ux, lc, uc)
res <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(df, dfc, x0, <span class="pl-c1">IPNewton</span>())</pre></div>
</article></div>