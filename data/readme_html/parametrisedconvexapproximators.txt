<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-parametrisedconvexapproximators" class="anchor" aria-hidden="true" href="#parametrisedconvexapproximators"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ParametrisedConvexApproximators</h1>
<p dir="auto"><a href="https://github.com/JinraeKim/ParametrisedConvexApproximators.jl">ParametrisedConvexApproximators.jl</a>
is a Julia package providing predefined parametrised convex approximators and related functionalities.
An official package of [3].</p>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">To install ParametrisedConvexApproximator,
please open Julia's interactive session (a.k.a REPL) and press <code>]</code> key
in the REPL to use the package mode, then type the following command</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="pkg&gt; add ParametrisedConvexApproximator"><pre>pkg<span class="pl-k">&gt;</span> add ParametrisedConvexApproximator</pre></div>
<h3 dir="auto"><a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Notes</h3>
<ul dir="auto">
<li>Activate multi-threading if available, e.g., <code>julia -t 7</code> enabling <code>7</code> threads.
It will reduce computation time to obtain multiple minimizers.</li>
<li>The benchmark result was reported in <a href="https://github.com/JinraeKim/ParametrisedConvexApproximators.jl/tree/v0.1.1">ParametrisedConvexApproximator.jl v0.1.1</a> [3].</li>
</ul>
<h2 dir="auto"><a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick Start</h2>
<p dir="auto">ParametrisedConvexApproximators.jl focuses on providing predefined approximators
including parametrised convex approximators.
Note that when approximators receive two arguments, the first and second arguments correspond to
condition and decision vectors, usually denoted by <code>x</code> and <code>u</code>.</p>
<h3 dir="auto"><a id="user-content-network-construction" class="anchor" aria-hidden="true" href="#network-construction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Network construction</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ParametrisedConvexApproximators
using Flux
using Random  # for random seed

# construction
seed = 2022
Random.seed!(seed)
n, m = 3, 2
i_max = 20
T = 1.0
h_array = [64, 64]
act = Flux.leakyrelu
network = PLSE(n, m, i_max, T, h_array, act)  # parametrised log-sum-exp (PLSE) network
x, u = rand(n), rand(m)
f̂ = network(x, u)
@show f̂"><pre><span class="pl-k">using</span> ParametrisedConvexApproximators
<span class="pl-k">using</span> Flux
<span class="pl-k">using</span> Random  <span class="pl-c"><span class="pl-c">#</span> for random seed</span>

<span class="pl-c"><span class="pl-c">#</span> construction</span>
seed <span class="pl-k">=</span> <span class="pl-c1">2022</span>
Random<span class="pl-k">.</span><span class="pl-c1">seed!</span>(seed)
n, m <span class="pl-k">=</span> <span class="pl-c1">3</span>, <span class="pl-c1">2</span>
i_max <span class="pl-k">=</span> <span class="pl-c1">20</span>
T <span class="pl-k">=</span> <span class="pl-c1">1.0</span>
h_array <span class="pl-k">=</span> [<span class="pl-c1">64</span>, <span class="pl-c1">64</span>]
act <span class="pl-k">=</span> Flux<span class="pl-k">.</span>leakyrelu
network <span class="pl-k">=</span> <span class="pl-c1">PLSE</span>(n, m, i_max, T, h_array, act)  <span class="pl-c"><span class="pl-c">#</span> parametrised log-sum-exp (PLSE) network</span>
x, u <span class="pl-k">=</span> <span class="pl-c1">rand</span>(n), <span class="pl-c1">rand</span>(m)
f̂ <span class="pl-k">=</span> <span class="pl-c1">network</span>(x, u)
<span class="pl-c1">@show</span> f̂</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="f̂ = [2.995747603812025]  # size(f̂) = (1,)"><pre>f̂ <span class="pl-k">=</span> [<span class="pl-c1">2.995747603812025</span>]  <span class="pl-c"><span class="pl-c">#</span> size(f̂) = (1,)</span></pre></div>
<h3 dir="auto"><a id="user-content-prepare-dataset" class="anchor" aria-hidden="true" href="#prepare-dataset"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Prepare dataset</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="min_condition = -ones(n)
max_condition = +ones(n)
min_decision = -ones(m)
max_decision = +ones(m)
func_name = :quadratic  # f(x, u) = transpose(x)*x + transpose(u)*u
N = 5_000

dataset = SimpleDataset(
    func_name;
    N=N, n=n, m=m, seed=seed,
    min_condition=min_condition,
    max_condition=max_condition,
    min_decision=min_decision,
    max_decision=max_decision,
)"><pre>min_condition <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">ones</span>(n)
max_condition <span class="pl-k">=</span> <span class="pl-k">+</span><span class="pl-c1">ones</span>(n)
min_decision <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">ones</span>(m)
max_decision <span class="pl-k">=</span> <span class="pl-k">+</span><span class="pl-c1">ones</span>(m)
func_name <span class="pl-k">=</span> <span class="pl-c1">:quadratic</span>  <span class="pl-c"><span class="pl-c">#</span> f(x, u) = transpose(x)*x + transpose(u)*u</span>
N <span class="pl-k">=</span> <span class="pl-c1">5_000</span>

dataset <span class="pl-k">=</span> <span class="pl-c1">SimpleDataset</span>(
    func_name;
    N<span class="pl-k">=</span>N, n<span class="pl-k">=</span>n, m<span class="pl-k">=</span>m, seed<span class="pl-k">=</span>seed,
    min_condition<span class="pl-k">=</span>min_condition,
    max_condition<span class="pl-k">=</span>max_condition,
    min_decision<span class="pl-k">=</span>min_decision,
    max_decision<span class="pl-k">=</span>max_decision,
)</pre></div>
<h3 dir="auto"><a id="user-content-network-training" class="anchor" aria-hidden="true" href="#network-training"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Network training</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="trainer = SupervisedLearningTrainer(dataset, network; optimiser=Adam(1e-4))

@show get_loss(trainer, :train)
@show get_loss(trainer, :validate)
Flux.train!(trainer; epochs=200)
@show get_loss(trainer, :test)"><pre>trainer <span class="pl-k">=</span> <span class="pl-c1">SupervisedLearningTrainer</span>(dataset, network; optimiser<span class="pl-k">=</span><span class="pl-c1">Adam</span>(<span class="pl-c1">1e-4</span>))

<span class="pl-c1">@show</span> <span class="pl-c1">get_loss</span>(trainer, <span class="pl-c1">:train</span>)
<span class="pl-c1">@show</span> <span class="pl-c1">get_loss</span>(trainer, <span class="pl-c1">:validate</span>)
Flux<span class="pl-k">.</span><span class="pl-c1">train!</span>(trainer; epochs<span class="pl-k">=</span><span class="pl-c1">200</span>)
<span class="pl-c1">@show</span> <span class="pl-c1">get_loss</span>(trainer, <span class="pl-c1">:test</span>)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="get_loss(trainer, :train) = 2.2485616017365517
get_loss(trainer, :validate) = 2.2884594157659994

...

epoch: 199/200
loss_train = 0.00020636060117068826
loss_validate = 0.00027629941017224863
Best network found!
minimum_loss_validate = 0.00027629941017224863
epoch: 200/200
loss_train = 0.00020551515617350474
loss_validate = 0.0002751188168629372
Best network found!
minimum_loss_validate = 0.0002751188168629372

get_loss(trainer, :test) = 0.0002642962384649246"><pre><span class="pl-en">get_loss</span>(trainer, <span class="pl-c1">:train</span>) <span class="pl-k">=</span> <span class="pl-c1">2.2485616017365517</span>
<span class="pl-en">get_loss</span>(trainer, <span class="pl-c1">:validate</span>) <span class="pl-k">=</span> <span class="pl-c1">2.2884594157659994</span>

<span class="pl-k">...</span>

epoch<span class="pl-k">:</span> <span class="pl-c1">199</span><span class="pl-k">/</span><span class="pl-c1">200</span>
loss_train <span class="pl-k">=</span> <span class="pl-c1">0.00020636060117068826</span>
loss_validate <span class="pl-k">=</span> <span class="pl-c1">0.00027629941017224863</span>
Best network found!
minimum_loss_validate <span class="pl-k">=</span> <span class="pl-c1">0.00027629941017224863</span>
epoch<span class="pl-k">:</span> <span class="pl-c1">200</span><span class="pl-k">/</span><span class="pl-c1">200</span>
loss_train <span class="pl-k">=</span> <span class="pl-c1">0.00020551515617350474</span>
loss_validate <span class="pl-k">=</span> <span class="pl-c1">0.0002751188168629372</span>
Best network found!
minimum_loss_validate <span class="pl-k">=</span> <span class="pl-c1">0.0002751188168629372</span>

<span class="pl-en">get_loss</span>(trainer, <span class="pl-c1">:test</span>) <span class="pl-k">=</span> <span class="pl-c1">0.0002642962384649246</span></pre></div>
<h3 dir="auto"><a id="user-content-conditional-decision-making-via-optimization-given-x-find-a-minimizer-u-and-optimal-value" class="anchor" aria-hidden="true" href="#conditional-decision-making-via-optimization-given-x-find-a-minimizer-u-and-optimal-value"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Conditional decision making via optimization (given <code>x</code>, find a minimizer <code>u</code> and optimal value)</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# optimization
Random.seed!(seed)
x = rand(n)  # any value
minimiser = optimise(network, x; u_min=min_decision, u_max=max_decision)  # minimsation
@show minimiser
@show network(x, minimiser)
@show dataset[:train].metadata.target_function(x, minimiser)"><pre><span class="pl-c"><span class="pl-c">#</span> optimization</span>
Random<span class="pl-k">.</span><span class="pl-c1">seed!</span>(seed)
x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(n)  <span class="pl-c"><span class="pl-c">#</span> any value</span>
minimiser <span class="pl-k">=</span> <span class="pl-c1">optimise</span>(network, x; u_min<span class="pl-k">=</span>min_decision, u_max<span class="pl-k">=</span>max_decision)  <span class="pl-c"><span class="pl-c">#</span> minimsation</span>
<span class="pl-c1">@show</span> minimiser
<span class="pl-c1">@show</span> <span class="pl-c1">network</span>(x, minimiser)
<span class="pl-c1">@show</span> dataset[<span class="pl-c1">:train</span>]<span class="pl-k">.</span>metadata<span class="pl-k">.</span><span class="pl-c1">target_function</span>(x, minimiser)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="minimiser = [-0.00863654920254873, 0.014258700223990051]
network(x, minimiser) = [1.1275475934947705]
(dataset[:train]).metadata.target_function(x, minimiser) = 1.1027324438048691"><pre>minimiser <span class="pl-k">=</span> [<span class="pl-k">-</span><span class="pl-c1">0.00863654920254873</span>, <span class="pl-c1">0.014258700223990051</span>]
<span class="pl-en">network</span>(x, minimiser) <span class="pl-k">=</span> [<span class="pl-c1">1.1275475934947705</span>]
(dataset[<span class="pl-c1">:train</span>])<span class="pl-k">.</span>metadata<span class="pl-k">.</span><span class="pl-en">target_function</span>(x, minimiser) <span class="pl-k">=</span> <span class="pl-c1">1.1027324438048691</span></pre></div>
<h2 dir="auto"><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Documentation</h2>
<h3 dir="auto"><a id="user-content-types" class="anchor" aria-hidden="true" href="#types"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Types</h3>
<ul dir="auto">
<li><code>AbstractApproximator</code> is an abstract type of approximator.</li>
<li><code>ParametrisedConvexApproximator &lt;: AbstractApproximator</code> is an abstract type of parametrised convex approximator.</li>
<li><code>ConvexApproximator &lt;: ParametrisedConvexApproximator</code> is an abstract type of convex approximator.</li>
<li><code>DifferenceOfConvexApproximator &lt;: AbstractApproximator</code> is an abstract type of difference of convex approximator.</li>
</ul>
<h3 dir="auto"><a id="user-content-approximators" class="anchor" aria-hidden="true" href="#approximators"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Approximators</h3>
<ul dir="auto">
<li>
<p dir="auto">All approximators in ParametrisedConvexApproximators.jl receive two arguments, namely, <code>x</code> and <code>u</code>.
When <code>x</code> and <code>u</code> are vectors whose lengths are <code>n</code> and <code>m</code>, respectively,
the output of an approximator is <strong>one-length vector</strong>.</p>
<ul dir="auto">
<li>Note that <code>x</code> and <code>u</code> can be matrices, whose sizes are <code>(n, d)</code> and <code>(m, d)</code>,
for evaluations of <code>d</code> pairs of <code>x</code>'s and <code>u</code>'s.
In this case, the output's size is <code>(1, d)</code>.</li>
</ul>
</li>
<li>
<p dir="auto">The list of predefined approximators:</p>
<ul dir="auto">
<li><code>FNN::AbstractApproximator</code>: feedforward neural network</li>
<li><code>MA::ConvexApproximator</code>: max-affine (MA) network [1]</li>
<li><code>LSE::ConvexApproximator</code>: log-sum-exp (LSE) network [1]</li>
<li><code>PICNN::ParametrisedConvexApproximator</code>: partially input-convex neural network (PICNN) [2]</li>
<li><code>PMA::ParametrisedConvexApproximator</code>: parametrised MA (PMA) network [3]</li>
<li><code>PLSE::ParametrisedConvexApproximator</code>: parametrised LSE (PLSE) network [3]
<ul dir="auto">
<li>The default setting is <code>strict = false</code>.</li>
</ul>
</li>
<li><code>DLSE::DifferenceOfConvexApproximator</code>: difference of LSE (DLSE) network [4]</li>
</ul>
</li>
</ul>
<h3 dir="auto"><a id="user-content-utilities" class="anchor" aria-hidden="true" href="#utilities"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Utilities</h3>
<ul dir="auto">
<li><code>(nn::approximator)(x, u)</code> gives an inference (approximate function value).</li>
<li><code>minimiser = optimize(approximator, x; u_min=nothing, u_max=nothing)</code> provides the minimiser for given condition <code>x</code>
considering box constraints of <code>u &gt;= u_min</code> and <code>u &lt;= u_max</code> (element-wise).
<ul dir="auto">
<li>The condition variable <code>x</code> can be a vector, i.e., <code>size(x) = (n,)</code>,
or a matrix for multiple conditions via multi-threading, i.e., <code>size(x) = (n, d)</code>.</li>
</ul>
</li>
</ul>
<h3 dir="auto"><a id="user-content-dataset" class="anchor" aria-hidden="true" href="#dataset"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Dataset</h3>
<ul dir="auto">
<li><code>SimpleDataset &lt;: DecisionMakingDataset</code> is used for analytically-expressed cost functions.</li>
</ul>
<h3 dir="auto"><a id="user-content-trainer" class="anchor" aria-hidden="true" href="#trainer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Trainer</h3>
<ul dir="auto">
<li><code>SupervisedLearningTrainer</code></li>
</ul>
<h2 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<ul dir="auto">
<li>[1] <a href="https://ieeexplore.ieee.org/abstract/document/8715799?casa_token=ptHxee1NJ30AAAAA:etAIY0UkR0yg6YK7mgtEzCzHavM0d6Cos1VNzpn0cw5hbiEnFnAxNDm1rflWjDAOa-iO6xU5Lg" rel="nofollow">G. C. Calafiore, S. Gaubert, and C. Possieri, “Log-Sum-Exp Neural Networks and Posynomial Models for Convex and Log-Log-Convex Data,” IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 3, pp. 827–838, Mar. 2020, doi: 10.1109/TNNLS.2019.2910417.</a></li>
<li>[2] <a href="http://proceedings.mlr.press/v70/amos17b.html" rel="nofollow">B. Amos, L. Xu, and J. Z. Kolter, “Input Convex Neural Networks,” in Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, Jul. 2017, pp. 146–155.</a></li>
<li>[3] <a href="https://ieeexplore.ieee.org/document/9833537" rel="nofollow">J. Kim and Y. Kim, “Parameterized Convex Universal Approximators for Decision-Making Problems,” IEEE Trans. Neural Netw. Learning Syst., accepted for publication, 2022, doi: 10.1109/TNNLS.2022.3190198.</a></li>
<li>[4] <a href="https://ieeexplore.ieee.org/abstract/document/9032340" rel="nofollow">G. C. Calafiore, S. Gaubert, and C. Possieri, “A Universal Approximation Result for Difference of Log-Sum-Exp Neural Networks,” IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 12, pp. 5603–5612, Dec. 2020, doi: 10.1109/TNNLS.2020.2975051.</a></li>
</ul>
</article></div>