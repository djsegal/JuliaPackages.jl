<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-petsc" class="anchor" aria-hidden="true" href="#petsc"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>PETSc</h1>
<p><a href="https://travis-ci.org/JuliaParallel/PETSc.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/176e4710c043d75b8fca4c7e3922ba563a0e3787/68747470733a2f2f7472617669732d63692e6f72672f4a756c6961506172616c6c656c2f50455453632e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/JuliaParallel/PETSc.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="http://codecov.io/github/JuliaParallel/PETSc.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/0d6cffbf14ba9ae0b75bc302546a8c4a6886b650/687474703a2f2f636f6465636f762e696f2f6769746875622f4a756c6961506172616c6c656c2f50455453632e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/JuliaParallel/PETSc.jl/coverage.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/JuliaParallel/PETSc.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/7fd2de19b78bed36a2ced8a0a81a3b2131517643/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c6961506172616c6c656c2f50455453632e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/JuliaParallel/PETSc.jl/badge.svg?branch=master&amp;service=github" style="max-width:100%;"></a></p>
<p>This package provides a high level interface for PETSc, enabling the use of PETSc as an <code>AbstractArray</code>.  A low level interface is also available in the submodule <code>PETSc.C</code>.</p>
<p>This package requires the <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl package</a> be installed.  Once it is installed you should be able to run both Julia and Petsc in parallel using MPI for all communication.  The testing verifies that PETSc can be used both serially and in parallel.</p>
<p>To use the package, simply put <code>using PETSc</code> at the top of your Julia source file.  The module exports the names of all the functions, as well as the PETSc data type aliases and constants such as <code>PETSC_DECIDE</code>.</p>
<p>In general, it is possible to run PETSc in parallel. To do so with 4 processors, do:</p>
<pre><code>mpirun -np 4 julia ./name_of_file
</code></pre>
<p>Note that this launches 4 independent Julia processes.  They are not aware of each other using Julia's built-in parallelism, and MPI is used for all communications.</p>
<p>To run in serial, do:</p>
<pre><code>julia ./name_of_file
</code></pre>
<p>Even when running serially, the <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl package</a> must be installed.</p>
<p>An example of using a Krylov subspace method to solve a linear system is in  <code>test/test_ksp.jl</code>, which solves a simple system with a Krylov subspace method and compares the result with a direct solve using Julia's backslash operator.  This works in serial and in parallel.  It requires some variables declared at the top of <code>runtests.jl</code> to work.</p>
<h2><a id="user-content-to-do" class="anchor" aria-hidden="true" href="#to-do"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>To do:</h2>
<ul>
<li>Make the script for building PETSc more flexible, e.g. allowing more configuration options like building BLAS or LAPCK, while ensure it remains completely autonomous (needed for Travis testing)</li>
<li>Wrap more KSP functions</li>
</ul>
<h2><a id="user-content-status" class="anchor" aria-hidden="true" href="#status"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Status</h2>
<h3><a id="user-content-vector" class="anchor" aria-hidden="true" href="#vector"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Vector</h3>
<p>The <code>AbstractArray</code> for <code>PetscVec</code> is implemented.  Some additional PETSc
BLAS functions are wrapped as well.</p>
<h3><a id="user-content-matrix" class="anchor" aria-hidden="true" href="#matrix"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Matrix</h3>
<p>The AbstractArray interface for <code>PetscMat</code> is implemented.  Preallocation
is supported through optional keyword arguments to the matrix constructor or
the <code>setpreallocation</code> function.  It possible to set multiple values in the
matrix without intermediate assembly using the <code>assemble</code> function or by
setting the <code>Mat</code> object field <code>assembling</code> to <code>false</code> and calling <code>setindex</code>
repeatedly.</p>
<h3><a id="user-content-ksp" class="anchor" aria-hidden="true" href="#ksp"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>KSP</h3>
<p>Just enough KSP functions are implimented to do a GMRES solve.  Adding more
functionality is the current priority.</p>
<h2><a id="user-content-directory-structure" class="anchor" aria-hidden="true" href="#directory-structure"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Directory Structure</h2>
<p><code>/src</code> : source files.  PETSc.jl is the main file containing initialization, with the functions for each type of Petsc object in its own file.  All constants are declared in <code>petsc_constants.jl</code>.</p>
<p><code>/src/generated</code>: auto generated wrappers from Clang.jl.  Not directly useful, but easy to modify to make useful</p>
<p><code>/test</code> : contains <code>runtest.jl</code>, which does some setup and runs all tests on all three version of Petsc currently supported.  Tests for each type of Petsc object (mirroring the files in <code>/src</code>) are contained in separate files.</p>
<p><code>/deps</code> : builds Petsc if needed.  See description below</p>
<h2><a id="user-content-building-petsc" class="anchor" aria-hidden="true" href="#building-petsc"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Building PETSc</h2>
<p>Building the package will build build the 3 versions of PETSc in the <code>/deps</code>
directory, and writes the file <code>lib_locations.jl</code> to the <code>/src/generated</code>
directory to tell the package the location of the libraries.  Note that
this builds the debug versions of PETSc, which are recommended to use for all
development.  If you wish to do high performance computations, you should
build the optimized versions of the library.  See the PETSc website for
details.</p>
<h2><a id="user-content-installing-mpijl" class="anchor" aria-hidden="true" href="#installing-mpijl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installing <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a></h2>
<p>This package requires MPI.jl, although it is not listed in the REQUIRE file because that would download the release version of MPI.jl, which does not work.  Instead, you must use the master branch.  After you have an MPI implementation installed, <code>Pkg.build("Petsc")</code> will install it and then PETSc, according to the description above.  If you wish to install it manually, do:</p>
<div class="highlight highlight-source-julia"><pre>  Pkg<span class="pl-k">.</span><span class="pl-c1">clone</span>(<span class="pl-s"><span class="pl-pds">"</span>MPI<span class="pl-pds">"</span></span>)
  Pkg<span class="pl-k">.</span><span class="pl-c1">build</span>(<span class="pl-s"><span class="pl-pds">"</span>MPI<span class="pl-pds">"</span></span>)</pre></div>
<h2><a id="user-content-auto-generation-notes" class="anchor" aria-hidden="true" href="#auto-generation-notes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Auto Generation Notes</h2>
<p>PETSc uses preprocessor variables to decide what code to include when compiling
the library.  Clang does not know what preprocessor variables were defined at
compile time, so it does not correctly detect the typealiases <code>PetscScalar</code>, <code>PetscReal</code>, etc.  To correctly autogenerate wrappers, the proper variables must be passed to Clang with the -D switch.  Note that users will not need to generate their own wrappers because they have already been generated and commit to the repo.</p>
</article></div>