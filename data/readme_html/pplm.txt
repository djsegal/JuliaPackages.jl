<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-pplmjl" class="anchor" aria-hidden="true" href="#pplmjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>PPLM.jl</h1>
<p dir="auto"><a href="https://adarshkumar712.github.io/PPLM.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://adarshkumar712.github.io/PPLM.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/adarshkumar712/PPLM.jl/actions"><img src="https://github.com/adarshkumar712/PPLM.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a></p>
<p dir="auto">PPLM.jl is a Julia Package for Controllable Text Generation based on Plug and Play Language Models. The implementation is primarily based on
Transformers.jl GPT2 and allows user to steer the Text generation task based on some Attribute Models. While being centered around the idea of <b>Gradient based Perturbation</b> from PPLM paper, PPLM.jl supports attribute controlled changes in <code>Hidden States</code> and <code>past key values</code> of GPT2 model.</p>
<ul dir="auto">
<li>
<h4 dir="auto"><a id="user-content-original-implementation-of-pplm-uber-researchpplm" class="anchor" aria-hidden="true" href="#original-implementation-of-pplm-uber-researchpplm"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/uber-research/PPLM">Original Implementation of PPLM: <em>uber-research/PPLM</em></a></h4>
</li>
</ul>
<h2 dir="auto"><a id="user-content-plug-and-play-language-models-a-simple-approach-to-controlled-text-generation" class="anchor" aria-hidden="true" href="#plug-and-play-language-models-a-simple-approach-to-controlled-text-generation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Plug and Play Language Models: a Simple Approach to Controlled Text Generation</h2>
<p dir="auto">Authors: Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, and Rosanne Liu</p>
<p dir="auto">While large pretrained language models can generate coherent text, it's hard to control the context are actually generating.
Plug and Play Language Models or PPLM allows a user to flexibly plug in one or more tiny attribute models representing the desired steering objective into a large, unconditional language model (LM). The main feature of PPLM is that no fine-tuning of Large LMs is required, thus enabling user to leverage LMs without any hardwares needed to train them.</p>
<p dir="auto">Arxiv: <a href="https://arxiv.org/abs/1912.02164" rel="nofollow">https://arxiv.org/abs/1912.02164</a></p>
<h2 dir="auto"><a id="user-content-whats-in-pplmjl" class="anchor" aria-hidden="true" href="#whats-in-pplmjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>What's in PPLM.jl?</h2>
<p dir="auto">PPLM.jl is a <code>Transformers.jl</code> based PPLM implementation in Julia to facilitate <b>attribute controlled text generation</b>. While the main feature of this package is to help with Controlled Text generation, it also facilitates the following through simple API functions:</p>
<ol dir="auto">
<li>GPT2 pretrained Tokenizer</li>
<li>Normal Text generation with GPT2 using few lines of code.</li>
<li>Pretrained Discriminators from Huggingface loaded as BSON file.</li>
<li>Some predefined BagofWords.</li>
<li>Discriminator Training -  Linear layer classifier on GPT2 model</li>
<li>Some more options for Controlled generation of Text, beyond PPLM.</li>
</ol>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">In order to install the PPLM package, write the following in the Julia Prompt:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="] add PPLM"><pre>] add PPLM</pre></div>
<p dir="auto">or</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Pkg
Pkg.add(&quot;PPLM&quot;)"><pre><span class="pl-k">using</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>PPLM<span class="pl-pds">"</span></span>)</pre></div>
<h2 dir="auto"><a id="user-content-roadmap--checkpoints" class="anchor" aria-hidden="true" href="#roadmap--checkpoints"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>RoadMap / Checkpoints</h2>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> GPT2 Tokenizer</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Discriminator structure</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Data Preprocessing</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Normal Text Generation</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Controlled Text Generation: Perturb Probabilities</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Controlled Text Generation: Perturb hidden states</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Controlled Text Generation: Perturb Past key values</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Support BagOfWords Models</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Add Docstrings</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Add Documentation</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""> Add Jupyter Notebook for example on Discriminator Training</li>
</ul>
<p dir="auto">For more details on the progress, checkout the <a href="https://github.com/AdarshKumar712/PPLM.jl/projects/1">Project:PPLM</a></p>
<h2 dir="auto"><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h2>
<p dir="auto"><strong>Note</strong>: For different topics, you may need to tune some hyperparameters like <code>stepsize</code>, <code>fusion_gm_scale</code> etc. to get some really interesting results. Also note that in first iteration, it usually takes more time to evaluate the gradients but becomes fast in consecutive passes. So may need to wait for 2-3 minutes for the first time.</p>
<p dir="auto">First let's load the package and the model:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using PPLM

tokenizer, model = PPLM.get_gpt2();"><pre><span class="pl-k">using</span> PPLM

tokenizer, model <span class="pl-k">=</span> PPLM<span class="pl-k">.</span><span class="pl-c1">get_gpt2</span>();</pre></div>
<p dir="auto">Example for <strong>BoW Model</strong>:</p>
<blockquote>
<p dir="auto"><strong>Prompt</strong>: To conclude</p>
</blockquote>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="args= PPLM.pplm(perturb=&quot;past&quot;, bow_list = [&quot;politics&quot;], stepsize=0.1, fusion_gm_scale=0.8f0, top_k=50)

PPLM.sample_pplm(args; tokenizer=tokenizer, model=model, prompt=&quot;To conclude&quot;)"><pre class="notranslate"><code>args= PPLM.pplm(perturb="past", bow_list = ["politics"], stepsize=0.1, fusion_gm_scale=0.8f0, top_k=50)

PPLM.sample_pplm(args; tokenizer=tokenizer, model=model, prompt="To conclude")
</code></pre></div>
<p dir="auto">Sample generated:</p>
<p dir="auto">Nomral Generation:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="&quot;To conclude, it is only fair to ask, on the other hand, what we think about one particular type of religious denomination that has an unusual relation to American history (other than the ones associated with Catholicism)?\n\nI could imagine it is just because American social studies scholars aren't as committed to explaining the causes of the American revival. Nor would I imagine Protestant professors who write for the Nation, not least because they might fear an attack by critics on their writings that might bring a backlash against their conclusions,&quot;"><pre><span class="pl-s"><span class="pl-pds">"</span>To conclude, it is only fair to ask, on the other hand, what we think about one particular type of religious denomination that has an unusual relation to American history (other than the ones associated with Catholicism)?<span class="pl-cce">\n\n</span>I could imagine it is just because American social studies scholars aren't as committed to explaining the causes of the American revival. Nor would I imagine Protestant professors who write for the Nation, not least because they might fear an attack by critics on their writings that might bring a backlash against their conclusions,<span class="pl-pds">"</span></span></pre></div>
<p dir="auto">With BoW model (bow_list = <code>["politics"]</code>)</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="&quot;To conclude, it's important for governments, from the government of Canada, who decide matters of 
international importance and culture and language issues to the authorities the responsible party for 
immigration enforcement, when that person's an international terrorist, as these are important and cultural 
communities, rather and international business people, like the Canadian government, should take seriously 
when they say these, to the authorities, and then have the Canadian people deal with, and to them be more 
involved in the process itself and their work ethics should really be to&quot;"><pre><span class="pl-s"><span class="pl-pds">"</span>To conclude, it's important for governments, from the government of Canada, who decide matters of </span>
<span class="pl-s">international importance and culture and language issues to the authorities the responsible party for </span>
<span class="pl-s">immigration enforcement, when that person's an international terrorist, as these are important and cultural </span>
<span class="pl-s">communities, rather and international business people, like the Canadian government, should take seriously </span>
<span class="pl-s">when they say these, to the authorities, and then have the Canadian people deal with, and to them be more </span>
<span class="pl-s">involved in the process itself and their work ethics should really be to<span class="pl-pds">"</span></span></pre></div>
<p dir="auto">Example for <strong>Discriminator</strong></p>
<blockquote>
<p dir="auto"><strong>Prompt</strong>: "You should just kill"</p>
</blockquote>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="args = PPLM.pplm(method=&quot;Discrim&quot;, discrim=&quot;toxicity&quot;, target_class_id=1, stepsize=0.008, fusion_kl_scale=0.05);

PPLM.sample_pplm(args; tokenizer=tokenizer, model=model, prompt=&quot;You should just kill&quot;)"><pre>args <span class="pl-k">=</span> PPLM<span class="pl-k">.</span><span class="pl-c1">pplm</span>(method<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Discrim<span class="pl-pds">"</span></span>, discrim<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>toxicity<span class="pl-pds">"</span></span>, target_class_id<span class="pl-k">=</span><span class="pl-c1">1</span>, stepsize<span class="pl-k">=</span><span class="pl-c1">0.008</span>, fusion_kl_scale<span class="pl-k">=</span><span class="pl-c1">0.05</span>);

PPLM<span class="pl-k">.</span><span class="pl-c1">sample_pplm</span>(args; tokenizer<span class="pl-k">=</span>tokenizer, model<span class="pl-k">=</span>model, prompt<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>You should just kill<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">Sample generated:</p>
<p dir="auto">Nomral Generation:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="&quot;You should just kill him.\n\n-The Chosen\n\nYou never heard, no matter how stupid people said it. I 
don't understand how she could think she was safe when she had nothing but contempt for me for four very 
fucking years I just walked along and played the part of a woman who had the power to do what any woman 
can do if a woman's life isn't as she told herself it would be so. What's on the page? I mean, there's 
my dad who was just running&quot;"><pre><span class="pl-s"><span class="pl-pds">"</span>You should just kill him.<span class="pl-cce">\n\n</span>-The Chosen<span class="pl-cce">\n\n</span>You never heard, no matter how stupid people said it. I </span>
<span class="pl-s">don't understand how she could think she was safe when she had nothing but contempt for me for four very </span>
<span class="pl-s">fucking years I just walked along and played the part of a woman who had the power to do what any woman </span>
<span class="pl-s">can do if a woman's life isn't as she told herself it would be so. What's on the page? I mean, there's </span>
<span class="pl-s">my dad who was just running<span class="pl-pds">"</span></span></pre></div>
<p dir="auto">With Disciminator model (discrim = "toxicity")</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="&quot;You should just kill yourself before you realize how much harm it can do. If you have never spent a 
penny you can always try to quit sometime. Some men want a break and some don't: If money helps you, it'll 
help yourself too, but try to make up for it if that helps or if something good starts to come out.\n\nYou 
can do even more harm to yourself by being a \&quot;good man,\&quot; that is, by not being selfish.\n\n5 What Would
Stake Out\n&quot;"><pre><span class="pl-s"><span class="pl-pds">"</span>You should just kill yourself before you realize how much harm it can do. If you have never spent a </span>
<span class="pl-s">penny you can always try to quit sometime. Some men want a break and some don't: If money helps you, it'll </span>
<span class="pl-s">help yourself too, but try to make up for it if that helps or if something good starts to come out.<span class="pl-cce">\n\n</span>You </span>
<span class="pl-s">can do even more harm to yourself by being a <span class="pl-cce">\"</span>good man,<span class="pl-cce">\"</span> that is, by not being selfish.<span class="pl-cce">\n\n</span>5 What Would</span>
<span class="pl-s">Stake Out<span class="pl-cce">\n</span><span class="pl-pds">"</span></span></pre></div>
<p dir="auto">For more, checkout the documentation.</p>
<h2 dir="auto"><a id="user-content-tutorials--blogs" class="anchor" aria-hidden="true" href="#tutorials--blogs"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Tutorials / Blogs</h2>
<ol dir="auto">
<li><a href="https://nextjournal.com/Adarshkumar712/gsoc-2021-pplm.jl" rel="nofollow">PPLM Part 1</a></li>
<li>More Blogs Comming soon... (In the meantime checkout the documentation for some examples on usage)</li>
</ol>
<p dir="auto"><strong>Note</strong>: There might be some differences here from original implementation of PPLM, but the overall idea of Plug and Play Language Models remains the same as the paper. In case some feature from original repository of PPLM is missing here, I will try to accomodate that in future.</p>
<h1 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h1>
<ol dir="auto">
<li><a href="https://arxiv.org/abs/1912.02164" rel="nofollow">Plug and Play Language Models: A Simple Approach to Controlled Text Generation</a></li>
<li><a href="https://github.com/uber-research/PPLM">https://github.com/uber-research/PPLM</a></li>
<li><a href="https://eng.uber.com/pplm/" rel="nofollow">https://eng.uber.com/pplm/</a></li>
</ol>
</article></div>