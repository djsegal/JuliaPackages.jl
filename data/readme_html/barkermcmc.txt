<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-barkermcmc" class="anchor" aria-hidden="true" href="#barkermcmc"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>BarkerMCMC</h1>
<p dir="auto"><a href="http://scheidan.github.io/BarkerMCMC.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/scheidan/BarkerMCMC.jl/actions/workflows/CI.yml?query=branch%3Amain"><img src="https://github.com/scheidan/BarkerMCMC.jl/actions/workflows/CI.yml/badge.svg?branch=main" alt="Build Status" style="max-width: 100%;"></a> <a href="https://codecov.io/gh/scheidan/BarkerMCMC.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/15e691616b848b45bad265b116b725b0e5156e14e6dc290a03ac8662169ed0eb/68747470733a2f2f636f6465636f762e696f2f67682f736368656964616e2f4261726b65724d434d432e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/scheidan/BarkerMCMC.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">A Monte Carlo Markov Chain sampler that makes use of gradient
information. Proposed by Livingstone et al. (2021)</p>
<p dir="auto">The adaptative preconditioning is based on Andrieu and Thoms (2008),
Algorithm 4 in Section 5. For details see Algorithm 7.2 of the supporting information
of Livingstone et al. (2021).</p>
<h3 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h3>
<p dir="auto"><code>] add BarkerMCMC</code></p>
<h3 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h3>
<p dir="auto">See the documentation for all arguments.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using BarkerMCMC

# --- Target distribution
function log_p_rosebruck_2d(x; k=1/200)
    -k*(100*(x[2] - x[1]^2)^2 + (1 - x[1])^2)
end

function ∇log_p_rosebruck_2d(x; k=1/200)
    [-2*k*(200*x[1]^3 - 200*x[1]*x[2] + x[1] -1),   # d/dx[1]
     -200*k*(x[2] - x[1]^2)]                        # d/dx[2]
end

# --- Sampling
# see `?barker_mcmc` for all options
res = barker_mcmc(log_p_rosebruck_2d,
                  ∇log_p_rosebruck_2d,
                  [5.0, 5.0];
                  n_iter = 1_000,
                  target_acceptance_rate=0.4)

res.samples
res.log_p

# --- Result

# acceptance rate
length(unique(res.samples[:,1])) / size(res.samples, 1)

# You may want to use `MCMCChains.jl` for plots and diagonstics
# (must be installed separately)

using MCMCChains
using StatsPlots

chain = Chains(res.samples, [:x1, :x2])
chains[200:10:end]                 # remove burn-in and thinning

plot(chains)
meanplot(chain)
histogram(chain)
autocorplot(chain)
corner(chain)"><pre><span class="pl-k">using</span> BarkerMCMC

<span class="pl-c"><span class="pl-c">#</span> --- Target distribution</span>
<span class="pl-k">function</span> <span class="pl-en">log_p_rosebruck_2d</span>(x; k<span class="pl-k">=</span><span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">200</span>)
    <span class="pl-k">-</span>k<span class="pl-k">*</span>(<span class="pl-c1">100</span><span class="pl-k">*</span>(x[<span class="pl-c1">2</span>] <span class="pl-k">-</span> x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>)<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> (<span class="pl-c1">1</span> <span class="pl-k">-</span> x[<span class="pl-c1">1</span>])<span class="pl-k">^</span><span class="pl-c1">2</span>)
<span class="pl-k">end</span>

<span class="pl-k">function</span> <span class="pl-en">∇log_p_rosebruck_2d</span>(x; k<span class="pl-k">=</span><span class="pl-c1">1</span><span class="pl-k">/</span><span class="pl-c1">200</span>)
    [<span class="pl-k">-</span><span class="pl-c1">2</span><span class="pl-k">*</span>k<span class="pl-k">*</span>(<span class="pl-c1">200</span><span class="pl-k">*</span>x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">3</span> <span class="pl-k">-</span> <span class="pl-c1">200</span><span class="pl-k">*</span>x[<span class="pl-c1">1</span>]<span class="pl-k">*</span>x[<span class="pl-c1">2</span>] <span class="pl-k">+</span> x[<span class="pl-c1">1</span>] <span class="pl-k">-</span><span class="pl-c1">1</span>),   <span class="pl-c"><span class="pl-c">#</span> d/dx[1]</span>
     <span class="pl-k">-</span><span class="pl-c1">200</span><span class="pl-k">*</span>k<span class="pl-k">*</span>(x[<span class="pl-c1">2</span>] <span class="pl-k">-</span> x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span>)]                        <span class="pl-c"><span class="pl-c">#</span> d/dx[2]</span>
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> --- Sampling</span>
<span class="pl-c"><span class="pl-c">#</span> see `?barker_mcmc` for all options</span>
res <span class="pl-k">=</span> <span class="pl-c1">barker_mcmc</span>(log_p_rosebruck_2d,
                  ∇log_p_rosebruck_2d,
                  [<span class="pl-c1">5.0</span>, <span class="pl-c1">5.0</span>];
                  n_iter <span class="pl-k">=</span> <span class="pl-c1">1_000</span>,
                  target_acceptance_rate<span class="pl-k">=</span><span class="pl-c1">0.4</span>)

res<span class="pl-k">.</span>samples
res<span class="pl-k">.</span>log_p

<span class="pl-c"><span class="pl-c">#</span> --- Result</span>

<span class="pl-c"><span class="pl-c">#</span> acceptance rate</span>
<span class="pl-c1">length</span>(<span class="pl-c1">unique</span>(res<span class="pl-k">.</span>samples[:,<span class="pl-c1">1</span>])) <span class="pl-k">/</span> <span class="pl-c1">size</span>(res<span class="pl-k">.</span>samples, <span class="pl-c1">1</span>)

<span class="pl-c"><span class="pl-c">#</span> You may want to use `MCMCChains.jl` for plots and diagonstics</span>
<span class="pl-c"><span class="pl-c">#</span> (must be installed separately)</span>

<span class="pl-k">using</span> MCMCChains
<span class="pl-k">using</span> StatsPlots

chain <span class="pl-k">=</span> <span class="pl-c1">Chains</span>(res<span class="pl-k">.</span>samples, [<span class="pl-c1">:x1</span>, <span class="pl-c1">:x2</span>])
chains[<span class="pl-c1">200</span><span class="pl-k">:</span><span class="pl-c1">10</span><span class="pl-k">:</span><span class="pl-c1">end</span>]                 <span class="pl-c"><span class="pl-c">#</span> remove burn-in and thinning</span>

<span class="pl-c1">plot</span>(chains)
<span class="pl-c1">meanplot</span>(chain)
<span class="pl-c1">histogram</span>(chain)
<span class="pl-c1">autocorplot</span>(chain)
<span class="pl-c1">corner</span>(chain)</pre></div>
<h3 dir="auto"><a id="user-content-related-julia-packages" class="anchor" aria-hidden="true" href="#related-julia-packages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Related Julia Packages</h3>
<ul dir="auto">
<li><a href="https://github.com/TuringLang/MCMCChains.jl">MCMCChains.jl</a></li>
</ul>
<h4 dir="auto"><a id="user-content-hamiltonian-monte-carlo-gradient-based" class="anchor" aria-hidden="true" href="#hamiltonian-monte-carlo-gradient-based"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Hamiltonian Monte Carlo (gradient based)</h4>
<ul dir="auto">
<li><a href="https://github.com/tpapp/DynamicHMC.jl">DynamicHMC.jl</a></li>
<li><a href="https://github.com/TuringLang/AdvancedHMC.jl">AdvancedHMC.jl</a></li>
</ul>
<h4 dir="auto"><a id="user-content-adaptive-mcmc-without-gradient" class="anchor" aria-hidden="true" href="#adaptive-mcmc-without-gradient"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Adaptive MCMC (without gradient)</h4>
<ul dir="auto">
<li><a href="https://github.com/mvihola/AdaptiveMCMC.jl">AdaptiveMCMC.jl</a></li>
<li><a href="https://github.com/anthofflab/RobustAdaptiveMetropolisSampler.jl">RobustAdaptiveMetropolisSampler.jl</a></li>
<li><a href="https://github.com/mauro3/KissMCMC.jl">KissMCMC.jl</a></li>
</ul>
<h3 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h3>
<p dir="auto">Andrieu, C., Thoms, J., 2008. A tutorial on adaptive MCMC. Statistics and computing 18, 343–373.</p>
<p dir="auto">Livingstone, S., Zanella, G., 2021. The Barker proposal: Combining robustness and efficiency in gradient-based MCMC. Journal of the Royal Statistical Society: Series B (Statistical Methodology). <a href="https://doi.org/10.1111/rssb.12482" rel="nofollow">https://doi.org/10.1111/rssb.12482</a>
(see <a href="https://github.com/gzanella/barker">https://github.com/gzanella/barker</a> for the R code used)</p>
</article></div>