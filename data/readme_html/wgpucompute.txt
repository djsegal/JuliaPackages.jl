<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-wgpucompute" class="anchor" aria-hidden="true" href="#wgpucompute"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>WGPUCompute</h1>
<p dir="auto"><a href="https://arhik.github.io/WGPUCompute.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://arhik.github.io/WGPUCompute.jl/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/arhik/WGPUCompute.jl/actions/workflows/CI.yml?query=branch%3Amain"><img src="https://github.com/arhik/WGPUCompute.jl/actions/workflows/CI.yml/badge.svg?branch=main" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/arhik/WGPUCompute.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/a94d653c6d489ad2a642729f7250cae420386b0ca9ab3042eabfb49d8fac9f37/68747470733a2f2f636f6465636f762e696f2f67682f617268696b2f57475055436f6d707574652e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/arhik/WGPUCompute.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">WIP progress</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="
using BenchmarkTools 
using WGPUCompute

aArray = WgpuArray{Float32}(undef, (1024, 1024, 100)) 
bArray = WgpuArray{Float32}(rand(Float32, (1024, 1024, 100)))

@benchmark copyto!(aArray, 1, bArray, 1, prod(size(aArray)))
"><pre><span class="pl-k">using</span> BenchmarkTools 
<span class="pl-k">using</span> WGPUCompute

aArray <span class="pl-k">=</span> <span class="pl-c1">WgpuArray</span><span class="pl-c1">{Float32}</span>(undef, (<span class="pl-c1">1024</span>, <span class="pl-c1">1024</span>, <span class="pl-c1">100</span>)) 
bArray <span class="pl-k">=</span> <span class="pl-c1">WgpuArray</span><span class="pl-c1">{Float32}</span>(<span class="pl-c1">rand</span>(Float32, (<span class="pl-c1">1024</span>, <span class="pl-c1">1024</span>, <span class="pl-c1">100</span>)))

<span class="pl-c1">@benchmark</span> <span class="pl-c1">copyto!</span>(aArray, <span class="pl-c1">1</span>, bArray, <span class="pl-c1">1</span>, <span class="pl-c1">prod</span>(<span class="pl-c1">size</span>(aArray)))
</pre></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="BenchmarkTools.Trial: 403 samples with 1 evaluation.
 Range (min … max):  30.041 μs … 15.397 ms  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     13.710 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   12.424 ms ±  4.124 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%

  ▄                                                   ▇█
  █▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁████▇▅▆ ▆
  30 μs        Histogram: log(frequency) by time      15.3 ms &lt;

 Memory estimate: 3.06 KiB, allocs estimate: 96."><pre class="notranslate"><code>BenchmarkTools.Trial: 403 samples with 1 evaluation.
 Range (min … max):  30.041 μs … 15.397 ms  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     13.710 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   12.424 ms ±  4.124 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%

  ▄                                                   ▇█
  █▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁████▇▅▆ ▆
  30 μs        Histogram: log(frequency) by time      15.3 ms &lt;

 Memory estimate: 3.06 KiB, allocs estimate: 96.
</code></pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="
julia&gt; using WGPUCompute

julia&gt; y = WgpuArray((rand(4, 4, 1) .-0.5) .|&gt; Float32)
4×4×1 WgpuArray{Float32, 3}:
[:, :, 1] =
 -0.383893   0.16837     0.0140184   0.199563
 -0.336961  -0.192162   -0.179518   -0.0335313
  0.444875   0.0344275  -0.100446    0.498892
 -0.354451  -0.488507   -0.078437   -0.132585

julia&gt; @kernel function Relu(x::WgpuArray{T, N}) where {T, N}
               gIdx = globalId.x * globalId.y + globalId.z
               value = x[gIdx]
               out[gIdx] = max(value, 0.0)
       end
WARNING: Method definition Relu(WGPUCompute.WgpuArray{T, N}) where {T, N} in module Main at REPL[26]:1 overwritten on the same line.
Relu (generic function with 1 method)

julia&gt; Relu(y)
4×4×1 WgpuArray{Float32, 3}:
[:, :, 1] =
 0.0       0.16837    0.0140184  0.199563
 0.0       0.0        0.0        0.0
 0.444875  0.0344275  0.0        0.498892
 0.0       0.0        0.0        0.0

&gt; Internally compute shader is generated like below for Relu
 ┌ Info:
 │ struct IOArray {
 │     data:array&lt;f32&gt;
 │ };
 │
 │ @group(0) @binding(0) var&lt;storage, read_write&gt; input0:IOArray ;
 │ @group(0) @binding(1) var&lt;storage, read_write&gt; ouput1:IOArray ;
 │ @compute @workgroup_size(8, 8, 4)
 │ fn Relu(@builtin(global_invocation_id) global_id:vec3&lt;u32&gt;) {
 │     let gIdx = global_id.x * global_id.y+global_id.z;
 │     let value = input0.data[gIdx];
 │     ouput1.data[gIdx] = max(value, 0.0);
 │ }
 └
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> WGPUCompute

julia<span class="pl-k">&gt;</span> y <span class="pl-k">=</span> <span class="pl-c1">WgpuArray</span>((<span class="pl-c1">rand</span>(<span class="pl-c1">4</span>, <span class="pl-c1">4</span>, <span class="pl-c1">1</span>) <span class="pl-k">.-</span><span class="pl-c1">0.5</span>) <span class="pl-k">.|</span><span class="pl-k">&gt;</span> Float32)
<span class="pl-c1">4</span><span class="pl-k">×</span><span class="pl-c1">4</span><span class="pl-k">×</span><span class="pl-c1">1</span> WgpuArray{Float32, <span class="pl-c1">3</span>}<span class="pl-k">:</span>
[:, :, <span class="pl-c1">1</span>] <span class="pl-k">=</span>
 <span class="pl-k">-</span><span class="pl-c1">0.383893</span>   <span class="pl-c1">0.16837</span>     <span class="pl-c1">0.0140184</span>   <span class="pl-c1">0.199563</span>
 <span class="pl-k">-</span><span class="pl-c1">0.336961</span>  <span class="pl-k">-</span><span class="pl-c1">0.192162</span>   <span class="pl-k">-</span><span class="pl-c1">0.179518</span>   <span class="pl-k">-</span><span class="pl-c1">0.0335313</span>
  <span class="pl-c1">0.444875</span>   <span class="pl-c1">0.0344275</span>  <span class="pl-k">-</span><span class="pl-c1">0.100446</span>    <span class="pl-c1">0.498892</span>
 <span class="pl-k">-</span><span class="pl-c1">0.354451</span>  <span class="pl-k">-</span><span class="pl-c1">0.488507</span>   <span class="pl-k">-</span><span class="pl-c1">0.078437</span>   <span class="pl-k">-</span><span class="pl-c1">0.132585</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@kernel</span> <span class="pl-k">function</span> <span class="pl-en">Relu</span>(x<span class="pl-k">::</span><span class="pl-c1">WgpuArray{T, N}</span>) <span class="pl-k">where</span> {T, N}
               gIdx <span class="pl-k">=</span> globalId<span class="pl-k">.</span>x <span class="pl-k">*</span> globalId<span class="pl-k">.</span>y <span class="pl-k">+</span> globalId<span class="pl-k">.</span>z
               value <span class="pl-k">=</span> x[gIdx]
               out[gIdx] <span class="pl-k">=</span> <span class="pl-c1">max</span>(value, <span class="pl-c1">0.0</span>)
       <span class="pl-k">end</span>
WARNING<span class="pl-k">:</span> Method definition <span class="pl-c1">Relu</span>(WGPUCompute<span class="pl-k">.</span>WgpuArray{T, N}) <span class="pl-k">where</span> {T, N} <span class="pl-k">in</span> <span class="pl-k">module</span> Main at REPL[<span class="pl-c1">26</span>]<span class="pl-k">:</span><span class="pl-c1">1</span> overwritten on the same line.
Relu (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">Relu</span>(y)
<span class="pl-c1">4</span><span class="pl-k">×</span><span class="pl-c1">4</span><span class="pl-k">×</span><span class="pl-c1">1</span> WgpuArray{Float32, <span class="pl-c1">3</span>}<span class="pl-k">:</span>
[:, :, <span class="pl-c1">1</span>] <span class="pl-k">=</span>
 <span class="pl-c1">0.0</span>       <span class="pl-c1">0.16837</span>    <span class="pl-c1">0.0140184</span>  <span class="pl-c1">0.199563</span>
 <span class="pl-c1">0.0</span>       <span class="pl-c1">0.0</span>        <span class="pl-c1">0.0</span>        <span class="pl-c1">0.0</span>
 <span class="pl-c1">0.444875</span>  <span class="pl-c1">0.0344275</span>  <span class="pl-c1">0.0</span>        <span class="pl-c1">0.498892</span>
 <span class="pl-c1">0.0</span>       <span class="pl-c1">0.0</span>        <span class="pl-c1">0.0</span>        <span class="pl-c1">0.0</span>

<span class="pl-k">&gt;</span> Internally compute shader is generated like below <span class="pl-k">for</span> Relu
 ┌ Info<span class="pl-k">:</span>
 │ <span class="pl-k">struct</span> IOArray {
 │     data<span class="pl-k">:</span>array<span class="pl-k">&lt;</span>f32<span class="pl-k">&gt;</span>
 │ };
 │
 │ <span class="pl-c1">@group</span>(<span class="pl-c1">0</span>) <span class="pl-c1">@binding</span>(<span class="pl-c1">0</span>) var<span class="pl-k">&lt;</span>storage, read_write<span class="pl-k">&gt;</span> input0<span class="pl-k">:</span>IOArray ;
 │ <span class="pl-c1">@group</span>(<span class="pl-c1">0</span>) <span class="pl-c1">@binding</span>(<span class="pl-c1">1</span>) var<span class="pl-k">&lt;</span>storage, read_write<span class="pl-k">&gt;</span> ouput1<span class="pl-k">:</span>IOArray ;
 │ <span class="pl-c1">@compute</span> <span class="pl-c1">@workgroup_size</span>(<span class="pl-c1">8</span>, <span class="pl-c1">8</span>, <span class="pl-c1">4</span>)
 │ fn <span class="pl-c1">Relu</span>(<span class="pl-c1">@builtin</span>(global_invocation_id) global_id<span class="pl-k">:</span>vec3<span class="pl-k">&lt;</span>u32<span class="pl-k">&gt;</span>) {
 │     <span class="pl-k">let</span> gIdx <span class="pl-k">=</span> global_id<span class="pl-k">.</span>x <span class="pl-k">*</span> global_id<span class="pl-k">.</span>y<span class="pl-k">+</span>global_id<span class="pl-k">.</span>z;
 │     <span class="pl-k">let</span> value <span class="pl-k">=</span> input0<span class="pl-k">.</span>data[gIdx];
 │     ouput1<span class="pl-k">.</span>data[gIdx] <span class="pl-k">=</span> <span class="pl-c1">max</span>(value, <span class="pl-c1">0.0</span>);
 │ }
 └
</pre></div>
<h2 dir="auto"><a id="user-content-issues-in-example-above" class="anchor" aria-hidden="true" href="#issues-in-example-above"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Issues in example above.</h2>
<ul dir="auto">
<li>globalDim is not supported yet. As a temporary fix global_id.y is used.</li>
<li>in generated shader code, @workgroup_size is hardcoded.</li>
</ul>
<h2 dir="auto"><a id="user-content-known-issues" class="anchor" aria-hidden="true" href="#known-issues"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Known issues</h2>
<ul dir="auto">
<li>Currently kernel macro has hardcoded sections and would expect :Relu as main function name. And it is
being currently worked on.</li>
<li>Doesn't have an api to pass @workgroup_size and @dispath_size yet. The example above is hardcoded.</li>
<li>jupyter notebooks are not supported yet because of some softscope issues.</li>
</ul>
<h2 dir="auto"><a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>TODO</h2>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> Fix known issues.</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> Explore possibility of JSServe the generated wgsl code in web app.</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> Complete SPIRV version</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> Explore and adhere to Binary generation eventually.</li>
</ul>
</article></div>