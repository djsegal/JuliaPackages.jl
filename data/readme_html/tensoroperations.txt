<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-tensoroperationsjl" class="anchor" aria-hidden="true" href="#tensoroperationsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>TensorOperations.jl</h1>
<p>Fast tensor operations using a convenient Einstein index notation.</p>
<table>
<thead>
<tr>
<th align="center"><strong>Documentation</strong></th>
<th align="center"><strong>Build Status</strong></th>
<th align="center"><strong>Digital Object Identifier</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://jutho.github.io/TensorOperations.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/f7b92a177c912c1cc007fc9b40f17ff3ee3bb414/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a> <a href="https://jutho.github.io/TensorOperations.jl/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/3e353c26ddfe819150acbc732248f4f2a37f5175/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a></td>
<td align="center"><a href="https://travis-ci.org/Jutho/TensorOperations.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/5c145165b1ca28c3424bc6032c0cd082be3c9aa5/68747470733a2f2f7472617669732d63692e6f72672f4a7574686f2f54656e736f724f7065726174696f6e732e6a6c2e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://travis-ci.org/Jutho/TensorOperations.jl.svg?branch=master" style="max-width:100%;"></a> <a href="https://ci.appveyor.com/project/jutho/tensoroperations-jl/branch/master" rel="nofollow"><img src="https://camo.githubusercontent.com/bd211e27463b456a6af7a08ef5984bd2902458e3/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f4a7574686f2f54656e736f724f7065726174696f6e732e6a6c3f7376673d74727565266272616e63683d6d6173746572" alt="" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/Jutho/TensorOperations.jl?svg=true&amp;branch=master" style="max-width:100%;"></a> <a href="https://codecov.io/gh/Jutho/TensorOperations.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/924fc634d3009df0b00fce9542a2ae3a61b5525e/68747470733a2f2f636f6465636f762e696f2f67682f4a7574686f2f54656e736f724f7065726174696f6e732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="" data-canonical-src="https://codecov.io/gh/Jutho/TensorOperations.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a> <a href="https://coveralls.io/github/Jutho/TensorOperations.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/f146eb9e0c0c9683bce23edfc344f38d6185dbde/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4a7574686f2f54656e736f724f7065726174696f6e732e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://coveralls.io/repos/github/Jutho/TensorOperations.jl/badge.svg?branch=master" style="max-width:100%;"></a></td>
<td align="center"><a href="https://doi.org/10.5281/zenodo.3245497" rel="nofollow"><img src="https://camo.githubusercontent.com/92e2a2129a358cced2a024ea9435f925a590a1c7/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e333234353439372e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.3245497.svg" style="max-width:100%;"></a></td>
</tr>
</tbody>
</table>
<p><strong>TensorOperations v2.0.0 represents a significant update and rewrite from previous versions.</strong></p>
<ul>
<li>
<p>Tensoroperations.jl now exports an <code>ncon</code> method, familiar in the quantum tensor network community and mostly compatible with e.g. <a href="https://arxiv.org/abs/1402.0939" rel="nofollow">arXiv:1402.0939</a>. Unlike the <code>@tensor</code> which has been at the heart of TensorOperations.jl, the <code>ncon</code> analyzes the network at runtime, and as a consequence has a non-inferrable output. On the other hand, this allows to use dynamical index specifications which are not known at compile time. There is also an <code>@ncon</code> macro which uses the same format and also allows for dynamical index specifications, but has the advantage that it adds a hook into the global LRU cache where temporary objects are stored and recycled.</p>
</li>
<li>
<p>TensorOperations.jl now supports <code>CuArray</code> objects via the NVidia's CUTENSOR library, which is wrapped in CuArrays.jl. This requires that the latter is also loaded with <code>using CuArrays</code>. <code>CuArray</code> objects can directly be used in the existing calls and macro environments like <code>@tensor</code> and <code>@ncon</code>. However, no operation should try to mix a normal <code>Array</code> and a <code>CuArray</code>. There is also a new <code>@cutensor</code> macro which will transform all array objects to the GPU and perform the contractions and permutations there. Objects are moved to the GPU when they are first needed, so that transfer times of later objects can coincide with computation time for operations on earlier objects.</p>
</li>
<li>
<p>TensorOperations.jl now has a <code>@notensor</code> macro to indicate that a block within an <code>@tensor</code> environment (or <code>@tensoropt</code> or <code>@cutensor</code>) should be left alone and contains valid Julia code that should not be transformed.</p>
</li>
</ul>
<h3><a id="user-content-code-example" class="anchor" aria-hidden="true" href="#code-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Code Example</h3>
<p>TensorOperations.jl is mostly used through the <code>@tensor</code> macro which allows one to express a given operation in terms of <a href="https://en.wikipedia.org/wiki/Abstract_index_notation" rel="nofollow">index notation</a> format, a.k.a. <a href="https://en.wikipedia.org/wiki/Einstein_notation" rel="nofollow">Einstein notation</a> (using Einstein's summation convention).</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> TensorOperations
α<span class="pl-k">=</span><span class="pl-c1">randn</span>()
A<span class="pl-k">=</span><span class="pl-c1">randn</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>)
B<span class="pl-k">=</span><span class="pl-c1">randn</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>)
C<span class="pl-k">=</span><span class="pl-c1">randn</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>)
D<span class="pl-k">=</span><span class="pl-c1">zeros</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>)
<span class="pl-c1">@tensor</span> <span class="pl-k">begin</span>
    D[a,b,c] <span class="pl-k">=</span> A[a,e,f,c,f,g]<span class="pl-k">*</span>B[g,b,e] <span class="pl-k">+</span> α<span class="pl-k">*</span>C[c,a,b]
    E[a,b,c] <span class="pl-k">:=</span> A[a,e,f,c,f,g]<span class="pl-k">*</span>B[g,b,e] <span class="pl-k">+</span> α<span class="pl-k">*</span>C[c,a,b]
<span class="pl-k">end</span></pre></div>
<p>In the second to last line, the result of the operation will be stored in the preallocated array <code>D</code>, whereas the last line uses a different assignment operator <code>:=</code> in order to define and allocate a new array <code>E</code> of the correct size. The contents of <code>D</code> and <code>E</code> will be equal.</p>
<p>For more information, please see the docs.</p>
</article></div>