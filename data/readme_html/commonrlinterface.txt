<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-commonrlinterface" class="anchor" aria-hidden="true" href="#commonrlinterface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>CommonRLInterface</h1>
<p><a href="https://JuliaReinforcementLearning.github.io/CommonRLInterface.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/f7b92a177c912c1cc007fc9b40f17ff3ee3bb414/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a>
<a href="https://JuliaReinforcementLearning.github.io/CommonRLInterface.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/3e353c26ddfe819150acbc732248f4f2a37f5175/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a>
<a href="https://travis-ci.com/JuliaReinforcementLearning/CommonRLInterface.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/bb6d0071266010f83c8ff3031fa4bb0feb99f552/68747470733a2f2f7472617669732d63692e636f6d2f4a756c69615265696e666f7263656d656e744c6561726e696e672f436f6d6d6f6e524c496e746572666163652e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/JuliaReinforcementLearning/CommonRLInterface.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/JuliaReinforcementLearning/CommonRLInterface.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/eda472d506df8eecda6c9c4257d57e8194afc283/68747470733a2f2f636f6465636f762e696f2f67682f4a756c69615265696e666f7263656d656e744c6561726e696e672f436f6d6d6f6e524c496e746572666163652e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/JuliaReinforcementLearning/CommonRLInterface.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p>This package is designed for two reasons:</p>
<ol>
<li>to provide compatibility between different reinforcement learning (RL) environment interfaces - for example, an algorithm that uses <code>YourRLInterface</code> should be able to use an environment from <code>MyRLInterface</code> <em>without</em> depending on <code>MyRLInterface</code> as long as they both support <code>CommonRLInterface</code>.</li>
<li>to provide a very basic interface for users to write their own RL environments and algorithms.</li>
</ol>
<p>To accomplish this, there is a single abstract environment type, <code>AbstractEnv</code>, a small required interface, and a larger optional interface will be added soon.</p>
<h2><a id="user-content-required-interface" class="anchor" aria-hidden="true" href="#required-interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Required Interface</h2>
<p>The interface has only three required functions:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">step!</span>(env, a)   <span class="pl-c"><span class="pl-c">#</span> returns an observation, reward, done, and info</span>
<span class="pl-c1">reset!</span>(env)     <span class="pl-c"><span class="pl-c">#</span> returns an observation</span>
<span class="pl-c1">actions</span>(env)    <span class="pl-c"><span class="pl-c">#</span> returns the set of all possible actions for the environment</span></pre></div>
<h2><a id="user-content-optional-interface" class="anchor" aria-hidden="true" href="#optional-interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optional Interface</h2>
<p>In the near future, a number of optional interface functions will be added. Please file an issue if you would like to see a particular interface function.</p>
<h2><a id="user-content-additional-info" class="anchor" aria-hidden="true" href="#additional-info"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Additional info</h2>
<h3><a id="user-content-what-does-it-mean-for-an-rl-framework-to-support-commonrlinterface" class="anchor" aria-hidden="true" href="#what-does-it-mean-for-an-rl-framework-to-support-commonrlinterface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>What does it mean for an RL Framework to "support" CommonRLInterface?</h3>
<p>Suppose you have an abstract environment type in your package called <code>YourEnv</code>. Support for <code>AbstractEnv</code> means:</p>
<ol>
<li>
<p>You provide a convert methods</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">convert</span>(Type{YourEnv}, <span class="pl-k">::</span><span class="pl-c1">AbstractEnv</span>)
<span class="pl-c1">convert</span>(Type{AbstractEnv}, <span class="pl-k">::</span><span class="pl-c1">YourEnv</span>)</pre></div>
<p>If there are additional options in the conversion, you are encouraged to create and document constructors with additional arguments.</p>
</li>
<li>
<p>You provide an implementation of the interface functions from your framework only using functions from CommonRLInterface</p>
</li>
<li>
<p>You implement at minimum</p>
<ul>
<li><code>CommonRL.reset!(::YourCommonEnv)</code></li>
<li><code>CommonRL.step!(::YourCommonEnv, a)</code></li>
<li><code>CommonRL.actions(::YourCommonEnv)</code>
and as many optional functions as you'd like to support, where <code>YourCommonEnv</code> is the concrete type returned by <code>convert(Type{AbstractEnv}, ::YourEnv)</code></li>
</ul>
</li>
</ol>
<h3><a id="user-content-what-does-an-environment-implementation-look-like" class="anchor" aria-hidden="true" href="#what-does-an-environment-implementation-look-like"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>What does an environment implementation look like?</h3>
<p>A 1-D LQR problem with discrete actions might look like this:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">mutable struct</span> LQREnv <span class="pl-k">&lt;:</span> <span class="pl-c1">AbstractEnv</span>
    s<span class="pl-k">::</span><span class="pl-c1">Float64</span>
<span class="pl-k">end</span>

<span class="pl-k">function</span> CommonRLInterface<span class="pl-k">.</span><span class="pl-en">reset!</span>(m<span class="pl-k">::</span><span class="pl-c1">LQREnv</span>)
    m<span class="pl-k">.</span>s <span class="pl-k">=</span> <span class="pl-c1">0.0</span>
<span class="pl-k">end</span>

<span class="pl-k">function</span> CommonRLInterface<span class="pl-k">.</span><span class="pl-en">step!</span>(m<span class="pl-k">::</span><span class="pl-c1">LQREnv</span>, a)
    r <span class="pl-k">=</span> <span class="pl-k">-</span>m<span class="pl-k">.</span>s<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">-</span> a<span class="pl-k">^</span><span class="pl-c1">2</span>
    sp <span class="pl-k">=</span> m<span class="pl-k">.</span>s <span class="pl-k">=</span> m<span class="pl-k">.</span>s <span class="pl-k">+</span> a <span class="pl-k">+</span> <span class="pl-c1">randn</span>()
    <span class="pl-k">return</span> sp, r, <span class="pl-c1">false</span>, <span class="pl-c1">NamedTuple</span>()
<span class="pl-k">end</span>

CommonRLInterface<span class="pl-k">.</span><span class="pl-en">actions</span>(m<span class="pl-k">::</span><span class="pl-c1">LQREnv</span>) <span class="pl-k">=</span> (<span class="pl-k">-</span><span class="pl-c1">1.0</span>, <span class="pl-c1">0.0</span>, <span class="pl-c1">1.0</span>)

<span class="pl-c"><span class="pl-c">#</span> from version 0.2 on, you can implement optional functions like this:</span>
<span class="pl-c"><span class="pl-c">#</span> @provide CommonRLInterface.clone(m::LQREnv) = LQREnv(m.s)</span></pre></div>
<h3><a id="user-content-what-does-a-simulation-with-a-random-policy-look-like" class="anchor" aria-hidden="true" href="#what-does-a-simulation-with-a-random-policy-look-like"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>What does a simulation with a random policy look like?</h3>
<div class="highlight highlight-source-julia"><pre>env <span class="pl-k">=</span> <span class="pl-c1">YourEnv</span>()
done <span class="pl-k">=</span> <span class="pl-c1">false</span>
o <span class="pl-k">=</span> <span class="pl-c1">reset!</span>(env)
acts <span class="pl-k">=</span> <span class="pl-c1">actions</span>(env)
rsum <span class="pl-k">=</span> <span class="pl-c1">0.0</span>
<span class="pl-k">while</span> <span class="pl-k">!</span>done
    o, r, done, info <span class="pl-k">=</span> <span class="pl-c1">step!</span>(env, <span class="pl-c1">rand</span>(acts)) 
    r <span class="pl-k">+=</span> rsum
<span class="pl-k">end</span>
<span class="pl-c1">@show</span> rsum</pre></div>
<h3><a id="user-content-what-does-it-mean-for-an-algorithm-to-support-commonrlinterface" class="anchor" aria-hidden="true" href="#what-does-it-mean-for-an-algorithm-to-support-commonrlinterface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>What does it mean for an algorithm to "support" CommonRLInterface?</h3>
<p>You should have a method of your solver or algorithm that accepts a <code>AbstractEnv</code>, perhaps handling it by converting it to your framework first, e.g.</p>
<pre><code>solve(env::AbstractEnv) = solve(convert(YourEnv, env))
</code></pre>
</article></div>