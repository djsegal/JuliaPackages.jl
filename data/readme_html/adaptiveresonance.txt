<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a href="https://AP6YC.github.io/AdaptiveResonance.jl/dev" rel="nofollow"><img src="https://github.com/AP6YC/FileStorage/raw/main/AdaptiveResonance/header.png?raw=true" alt="adaptiveresonance-header" style="max-width: 100%;"></a></p>
<p dir="auto">A Julia package for Adaptive Resonance Theory (ART) algorithms.</p>
<table>
<thead>
<tr>
<th align="center"><strong>Documentation</strong></th>
<th align="center"><strong>Testing Status</strong></th>
<th align="center"><strong>Coverage</strong></th>
<th align="center"><strong>Reference</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://AP6YC.github.io/AdaptiveResonance.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://github.com/AP6YC/AdaptiveResonance.jl/actions?query=workflow%3ACI"><img src="https://github.com/AP6YC/AdaptiveResonance.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://codecov.io/gh/AP6YC/AdaptiveResonance.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/71a23bab81a668ad456df387605bc042533d68b6c9796e00631568b19828a614/68747470733a2f2f636f6465636f762e696f2f67682f41503659432f41646170746976655265736f6e616e63652e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Codecov" data-canonical-src="https://codecov.io/gh/AP6YC/AdaptiveResonance.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://doi.org/10.21105/joss.03671" rel="nofollow"><img src="https://camo.githubusercontent.com/b5e3e327794711c0579095556abf93eed4d22cc21fec32f5cc4d593ed5bfd015/68747470733a2f2f6a6f73732e7468656f6a2e6f72672f7061706572732f31302e32313130352f6a6f73732e30333637312f7374617475732e737667" alt="DOI" data-canonical-src="https://joss.theoj.org/papers/10.21105/joss.03671/status.svg" style="max-width: 100%;"></a></td>
</tr>
<tr>
<td align="center"><a href="https://AP6YC.github.io/AdaptiveResonance.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://ci.appveyor.com/project/AP6YC/AdaptiveResonance-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/3d77e75eac1be4150db1e7c791acaeeb27505ccb920e8a6810b5beb127dff045/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f41503659432f41646170746976655265736f6e616e63652e6a6c3f7376673d74727565" alt="Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/AP6YC/AdaptiveResonance.jl?svg=true" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://coveralls.io/github/AP6YC/AdaptiveResonance.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/cb32c0200d3ba39efb949ace5a4169cd1637ea05a7fd319031c4836f2708df62/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f41503659432f41646170746976655265736f6e616e63652e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coveralls" data-canonical-src="https://coveralls.io/repos/github/AP6YC/AdaptiveResonance.jl/badge.svg?branch=master" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://doi.org/10.5281/zenodo.5748453" rel="nofollow"><img src="https://camo.githubusercontent.com/74fa8ad3e73e2a291aa03ecc3dd12e25b900c4d3840908bbcdfbbfd0ae559d98/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e353734383435332e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.5748453.svg" style="max-width: 100%;"></a></td>
</tr>
<tr>
<td align="center"><strong>Documentation Build</strong></td>
<td align="center"><strong>JuliaHub Status</strong></td>
<td align="center"><strong>Dependents</strong></td>
<td align="center"><strong>Release</strong></td>
</tr>
<tr>
<td align="center"><a href="https://github.com/AP6YC/AdaptiveResonance.jl/actions/workflows/Documentation.yml"><img src="https://github.com/AP6YC/AdaptiveResonance.jl/actions/workflows/Documentation.yml/badge.svg" alt="Documentation" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://juliahub.com/ui/Packages/AdaptiveResonance/Sm0We" rel="nofollow"><img src="https://camo.githubusercontent.com/5fa4b74d5859b91de3e8b59d20ac5914f8796a19c737f6c3b980edebc487ab32/68747470733a2f2f6a756c69616875622e636f6d2f646f63732f41646170746976655265736f6e616e63652f706b676576616c2e737667" alt="pkgeval" data-canonical-src="https://juliahub.com/docs/AdaptiveResonance/pkgeval.svg" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://juliahub.com/ui/Packages/AdaptiveResonance/Sm0We?t=2" rel="nofollow"><img src="https://camo.githubusercontent.com/befcf72d74614e8716696792a63a24704f23171d77099b0f7e3d9f1895c828f9/68747470733a2f2f6a756c69616875622e636f6d2f646f63732f41646170746976655265736f6e616e63652f646570732e737667" alt="deps" data-canonical-src="https://juliahub.com/docs/AdaptiveResonance/deps.svg" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://juliahub.com/ui/Packages/AdaptiveResonance/Sm0We" rel="nofollow"><img src="https://camo.githubusercontent.com/afe8e6e882e5051946d7826d8ac8171f7035b3209985de98faa2dd3bea53b794/68747470733a2f2f6a756c69616875622e636f6d2f646f63732f41646170746976655265736f6e616e63652f76657273696f6e2e737667" alt="version" data-canonical-src="https://juliahub.com/docs/AdaptiveResonance/version.svg" style="max-width: 100%;"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">Please read the <a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/" rel="nofollow">documentation</a> for detailed usage and tutorials.</p>
<h2 dir="auto"><a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contents</h2>
<ul dir="auto">
<li><a href="#contents">Contents</a></li>
<li><a href="#overview">Overview</a></li>
<li><a href="#usage">Usage</a>
<ul dir="auto">
<li><a href="#installation">Installation</a></li>
<li><a href="#quickstart">Quickstart</a></li>
<li><a href="#implemented-modules">Implemented Modules</a></li>
<li><a href="#contributing">Contributing</a></li>
</ul>
</li>
<li><a href="#acknowledgements">Acknowledgements</a>
<ul dir="auto">
<li><a href="#authors">Authors</a></li>
<li><a href="#support">Support</a></li>
<li><a href="#history">History</a></li>
<li><a href="#software">Software</a></li>
<li><a href="#datasets">Datasets</a></li>
<li><a href="#license">License</a></li>
<li><a href="#citation">Citation</a></li>
</ul>
</li>
</ul>
<h2 dir="auto"><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Overview</h2>
<p dir="auto">Adaptive Resonance Theory (ART) is a neurocognitive theory of how recurrent cellular networks can learn distributed patterns without supervision.
As a theory, it provides coherent and consistent explanations of how real neural networks learn patterns through competition, and it predicts the phenomena of attention and expectation as central to learning.
In engineering, the theory has been applied to a myriad of algorithmic models for unsupervised machine learning, though it has been extended to supervised and reinforcement learning frameworks.
This package provides implementations of many of these algorithms in Julia for both scientific research and engineering applications.
Basic installation is outlined in <a href="#installation">Installation</a>, while a quickstart is provided in <a href="#quickstart">Quickstart</a>.
Detailed usage and examples are provided in the <a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/" rel="nofollow">documentation</a>.</p>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<h3 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h3>
<p dir="auto">This project is distributed as a <a href="https://julialang.org/" rel="nofollow">Julia</a> package, available on <a href="https://juliahub.com/" rel="nofollow">JuliaHub</a>, so you must first <a href="https://julialang.org/downloads/" rel="nofollow">install Julia</a> on your system.
Its usage follows the usual <a href="https://docs.julialang.org/en/v1/stdlib/Pkg/" rel="nofollow">Julia package installation procedure</a>, interactively:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="julia&gt; ]
(@v1.8) pkg&gt; add AdaptiveResonance"><pre lang="julia-repl" class="notranslate"><code>julia&gt; ]
(@v1.8) pkg&gt; add AdaptiveResonance
</code></pre></div>
<p dir="auto">or programmatically:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="julia&gt; using Pkg
julia&gt; Pkg.add(&quot;AdaptiveResonance&quot;)"><pre lang="julia-repl" class="notranslate"><code>julia&gt; using Pkg
julia&gt; Pkg.add("AdaptiveResonance")
</code></pre></div>
<p dir="auto">You may also add the package directly from GitHub to get the latest changes between releases:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="julia&gt; ]
(@v1.8) pkg&gt; add https://github.com/AP6YC/AdaptiveResonance.jl"><pre lang="julia-repl" class="notranslate"><code>julia&gt; ]
(@v1.8) pkg&gt; add https://github.com/AP6YC/AdaptiveResonance.jl
</code></pre></div>
<h3 dir="auto"><a id="user-content-quickstart" class="anchor" aria-hidden="true" href="#quickstart"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quickstart</h3>
<p dir="auto">Load the module with</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using AdaptiveResonance"><pre><span class="pl-k">using</span> AdaptiveResonance</pre></div>
<p dir="auto">The stateful information of ART modules are structs with default constructures such as</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="art = DDVFA()"><pre>art <span class="pl-k">=</span> <span class="pl-c1">DDVFA</span>()</pre></div>
<p dir="auto">You can pass module-specific options during construction with keyword arguments such as</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="art = DDVFA(rho_ub=0.75, rho_lb=0.4)"><pre>art <span class="pl-k">=</span> <span class="pl-c1">DDVFA</span>(rho_ub<span class="pl-k">=</span><span class="pl-c1">0.75</span>, rho_lb<span class="pl-k">=</span><span class="pl-c1">0.4</span>)</pre></div>
<p dir="auto">For more advanced users, options for the modules are contained in <a href="https://github.com/mauro3/Parameters.jl"><code>Parameters.jl</code></a> structs.
These options can be passed keyword arguments before instantiating the model:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="opts = opts_DDVFA(rho_ub=0.75, rho_lb=0.4)
art = DDVFA(opts)"><pre>opts <span class="pl-k">=</span> <span class="pl-c1">opts_DDVFA</span>(rho_ub<span class="pl-k">=</span><span class="pl-c1">0.75</span>, rho_lb<span class="pl-k">=</span><span class="pl-c1">0.4</span>)
art <span class="pl-k">=</span> <span class="pl-c1">DDVFA</span>(opts)</pre></div>
<p dir="auto">Train and test the models with <code>train!</code> and <code>classify</code>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Unsupervised ART module
art = DDVFA()

# Supervised ARTMAP module
artmap = SFAM()

# Load some data
train_x, train_y, test_x, test_y = load_your_data()

# Unsupervised training and testing
train!(art, train_x)
y_hat_art = classify(art, test_x)

# Supervised training and testing
train!(artmap, train_x, train_y)
y_hat_artmap = classify(art, test_x)"><pre><span class="pl-c"><span class="pl-c">#</span> Unsupervised ART module</span>
art <span class="pl-k">=</span> <span class="pl-c1">DDVFA</span>()

<span class="pl-c"><span class="pl-c">#</span> Supervised ARTMAP module</span>
artmap <span class="pl-k">=</span> <span class="pl-c1">SFAM</span>()

<span class="pl-c"><span class="pl-c">#</span> Load some data</span>
train_x, train_y, test_x, test_y <span class="pl-k">=</span> <span class="pl-c1">load_your_data</span>()

<span class="pl-c"><span class="pl-c">#</span> Unsupervised training and testing</span>
<span class="pl-c1">train!</span>(art, train_x)
y_hat_art <span class="pl-k">=</span> <span class="pl-c1">classify</span>(art, test_x)

<span class="pl-c"><span class="pl-c">#</span> Supervised training and testing</span>
<span class="pl-c1">train!</span>(artmap, train_x, train_y)
y_hat_artmap <span class="pl-k">=</span> <span class="pl-c1">classify</span>(art, test_x)</pre></div>
<p dir="auto"><code>train!</code> and <code>classify</code> can accept incremental or batch data, where rows are features and columns are samples.</p>
<p dir="auto">Unsupervised ART modules can also accommodate simple supervised learning where internal categories are mapped to supervised labels with the keyword argument <code>y</code>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Unsupervised ART module
art = DDVFA()
train!(art, train_x, y=train_y)"><pre><span class="pl-c"><span class="pl-c">#</span> Unsupervised ART module</span>
art <span class="pl-k">=</span> <span class="pl-c1">DDVFA</span>()
<span class="pl-c1">train!</span>(art, train_x, y<span class="pl-k">=</span>train_y)</pre></div>
<p dir="auto">These modules also support retrieving the "best-matching unit" in the case of complete mismatch (i.e., the next-best category if the presented sample is completely unrecognized) with the keyword argument <code>get_bmu</code>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Get the best-matching unit in the case of complete mismatch
y_hat_bmu = classify(art, test_x, get_bmu=true)"><pre><span class="pl-c"><span class="pl-c">#</span> Get the best-matching unit in the case of complete mismatch</span>
y_hat_bmu <span class="pl-k">=</span> <span class="pl-c1">classify</span>(art, test_x, get_bmu<span class="pl-k">=</span><span class="pl-c1">true</span>)</pre></div>
<h3 dir="auto"><a id="user-content-implemented-modules" class="anchor" aria-hidden="true" href="#implemented-modules"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Implemented Modules</h3>
<p dir="auto">This project has implementations of the following ART (unsupervised) and ARTMAP (supervised) modules:</p>
<ul dir="auto">
<li>ART
<ul dir="auto">
<li><strong><a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.FuzzyART" rel="nofollow"><code>FuzzyART</code></a></strong>: Fuzzy ART</li>
<li><strong><a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.DVFA" rel="nofollow"><code>DVFA</code></a></strong>: Dual Vigilance Fuzzy ART</li>
<li><strong><a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.DDVFA" rel="nofollow"><code>DDVFA</code></a></strong>: Distributed Dual Vigilance Fuzzy ART</li>
</ul>
</li>
<li>ARTMAP
<ul dir="auto">
<li><strong><a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.SFAM" rel="nofollow"><code>SFAM</code></a></strong>: Simplified Fuzzy ARTMAP</li>
<li><strong><a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.FAM" rel="nofollow"><code>FAM</code></a></strong>: Fuzzy ARTMAP</li>
</ul>
</li>
</ul>
<p dir="auto">Because each of these modules is a framework for many variants in the literature, this project also implements these <a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/modules/" rel="nofollow">variants</a> by changing their module <a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/guide/#art_options" rel="nofollow">options</a>.
Variants built upon these modules are:</p>
<ul dir="auto">
<li>ART
<ul dir="auto">
<li><strong><a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.GammaNormalizedFuzzyART-Tuple%7Bopts_FuzzyART%7D" rel="nofollow"><code>GammaNormalizedFuzzyART</code></a></strong>: Gamma-Normalized FuzzyART (variant of FuzzyART).</li>
</ul>
</li>
<li>ARTMAP
<ul dir="auto">
<li><strong><a href="https://ap6yc.github.io/AdaptiveResonance.jl/stable/man/full-index/#AdaptiveResonance.DAM-Tuple%7Bopts_SFAM%7D" rel="nofollow"><code>DAM</code></a></strong>: Default ARTMAP (variant of SFAM).</li>
</ul>
</li>
</ul>
<p dir="auto">In addition to these modules, this package contains the following accessory methods:</p>
<ul dir="auto">
<li><a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.artscene_filter-Union%7BTuple%7BArray%7BT,%203%7D%7D,%20Tuple%7BT%7D%7D%20where%20T%3C:AbstractFloat" rel="nofollow"><strong>ARTSCENE</strong></a>: the ARTSCENE algorithm's multiple-stage filtering process is implemented as <a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.artscene_filter-Union%7BTuple%7BArray%7BT,%203%7D%7D,%20Tuple%7BT%7D%7D%20where%20T%3C:AbstractFloat" rel="nofollow"><code>artscene_filter</code></a>. Each filter stage is implemented internally if further granularity is required.</li>
<li><a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.performance-Tuple%7BAbstractVector%7BT%7D%20where%20T%3C:Integer,%20AbstractVector%7BT%7D%20where%20T%3C:Integer%7D" rel="nofollow"><strong>performance</strong></a>: classification accuracy is implemented as <a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.performance-Tuple%7BAbstractVector%7BT%7D%20where%20T%3C:Integer,%20AbstractVector%7BT%7D%20where%20T%3C:Integer%7D" rel="nofollow"><code>performance</code></a>.</li>
<li><a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.complement_code-Tuple%7BAbstractArray%7BT%7D%20where%20T%3C:Real%7D" rel="nofollow"><strong>complement_code</strong></a>: complement coding is implemented with <a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.complement_code-Tuple%7BAbstractArray%7BT%7D%20where%20T%3C:Real%7D" rel="nofollow"><code>complement_code</code></a>.
However, training and classification methods complement code their inputs unless they are passed <code>preprocessed=true</code>, indicating to the model that this step has already been done.</li>
<li><a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.linear_normalization-Tuple%7BAbstractMatrix%7BT%7D%20where%20T%3C:Real%7D" rel="nofollow"><strong>linear_normalization</strong></a>: the first step to complement coding, <a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/full-index/#AdaptiveResonance.linear_normalization-Tuple%7BAbstractMatrix%7BT%7D%20where%20T%3C:Real%7D" rel="nofollow"><code>linear_normalization</code></a> normalizes input arrays within <code>[0, 1]</code>.</li>
</ul>
<h3 dir="auto"><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributing</h3>
<p dir="auto">If you have a question or concern, please raise an <a href="https://github.com/AP6YC/AdaptiveResonance.jl/issues">issue</a>.
For more details on how to work with the project, propose changes, or even contribute code, please see the <a href="https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/contributing/" rel="nofollow">Developer Notes</a> in the project's documentation.</p>
<p dir="auto">In summary:</p>
<ol dir="auto">
<li>Questions and requested changes should all be made in the <a href="https://github.com/AP6YC/AdaptiveResonance.jl/issues">issues</a> page.
These are preferred because they are publicly viewable and could assist or educate others with similar issues or questions.</li>
<li>For changes, this project accepts pull requests (PRs) from <code>feature/&lt;my-feature&gt;</code> branches onto the <code>develop</code> branch using the <a href="https://nvie.com/posts/a-successful-git-branching-model/" rel="nofollow">GitFlow</a> methodology.
If unit tests pass and the changes are beneficial, these PRs are merged into <code>develop</code> and eventually folded into versioned releases throug a <code>release</code> branch that is merged with the <code>master</code> branch.</li>
<li>The project follows the <a href="https://semver.org/" rel="nofollow">Semantic Versioning</a> convention of <code>major.minor.patch</code> incremental versioning numbers.
Patch versions are for bug fixes, minor versions are for backward-compatible changes, and major versions are for new and incompatible usage changes.</li>
</ol>
<h2 dir="auto"><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Acknowledgements</h2>
<h3 dir="auto"><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Authors</h3>
<p dir="auto">This package is developed and maintained by <a href="https://github.com/AP6YC">Sasha Petrenko</a> with sponsorship by the <a href="https://acil.mst.edu/" rel="nofollow">Applied Computational Intelligence Laboratory (ACIL)</a>.
The users <a href="https://github.com/aaronpeikert">@aaronpeikert</a>, <a href="https://github.com/hayesall">@hayesall</a>, and <a href="https://github.com/markNZed">@markNZed</a> have graciously contributed their time with reviews and feedback that has greatly improved the project.</p>
<h3 dir="auto"><a id="user-content-support" class="anchor" aria-hidden="true" href="#support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Support</h3>
<p dir="auto">This project is supported by grants from the <a href="https://c5isr.ccdc.army.mil/inside_c5isr_center/nvesd/" rel="nofollow">Night Vision Electronic Sensors Directorate</a>, the <a href="https://www.darpa.mil/program/lifelong-learning-machines" rel="nofollow">DARPA Lifelong Learning Machines (L2M) program</a>, <a href="http://www.teledyne.com/" rel="nofollow">Teledyne Technologies</a>, and the <a href="https://www.nsf.gov/" rel="nofollow">National Science Foundation</a>.
The material, findings, and conclusions here do not necessarily reflect the views of these entities.</p>
<p dir="auto">Research was sponsored by the Army Research Laboratory and was accomplished under
Cooperative Agreement Number W911NF-22-2-0209.
The views and conclusions contained in this document are
those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of
the Army Research Laboratory or the U.S. Government.
The U.S. Government is authorized to reproduce and
distribute reprints for Government purposes notwithstanding any copyright notation herein.</p>
<h3 dir="auto"><a id="user-content-history" class="anchor" aria-hidden="true" href="#history"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>History</h3>
<ul dir="auto">
<li>7/10/2020 - Begin project.</li>
<li>11/3/2020 - Complete baseline modules and tests.</li>
<li>2/8/2021 - Formalize usage documentation.</li>
<li>10/13/2021 - Initiate GitFlow contribution.</li>
<li>5/4/2022 - <a href="https://doi.org/10.21105/joss.03671" rel="nofollow">Acceptance to JOSS</a>.</li>
<li>10/11/2022 - v0.6.0</li>
<li>12/15/2022 - v0.7.0</li>
<li>1/30/2023 - v0.8.0</li>
</ul>
<h3 dir="auto"><a id="user-content-software" class="anchor" aria-hidden="true" href="#software"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Software</h3>
<p dir="auto">Adaptive Resonance Theory has been developed in theory and in application by many research groups since the theory's conception, and so this project was not developed in a vacuum.
This project itself is built upon the wisdom and precedent of decades of previous work in ART in a variety of programming languages.
The code in this repository is inspired the following repositories:</p>
<ul dir="auto">
<li><a href="https://github.com/ACIL-Group">ACIL Organization GitHub</a>
<ul dir="auto">
<li>MATLAB
<ul dir="auto">
<li><a href="https://github.com/ACIL-Group/DDVFA">DDVFA</a>: Companion MATLAB implementation of distrubuted dual vigilance fuzzy ART.</li>
<li><a href="https://github.com/ACIL-Group/DVFA">DVFA</a>: Companion MATLAB code for Dual Vigilance Fuzzy ART</li>
<li><a href="https://github.com/ACIL-Group/iCVI-toolbox">iCVI-toolbox</a>: A MATLAB toolbox for incremental/batch cluster validity indices</li>
<li><a href="https://github.com/ACIL-Group/CVIFA">CVIFA</a>: Companion MATLAB implementation of validity index-based vigilance test fuzzy ART.</li>
<li><a href="https://github.com/ACIL-Group/VAT-FA">VAT-FA</a>: Companion MATLAB code for VAT + Fuzzy ART.</li>
<li><a href="https://github.com/ACIL-Group/BARTMAP-CF">BARTMAP-CF</a>: Companion MATLAB code for BARTMAP-based collaborative filtering</li>
</ul>
</li>
<li>Python
<ul dir="auto">
<li><a href="https://github.com/ACIL-Group/NuART-Py">NuART-Py</a>: An internal ACIL python package for ART neural networks.</li>
<li><a href="https://github.com/ACIL-Group/DVHA">DVHA</a>: An python implementation of dual vigilance hypersphere ART.</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://techlab.bu.edu/resources/software/C51.html" rel="nofollow">Boston University's Cognitive and Neural Systems (CNS) Tech Lab</a></li>
<li><a href="ntu.edu.sg/home/asahtan/downloads.htm">Nanyang Technological University's Tan Ah Whee</a></li>
<li><a href="http://www2.imse-cnm.csic.es/~bernabe" rel="nofollow">Bernabé Linares-Barranco</a></li>
<li><a href="libtopoart.eu">Marko Tscherepanow's LibTopoART</a></li>
<li><a href="https://github.com/Lei-Meng">National University of Singapore's Lei Meng</a></li>
<li><a href="https://web.mst.edu/~tauritzd/art/" rel="nofollow">Daniel Tauritz's ART Clearinghouse</a></li>
</ul>
<h3 dir="auto"><a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Datasets</h3>
<p dir="auto">Boilerplate clustering datasets are periodically used to test, verify, and provide example of the functionality of the package.</p>
<ol dir="auto">
<li><a href="http://archive.ics.uci.edu/ml" rel="nofollow">UCI machine learning repository</a></li>
<li><a href="https://www.uni-marburg.de/fb12/arbeitsgruppen/datenbionik/data?language_sync=1" rel="nofollow">Fundamental Clustering Problems Suite (FCPS)</a></li>
<li><a href="https://www.researchgate.net/publication/239525861_Datasets_package" rel="nofollow">Nejc Ilc's unsupervised datasets package</a></li>
<li><a href="http://cs.uef.fi/sipu/datasets" rel="nofollow">Clustering basic benchmark</a></li>
</ol>
<h3 dir="auto"><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>License</h3>
<p dir="auto">This software is openly maintained by the ACIL of the Missouri University of Science and Technology under the <a href="LICENSE">MIT License</a>.</p>
<h3 dir="auto"><a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Citation</h3>
<p dir="auto">This project has a <a href="CITATION.cff">citation file</a> file that generates citation information for the package and corresponding JOSS paper, which can be accessed at the "Cite this repository button" under the "About" section of the GitHub page.</p>
<p dir="auto">You may also cite this repository with the following BibTeX entry:</p>
<div class="highlight highlight-text-bibtex notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="@article{Petrenko2022,
  doi = {10.21105/joss.03671},
  url = {https://doi.org/10.21105/joss.03671},
  year = {2022},
  publisher = {The Open Journal},
  volume = {7},
  number = {73},
  pages = {3671},
  author = {Sasha Petrenko and Donald C. Wunsch},
  title = {AdaptiveResonance.jl: A Julia Implementation of Adaptive Resonance Theory (ART) Algorithms},
  journal = {Journal of Open Source Software}
}"><pre><span class="pl-k">@article</span>{<span class="pl-en">Petrenko2022</span>,
  <span class="pl-s">doi</span> = <span class="pl-s"><span class="pl-pds">{</span>10.21105/joss.03671<span class="pl-pds">}</span></span>,
  <span class="pl-s">url</span> = <span class="pl-s"><span class="pl-pds">{</span>https://doi.org/10.21105/joss.03671<span class="pl-pds">}</span></span>,
  <span class="pl-s">year</span> = <span class="pl-s"><span class="pl-pds">{</span>2022<span class="pl-pds">}</span></span>,
  <span class="pl-s">publisher</span> = <span class="pl-s"><span class="pl-pds">{</span>The Open Journal<span class="pl-pds">}</span></span>,
  <span class="pl-s">volume</span> = <span class="pl-s"><span class="pl-pds">{</span>7<span class="pl-pds">}</span></span>,
  <span class="pl-s">number</span> = <span class="pl-s"><span class="pl-pds">{</span>73<span class="pl-pds">}</span></span>,
  <span class="pl-s">pages</span> = <span class="pl-s"><span class="pl-pds">{</span>3671<span class="pl-pds">}</span></span>,
  <span class="pl-s">author</span> = <span class="pl-s"><span class="pl-pds">{</span>Sasha Petrenko and Donald C. Wunsch<span class="pl-pds">}</span></span>,
  <span class="pl-s">title</span> = <span class="pl-s"><span class="pl-pds">{</span>AdaptiveResonance.jl: A Julia Implementation of Adaptive Resonance Theory (ART) Algorithms<span class="pl-pds">}</span></span>,
  <span class="pl-s">journal</span> = <span class="pl-s"><span class="pl-pds">{</span>Journal of Open Source Software<span class="pl-pds">}</span></span>
}</pre></div>
</article></div>