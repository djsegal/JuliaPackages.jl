<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-vecchiajl" class="anchor" aria-hidden="true" href="#vecchiajl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Vecchia.jl</h1>
<p dir="auto">A terse Julia implementation of Vecchia approximations to the Gaussian
likelihood, which work very well in many settings and run in <em>linear complexity
with data size</em> (assuming O(1) sized conditioning sets). As of now this is only
implemented for mean-zero processes. Implemented with chunked observations
instead of singleton observations as in Stein/Chi/Welty 2004 JRSSB [1].
Reasonably optimized for minimal allocations so that multithreading  really
works well while still being AD-compatible.  <strong>To my knowledge, this is the only
program that offers true Hessians of Vecchia likelihoods.</strong></p>
<p dir="auto">The accuracy of Vecchia approximations depends on the <em>screening effect</em> [2],
which can perhaps be considered as a substantially weakened Markovian-like
property. But the screening effect even for covariance functions that do exhibit
screening can be significantly weakened by measurement noise (corresponding to a
"nugget" in the spatial statistics terminology), for example, and so I highly
recommend investigating whether or not you have reason to expect that your
specific model exhibits screening to an acceptable degree. In some cases, like
with measurement noise, there are several workarounds and some are pretty easy
(including one based on the EM algorithm that this package now offers).  But for
some covariance functions screening really doesn't hold and so this
approximation scheme may not perform well. This isn't something that the code
can enforce, so user discretion is required.</p>
<p dir="auto">Here is a very quick demo:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LinearAlgebra, StaticArrays, Vecchia

# VERY IMPORTANT FOR MULTITHREADING, since this is many small BLAS/LAPACK calls:
BLAS.set_num_threads(1)

# Covariance function, in this case Matern(v=3/2):
kfn(x,y,p) = p[1]*exp(-norm(x-y)/p[2])*(1.0+norm(x-y)/p[2])

# Locations for fake measurements, in this case 2048 of them, and fake data 
# (data NOT from the correction distribution, this is just a maximally simple demo):
pts = [SVector{2, Float64}(randn(2)) for _ in 1:2048]
dat = randn(length(pts))

# Create the VecchiaConfig: 
# If you have multiple i.i.d. samples, pass in a matrix where each column is a sample.
chunksize = 10 
num_conditioning_chunks = 3
const cfg = Vecchia.kdtreeconfig(dat, pts, chunksize, num_conditioning_chunks, kfn)

# Estimate like so, with the default optimizer being Ipopt and using autodiff
# for all gradients and Hessians. TRUE Hessians are used in this estimation by
# default, not expected Fisher matrices.
mle = vecchia_estimate(cfg, some_init)"><pre><span class="pl-k">using</span> LinearAlgebra, StaticArrays, Vecchia

<span class="pl-c"><span class="pl-c">#</span> VERY IMPORTANT FOR MULTITHREADING, since this is many small BLAS/LAPACK calls:</span>
BLAS<span class="pl-k">.</span><span class="pl-c1">set_num_threads</span>(<span class="pl-c1">1</span>)

<span class="pl-c"><span class="pl-c">#</span> Covariance function, in this case Matern(v=3/2):</span>
<span class="pl-en">kfn</span>(x,y,p) <span class="pl-k">=</span> p[<span class="pl-c1">1</span>]<span class="pl-k">*</span><span class="pl-c1">exp</span>(<span class="pl-k">-</span><span class="pl-c1">norm</span>(x<span class="pl-k">-</span>y)<span class="pl-k">/</span>p[<span class="pl-c1">2</span>])<span class="pl-k">*</span>(<span class="pl-c1">1.0</span><span class="pl-k">+</span><span class="pl-c1">norm</span>(x<span class="pl-k">-</span>y)<span class="pl-k">/</span>p[<span class="pl-c1">2</span>])

<span class="pl-c"><span class="pl-c">#</span> Locations for fake measurements, in this case 2048 of them, and fake data </span>
<span class="pl-c"><span class="pl-c">#</span> (data NOT from the correction distribution, this is just a maximally simple demo):</span>
pts <span class="pl-k">=</span> [<span class="pl-c1">SVector</span><span class="pl-c1">{2, Float64}</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">2</span>)) <span class="pl-k">for</span> _ <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2048</span>]
dat <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">length</span>(pts))

<span class="pl-c"><span class="pl-c">#</span> Create the VecchiaConfig: </span>
<span class="pl-c"><span class="pl-c">#</span> If you have multiple i.i.d. samples, pass in a matrix where each column is a sample.</span>
chunksize <span class="pl-k">=</span> <span class="pl-c1">10</span> 
num_conditioning_chunks <span class="pl-k">=</span> <span class="pl-c1">3</span>
<span class="pl-k">const</span> cfg <span class="pl-k">=</span> Vecchia<span class="pl-k">.</span><span class="pl-c1">kdtreeconfig</span>(dat, pts, chunksize, num_conditioning_chunks, kfn)

<span class="pl-c"><span class="pl-c">#</span> Estimate like so, with the default optimizer being Ipopt and using autodiff</span>
<span class="pl-c"><span class="pl-c">#</span> for all gradients and Hessians. TRUE Hessians are used in this estimation by</span>
<span class="pl-c"><span class="pl-c">#</span> default, not expected Fisher matrices.</span>
mle <span class="pl-k">=</span> <span class="pl-c1">vecchia_estimate</span>(cfg, some_init)</pre></div>
<p dir="auto"><strong>See the example files for a heavily commented demonstration.</strong></p>
<p dir="auto">The code is organized with modularity and user-specific applications in mind, so
the primary way to interact with the approximation is to create a
<code>VecchiaConfig</code> object that specifies the chunks and conditioning sets for each
chunk. The only provided one is a very basic option that orders the points with
a KD-tree with a specified terminal leaf size (so that each leaf is a chunk),
re-orders those chunks based on the leaf centers, and then picks conditioning
sets based on the user-provided size.</p>
<p dir="auto">If you want something fancier, for example the maximin ordering of Guinness 2018
technometrics with the NN-based conditioning sets, which was recently proved to
have some nice properties (Schafer et al 2021 SISC), that shouldn't be very hard
to implement after skimming the existing constructor to see what the struct
fields in <code>VecchiaConfig</code> mean and stuff. I really made an effort to design this
in such a way that you can specialize how you want but then just enjoy the
painfully optimized generic log-likelihood, precision matrix, and sparse
(reverse)-Cholesky functionality without having to rebuild from scratch every
time.</p>
<h1 dir="auto"><a id="user-content-advanced-usage" class="anchor" aria-hidden="true" href="#advanced-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Advanced Usage</h1>
<h2 dir="auto"><a id="user-content-estimation-with-a-nuggetmeasurement-error" class="anchor" aria-hidden="true" href="#estimation-with-a-nuggetmeasurement-error"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Estimation with a nugget/measurement error</h2>
<p dir="auto">As mentioned above, measurement error can really hurt the accuracy of these
approximations. If your model is effectively given by <code>data(x) = good_gp(x) + iid_noise(x)</code>, where <code>good_gp</code> is something that screens well that you actually
want to use Vecchia on and <code>iid_noise</code> has VARIANCE <code>eta^2</code>, then you can
estimate all parameters, including <code>eta^2</code>, with the built in EM algorithm
procedure that is demonstrated in <code>./example/example_estimate_noise.jl</code>. See
also the <a href="https://arxiv.org/abs/2208.06877" rel="nofollow">paper</a> for a lot more information.</p>
<p dir="auto">This method works equally well for <strong>any</strong> perturbation whose covariance matrix
admits a fast solve, although ideally also a fast log-determinant. The code now
allows you to provide an arbitrary struct for working with the error covariance
matrix, and you can inspect <code>./src/errormatrix.jl</code> for a demonstration of the
methods that you need to provide that struct for everything to "just work".</p>
<p dir="auto"><strong>If you use this method, please cite <a href="https://arxiv.org/abs/2208.06877" rel="nofollow">this paper</a></strong>.</p>
<h2 dir="auto"><a id="user-content-sparse-precision-matrix-and-reverse-cholesky-factors" class="anchor" aria-hidden="true" href="#sparse-precision-matrix-and-reverse-cholesky-factors"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Sparse precision matrix and ("reverse") Cholesky factors</h2>
<p dir="auto">While it will almost always be faster to just evaluated the likelihood with
<code>Vecchia.nll(cfg, params)</code>, you <em>can</em> actually obtain the precision matrix <code>S</code>
such that <code>Vecchia.nll(cfg, params) == -logdet(S) + dot(data, S, data)</code>. You can
<em>also</em> obtain the upper triangular matrix <code>U</code> such that <code>S = U*U'</code>. <strong>Note that
these objects correspond to permuted data, though, not the ordering in which you
provided the data</strong>.</p>
<p dir="auto">While this package originally offered both, the direct assembly of <code>U</code> is much
simpler and in order to streamline this code I have removed the option to
directly assemble <code>S</code> that used the different algorithm of Sun and Stein (2016).</p>
<p dir="auto">Here is an example usage:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Note that this is NOT given in the form of a sparse matrix, it is a custom
# struct with just two methods: U'*x and logdet(U), which is all you need to
# evaluate the likelihood. 
U = Vecchia.rchol(vecc, sample_p)

# If you want the sparse matrix (don't forget to wrap as UpperTriangular!):
U_SparseMatrixCSC = UpperTriangular(sparse(U))

# If you want S back, for example:
S = U_SparseMatrixCSC*U_SparseMatrixCSC'

# Here is how I'd recommend getting your data in the correct permutation out:
data_perm = reduce(vcat, vecc.data)"><pre><span class="pl-c"><span class="pl-c">#</span> Note that this is NOT given in the form of a sparse matrix, it is a custom</span>
<span class="pl-c"><span class="pl-c">#</span> struct with just two methods: U'*x and logdet(U), which is all you need to</span>
<span class="pl-c"><span class="pl-c">#</span> evaluate the likelihood. </span>
U <span class="pl-k">=</span> Vecchia<span class="pl-k">.</span><span class="pl-c1">rchol</span>(vecc, sample_p)

<span class="pl-c"><span class="pl-c">#</span> If you want the sparse matrix (don't forget to wrap as UpperTriangular!):</span>
U_SparseMatrixCSC <span class="pl-k">=</span> <span class="pl-c1">UpperTriangular</span>(<span class="pl-c1">sparse</span>(U))

<span class="pl-c"><span class="pl-c">#</span> If you want S back, for example:</span>
S <span class="pl-k">=</span> U_SparseMatrixCSC<span class="pl-k">*</span>U_SparseMatrixCSC<span class="pl-k">'</span>

<span class="pl-c"><span class="pl-c">#</span> Here is how I'd recommend getting your data in the correct permutation out:</span>
data_perm <span class="pl-k">=</span> <span class="pl-c1">reduce</span>(vcat, vecc<span class="pl-k">.</span>data)</pre></div>
<p dir="auto">You'll get a warning the first time you call <code>rchol</code> re-iterating the issue
about permutations. If you want to avoid that, you can pass in the kwarg
<code>issue_warning=false</code>.</p>
<h2 dir="auto"><a id="user-content-expensive-or-complicated-kernel-functions" class="anchor" aria-hidden="true" href="#expensive-or-complicated-kernel-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Expensive or Complicated Kernel Functions</h2>
<p dir="auto"><code>Vecchia.jl</code> is pretty judicious about when and where the covariance function is
evaluated. For sufficiently fancy kernels that involve a lot of
side-computations or carrying around additional objects, there might be some
performance to be gained by "specializing" the internal function
<code>Vecchia.updatebuf!</code>, which is the only place where the kernel function is
called. Here is an example of this syntax:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="
# Create some struct to carry around all of your extra pieces that, for example,
# would otherwise need to be computed redundantly.
struct MyExpensiveKernel
  # ... 
end

# Now write a special method of Vecchia.updatebuf!. This might technically be
# type piracy, but I won't tell anybody if you won't.
#
# Note that you could also instead do fn::typeof(myspecificfunction) if you just
# wanted a special method for one specific function instead of a struct.
function Vecchia.updatebuf!(buf, pts1, pts2, fn::MyExpensiveKernel,
                            params; skipltri=false)
  println(&quot;Wow, neat!&quot;) 
  # ... (now do things to update buf)
end

# Create Vecchia config object:
const my_vecc_config = Vecchia.kdtreeconfig(..., MyExpensiveKernel(...))

# Now when you call this function, you will see &quot;Wow, neat!&quot; pop up every time
# that Vecchia.updatebuf! gets called. Once you're done testing and want to
# actually go fast, I would obviously recommend getting rid of the print
# statement.
Vecchia.nll(my_vecc_config, params)"><pre><span class="pl-c"><span class="pl-c">#</span> Create some struct to carry around all of your extra pieces that, for example,</span>
<span class="pl-c"><span class="pl-c">#</span> would otherwise need to be computed redundantly.</span>
<span class="pl-k">struct</span> MyExpensiveKernel
  <span class="pl-c"><span class="pl-c">#</span> ... </span>
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> Now write a special method of Vecchia.updatebuf!. This might technically be</span>
<span class="pl-c"><span class="pl-c">#</span> type piracy, but I won't tell anybody if you won't.</span>
<span class="pl-c"><span class="pl-c">#</span></span>
<span class="pl-c"><span class="pl-c">#</span> Note that you could also instead do fn::typeof(myspecificfunction) if you just</span>
<span class="pl-c"><span class="pl-c">#</span> wanted a special method for one specific function instead of a struct.</span>
<span class="pl-k">function</span> Vecchia<span class="pl-k">.</span><span class="pl-en">updatebuf!</span>(buf, pts1, pts2, fn<span class="pl-k">::</span><span class="pl-c1">MyExpensiveKernel</span>,
                            params; skipltri<span class="pl-k">=</span><span class="pl-c1">false</span>)
  <span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span>Wow, neat!<span class="pl-pds">"</span></span>) 
  <span class="pl-c"><span class="pl-c">#</span> ... (now do things to update buf)</span>
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> Create Vecchia config object:</span>
<span class="pl-k">const</span> my_vecc_config <span class="pl-k">=</span> Vecchia<span class="pl-k">.</span><span class="pl-c1">kdtreeconfig</span>(<span class="pl-k">...</span>, <span class="pl-c1">MyExpensiveKernel</span>(<span class="pl-k">...</span>))

<span class="pl-c"><span class="pl-c">#</span> Now when you call this function, you will see "Wow, neat!" pop up every time</span>
<span class="pl-c"><span class="pl-c">#</span> that Vecchia.updatebuf! gets called. Once you're done testing and want to</span>
<span class="pl-c"><span class="pl-c">#</span> actually go fast, I would obviously recommend getting rid of the print</span>
<span class="pl-c"><span class="pl-c">#</span> statement.</span>
Vecchia<span class="pl-k">.</span><span class="pl-c1">nll</span>(my_vecc_config, params)</pre></div>
<p dir="auto">In general, this probably won't be necessary for you. But I know I for one work
with some pretty exotic kernels regularly. And from experience I can attest
that, with some creativity, you can really cram a lot of efficient complexity
into the approximation with this approach without having to develop any new
boilerplate.</p>
<h2 dir="auto"><a id="user-content-mean-functions" class="anchor" aria-hidden="true" href="#mean-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Mean functions</h2>
<p dir="auto">...are currently not super officially supported. But you can now pass AD through
the <code>VecchiaConfig</code> struct itself. So a very simple hacky way to get your mean
function going would be a code pattern like</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# see other examples for the rest of the args to the kdtreeconfig and stuff.
function my_nonzeromean_nll(params, ...)
  parametric_mean = mean_function(params, ...) 
  cfg = Vecchia.kdtreeconfig(data - parametric_mean, ...) 
  Vecchia.nll(cfg, params)
end"><pre><span class="pl-c"><span class="pl-c">#</span> see other examples for the rest of the args to the kdtreeconfig and stuff.</span>
<span class="pl-k">function</span> <span class="pl-en">my_nonzeromean_nll</span>(params, <span class="pl-k">...</span>)
  parametric_mean <span class="pl-k">=</span> <span class="pl-c1">mean_function</span>(params, <span class="pl-k">...</span>) 
  cfg <span class="pl-k">=</span> Vecchia<span class="pl-k">.</span><span class="pl-c1">kdtreeconfig</span>(data <span class="pl-k">-</span> parametric_mean, <span class="pl-k">...</span>) 
  Vecchia<span class="pl-k">.</span><span class="pl-c1">nll</span>(cfg, params)
<span class="pl-k">end</span></pre></div>
<p dir="auto">This will of course mean you rebuild the <code>VecchiaConfig</code> every time you evaluate
the likelihood, which isn't ideal and is why I say that mean functions aren't
really in this package yet. But then, at least the generic KD-tree configs get
built pretty quickly, and so if you have enough data that Vecchia approximations
are actually helpful, you probably won't feel it too much. And now you can just
do <code>ForwardDiff.{gradient, hessian}(my_nonzeromean_nll, params)</code> without any
additional code. If you wanted to fit billions of points, this probably isn't
taking the problem seriously enough. But until your data sizes get there, this
slight inefficiency probably won't be the bottleneck either.</p>
<p dir="auto">I'm very open to feedback/comments/suggestions on the best way to incorporate
mean functions. It just isn't obvious to me how best to do it, and I don't
really need them myself (at least, not beyond what I can do with this current
pattern) so I'm not feeling super motivated to think hard about the best design
choice.</p>
<h1 dir="auto"><a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Citation</h1>
<p dir="auto">If you use this software in your work, <strong>particularly if you actually use
second-order optimization with the real Hessians</strong>,  please cite the package itself:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="@software{Geoga_Vecchia_jl,
  author = {Geoga, Christopher J.},
  title  = {Vecchia.jl},
  url    = {https://github.com/cgeoga/Vecchia.jl},
  year   = {2021},
  publisher = {Github}
}"><pre class="notranslate"><code>@software{Geoga_Vecchia_jl,
  author = {Geoga, Christopher J.},
  title  = {Vecchia.jl},
  url    = {https://github.com/cgeoga/Vecchia.jl},
  year   = {2021},
  publisher = {Github}
}
</code></pre></div>
<p dir="auto">I would also be curious to see/hear about your application if you're willing to
share it or take the time to tell me about it.</p>
<h1 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h1>
<p dir="auto">[1] <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1046/j.1369-7412.2003.05512.x" rel="nofollow">https://rss.onlinelibrary.wiley.com/doi/abs/10.1046/j.1369-7412.2003.05512.x</a></p>
<p dir="auto">[2] <a href="https://arxiv.org/pdf/1203.1801.pdf" rel="nofollow">https://arxiv.org/pdf/1203.1801.pdf</a></p>
</article></div>