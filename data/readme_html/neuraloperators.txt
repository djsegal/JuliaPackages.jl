<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-neuraloperators" class="anchor" aria-hidden="true" href="#neuraloperators"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>NeuralOperators</h1>
<p dir="auto"><a href="https://julialang.zulipchat.com/#narrow/stream/279055-sciml-bridged" rel="nofollow"><img src="https://camo.githubusercontent.com/667867fc71b8b3c9ed350ce154a04d38adca002ecfa38edf519284e0365ee553/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d5a756c6970266d6573736167653d6368617426636f6c6f723d393535386232266c6162656c436f6c6f723d333839383236" alt="Join the chat at https://julialang.zulipchat.com #sciml-bridged" data-canonical-src="https://img.shields.io/static/v1?label=Zulip&amp;message=chat&amp;color=9558b2&amp;labelColor=389826" style="max-width: 100%;"></a>
<a href="https://docs.sciml.ai/NeuralOperators/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/88037a523f970520933771e764f5abff55de9382efc91cd89dd43ef0bb49a85f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d5363694d4c2d626c75652e737667" alt="Global Docs" data-canonical-src="https://img.shields.io/badge/docs-SciML-blue.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><a href="https://codecov.io/gh/SciML/NeuralOperators.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/ae5fdfb87bff99853421d7dfe6fad74d1a3640bac5762f8402aab1d0e2e9a1e3/68747470733a2f2f636f6465636f762e696f2f67682f5363694d4c2f4e657572616c4f70657261746f72732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/SciML/NeuralOperators.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a>
<a href="https://github.com/SciML/NeuralOperators.jl/actions?query=workflow%3ACI"><img src="https://github.com/SciML/NeuralOperators.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://buildkite.com/julialang/neuraloperators-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/ccdfc5db283f42fb808ee2c84ba3ab54cc3ebf8db52f4e65982c6559a791205a/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f62653835333035356462396533303933313731353762376532393833653735326236303730353530326536323261313339652e7376673f6272616e63683d6d61696e" alt="Build status" data-canonical-src="https://badge.buildkite.com/be853055db9e309317157b7e2983e752b60705502e622a139e.svg?branch=main" style="max-width: 100%;"></a></p>
<p dir="auto"><a href="https://github.com/SciML/ColPrac"><img src="https://camo.githubusercontent.com/2496bdc13cbc9c458dfa19a108b1f333353f62917355a4cdee582bbdf8be43cf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f6c507261632d436f6e7472696275746f722532377325323047756964652d626c756576696f6c6574" alt="ColPrac: Contributor's Guide on Collaborative Practices for Community Packages" data-canonical-src="https://img.shields.io/badge/ColPrac-Contributor%27s%20Guide-blueviolet" style="max-width: 100%;"></a>
<a href="https://github.com/SciML/SciMLStyle"><img src="https://camo.githubusercontent.com/3e16f03bad047817fbc07f49307817ed7919ef79c339dc75ad4ce813012c3e0b/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d636f64652532307374796c65266d6573736167653d5363694d4c26636f6c6f723d393535386232266c6162656c436f6c6f723d333839383236" alt="SciML Code Style" data-canonical-src="https://img.shields.io/static/v1?label=code%20style&amp;message=SciML&amp;color=9558b2&amp;labelColor=389826" style="max-width: 100%;"></a></p>
<table>
<thead>
<tr>
<th align="center"><strong>Ground Truth</strong></th>
<th align="center"><strong>Inferenced</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a target="_blank" rel="noopener noreferrer" href="example/FlowOverCircle/gallery/ans.gif"><img src="example/FlowOverCircle/gallery/ans.gif" alt="" data-animated-image="" style="max-width: 100%;"></a></td>
<td align="center"><a target="_blank" rel="noopener noreferrer" href="example/FlowOverCircle/gallery/inferenced.gif"><img src="example/FlowOverCircle/gallery/inferenced.gif" alt="" data-animated-image="" style="max-width: 100%;"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">The demonstration showing above is Navier-Stokes equation learned by the <code>MarkovNeuralOperator</code> with only one time step information.
Example can be found in <a href="example/FlowOverCircle"><code>example/FlowOverCircle</code></a>.</p>
<h2 dir="auto"><a id="user-content-abstract" class="anchor" aria-hidden="true" href="#abstract"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Abstract</h2>
<p dir="auto">Neural operator is a novel deep learning architecture.
It learns a operator, which is a mapping between infinite-dimensional function spaces.
It can be used to resolve <a href="https://en.wikipedia.org/wiki/Partial_differential_equation" rel="nofollow">partial differential equations (PDE)</a>.
Instead of solving by finite element method, a PDE problem can be resolved by training a neural network to learn an operator mapping
from infinite-dimensional space (u, t) to infinite-dimensional space f(u, t).
Neural operator learns a continuous function between two continuous function spaces.
The kernel can be trained on different geometry, which is learned from a graph.</p>
<p dir="auto"><strong><a href="https://docs.sciml.ai/NeuralOperators/stable/apis/#Fourier-neural-operator" rel="nofollow">Fourier neural operator</a></strong> learns a neural operator with Dirichlet kernel to form a Fourier transformation.
It performs Fourier transformation across infinite-dimensional function spaces and learns better than neural operator.</p>
<p dir="auto"><strong><a href="https://docs.sciml.ai/NeuralOperators/stable/apis/#Markov-neural-operator" rel="nofollow">Markov neural operator</a></strong> learns a neural operator with Fourier operators.
With only one time step information of learning, it can predict the following few steps with low loss
by linking the operators into a Markov chain.</p>
<p dir="auto"><strong><a href="https://docs.sciml.ai/NeuralOperators/stable/apis/#DeepONet" rel="nofollow">DeepONet operator</a></strong> (Deep Operator Network) learns a neural operator with the help of two sub-neural net structures described as the branch and the trunk network.
The branch network is fed the initial conditions data, whereas the trunk is fed with the locations where the target(output) is evaluated from the corresponding initial conditions.
It is important that the output size of the branch and trunk subnets is same so that a dot product can be performed between them.</p>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<h3 dir="auto"><a id="user-content-fourier-neural-operator" class="anchor" aria-hidden="true" href="#fourier-neural-operator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Fourier Neural Operator</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="model = Chain(
              # lift (d + 1)-dimensional vector field to n-dimensional vector field
              # here, d == 1 and n == 64
              Dense(2, 64),
              # map each hidden representation to the next by integral kernel operator
              OperatorKernel(64 =&gt; 64, (16,), FourierTransform, gelu),
              OperatorKernel(64 =&gt; 64, (16,), FourierTransform, gelu),
              OperatorKernel(64 =&gt; 64, (16,), FourierTransform, gelu),
              OperatorKernel(64 =&gt; 64, (16,), FourierTransform),
              # project back to the scalar field of interest space
              Dense(64, 128, gelu),
              Dense(128, 1))"><pre>model <span class="pl-k">=</span> <span class="pl-c1">Chain</span>(
              <span class="pl-c"><span class="pl-c">#</span> lift (d + 1)-dimensional vector field to n-dimensional vector field</span>
              <span class="pl-c"><span class="pl-c">#</span> here, d == 1 and n == 64</span>
              <span class="pl-c1">Dense</span>(<span class="pl-c1">2</span>, <span class="pl-c1">64</span>),
              <span class="pl-c"><span class="pl-c">#</span> map each hidden representation to the next by integral kernel operator</span>
              <span class="pl-c1">OperatorKernel</span>(<span class="pl-c1">64</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">64</span>, (<span class="pl-c1">16</span>,), FourierTransform, gelu),
              <span class="pl-c1">OperatorKernel</span>(<span class="pl-c1">64</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">64</span>, (<span class="pl-c1">16</span>,), FourierTransform, gelu),
              <span class="pl-c1">OperatorKernel</span>(<span class="pl-c1">64</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">64</span>, (<span class="pl-c1">16</span>,), FourierTransform, gelu),
              <span class="pl-c1">OperatorKernel</span>(<span class="pl-c1">64</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">64</span>, (<span class="pl-c1">16</span>,), FourierTransform),
              <span class="pl-c"><span class="pl-c">#</span> project back to the scalar field of interest space</span>
              <span class="pl-c1">Dense</span>(<span class="pl-c1">64</span>, <span class="pl-c1">128</span>, gelu),
              <span class="pl-c1">Dense</span>(<span class="pl-c1">128</span>, <span class="pl-c1">1</span>))</pre></div>
<p dir="auto">Or one can just call:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="model = FourierNeuralOperator(ch = (2, 64, 64, 64, 64, 64, 128, 1),
                              modes = (16,),
                              œÉ = gelu)"><pre>model <span class="pl-k">=</span> <span class="pl-c1">FourierNeuralOperator</span>(ch <span class="pl-k">=</span> (<span class="pl-c1">2</span>, <span class="pl-c1">64</span>, <span class="pl-c1">64</span>, <span class="pl-c1">64</span>, <span class="pl-c1">64</span>, <span class="pl-c1">64</span>, <span class="pl-c1">128</span>, <span class="pl-c1">1</span>),
                              modes <span class="pl-k">=</span> (<span class="pl-c1">16</span>,),
                              œÉ <span class="pl-k">=</span> gelu)</pre></div>
<p dir="auto">And then train as a Flux model.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="loss(ùê±, ùê≤) = l‚ÇÇloss(model(ùê±), ùê≤)
opt = Flux.Optimiser(WeightDecay(1.0f-4), Flux.Adam(1.0f-3))
Flux.@epochs 50 Flux.train!(loss, params(model), data, opt)"><pre><span class="pl-en">loss</span>(ùê±, ùê≤) <span class="pl-k">=</span> <span class="pl-c1">l‚ÇÇloss</span>(<span class="pl-c1">model</span>(ùê±), ùê≤)
opt <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">Optimiser</span>(<span class="pl-c1">WeightDecay</span>(<span class="pl-c1">1.0f-4</span>), Flux<span class="pl-k">.</span><span class="pl-c1">Adam</span>(<span class="pl-c1">1.0f-3</span>))
Flux<span class="pl-k">.</span><span class="pl-c1">@epochs</span> <span class="pl-c1">50</span> Flux<span class="pl-k">.</span><span class="pl-c1">train!</span>(loss, <span class="pl-c1">params</span>(model), data, opt)</pre></div>
<h3 dir="auto"><a id="user-content-deeponet" class="anchor" aria-hidden="true" href="#deeponet"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DeepONet</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# tuple of Ints for branch net architecture and then for trunk net,
# followed by activations for branch and trunk respectively
model = DeepONet((32, 64, 72), (24, 64, 72), œÉ, tanh)"><pre><span class="pl-c"><span class="pl-c">#</span> tuple of Ints for branch net architecture and then for trunk net,</span>
<span class="pl-c"><span class="pl-c">#</span> followed by activations for branch and trunk respectively</span>
model <span class="pl-k">=</span> <span class="pl-c1">DeepONet</span>((<span class="pl-c1">32</span>, <span class="pl-c1">64</span>, <span class="pl-c1">72</span>), (<span class="pl-c1">24</span>, <span class="pl-c1">64</span>, <span class="pl-c1">72</span>), œÉ, tanh)</pre></div>
<p dir="auto">Or specify branch and trunk as separate <code>Chain</code> from Flux and pass to <code>DeepONet</code></p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="branch = Chain(Dense(32, 64, œÉ), Dense(64, 72, œÉ))
trunk = Chain(Dense(24, 64, tanh), Dense(64, 72, tanh))
model = DeepONet(branch, trunk)"><pre>branch <span class="pl-k">=</span> <span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">32</span>, <span class="pl-c1">64</span>, œÉ), <span class="pl-c1">Dense</span>(<span class="pl-c1">64</span>, <span class="pl-c1">72</span>, œÉ))
trunk <span class="pl-k">=</span> <span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">24</span>, <span class="pl-c1">64</span>, tanh), <span class="pl-c1">Dense</span>(<span class="pl-c1">64</span>, <span class="pl-c1">72</span>, tanh))
model <span class="pl-k">=</span> <span class="pl-c1">DeepONet</span>(branch, trunk)</pre></div>
<p dir="auto">You can again specify loss, optimization and training parameters just as you would for a simple neural network with Flux.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="loss(xtrain, ytrain, sensor) = Flux.Losses.mse(model(xtrain, sensor), ytrain)
evalcb() = @show(loss(xval, yval, grid))

learning_rate = 0.001
opt = Adam(learning_rate)
parameters = params(model)
Flux.@epochs 400 Flux.train!(loss, parameters, [(xtrain, ytrain, grid)], opt, cb = evalcb)"><pre><span class="pl-en">loss</span>(xtrain, ytrain, sensor) <span class="pl-k">=</span> Flux<span class="pl-k">.</span>Losses<span class="pl-k">.</span><span class="pl-c1">mse</span>(<span class="pl-c1">model</span>(xtrain, sensor), ytrain)
<span class="pl-en">evalcb</span>() <span class="pl-k">=</span> <span class="pl-c1">@show</span>(<span class="pl-c1">loss</span>(xval, yval, grid))

learning_rate <span class="pl-k">=</span> <span class="pl-c1">0.001</span>
opt <span class="pl-k">=</span> <span class="pl-c1">Adam</span>(learning_rate)
parameters <span class="pl-k">=</span> <span class="pl-c1">params</span>(model)
Flux<span class="pl-k">.</span><span class="pl-c1">@epochs</span> <span class="pl-c1">400</span> Flux<span class="pl-k">.</span><span class="pl-c1">train!</span>(loss, parameters, [(xtrain, ytrain, grid)], opt, cb <span class="pl-k">=</span> evalcb)</pre></div>
<h2 dir="auto"><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h2>
<p dir="auto">PDE training examples are provided in <code>example</code> folder.</p>
<h3 dir="auto"><a id="user-content-one-dimensional-fourier-neural-operator" class="anchor" aria-hidden="true" href="#one-dimensional-fourier-neural-operator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>One-dimensional Fourier Neural Operator</h3>
<p dir="auto"><a href="example/Burgers">Burgers' equation</a></p>
<h3 dir="auto"><a id="user-content-deeponet-implementation-for-solving-burgers-equation" class="anchor" aria-hidden="true" href="#deeponet-implementation-for-solving-burgers-equation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>DeepONet implementation for solving Burgers' equation</h3>
<p dir="auto"><a href="example/Burgers/src/Burgers_deeponet.jl">Burgers' equation</a></p>
<h3 dir="auto"><a id="user-content-two-dimensional-fourier-neural-operator" class="anchor" aria-hidden="true" href="#two-dimensional-fourier-neural-operator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Two-dimensional Fourier Neural Operator</h3>
<p dir="auto"><a href="example/DoublePendulum">Double Pendulum</a></p>
<h3 dir="auto"><a id="user-content-markov-neural-operator" class="anchor" aria-hidden="true" href="#markov-neural-operator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Markov Neural Operator</h3>
<p dir="auto"><a href="example/FlowOverCircle">Time dependent Navier-Stokes equation</a></p>
<h3 dir="auto"><a id="user-content-super-resolution-with-mno" class="anchor" aria-hidden="true" href="#super-resolution-with-mno"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Super Resolution with MNO</h3>
<p dir="auto"><a href="example/SuperResolution">Super resolution on time dependent Navier-Stokes equation</a></p>
<h2 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://arxiv.org/abs/2010.08895" rel="nofollow">Fourier Neural Operator for Parametric Partial Differential Equations</a></p>
<ul dir="auto">
<li><a href="https://github.com/zongyi-li/fourier_neural_operator">zongyi-li/fourier_neural_operator</a></li>
</ul>
</li>
<li>
<p dir="auto"><a href="https://arxiv.org/abs/2003.03485" rel="nofollow">Neural Operator: Graph Kernel Network for Partial Differential Equations</a></p>
<ul dir="auto">
<li><a href="https://github.com/zongyi-li/graph-pde">zongyi-li/graph-pde</a></li>
</ul>
</li>
<li>
<p dir="auto"><a href="https://arxiv.org/abs/2106.06898" rel="nofollow">Markov Neural Operators for Learning Chaotic Systems</a></p>
</li>
<li>
<p dir="auto"><a href="https://arxiv.org/abs/1910.03193" rel="nofollow">DeepONet: Learning nonlinear operators for identifying  differential equations based on the universal approximation theorem of operators</a></p>
</li>
</ul>
</article></div>