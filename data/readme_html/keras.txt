<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-kerasjl" class="anchor" aria-hidden="true" href="#kerasjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Keras.jl</h1>
<p>Load Keras models in Julia.</p>
<p>This is not a wrapper around <a href="keras.io">Keras</a>. This is built on top of <a href="https://github.com/FluxML/Flux.jl">Flux</a>, to directly load Keras models into Flux.
[W.I.P]</p>
<h2><a id="user-content-how" class="anchor" aria-hidden="true" href="#how"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How?</h2>
<p>Loading a model in Flux is fairly simple. Clone this repository into <code>~/.julia/v0.6</code>. Make sure you have all dependencies installed. In order to load a model, you need to have two files:</p>
<ol>
<li>The <code>model.json</code> file. This stores the structure of the model. This can be obtained from any Keras model using the <code>model.to_json()</code> method.</li>
<li>The <code>weights.h5</code> file. This stores the weights associated with different layers of the pre-trained Keras model. This file can be produced from a Keras model using <code>Keras.save_weights(weight_file_name)</code>.</li>
</ol>
<p>(The files can have any other name (as long as they are in the correct format). I'm using model.json and weights.h5 as an example here)</p>
<p>Keras models can broadly be divided into two categories:</p>
<ol>
<li>The models using the <code>sequential</code> API.</li>
<li>The models using the <code>functional</code> API. (Also called <code>Model</code> API)</li>
</ol>
<p>Due to subtle differences in their structure and functioning, you need to follow different steps to run these models in Flux. You can check the type of the model by:</p>
<pre><code>&gt;&gt;&gt; using Keras

&gt;&gt;&gt; Keras.check_modeltype("model.json")
</code></pre>
<h2><a id="user-content-running-sequential-models" class="anchor" aria-hidden="true" href="#running-sequential-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Running Sequential Models</h2>
<pre><code>&gt;&gt;&gt; using Keras

&gt;&gt;&gt; model = Keras.load("model.json", "weights.h5")
</code></pre>
<p><code>model</code> is now the corresponding model in Flux. This can be used directly as:</p>
<pre><code>&gt;&gt;&gt; model(rand(28,28,1,1))
</code></pre>
<p>Another straight-forward way of running such models is:</p>
<pre><code>&gt;&gt;&gt; using Keras

&gt;&gt;&gt; Keras.load("model.json", "weights.h5", ip)
</code></pre>
<p>Where <code>ip</code> is our input. This directly returns the models output.</p>
<h2><a id="user-content-running-functional-models" class="anchor" aria-hidden="true" href="#running-functional-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Running Functional Models.</h2>
<p>Functional models can be tricky as they may consist of a number of sub-graphs within themselves. Running such models is similar to the second way of running Sequential models mentioned above.</p>
<pre><code>&gt;&gt;&gt; using Keras

&gt;&gt;&gt; Keras.load("model.json", "weight.h5", ip)
</code></pre>
<p>Where <code>ip</code> is the input to our model. This directly returns the output. (Note: Currently there is no other way of running functional API models).</p>
<h2><a id="user-content-intermediate-outputs" class="anchor" aria-hidden="true" href="#intermediate-outputs"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Intermediate outputs</h2>
<p>Keras.jl also allows you to get the intermediate outputs of a model. Suppose your model contains <code>m</code> layers, and you need the output
after <code>n</code> layers (<code>m &gt; n</code>).</p>
<pre><code>&gt;&gt;&gt; model[1:n](ip)
</code></pre>
<p>Should give you the output after exactly <code>n</code> layers.</p>
<h2><a id="user-content-insight" class="anchor" aria-hidden="true" href="#insight"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Insight</h2>
<p>The process of loading and running a Keras model in Flux mainly consists of two parts:</p>
<ol>
<li>Converting all Keras operators to Flux ops.</li>
<li>Generating the computation graph from the Flux operators obtained.</li>
</ol>
<p>In order to get correct results, make sure that the value of <code>mode</code> parameter is set to 0 (<a href="https://github.com/FluxML/NNlib.jl/blob/master/src/impl/conv.jl#L259">here</a>). It's default value is 0, so if you haven't
played around with NNlib.jl, you're good to go!</p>
<h2><a id="user-content-issues" class="anchor" aria-hidden="true" href="#issues"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Issues</h2>
<p>Since this is currently under development, feel free to open any issue you encounter. You can post your queries on Julia
Slack, generally on the #machine-learning channel.</p>
<h3><a id="user-content-current-impediments" class="anchor" aria-hidden="true" href="#current-impediments"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Current Impediments:</h3>
<p><a href="https://keras.io/layers/core/#lambda" rel="nofollow">Lambda</a> layers cannot be handled at this moment. This is because we'd need to handle the Python AST, for parsing it as JSON.</p>
</article></div>