<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-kerasjl" class="anchor" aria-hidden="true" href="#kerasjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Keras.jl</h1>
<p>Load Keras models in Julia.</p>
<p>This is not a wrapper around <a href="keras.io">Keras</a>. This is built on top of <a href="https://github.com/FluxML/Flux.jl">Flux</a>, to directly load Keras models into Flux.
[W.I.P]</p>
<h2><a id="user-content-how" class="anchor" aria-hidden="true" href="#how"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>How?</h2>
<p>Loading a model in Flux is fairly simple. Clone this repository into <code>~/.julia/v0.6</code>. Make sure you have all dependencies installed. In order to load a model, you need to have two files:</p>
<ol>
<li>The <code>model.json</code> file. This stores the structure of the model. This can be obtained from any Keras model using the <code>model.to_json()</code> method.</li>
<li>The <code>weights.h5</code> file. This stores the weights associated with different layers of the pre-trained Keras model. This file can be produced from a Keras model using <code>Keras.save_weights(weight_file_name)</code>.</li>
</ol>
<p>(The files can have any other name (as long as they are in the correct format). I'm using model.json and weights.h5 as an example here)</p>
<p>Keras models can broadly be divided into two categories:</p>
<ol>
<li>The models using the <code>sequential</code> API.</li>
<li>The models using the <code>functional</code> API. (Also called <code>Model</code> API)</li>
</ol>
<p>Due to subtle differences in their structure and functioning, you need to follow different steps to run these models in Flux. You can check the type of the model by:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="&gt;&gt;&gt; using Keras

&gt;&gt;&gt; Keras.check_modeltype(&quot;model.json&quot;)
"><pre><code>&gt;&gt;&gt; using Keras

&gt;&gt;&gt; Keras.check_modeltype("model.json")
</code></pre></div>
<h2><a id="user-content-running-sequential-models" class="anchor" aria-hidden="true" href="#running-sequential-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Running Sequential Models</h2>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="&gt;&gt;&gt; using Keras

&gt;&gt;&gt; model = Keras.load(&quot;model.json&quot;, &quot;weights.h5&quot;)
"><pre><code>&gt;&gt;&gt; using Keras

&gt;&gt;&gt; model = Keras.load("model.json", "weights.h5")
</code></pre></div>
<p><code>model</code> is now the corresponding model in Flux. This can be used directly as:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="&gt;&gt;&gt; model(rand(28,28,1,1))
"><pre><code>&gt;&gt;&gt; model(rand(28,28,1,1))
</code></pre></div>
<p>Another straight-forward way of running such models is:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="&gt;&gt;&gt; using Keras

&gt;&gt;&gt; Keras.load(&quot;model.json&quot;, &quot;weights.h5&quot;, ip)
"><pre><code>&gt;&gt;&gt; using Keras

&gt;&gt;&gt; Keras.load("model.json", "weights.h5", ip)
</code></pre></div>
<p>Where <code>ip</code> is our input. This directly returns the models output.</p>
<h2><a id="user-content-running-functional-models" class="anchor" aria-hidden="true" href="#running-functional-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Running Functional Models.</h2>
<p>Functional models can be tricky as they may consist of a number of sub-graphs within themselves. Running such models is similar to the second way of running Sequential models mentioned above.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="&gt;&gt;&gt; using Keras

&gt;&gt;&gt; Keras.load(&quot;model.json&quot;, &quot;weight.h5&quot;, ip)
"><pre><code>&gt;&gt;&gt; using Keras

&gt;&gt;&gt; Keras.load("model.json", "weight.h5", ip)
</code></pre></div>
<p>Where <code>ip</code> is the input to our model. This directly returns the output. (Note: Currently there is no other way of running functional API models).</p>
<h2><a id="user-content-intermediate-outputs" class="anchor" aria-hidden="true" href="#intermediate-outputs"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Intermediate outputs</h2>
<p>Keras.jl also allows you to get the intermediate outputs of a model. Suppose your model contains <code>m</code> layers, and you need the output
after <code>n</code> layers (<code>m &gt; n</code>).</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="&gt;&gt;&gt; model[1:n](ip)
"><pre><code>&gt;&gt;&gt; model[1:n](ip)
</code></pre></div>
<p>Should give you the output after exactly <code>n</code> layers.</p>
<h2><a id="user-content-insight" class="anchor" aria-hidden="true" href="#insight"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Insight</h2>
<p>The process of loading and running a Keras model in Flux mainly consists of two parts:</p>
<ol>
<li>Converting all Keras operators to Flux ops.</li>
<li>Generating the computation graph from the Flux operators obtained.</li>
</ol>
<p>In order to get correct results, make sure that the value of <code>mode</code> parameter is set to 0 (<a href="https://github.com/FluxML/NNlib.jl/blob/master/src/impl/conv.jl#L259">here</a>). It's default value is 0, so if you haven't
played around with NNlib.jl, you're good to go!</p>
<h2><a id="user-content-issues" class="anchor" aria-hidden="true" href="#issues"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Issues</h2>
<p>Since this is currently under development, feel free to open any issue you encounter. You can post your queries on Julia
Slack, generally on the #machine-learning channel.</p>
<h3><a id="user-content-current-impediments" class="anchor" aria-hidden="true" href="#current-impediments"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Current Impediments:</h3>
<p><a href="https://keras.io/layers/core/#lambda" rel="nofollow">Lambda</a> layers cannot be handled at this moment. This is because we'd need to handle the Python AST, for parsing it as JSON.</p>
</article></div>