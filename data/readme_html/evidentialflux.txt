<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-evidentialflux" class="anchor" aria-hidden="true" href="#evidentialflux"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>EvidentialFlux</h1>
<p dir="auto"><a href="https://github.com/DoktorMike/EvidentialFlux.jl/actions/workflows/documentation.yml"><img src="https://github.com/DoktorMike/EvidentialFlux.jl/actions/workflows/documentation.yml/badge.svg" alt="Documentation" style="max-width: 100%;"></a>
<a href="https://doktormike.github.io/EvidentialFlux.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://doktormike.github.io/EvidentialFlux.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/SciML/SciMLStyle"><img src="https://camo.githubusercontent.com/3e16f03bad047817fbc07f49307817ed7919ef79c339dc75ad4ce813012c3e0b/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d636f64652532307374796c65266d6573736167653d5363694d4c26636f6c6f723d393535386232266c6162656c436f6c6f723d333839383236" alt="SciML Code Style" data-canonical-src="https://img.shields.io/static/v1?label=code%20style&amp;message=SciML&amp;color=9558b2&amp;labelColor=389826" style="max-width: 100%;"></a>
<a href="https://github.com/DoktorMike/EvidentialFlux.jl/actions/workflows/FormatCheck.yml"><img src="https://github.com/DoktorMike/EvidentialFlux.jl/actions/workflows/FormatCheck.yml/badge.svg" alt="format-check" style="max-width: 100%;"></a>
<a href="https://zenodo.org/badge/latestdoi/487830887" rel="nofollow"><img src="https://camo.githubusercontent.com/329baefbdc2e7493588aafdee90d7255e9d1da9b208d7293754dbd5ef3a7ab72/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3438373833303838372e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/487830887.svg" style="max-width: 100%;"></a></p>
<p dir="auto">This is a Julia implementation in Flux of the Evidential Deep Learning
framework. It strives to estimate heteroskedastic aleatoric uncertainty as well
as epistemic uncertainty along with every prediction made. All of it calculated
in one glorious forward pass. Boom!</p>
<h2 dir="auto"><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installing</h2>
<p dir="auto">If you want bleeding edge you can install it directly from my repo like this:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Pkg; Pkg.add(url=&quot;https://github.com/DoktorMike/EvidentialFlux.jl&quot;)"><pre><span class="pl-k">using</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(url<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>https://github.com/DoktorMike/EvidentialFlux.jl<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">Otherwise just do</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Pkg; Pkg.add(&quot;EvidentialFlux.jl&quot;)"><pre><span class="pl-k">using</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>EvidentialFlux.jl<span class="pl-pds">"</span></span>)</pre></div>
<h2 dir="auto"><a id="user-content-for-the-impatient" class="anchor" aria-hidden="true" href="#for-the-impatient"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>For the impatient</h2>
<p dir="auto">Below is an example of how to train Deep Evidential Regression model, extract
the predictions as well as the epistemic and aleatoric uncertainty. For a more
elaborate example have a look in the examples folder.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Flux
using EvidentialFlux

x = Float32.(-4:0.1:4)
y = x .^3 .+ randn(Float32, length(x)) .* 3

lr = 0.0005
m = Chain(Dense(1 =&gt; 100, relu), Dense(100 =&gt; 100, relu), Dense(100 =&gt; 100, relu), NIG(100 =&gt; 1))
opt = AdamW(lr, (0.89, 0.995), 0.001)
pars = Flux.params(m)
for epoch in 1:500
    grads = Flux.gradient(pars) do
        ŷ = m(x') 
        γ, ν, α, β = ŷ[1, :], ŷ[2, :], ŷ[3, :], ŷ[4, :]
        trnloss = Statistics.mean(nigloss2(y, γ, ν, α, β, 0.01, 2))
        trnloss
    end
    Flux.Optimise.update!(opt, pars, grads)
end

γ, ν, α, β = predict(m, x)
eu = epistemic(ν)
au = aleatoric(ν, α, β)"><pre><span class="pl-k">using</span> Flux
<span class="pl-k">using</span> EvidentialFlux

x <span class="pl-k">=</span> <span class="pl-c1">Float32</span>.(<span class="pl-k">-</span><span class="pl-c1">4</span><span class="pl-k">:</span><span class="pl-c1">0.1</span><span class="pl-k">:</span><span class="pl-c1">4</span>)
y <span class="pl-k">=</span> x <span class="pl-k">.^</span><span class="pl-c1">3</span> <span class="pl-k">.+</span> <span class="pl-c1">randn</span>(Float32, <span class="pl-c1">length</span>(x)) <span class="pl-k">.*</span> <span class="pl-c1">3</span>

lr <span class="pl-k">=</span> <span class="pl-c1">0.0005</span>
m <span class="pl-k">=</span> <span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">1</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">100</span>, relu), <span class="pl-c1">Dense</span>(<span class="pl-c1">100</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">100</span>, relu), <span class="pl-c1">Dense</span>(<span class="pl-c1">100</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">100</span>, relu), <span class="pl-c1">NIG</span>(<span class="pl-c1">100</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">1</span>))
opt <span class="pl-k">=</span> <span class="pl-c1">AdamW</span>(lr, (<span class="pl-c1">0.89</span>, <span class="pl-c1">0.995</span>), <span class="pl-c1">0.001</span>)
pars <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">params</span>(m)
<span class="pl-k">for</span> epoch <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">500</span>
    grads <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">gradient</span>(pars) <span class="pl-k">do</span>
        ŷ <span class="pl-k">=</span> <span class="pl-c1">m</span>(x<span class="pl-k">'</span>) 
        γ, ν, α, β <span class="pl-k">=</span> ŷ[<span class="pl-c1">1</span>, :], ŷ[<span class="pl-c1">2</span>, :], ŷ[<span class="pl-c1">3</span>, :], ŷ[<span class="pl-c1">4</span>, :]
        trnloss <span class="pl-k">=</span> Statistics<span class="pl-k">.</span><span class="pl-c1">mean</span>(<span class="pl-c1">nigloss2</span>(y, γ, ν, α, β, <span class="pl-c1">0.01</span>, <span class="pl-c1">2</span>))
        trnloss
    <span class="pl-k">end</span>
    Flux<span class="pl-k">.</span>Optimise<span class="pl-k">.</span><span class="pl-c1">update!</span>(opt, pars, grads)
<span class="pl-k">end</span>

γ, ν, α, β <span class="pl-k">=</span> <span class="pl-c1">predict</span>(m, x)
eu <span class="pl-k">=</span> <span class="pl-c1">epistemic</span>(ν)
au <span class="pl-k">=</span> <span class="pl-c1">aleatoric</span>(ν, α, β)</pre></div>
<h2 dir="auto"><a id="user-content-classification" class="anchor" aria-hidden="true" href="#classification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Classification</h2>
<p dir="auto">Deep evidential modeling works for classification as well as for regression. In
the plot below you can see the epistemic uncertainty as a consequence of
position in the plot. The task is to separate three Gaussians in 2D. The code
for this example can be found in
<a href="examples/classification.jl">classification.jl</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="images/threegaussians.png"><img src="images/threegaussians.png" alt="uncertainty" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-regression" class="anchor" aria-hidden="true" href="#regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Regression</h2>
<p dir="auto">In the case of a regression problem, we utilize the NormalInverseGamma
distribution to model a type II likelihood function that then explicitly
models the aleatoric and epistemic uncertainty. The code for the example
producing the plot below can be found in
<a href="examples/regression.jl">regression.jl</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="images/cubefun.png"><img src="images/cubefun.png" alt="uncertainty" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-summary" class="anchor" aria-hidden="true" href="#summary"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Summary</h2>
<p dir="auto">Uncertainty is crucial for the deployment and utilization of robust machine
learning in production. No model is perfect and each one of them has
strengths and weaknesses, but as a minimum requirement, we should all
at least demand that our models report uncertainty in every prediction.</p>
</article></div>