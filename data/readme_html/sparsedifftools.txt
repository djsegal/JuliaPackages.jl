<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-sparsedifftoolsjl" class="anchor" aria-hidden="true" href="#sparsedifftoolsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>SparseDiffTools.jl</h1>
<p dir="auto"><a href="https://julialang.zulipchat.com/#narrow/stream/279055-sciml-bridged" rel="nofollow"><img src="https://camo.githubusercontent.com/667867fc71b8b3c9ed350ce154a04d38adca002ecfa38edf519284e0365ee553/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d5a756c6970266d6573736167653d6368617426636f6c6f723d393535386232266c6162656c436f6c6f723d333839383236" alt="Join the chat at https://julialang.zulipchat.com #sciml-bridged" data-canonical-src="https://img.shields.io/static/v1?label=Zulip&amp;message=chat&amp;color=9558b2&amp;labelColor=389826" style="max-width: 100%;"></a>
<a href="https://docs.sciml.ai/SparseDiffTools/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/88037a523f970520933771e764f5abff55de9382efc91cd89dd43ef0bb49a85f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d5363694d4c2d626c75652e737667" alt="Global Docs" data-canonical-src="https://img.shields.io/badge/docs-SciML-blue.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><a href="https://codecov.io/gh/JuliaDiff/SparseDiffTools.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/bff3d15a9a16869304646281f2f32d88a98d28b918c578f8d63141d38debad1e/68747470733a2f2f636f6465636f762e696f2f67682f4a756c6961446966662f53706172736544696666546f6f6c732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/JuliaDiff/SparseDiffTools.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a>
<a href="https://github.com/JuliaDiff/SparseDiffTools.jl/actions?query=workflow%3ACI"><img src="https://github.com/JuliaDiff/SparseDiffTools.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://buildkite.com/julialang/sparsedifftools-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/d988cbbad25660b2433643d22196ce11c719bc77a32f048eeeaaec48c82e167b/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f65613764663036316532303332386636306433653038313664393764326438353631363666326561373033303734386365662e737667" alt="buildkite" data-canonical-src="https://badge.buildkite.com/ea7df061e20328f60d3e0816d97d2d856166f2ea7030748cef.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><a href="https://github.com/SciML/ColPrac"><img src="https://camo.githubusercontent.com/a6c1efcb19a957860ecb25966a730260b03d6e05380d0c27992ee7f9e3b1feb3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f6c507261632d436f6e7472696275746f72277325323047756964652d626c756576696f6c6574" alt="ColPrac: Contributor's Guide on Collaborative Practices for Community Packages" data-canonical-src="https://img.shields.io/badge/ColPrac-Contributor's%20Guide-blueviolet" style="max-width: 100%;"></a>
<a href="https://github.com/SciML/SciMLStyle"><img src="https://camo.githubusercontent.com/3e16f03bad047817fbc07f49307817ed7919ef79c339dc75ad4ce813012c3e0b/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d636f64652532307374796c65266d6573736167653d5363694d4c26636f6c6f723d393535386232266c6162656c436f6c6f723d333839383236" alt="SciML Code Style" data-canonical-src="https://img.shields.io/static/v1?label=code%20style&amp;message=SciML&amp;color=9558b2&amp;labelColor=389826" style="max-width: 100%;"></a></p>
<p dir="auto">This package is for exploiting sparsity in Jacobians and Hessians to accelerate
computations. Matrix-free Jacobian-vector product and Hessian-vector product
operators are provided that are compatible with AbstractMatrix-based libraries
like IterativeSolvers.jl for easy and efficient Newton-Krylov implementation. It is
possible to perform matrix coloring, and utilize coloring in Jacobian and Hessian
construction.</p>
<p dir="auto">Optionally, automatic and numerical differentiation are utilized.</p>
<h2 dir="auto"><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h2>
<p dir="auto">Suppose we had the function</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="fcalls = 0
function f(y,x) # in-place
  global fcalls += 1
  for i in 2:length(x)-1
    y[i] = x[i-1] - 2x[i] + x[i+1]
  end
  y[1] = -2x[1] + x[2]
  y[end] = x[end-1] - 2x[end]
  nothing
end

function g(x) # out-of-place
  global fcalls += 1
  y = zero(x)
  for i in 2:length(x)-1
    y[i] = x[i-1] - 2x[i] + x[i+1]
  end
  y[1] = -2x[1] + x[2]
  y[end] = x[end-1] - 2x[end]
  y
end"><pre>fcalls <span class="pl-k">=</span> <span class="pl-c1">0</span>
<span class="pl-k">function</span> <span class="pl-en">f</span>(y,x) <span class="pl-c"><span class="pl-c">#</span> in-place</span>
  <span class="pl-k">global</span> fcalls <span class="pl-k">+=</span> <span class="pl-c1">1</span>
  <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">length</span>(x)<span class="pl-k">-</span><span class="pl-c1">1</span>
    y[i] <span class="pl-k">=</span> x[i<span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-k">-</span> <span class="pl-c1">2</span>x[i] <span class="pl-k">+</span> x[i<span class="pl-k">+</span><span class="pl-c1">1</span>]
  <span class="pl-k">end</span>
  y[<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">2</span>x[<span class="pl-c1">1</span>] <span class="pl-k">+</span> x[<span class="pl-c1">2</span>]
  y[<span class="pl-c1">end</span>] <span class="pl-k">=</span> x[<span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-k">-</span> <span class="pl-c1">2</span>x[<span class="pl-c1">end</span>]
  <span class="pl-c1">nothing</span>
<span class="pl-k">end</span>

<span class="pl-k">function</span> <span class="pl-en">g</span>(x) <span class="pl-c"><span class="pl-c">#</span> out-of-place</span>
  <span class="pl-k">global</span> fcalls <span class="pl-k">+=</span> <span class="pl-c1">1</span>
  y <span class="pl-k">=</span> <span class="pl-c1">zero</span>(x)
  <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">length</span>(x)<span class="pl-k">-</span><span class="pl-c1">1</span>
    y[i] <span class="pl-k">=</span> x[i<span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-k">-</span> <span class="pl-c1">2</span>x[i] <span class="pl-k">+</span> x[i<span class="pl-k">+</span><span class="pl-c1">1</span>]
  <span class="pl-k">end</span>
  y[<span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">2</span>x[<span class="pl-c1">1</span>] <span class="pl-k">+</span> x[<span class="pl-c1">2</span>]
  y[<span class="pl-c1">end</span>] <span class="pl-k">=</span> x[<span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">1</span>] <span class="pl-k">-</span> <span class="pl-c1">2</span>x[<span class="pl-c1">end</span>]
  y
<span class="pl-k">end</span></pre></div>
<p dir="auto">For this function, we know that the sparsity pattern of the Jacobian is a
<code>Tridiagonal</code> matrix. However, if we didn't know the sparsity pattern for
the Jacobian, we could use the <code>Symbolics.jacobian_sparsity</code> function to automatically
detect the sparsity pattern. We declare that the function <code>f</code> outputs a
vector of length 30 and takes in a vector of length 30, and <code>jacobian_sparsity</code> returns
a <code>SparseMatrixCSC</code>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Symbolics
input = rand(30)
output = similar(input)
sparsity_pattern = Symbolics.jacobian_sparsity(f,output,input)
jac = Float64.(sparsity_pattern)"><pre><span class="pl-k">using</span> Symbolics
input <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">30</span>)
output <span class="pl-k">=</span> <span class="pl-c1">similar</span>(input)
sparsity_pattern <span class="pl-k">=</span> Symbolics<span class="pl-k">.</span><span class="pl-c1">jacobian_sparsity</span>(f,output,input)
jac <span class="pl-k">=</span> <span class="pl-c1">Float64</span>.(sparsity_pattern)</pre></div>
<p dir="auto">Now we call <code>matrix_colors</code> to get the colorvec vector for that matrix:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using SparseDiffTools
colors = matrix_colors(jac)"><pre><span class="pl-k">using</span> SparseDiffTools
colors <span class="pl-k">=</span> <span class="pl-c1">matrix_colors</span>(jac)</pre></div>
<p dir="auto">Since <code>maximum(colors)</code> is 3, this means that finite differencing can now
compute the Jacobian in just 4 <code>f</code>-evaluations. Generating the sparsity
pattern used 1 (pseudo) <code>f</code>-evaluation, so the total number of times that
<code>f</code> is called to compute the sparsity pattern plus the entire 30x30 Jacobian
is 5 times:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using FiniteDiff
FiniteDiff.finite_difference_jacobian!(jac, f, rand(30), colorvec=colors)
@show fcalls # 5"><pre><span class="pl-k">using</span> FiniteDiff
FiniteDiff<span class="pl-k">.</span><span class="pl-c1">finite_difference_jacobian!</span>(jac, f, <span class="pl-c1">rand</span>(<span class="pl-c1">30</span>), colorvec<span class="pl-k">=</span>colors)
<span class="pl-c1">@show</span> fcalls <span class="pl-c"><span class="pl-c">#</span> 5</span></pre></div>
<p dir="auto">In addition, a faster forward-mode autodiff call can be utilized as well:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="forwarddiff_color_jacobian!(jac, f, x, colorvec = colors)"><pre><span class="pl-c1">forwarddiff_color_jacobian!</span>(jac, f, x, colorvec <span class="pl-k">=</span> colors)</pre></div>
<p dir="auto">If one only needs to compute products, one can use the operators. For example,</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="x = rand(30)
J = JacVec(f,x)"><pre>x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">30</span>)
J <span class="pl-k">=</span> <span class="pl-c1">JacVec</span>(f,x)</pre></div>
<p dir="auto">makes <code>J</code> into a matrix-free operator which calculates <code>J*v</code> products. For
example:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="v = rand(30)
res = similar(v)
mul!(res,J,v) # Does 1 f evaluation"><pre>v <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">30</span>)
res <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v)
<span class="pl-c1">mul!</span>(res,J,v) <span class="pl-c"><span class="pl-c">#</span> Does 1 f evaluation</span></pre></div>
<p dir="auto">makes <code>res = J*v</code>. Additional operators for <code>HesVec</code> exists, including
<code>HesVecGrad</code> which allows one to utilize a gradient function. These operators
are compatible with iterative solver libraries like IterativeSolvers.jl, meaning
the following performs the Newton-Krylov update iteration:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using IterativeSolvers
gmres!(res,J,v)"><pre><span class="pl-k">using</span> IterativeSolvers
<span class="pl-c1">gmres!</span>(res,J,v)</pre></div>
<h2 dir="auto"><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Documentation</h2>
<h3 dir="auto"><a id="user-content-matrix-coloring" class="anchor" aria-hidden="true" href="#matrix-coloring"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Matrix Coloring</h3>
<p dir="auto">This library extends the common <code>ArrayInterfaceCore.matrix_colors</code> function to allow
for coloring sparse matrices using graphical techniques.</p>
<p dir="auto">Matrix coloring allows you to reduce the number of times finite differencing
requires an <code>f</code> call to <code>maximum(colors)+1</code>, or reduces automatic differentiation
to using <code>maximum(colors)</code> partials. Since normally these values are <code>length(x)</code>,
this can be significant savings.</p>
<p dir="auto">The API for computing the colorvec vector is:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="matrix_colors(A::AbstractMatrix,alg::SparseDiffToolsColoringAlgorithm = GreedyD1Color();
              partition_by_rows::Bool = false)"><pre><span class="pl-c1">matrix_colors</span>(A<span class="pl-k">::</span><span class="pl-c1">AbstractMatrix</span>,alg<span class="pl-k">::</span><span class="pl-c1">SparseDiffToolsColoringAlgorithm</span> <span class="pl-k">=</span> <span class="pl-c1">GreedyD1Color</span>();
              partition_by_rows<span class="pl-k">::</span><span class="pl-c1">Bool</span> <span class="pl-k">=</span> <span class="pl-c1">false</span>)</pre></div>
<p dir="auto">The first argument is the abstract matrix which represents the sparsity pattern
of the Jacobian. The second argument is the optional choice of coloring algorithm.
It will default to a greedy distance 1 coloring, though if your special matrix
type has more information, like is a <code>Tridiagonal</code> or <code>BlockBandedMatrix</code>, the
colorvec vector will be analytically calculated instead. The keyword argument
<code>partition_by_rows</code> allows you to partition the Jacobian on the basis of rows instead
of columns and generate a corresponding coloring vector which can be used for
reverse-mode AD. Default value is false.</p>
<p dir="auto">The result is a vector which assigns a colorvec to each column (or row) of the matrix.</p>
<h3 dir="auto"><a id="user-content-colorvec-assisted-differentiation" class="anchor" aria-hidden="true" href="#colorvec-assisted-differentiation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Colorvec-Assisted Differentiation</h3>
<p dir="auto">Colorvec-assisted differentiation for numerical differentiation is provided by
FiniteDiff.jl and for automatic differentiation is provided by
ForwardDiff.jl.</p>
<p dir="auto">For FiniteDiff.jl, one simply has to use the provided <code>colorvec</code> keyword
argument. See
<a href="https://github.com/JuliaDiff/FiniteDiff.jl#jacobians">the FiniteDiff Jacobian documentation</a>
for more details.</p>
<p dir="auto">For forward-mode automatic differentiation, use of a colorvec vector is provided
by the following function:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="forwarddiff_color_jacobian!(J::AbstractMatrix{&lt;:Number},
                            f,
                            x::AbstractArray{&lt;:Number};
                            dx = nothing,
                            colorvec = eachindex(x),
                            sparsity = nothing)"><pre><span class="pl-c1">forwarddiff_color_jacobian!</span>(J<span class="pl-k">::</span><span class="pl-c1">AbstractMatrix{&lt;:Number}</span>,
                            f,
                            x<span class="pl-k">::</span><span class="pl-c1">AbstractArray{&lt;:Number}</span>;
                            dx <span class="pl-k">=</span> <span class="pl-c1">nothing</span>,
                            colorvec <span class="pl-k">=</span> <span class="pl-c1">eachindex</span>(x),
                            sparsity <span class="pl-k">=</span> <span class="pl-c1">nothing</span>)</pre></div>
<p dir="auto">Notice that if a sparsity pattern is not supplied then the built Jacobian will
be the compressed Jacobian: <code>sparsity</code> must be a sparse matrix or a structured matrix
(<code>Tridiagonal</code>, <code>Banded</code>, etc. conforming to the ArrayInterfaceCore.jl specs) with the
appropriate sparsity pattern to allow for decompression.</p>
<p dir="auto">This call will allocate the cache variables each time. To avoid allocating the
cache, construct the cache in advance:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="ForwardColorJacCache(f,x,_chunksize = nothing;
                              dx = nothing,
                              colorvec=1:length(x),
                              sparsity = nothing)"><pre><span class="pl-c1">ForwardColorJacCache</span>(f,x,_chunksize <span class="pl-k">=</span> <span class="pl-c1">nothing</span>;
                              dx <span class="pl-k">=</span> <span class="pl-c1">nothing</span>,
                              colorvec<span class="pl-k">=</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">length</span>(x),
                              sparsity <span class="pl-k">=</span> <span class="pl-c1">nothing</span>)</pre></div>
<p dir="auto">and utilize the following signature:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="forwarddiff_color_jacobian!(J::AbstractMatrix{&lt;:Number},
                            f,
                            x::AbstractArray{&lt;:Number},
                            jac_cache::ForwardColorJacCache)"><pre><span class="pl-c1">forwarddiff_color_jacobian!</span>(J<span class="pl-k">::</span><span class="pl-c1">AbstractMatrix{&lt;:Number}</span>,
                            f,
                            x<span class="pl-k">::</span><span class="pl-c1">AbstractArray{&lt;:Number}</span>,
                            jac_cache<span class="pl-k">::</span><span class="pl-c1">ForwardColorJacCache</span>)</pre></div>
<p dir="auto"><code>dx</code> is a pre-allocated output vector which is used to declare the output size,
and thus allows for specifying a non-square Jacobian.</p>
<p dir="auto">If one is using an out-of-place function <code>f(x)</code>, then the alternative form
ca be used:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="jacout = forwarddiff_color_jacobian(g, x,
                                    dx = similar(x),
                                    colorvec = 1:length(x),
                                    sparsity = nothing,
                                    jac_prototype = nothing)"><pre>jacout <span class="pl-k">=</span> <span class="pl-c1">forwarddiff_color_jacobian</span>(g, x,
                                    dx <span class="pl-k">=</span> <span class="pl-c1">similar</span>(x),
                                    colorvec <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">length</span>(x),
                                    sparsity <span class="pl-k">=</span> <span class="pl-c1">nothing</span>,
                                    jac_prototype <span class="pl-k">=</span> <span class="pl-c1">nothing</span>)</pre></div>
<p dir="auto">Note that the out-of-place form is efficient and compatible with StaticArrays.
One can specify the type and shape of the output Jacobian by giving an
additional <code>jac_prototype</code> to the out-of place <code>forwarddiff_color_jacobian</code>
function, otherwise it will become a dense matrix. If <code>jac_prototype</code> and
<code>sparsity</code> are not specified, then the oop Jacobian will assume that the
function has a <em>square</em> Jacobian matrix. If it is not the case, please specify
the shape of output by giving <code>dx</code>.</p>
<p dir="auto">Similar functionality is available for Hessians, using finite differences of forward derivatives. Given a scalar function <code>f(x)</code>, a vector value for <code>x</code>,
and a color vector and sparsity pattern, this can be accomplished using
<code>numauto_color_hessian</code> or its in-place form <code>numauto_color_hessian!</code>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="H = numauto_color_hessian(f, x, colorvec, sparsity)
numauto_color_hessian!(H, f, x, colorvec, sparsity)"><pre>H <span class="pl-k">=</span> <span class="pl-c1">numauto_color_hessian</span>(f, x, colorvec, sparsity)
<span class="pl-c1">numauto_color_hessian!</span>(H, f, x, colorvec, sparsity)</pre></div>
<p dir="auto">To avoid unnecessary allocations every time the Hessian is computed,
construct a <code>ForwardColorHesCache</code> beforehand:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="hescache = ForwardColorHesCache(f, x, colorvec, sparsity)
numauto_color_hessian!(H, f, x, hescache)"><pre>hescache <span class="pl-k">=</span> <span class="pl-c1">ForwardColorHesCache</span>(f, x, colorvec, sparsity)
<span class="pl-c1">numauto_color_hessian!</span>(H, f, x, hescache)</pre></div>
<p dir="auto">By default, these methods use a mix of numerical and automatic differentiation,
namely by taking finite differences of gradients calculated via ForwardDiff.jl.
Alternatively, if you have your own custom gradient function <code>g!</code>, you can specify
it as an argument to <code>ForwardColorHesCache</code>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="hescache = ForwardColorHesCache(f, x, colorvec, sparsity, g!)"><pre>hescache <span class="pl-k">=</span> <span class="pl-c1">ForwardColorHesCache</span>(f, x, colorvec, sparsity, g!)</pre></div>
<p dir="auto">Note that any user-defined gradient needs to have the signature <code>g!(G, x)</code>,
i.e. updating the gradient <code>G</code> in place.</p>
<h3 dir="auto"><a id="user-content-jacobian-vector-and-hessian-vector-products" class="anchor" aria-hidden="true" href="#jacobian-vector-and-hessian-vector-products"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Jacobian-Vector and Hessian-Vector Products</h3>
<p dir="auto">Matrix-free implementations of Jacobian-Vector and Hessian-Vector products is
provided in both an operator and function form. For the functions, each choice
has the choice of being in-place and out-of-place, and the in-place versions
have the ability to pass in cache vectors to be non-allocating. When in-place
the function signature for Jacobians is <code>f!(du,u)</code>, while out-of-place has
<code>du=f(u)</code>. For Hessians, all functions must be <code>f(u)</code> which returns a scalar</p>
<p dir="auto">The functions for Jacobians are:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="auto_jacvec!(dy, f, x, v,
                      cache1 = ForwardDiff.Dual{DeivVecTag}.(x, v),
                      cache2 = ForwardDiff.Dual{DeivVecTag}.(x, v))

auto_jacvec(f, x, v)

# If compute_f0 is false, then `f(cache1,x)` will be computed
num_jacvec!(dy,f,x,v,cache1 = similar(v),
                     cache2 = similar(v);
                     compute_f0 = true)
num_jacvec(f,x,v,f0=nothing)"><pre><span class="pl-c1">auto_jacvec!</span>(dy, f, x, v,
                      cache1 <span class="pl-k">=</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">Dual</span><span class="pl-c1">{DeivVecTag}</span>.(x, v),
                      cache2 <span class="pl-k">=</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">Dual</span><span class="pl-c1">{DeivVecTag}</span>.(x, v))

<span class="pl-c1">auto_jacvec</span>(f, x, v)

<span class="pl-c"><span class="pl-c">#</span> If compute_f0 is false, then `f(cache1,x)` will be computed</span>
<span class="pl-c1">num_jacvec!</span>(dy,f,x,v,cache1 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v),
                     cache2 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v);
                     compute_f0 <span class="pl-k">=</span> <span class="pl-c1">true</span>)
<span class="pl-c1">num_jacvec</span>(f,x,v,f0<span class="pl-k">=</span><span class="pl-c1">nothing</span>)</pre></div>
<p dir="auto">For Hessians, the following are provided:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="num_hesvec!(dy,f,x,v,
             cache1 = similar(v),
             cache2 = similar(v),
             cache3 = similar(v))

num_hesvec(f,x,v)

numauto_hesvec!(dy,f,x,v,
                 cache = ForwardDiff.GradientConfig(f,v),
                 cache1 = similar(v),
                 cache2 = similar(v))

numauto_hesvec(f,x,v)

autonum_hesvec!(dy,f,x,v,
                 cache1 = similar(v),
                 cache2 = ForwardDiff.Dual{DeivVecTag}.(x, v),
                 cache3 = ForwardDiff.Dual{DeivVecTag}.(x, v))

autonum_hesvec(f,x,v)"><pre><span class="pl-c1">num_hesvec!</span>(dy,f,x,v,
             cache1 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v),
             cache2 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v),
             cache3 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v))

<span class="pl-c1">num_hesvec</span>(f,x,v)

<span class="pl-c1">numauto_hesvec!</span>(dy,f,x,v,
                 cache <span class="pl-k">=</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">GradientConfig</span>(f,v),
                 cache1 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v),
                 cache2 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v))

<span class="pl-c1">numauto_hesvec</span>(f,x,v)

<span class="pl-c1">autonum_hesvec!</span>(dy,f,x,v,
                 cache1 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v),
                 cache2 <span class="pl-k">=</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">Dual</span><span class="pl-c1">{DeivVecTag}</span>.(x, v),
                 cache3 <span class="pl-k">=</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">Dual</span><span class="pl-c1">{DeivVecTag}</span>.(x, v))

<span class="pl-c1">autonum_hesvec</span>(f,x,v)</pre></div>
<p dir="auto">In addition,
the following forms allow you to provide a gradient function <code>g(dy,x)</code> or <code>dy=g(x)</code>
respectively:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="num_hesvecgrad!(dy,g,x,v,
                     cache2 = similar(v),
                     cache3 = similar(v))

num_hesvecgrad(g,x,v)

auto_hesvecgrad!(dy,g,x,v,
                     cache2 = ForwardDiff.Dual{DeivVecTag}.(x, v),
                     cache3 = ForwardDiff.Dual{DeivVecTag}.(x, v))

auto_hesvecgrad(g,x,v)"><pre><span class="pl-c1">num_hesvecgrad!</span>(dy,g,x,v,
                     cache2 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v),
                     cache3 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v))

<span class="pl-c1">num_hesvecgrad</span>(g,x,v)

<span class="pl-c1">auto_hesvecgrad!</span>(dy,g,x,v,
                     cache2 <span class="pl-k">=</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">Dual</span><span class="pl-c1">{DeivVecTag}</span>.(x, v),
                     cache3 <span class="pl-k">=</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">Dual</span><span class="pl-c1">{DeivVecTag}</span>.(x, v))

<span class="pl-c1">auto_hesvecgrad</span>(g,x,v)</pre></div>
<p dir="auto">The <code>numauto</code> and <code>autonum</code> methods both mix numerical and automatic differentiation, with
the former almost always being more efficient and thus being recommended.</p>
<p dir="auto">Optionally, if you load Zygote.jl, the following <code>numback</code>
and <code>autoback</code> methods are available and allow numerical/ForwardDiff over reverse mode
automatic differentiation respectively, where the reverse-mode AD is provided by Zygote.jl.
Currently these methods are not competitive against <code>numauto</code>, but as Zygote.jl gets
optimized these will likely be the fastest.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Zygote # Required

numback_hesvec!(dy,f,x,v,
                     cache1 = similar(v),
                     cache2 = similar(v))

numback_hesvec(f,x,v)

# Currently errors! See https://github.com/FluxML/Zygote.jl/issues/241
autoback_hesvec!(dy,f,x,v,
                     cache2 = ForwardDiff.Dual{DeivVecTag}.(x, v),
                     cache3 = ForwardDiff.Dual{DeivVecTag}.(x, v))

autoback_hesvec(f,x,v)"><pre><span class="pl-k">using</span> Zygote <span class="pl-c"><span class="pl-c">#</span> Required</span>

<span class="pl-c1">numback_hesvec!</span>(dy,f,x,v,
                     cache1 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v),
                     cache2 <span class="pl-k">=</span> <span class="pl-c1">similar</span>(v))

<span class="pl-c1">numback_hesvec</span>(f,x,v)

<span class="pl-c"><span class="pl-c">#</span> Currently errors! See https://github.com/FluxML/Zygote.jl/issues/241</span>
<span class="pl-c1">autoback_hesvec!</span>(dy,f,x,v,
                     cache2 <span class="pl-k">=</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">Dual</span><span class="pl-c1">{DeivVecTag}</span>.(x, v),
                     cache3 <span class="pl-k">=</span> ForwardDiff<span class="pl-k">.</span><span class="pl-c1">Dual</span><span class="pl-c1">{DeivVecTag}</span>.(x, v))

<span class="pl-c1">autoback_hesvec</span>(f,x,v)</pre></div>
<h4 dir="auto"><a id="user-content-jv-and-hv-operators" class="anchor" aria-hidden="true" href="#jv-and-hv-operators"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>J<em>v and H</em>v Operators</h4>
<p dir="auto">The following produce matrix-free operators which are used for calculating
Jacobian-vector and Hessian-vector products where the differentiation takes
place at the vector <code>u</code>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="JacVec(f,x::AbstractArray;autodiff=true)
HesVec(f,x::AbstractArray;autodiff=true)
HesVecGrad(g,x::AbstractArray;autodiff=false)"><pre><span class="pl-c1">JacVec</span>(f,x<span class="pl-k">::</span><span class="pl-c1">AbstractArray</span>;autodiff<span class="pl-k">=</span><span class="pl-c1">true</span>)
<span class="pl-c1">HesVec</span>(f,x<span class="pl-k">::</span><span class="pl-c1">AbstractArray</span>;autodiff<span class="pl-k">=</span><span class="pl-c1">true</span>)
<span class="pl-c1">HesVecGrad</span>(g,x<span class="pl-k">::</span><span class="pl-c1">AbstractArray</span>;autodiff<span class="pl-k">=</span><span class="pl-c1">false</span>)</pre></div>
<p dir="auto">These all have the same interface, where <code>J*v</code> utilizes the out-of-place
Jacobian-vector or Hessian-vector function, whereas <code>mul!(res,J,v)</code> utilizes
the appropriate in-place versions. To update the location of differentiation
in the operator, simply mutate the vector <code>u</code>: <code>J.u .= ...</code>.</p>
</article></div>