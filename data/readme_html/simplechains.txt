<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-simplechains" class="anchor" aria-hidden="true" href="#simplechains"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>SimpleChains</h1>
<p dir="auto"><a href="https://PumasAI.github.io/SimpleChains.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://PumasAI.github.io/SimpleChains.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/PumasAI/SimpleChains.jl/actions"><img src="https://github.com/PumasAI/SimpleChains.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/PumasAI/SimpleChains.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/6c523bfc65186719c02fec9f8a45c8fd2222a79a98066b8ef564d053d6ac2757/68747470733a2f2f636f6465636f762e696f2f67682f50756d617341492f53696d706c65436861696e732e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="codecov-img" data-canonical-src="https://codecov.io/gh/PumasAI/SimpleChains.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto"><code>SimpleChains.jl</code> only supports simple chains, but it intends to be fast for small problems on the CPU.
Currently, <code>valgrad!</code> is the only means of extracting gradient information.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using SimpleChains, BenchmarkTools

# 24 covariates each per 200 observations
x = rand(24, 200); # 24 inputs per 200 observations

# 2 responses each per 200 observations
y = Matrix{Float64}(undef, 2, 200) .= randn.() .* 10;

schain = SimpleChain(
  static(24), # input dimension (optional)
  TurboDense{true}(tanh, 8), # dense layer with bias that maps to 8 outputs and applies `tanh` activation
  SimpleChains.Dropout(0.2), # dropout layer
  TurboDense{false}(identity, 2), # dense layer without bias that maps to 2 outputs and `identity` activation
  SquaredLoss(y)
);

p = SimpleChains.init_params(schain)
g = similar(p);

# Entirely in place evaluation
@benchmark valgrad!($g, $schain, $x, $p) # dropout active"><pre><span class="pl-k">using</span> SimpleChains, BenchmarkTools

<span class="pl-c"><span class="pl-c">#</span> 24 covariates each per 200 observations</span>
x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">24</span>, <span class="pl-c1">200</span>); <span class="pl-c"><span class="pl-c">#</span> 24 inputs per 200 observations</span>

<span class="pl-c"><span class="pl-c">#</span> 2 responses each per 200 observations</span>
y <span class="pl-k">=</span> <span class="pl-c1">Matrix</span><span class="pl-c1">{Float64}</span>(undef, <span class="pl-c1">2</span>, <span class="pl-c1">200</span>) <span class="pl-k">.=</span> <span class="pl-c1">randn</span>.() <span class="pl-k">.*</span> <span class="pl-c1">10</span>;

schain <span class="pl-k">=</span> <span class="pl-c1">SimpleChain</span>(
  <span class="pl-c1">static</span>(<span class="pl-c1">24</span>), <span class="pl-c"><span class="pl-c">#</span> input dimension (optional)</span>
  <span class="pl-c1">TurboDense</span><span class="pl-c1">{true}</span>(tanh, <span class="pl-c1">8</span>), <span class="pl-c"><span class="pl-c">#</span> dense layer with bias that maps to 8 outputs and applies `tanh` activation</span>
  SimpleChains<span class="pl-k">.</span><span class="pl-c1">Dropout</span>(<span class="pl-c1">0.2</span>), <span class="pl-c"><span class="pl-c">#</span> dropout layer</span>
  <span class="pl-c1">TurboDense</span><span class="pl-c1">{false}</span>(identity, <span class="pl-c1">2</span>), <span class="pl-c"><span class="pl-c">#</span> dense layer without bias that maps to 2 outputs and `identity` activation</span>
  <span class="pl-c1">SquaredLoss</span>(y)
);

p <span class="pl-k">=</span> SimpleChains<span class="pl-k">.</span><span class="pl-c1">init_params</span>(schain)
g <span class="pl-k">=</span> <span class="pl-c1">similar</span>(p);

<span class="pl-c"><span class="pl-c">#</span> Entirely in place evaluation</span>
<span class="pl-c1">@benchmark</span> <span class="pl-c1">valgrad!</span>(<span class="pl-k">$</span>g, <span class="pl-k">$</span>schain, <span class="pl-k">$</span>x, <span class="pl-k">$</span>p) <span class="pl-c"><span class="pl-c">#</span> dropout active</span></pre></div>
<p dir="auto">For comparison, using Flux, we would write:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Flux

chain = Chain(
  Dense(24, 8, tanh; bias = true),
  Flux.Dropout(0.2),
  Dense(8, 2, identity; bias = false)
);
chain.layers[2].active = true # activate dropout

ya = Array(y);

@benchmark gradient(Flux.params($chain)) do
  Flux.mse($chain($x), $ya)
end"><pre><span class="pl-k">using</span> Flux

chain <span class="pl-k">=</span> <span class="pl-c1">Chain</span>(
  <span class="pl-c1">Dense</span>(<span class="pl-c1">24</span>, <span class="pl-c1">8</span>, tanh; bias <span class="pl-k">=</span> <span class="pl-c1">true</span>),
  Flux<span class="pl-k">.</span><span class="pl-c1">Dropout</span>(<span class="pl-c1">0.2</span>),
  <span class="pl-c1">Dense</span>(<span class="pl-c1">8</span>, <span class="pl-c1">2</span>, identity; bias <span class="pl-k">=</span> <span class="pl-c1">false</span>)
);
chain<span class="pl-k">.</span>layers[<span class="pl-c1">2</span>]<span class="pl-k">.</span>active <span class="pl-k">=</span> <span class="pl-c1">true</span> <span class="pl-c"><span class="pl-c">#</span> activate dropout</span>

ya <span class="pl-k">=</span> <span class="pl-c1">Array</span>(y);

<span class="pl-c1">@benchmark</span> <span class="pl-c1">gradient</span>(Flux<span class="pl-k">.</span><span class="pl-c1">params</span>(<span class="pl-k">$</span>chain)) <span class="pl-k">do</span>
  Flux<span class="pl-k">.</span><span class="pl-c1">mse</span>(<span class="pl-k">$</span><span class="pl-c1">chain</span>(<span class="pl-k">$</span>x), <span class="pl-k">$</span>ya)
<span class="pl-k">end</span></pre></div>
<p dir="auto">Benchmark results:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; @benchmark valgrad!($g, $schain, $x, $p) # dropout active
BechmarkTools.Trial: 10000 samples with 6 evaluations.
 Range (min … max):  5.274 μs …  33.075 μs  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     5.657 μs               ┊ GC (median):    0.00%
 Time  (mean ± σ):   5.646 μs ± 349.777 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%
 Memory estimate: 0 bytes, allocs estimate: 0.
  
julia&gt; @benchmark gradient(Flux.params($chain)) do
         Flux.mse($chain($x), $ya)
       end
BechmarkTools.Trial: 10000 samples with 1 evaluations.
 Range (min … max):   83.674 μs …   4.865 ms  ┊ GC (min … max): 0.00% … 93.21%
 Time  (median):      96.430 μs               ┊ GC (median):    0.00%
 Time  (mean ± σ):   106.897 μs ± 197.689 μs  ┊ GC (mean ± σ):  7.96% ±  4.22%
 Memory estimate: 182.55 KiB, allocs estimate: 316."><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">valgrad!</span>(<span class="pl-k">$</span>g, <span class="pl-k">$</span>schain, <span class="pl-k">$</span>x, <span class="pl-k">$</span>p) <span class="pl-c"><span class="pl-c">#</span> dropout active</span>
BechmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">6</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">5.274</span> μs …  <span class="pl-c1">33.075</span> μs  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">5.657</span> μs               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">5.646</span> μs ± <span class="pl-c1">349.777</span> ns  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> ± <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">0.</span>
  
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">gradient</span>(Flux<span class="pl-k">.</span><span class="pl-c1">params</span>(<span class="pl-k">$</span>chain)) <span class="pl-k">do</span>
         Flux<span class="pl-k">.</span><span class="pl-c1">mse</span>(<span class="pl-k">$</span><span class="pl-c1">chain</span>(<span class="pl-k">$</span>x), <span class="pl-k">$</span>ya)
       <span class="pl-k">end</span>
BechmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">1</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>   <span class="pl-c1">83.674</span> μs …   <span class="pl-c1">4.865</span> ms  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">93.21</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>      <span class="pl-c1">96.430</span> μs               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">106.897</span> μs ± <span class="pl-c1">197.689</span> μs  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">7.96</span><span class="pl-k">%</span> ±  <span class="pl-c1">4.22</span><span class="pl-k">%</span>
 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">182.55</span> KiB, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">316.</span></pre></div>
</article></div>