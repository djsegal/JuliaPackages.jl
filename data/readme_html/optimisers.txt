<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/FluxML/Optimisers.jl/raw/master/docs/src/assets/logo.png"><img align="right" width="200px" src="https://github.com/FluxML/Optimisers.jl/raw/master/docs/src/assets/logo.png" style="max-width: 100%;"></a></p>
<h1 dir="auto"><a id="user-content-optimisersjl" class="anchor" aria-hidden="true" href="#optimisersjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Optimisers.jl</h1>

<p dir="auto"><a href="https://fluxml.ai/Optimisers.jl/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/FluxML/Optimisers.jl/actions"><img src="https://github.com/FluxML/Optimisers.jl/workflows/CI/badge.svg" alt="" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/FluxML/Optimisers.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/bc3eccd98ff0bf8dc1fcfb15a0c47b82ea23ca6aa050d62c24dbc33ec72bac2b/68747470733a2f2f636f6465636f762e696f2f67682f466c75784d4c2f4f7074696d69736572732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="" data-canonical-src="https://codecov.io/gh/FluxML/Optimisers.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">Optimisers.jl defines many standard gradient-based optimisation rules, and tools for applying them to deeply nested models.</p>
<p dir="auto">This is the future of training for <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> neural networks,
and the present for <a href="https://github.com/avik-pal/Lux.jl">Lux.jl</a>.
But it can be used separately on any array, or anything else understood by <a href="https://github.com/FluxML/Functors.jl">Functors.jl</a>.</p>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="] add Optimisers"><pre>] add Optimisers</pre></div>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">The core idea is that optimiser state (such as momentum) is explicitly handled.
It is initialised by <code>setup</code>, and then at each step, <code>update</code> returns both the new
state, and the model with its trainable parameters adjusted:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="state = Optimisers.setup(Optimisers.Adam(), model)  # just once

grad = Zygote.gradient(m -&gt; loss(m(x), y), model)[1]

state, model = Optimisers.update(state, model, grad)  # at every step"><pre>state <span class="pl-k">=</span> Optimisers<span class="pl-k">.</span><span class="pl-c1">setup</span>(Optimisers<span class="pl-k">.</span><span class="pl-c1">Adam</span>(), model)  <span class="pl-c"><span class="pl-c">#</span> just once</span>

grad <span class="pl-k">=</span> Zygote<span class="pl-k">.</span><span class="pl-c1">gradient</span>(m <span class="pl-k">-&gt;</span> <span class="pl-c1">loss</span>(<span class="pl-c1">m</span>(x), y), model)[<span class="pl-c1">1</span>]

state, model <span class="pl-k">=</span> Optimisers<span class="pl-k">.</span><span class="pl-c1">update</span>(state, model, grad)  <span class="pl-c"><span class="pl-c">#</span> at every step</span></pre></div>
<p dir="auto">For models with deeply nested layers containing the parameters (like <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> models),
this state is a similarly nested tree. As is the gradient: if using Zygote, you must use the "explicit" style as shown,
not the "implicit" one with <code>Params</code>.</p>
<p dir="auto">The function <code>destructure</code> collects all the trainable parameters into one vector,
and returns this along with a function to re-build a similar model:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="vector, re = Optimisers.destructure(model)

model2 = re(2 .* vector)"><pre>vector, re <span class="pl-k">=</span> Optimisers<span class="pl-k">.</span><span class="pl-c1">destructure</span>(model)

model2 <span class="pl-k">=</span> <span class="pl-c1">re</span>(<span class="pl-c1">2</span> <span class="pl-k">.*</span> vector)</pre></div>
<p dir="auto"><a href="https://fluxml.ai/Optimisers.jl/dev/" rel="nofollow">The documentation</a> explains usage in more detail,
describes all the optimization rules, and shows how to define new ones.</p>
</article></div>