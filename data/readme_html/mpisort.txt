<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-mpisort" class="anchor" aria-hidden="true" href="#mpisort"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>MPISort</h1>
<p dir="auto"><em>Don't put all your eggs in one basket!</em></p>
<p dir="auto"><a href="https://github.com/anicusan/MPISort.jl/actions/workflows/ci.yml"><img src="https://github.com/anicusan/MPISort.jl/actions/workflows/ci.yml/badge.svg" alt="CI" style="max-width: 100%;"></a>
<a href="https://github.com/anicusan/MPISort.jl"><img src="https://camo.githubusercontent.com/a0d2be6fbe4d3822b04bfda72f31c649840e02eed59bccdad0d0ee84b2644dcd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f616e69637573616e2f4d5049536f72742e6a6c" alt="License" data-canonical-src="https://img.shields.io/github/license/anicusan/MPISort.jl" style="max-width: 100%;"></a>
<a href="https://anicusan.github.io/MPISort.jl/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="DevDocs" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a></p>
<p dir="auto">Sorting <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="5c5d2546cacb1b66e6e245da5190a90f">$N$</math-renderer> elements spread out across <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="5c5d2546cacb1b66e6e245da5190a90f">$P$</math-renderer> processors, <em>with no processor being able to hold all
elements at once</em> is a difficult problem, with very few open-source implementations in
<a href="https://github.com/hsundar/usort">C++</a> and <a href="https://github.com/vipulharsh/HSS">Charm++</a>. This
library provides the <code>mpisort!</code> function for distributed MPI-based sorting algorithms following the
standard Julia <code>Base.sort!</code> signature; at the moment, one optimised algorithm is provided:</p>
<h2 dir="auto">
<a id="user-content-sihsort" class="anchor" aria-hidden="true" href="#sihsort"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>SIHSort</code>
</h2>
<p dir="auto">Sampling with interpolated histograms sorting algorithm (pronounced <em>sigh</em> sort, like anything
MPI-related), optimised for minimum inter-rank communication and memory footprint. Features:</p>
<ul dir="auto">
<li>
<strong>Does not require that distributed data fits into the memory of a single node</strong>. No IO either.</li>
<li>Works for any comparison-based data, with additional optimisations for numeric elements.</li>
<li>Optimised for minimum MPI communication; can use Julia threads on each shared-memory node.</li>
<li>The node-local arrays may have different sizes; sorting will try to balance number of elements held by each MPI rank.</li>
<li>Works with any <code>AbstractVector</code>, including accelerators such as GPUs (TODO: test this further). Julia type-inference and optimisations do wonders.</li>
<li>Implements the standard Julia <code>sort!</code> API, and naturally works for custom data, comparisons, orderings, etc.</li>
</ul>
<h3 dir="auto">
<a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# File:   mpisort.jl
# Run as: mpiexec -n 4 julia --threads=2 mpisort.jl

using MPI
using MPISort
using Random


# Initialise MPI, get communicator for all ranks, rank index, number of ranks
MPI.Init()

comm = MPI.COMM_WORLD
rank = MPI.Comm_rank(comm)
nranks = MPI.Comm_size(comm)

# Generate local array on each MPI rank - even with different number of elements
rng = Xoshiro(rank)
num_elements = 50 + rank * 2
local_array = rand(rng, 1:500, num_elements)

# Sort arrays across all MPI ranks
alg = SIHSort(comm)
sorted_local_array = mpisort!(local_array; alg=alg)

# Print each local array sequentially
for i in 0:nranks - 1
    rank == i &amp;&amp; @show rank sorted_local_array alg.stats
    MPI.Barrier(comm)
end
"><pre><span class="pl-c"><span class="pl-c">#</span> File:   mpisort.jl</span>
<span class="pl-c"><span class="pl-c">#</span> Run as: mpiexec -n 4 julia --threads=2 mpisort.jl</span>

<span class="pl-k">using</span> MPI
<span class="pl-k">using</span> MPISort
<span class="pl-k">using</span> Random


<span class="pl-c"><span class="pl-c">#</span> Initialise MPI, get communicator for all ranks, rank index, number of ranks</span>
MPI<span class="pl-k">.</span><span class="pl-c1">Init</span>()

comm <span class="pl-k">=</span> MPI<span class="pl-k">.</span>COMM_WORLD
rank <span class="pl-k">=</span> MPI<span class="pl-k">.</span><span class="pl-c1">Comm_rank</span>(comm)
nranks <span class="pl-k">=</span> MPI<span class="pl-k">.</span><span class="pl-c1">Comm_size</span>(comm)

<span class="pl-c"><span class="pl-c">#</span> Generate local array on each MPI rank - even with different number of elements</span>
rng <span class="pl-k">=</span> <span class="pl-c1">Xoshiro</span>(rank)
num_elements <span class="pl-k">=</span> <span class="pl-c1">50</span> <span class="pl-k">+</span> rank <span class="pl-k">*</span> <span class="pl-c1">2</span>
local_array <span class="pl-k">=</span> <span class="pl-c1">rand</span>(rng, <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">500</span>, num_elements)

<span class="pl-c"><span class="pl-c">#</span> Sort arrays across all MPI ranks</span>
alg <span class="pl-k">=</span> <span class="pl-c1">SIHSort</span>(comm)
sorted_local_array <span class="pl-k">=</span> <span class="pl-c1">mpisort!</span>(local_array; alg<span class="pl-k">=</span>alg)

<span class="pl-c"><span class="pl-c">#</span> Print each local array sequentially</span>
<span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">0</span><span class="pl-k">:</span>nranks <span class="pl-k">-</span> <span class="pl-c1">1</span>
    rank <span class="pl-k">==</span> i <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">@show</span> rank sorted_local_array alg<span class="pl-k">.</span>stats
    MPI<span class="pl-k">.</span><span class="pl-c1">Barrier</span>(comm)
<span class="pl-k">end</span>
</pre></div>
<p dir="auto"><strong>Note:</strong> because the data is redistributed between nodes, the vector size must change - hence it
is different to the in-place <code>Base.sort!</code>. The input vector is mutated, but another vector - with
potentially different size and elements - is returned. This is the reason for a different function
signature (<code>mpisort!</code> with a return value); however, it has the exact same inputs as <code>Base.sort!</code>.</p>
<p dir="auto">Different sorting settings:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="
# Automatically uses MPI.COMM_WORLD as communicator; doesn't save sorting stats
sorted_local_array = mpisort!(local_array; alg=SIHSort())

# Reverse sorting; specify communicator explicitly
sorted_local_array = mpisort!(local_array; alg=SIHSort(comm), rev=true)

# Specify key to sort by; see https://docs.julialang.org/en/v1/base/sort/
sorted_local_array = mpisort!(local_array; alg=SIHSort(), by=x-&gt;x[&quot;key&quot;])

# Different ordering; see https://docs.julialang.org/en/v1/base/sort/#Alternate-orderings
sorted_local_array = mpisort!(local_array; alg=SIHSort(), order=Reverse)

# Save sorting stats
alg = SIHSort(comm)
sorted_local_array = mpisort!(local_array; alg=alg)

@show alg.stats.splitters               # `nranks - 1` elements splitting arrays between nodes
@show alg.stats.num_elements            # `nranks` integers specifying number of elements on each node

# Use different in-place local sorter
alg = SIHSort(comm, nothing)            # Default: standard Base.sort!
alg = SIHSort(comm, QuickSort)          # Specify algorithm, passed to Base.sort!(...; alg=&lt;Algorithm&gt;)
alg = SIHSort(comm, v -&gt; mysorter!(v))  # Pass any function that sorts a local vector in-place
"><pre><span class="pl-c"><span class="pl-c">#</span> Automatically uses MPI.COMM_WORLD as communicator; doesn't save sorting stats</span>
sorted_local_array <span class="pl-k">=</span> <span class="pl-c1">mpisort!</span>(local_array; alg<span class="pl-k">=</span><span class="pl-c1">SIHSort</span>())

<span class="pl-c"><span class="pl-c">#</span> Reverse sorting; specify communicator explicitly</span>
sorted_local_array <span class="pl-k">=</span> <span class="pl-c1">mpisort!</span>(local_array; alg<span class="pl-k">=</span><span class="pl-c1">SIHSort</span>(comm), rev<span class="pl-k">=</span><span class="pl-c1">true</span>)

<span class="pl-c"><span class="pl-c">#</span> Specify key to sort by; see https://docs.julialang.org/en/v1/base/sort/</span>
sorted_local_array <span class="pl-k">=</span> <span class="pl-c1">mpisort!</span>(local_array; alg<span class="pl-k">=</span><span class="pl-c1">SIHSort</span>(), by<span class="pl-k">=</span>x<span class="pl-k">-&gt;</span>x[<span class="pl-s"><span class="pl-pds">"</span>key<span class="pl-pds">"</span></span>])

<span class="pl-c"><span class="pl-c">#</span> Different ordering; see https://docs.julialang.org/en/v1/base/sort/#Alternate-orderings</span>
sorted_local_array <span class="pl-k">=</span> <span class="pl-c1">mpisort!</span>(local_array; alg<span class="pl-k">=</span><span class="pl-c1">SIHSort</span>(), order<span class="pl-k">=</span>Reverse)

<span class="pl-c"><span class="pl-c">#</span> Save sorting stats</span>
alg <span class="pl-k">=</span> <span class="pl-c1">SIHSort</span>(comm)
sorted_local_array <span class="pl-k">=</span> <span class="pl-c1">mpisort!</span>(local_array; alg<span class="pl-k">=</span>alg)

<span class="pl-c1">@show</span> alg<span class="pl-k">.</span>stats<span class="pl-k">.</span>splitters               <span class="pl-c"><span class="pl-c">#</span> `nranks - 1` elements splitting arrays between nodes</span>
<span class="pl-c1">@show</span> alg<span class="pl-k">.</span>stats<span class="pl-k">.</span>num_elements            <span class="pl-c"><span class="pl-c">#</span> `nranks` integers specifying number of elements on each node</span>

<span class="pl-c"><span class="pl-c">#</span> Use different in-place local sorter</span>
alg <span class="pl-k">=</span> <span class="pl-c1">SIHSort</span>(comm, <span class="pl-c1">nothing</span>)            <span class="pl-c"><span class="pl-c">#</span> Default: standard Base.sort!</span>
alg <span class="pl-k">=</span> <span class="pl-c1">SIHSort</span>(comm, QuickSort)          <span class="pl-c"><span class="pl-c">#</span> Specify algorithm, passed to Base.sort!(...; alg=&lt;Algorithm&gt;)</span>
alg <span class="pl-k">=</span> <span class="pl-c1">SIHSort</span>(comm, v <span class="pl-k">-&gt;</span> <span class="pl-c1">mysorter!</span>(v))  <span class="pl-c"><span class="pl-c">#</span> Pass any function that sorts a local vector in-place</span>
</pre></div>
<h3 dir="auto">
<a id="user-content-communication-and-memory-footprint" class="anchor" aria-hidden="true" href="#communication-and-memory-footprint"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Communication and Memory Footprint</h3>
<p dir="auto">Only optimised collective MPI communication is used, in order: Gather, Bcast, Reduce, Bcast,
Alltoall, Allreduce, Alltoallv. I am not aware of a non-IO based algorithm with less communication
(if you do know one, please open an issue!).</p>
<p dir="auto">If <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="5c5d2546cacb1b66e6e245da5190a90f">$N$</math-renderer> is the total number of elements spread out across <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="5c5d2546cacb1b66e6e245da5190a90f">$P$</math-renderer> MPI ranks, then the per-rank memory
footprint of <code>SIHSort</code> is:</p>
<p dir="auto"><math-renderer class="js-display-math" style="display: block" data-static-url="https://github.githubassets.com/static" data-run-id="5c5d2546cacb1b66e6e245da5190a90f">$$ k P + k P + P + 3(P - 1) + \frac{N + \epsilon}{P} $$</math-renderer></p>
<p dir="auto">Where <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="5c5d2546cacb1b66e6e245da5190a90f">$k$</math-renderer> is the number of samples extracted from each node; following [1], we use:</p>
<p dir="auto"><math-renderer class="js-display-math" style="display: block" data-static-url="https://github.githubassets.com/static" data-run-id="5c5d2546cacb1b66e6e245da5190a90f">$$ k = 2P \ log_2 P $$</math-renderer></p>
<p dir="auto">Except for the final redistribution on a single new array of length <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="5c5d2546cacb1b66e6e245da5190a90f">$\frac{N + \epsilon}{P}$</math-renderer>, the
memory footprint only depends on the number of nodes involved, hence it should be scalable to
thousands of MPI ranks. Anyone got a spare 200,000 nodes to benchmark this?</p>
<h3 dir="auto">
<a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h3>
<p dir="auto">This algorithm builds on prior art:</p>
<ul dir="auto">
<li>[1] <em>Harsh V, Kale L, Solomonik E. Histogram sort with sampling.</em> : followed main ideas and theoretical results, but with deterministic sampling and original communication and interpolation optimisations.</li>
<li>[2] <em>Sundar H, Malhotra D, Biros G. Hyksort: a new variant of hypercube quicksort on distributed memory architectures.</em>
</li>
<li>[3] <em>Shi H, Schaeffer J. Parallel sorting by regular sampling.</em>
</li>
<li>[4] <em>Solomonik E, Kale LV. Highly scalable parallel sorting.</em>
</li>
<li>[5] <em>John Lapeyre, integer base-2 logarithm</em> - <a href="https://github.com/jlapeyre/ILog2.jl">https://github.com/jlapeyre/ILog2.jl</a>.</li>
<li>[6] <em>Byrne S, Wilcox LC, Churavy V. MPI. jl: Julia bindings for the Message Passing Interface.</em> : absolute heroes who made MPI a joy to use in Julia.</li>
</ul>
<h1 dir="auto">
<a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>License</h1>
<p dir="auto"><code>MPISort.jl</code> is MIT-licensed. Enjoy.</p>
</article></div>