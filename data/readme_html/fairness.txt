<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-fairnessjl" class="anchor" aria-hidden="true" href="#fairnessjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Fairness.jl</h1>
<p><a href="https://github.com/ashryaagr/Fairness.jl/actions"><img src="https://github.com/ashryaagr/Fairness.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width:100%;"></a>
<a href="https://ci.appveyor.com/project/ashryaagr/fairness-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/a3df5c04fa53fe74690bd26313c22992295724b643d9617f39bdbd97b0dd7ec4/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6c736837636f353466706c73646c34713f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/lsh7co54fplsdl4q?svg=true" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/ashryaagr/Fairness.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/4599e6408d7ae86251c184051ea0db57e660abd9cfb3e74e97b8c45eeac136be/68747470733a2f2f636f6465636f762e696f2f67682f6173687279616167722f466169726e6573732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d7762726b384d53654d70" alt="Coverage Status" data-canonical-src="https://codecov.io/gh/ashryaagr/Fairness.jl/branch/master/graph/badge.svg?token=wbrk8MSeMp" style="max-width:100%;"></a>
<a href="https://slackinvite.julialang.org/" rel="nofollow">
<img src="https://camo.githubusercontent.com/f49fc4d558d0b4d4b11248f9ba9afa980ef90bf923b89eae4b499b3b2ce92a73/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230736c61636b2d6f72616e67652e737667" alt="#mlj" data-canonical-src="https://img.shields.io/badge/chat-on%20slack-orange.svg" style="max-width:100%;">
</a>
<a href="https://www.ashrya.in/Fairness.jl/dev/" rel="nofollow">
<img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Documentation" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;">
</a></p>
<p><a href="https://github.com/ashryaagr/Fairness.jl">Fairness.jl</a> is a comprehensive bias audit and mitigation toolkit in julia. Extensive support and functionality provided by <a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> has been used in this package.</p>
<p>For an introduction to Fairness.jl refer the notebook available at <a href="https://nextjournal.com/ashryaagr/fairness" rel="nofollow">https://nextjournal.com/ashryaagr/fairness</a></p>
<blockquote>
<p><g-emoji class="g-emoji" alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png">⚠️</g-emoji> <strong>This is experimental software</strong>: We refer <a href="https://github.com/dssg/aequitas">Aequitas</a> for stable bias auditing.</p>
</blockquote>
<h1><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h1>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using Pkg
Pkg.activate(&quot;my_environment&quot;, shared=true)
Pkg.add(&quot;Fairness&quot;)
Pkg.add(&quot;MLJ&quot;)
"><pre><span class="pl-k">using</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">activate</span>(<span class="pl-s"><span class="pl-pds">"</span>my_environment<span class="pl-pds">"</span></span>, shared<span class="pl-k">=</span><span class="pl-c1">true</span>)
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>Fairness<span class="pl-pds">"</span></span>)
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>MLJ<span class="pl-pds">"</span></span>)</pre></div>
<h1><a id="user-content-what-fairnessjl-offers-over-its-alternatives" class="anchor" aria-hidden="true" href="#what-fairnessjl-offers-over-its-alternatives"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>What Fairness.jl offers over its alternatives?</h1>
<ul>
<li>As of writing, it is the only bias audit and mitigation toolkit to support data with multi-valued protected attribute. For eg. If the protected attribute, say race has more than 2 values: "Asian", "African", "American"..so on, then Fairness.jl can easily handle it with normal workflow.</li>
<li>Multiple Fairness algorithms can be applied at the same time by wrapping the wrapped Model. <a href="https://www.ashrya.in/Fairness.jl/dev/algorithms/#Composability" rel="nofollow">Example is available in Documentation</a></li>
<li>Due to the support for multi-valued protected attribute, intersectional fairness can also be dealt with this toolkit. For eg. If the data has 2 protected attributes, say race and gender, then Fairness.jl can be used to handle it by combining the attributes like "female_american", "male_asian"...so on.</li>
<li>Extensive support and functionality provided by <a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> can be leveraged when using Fairness.jl</li>
<li>Tuning of models using MLJTuning from MLJ. Numerious ML models from MLJModels can be used together with Fairness.jl</li>
<li>It leverages the flexibility and speed of Julia to make it more efficient and easy-to-use at the same time</li>
<li>Well structured and intutive design</li>
<li>Extensive tests and Documentation</li>
</ul>
<h1><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Getting Started</h1>
<ul>
<li><a href="https://www.ashrya.in/Fairness.jl/dev" rel="nofollow">Documentation</a> is a good starting point for this package.</li>
<li>To understand Fairness.jl, it is recommended that the user goes through the <a href="https://alan-turing-institute.github.io/MLJ.jl/stable/" rel="nofollow">MLJ Documentation</a>. It shall help the user in understanding the usage of machine, evaluate, etc.</li>
<li>Incase of any difficulty or confusion feel free to <a href="https://github.com/ashryaagr/Fairness.jl/issues/new">open an issue</a>.</li>
</ul>
<h1><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Example</h1>
<p>Following is an introductory example of using Fairness.jl. Observe how easy it has become to measure and mitigate bias in Machine Learning algorithms.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using Fairness, MLJ
X, y, ŷ = @load_toydata

julia&gt; model = ConstantClassifier()
ConstantClassifier() @904

julia&gt; wrappedModel = ReweighingSamplingWrapper(classifier=model, grp=:Sex)
ReweighingSamplingWrapper(
    grp = :Sex,
    classifier = ConstantClassifier(),
    factor = 1) @312

julia&gt; evaluate(
          wrappedModel,
          X, y,
          measures=MetricWrappers(
              [true_positive, true_positive_rate], grp=:Sex))
┌────────────────────┬─────────────────────────────────────────────────────────────────────────────────────┬───────────────────────────────────── ⋯
│ _.measure          │ _.measurement                                                                       │ _.per_fold                           ⋯
├────────────────────┼─────────────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────── ⋯
│ true_positive      │ Dict{Any,Any}(&quot;M&quot; =&gt; 2,&quot;overall&quot; =&gt; 4,&quot;F&quot; =&gt; 2)                                     │ Dict{Any,Any}[Dict(&quot;M&quot; =&gt; 0,&quot;overall ⋯
│ true_positive_rate │ Dict{Any,Any}(&quot;M&quot; =&gt; 0.8333333333333334,&quot;overall&quot; =&gt; 0.8333333333333334,&quot;F&quot; =&gt; 1.0) │ Dict{Any,Any}[Dict(&quot;M&quot; =&gt; 4.99999999 ⋯
└────────────────────┴─────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────── ⋯
"><pre><span class="pl-k">using</span> Fairness, MLJ
X, y, ŷ <span class="pl-k">=</span> <span class="pl-c1">@load_toydata</span>

julia<span class="pl-k">&gt;</span> model <span class="pl-k">=</span> <span class="pl-c1">ConstantClassifier</span>()
<span class="pl-c1">ConstantClassifier</span>() @<span class="pl-c1">904</span>

julia<span class="pl-k">&gt;</span> wrappedModel <span class="pl-k">=</span> <span class="pl-c1">ReweighingSamplingWrapper</span>(classifier<span class="pl-k">=</span>model, grp<span class="pl-k">=</span><span class="pl-c1">:Sex</span>)
<span class="pl-c1">ReweighingSamplingWrapper</span>(
    grp <span class="pl-k">=</span> <span class="pl-c1">:Sex</span>,
    classifier <span class="pl-k">=</span> <span class="pl-c1">ConstantClassifier</span>(),
    factor <span class="pl-k">=</span> <span class="pl-c1">1</span>) @<span class="pl-c1">312</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">evaluate</span>(
          wrappedModel,
          X, y,
          measures<span class="pl-k">=</span><span class="pl-c1">MetricWrappers</span>(
              [true_positive, true_positive_rate], grp<span class="pl-k">=</span><span class="pl-c1">:Sex</span>))
┌────────────────────┬─────────────────────────────────────────────────────────────────────────────────────┬───────────────────────────────────── ⋯
│ _<span class="pl-k">.</span>measure          │ _<span class="pl-k">.</span>measurement                                                                       │ _<span class="pl-k">.</span>per_fold                           ⋯
├────────────────────┼─────────────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────── ⋯
│ true_positive      │ <span class="pl-c1">Dict</span><span class="pl-c1">{Any,Any}</span>(<span class="pl-s"><span class="pl-pds">"</span>M<span class="pl-pds">"</span></span> <span class="pl-k">=&gt;</span> <span class="pl-c1">2</span>,<span class="pl-s"><span class="pl-pds">"</span>overall<span class="pl-pds">"</span></span> <span class="pl-k">=&gt;</span> <span class="pl-c1">4</span>,<span class="pl-s"><span class="pl-pds">"</span>F<span class="pl-pds">"</span></span> <span class="pl-k">=&gt;</span> <span class="pl-c1">2</span>)                                     │ Dict{Any,Any}[<span class="pl-c1">Dict</span>(<span class="pl-s"><span class="pl-pds">"</span>M<span class="pl-pds">"</span></span> <span class="pl-k">=&gt;</span> <span class="pl-c1">0</span>,<span class="pl-s"><span class="pl-pds">"</span>overall ⋯</span>
<span class="pl-s">│ true_positive_rate │ Dict{Any,Any}(<span class="pl-pds">"</span></span>M<span class="pl-s"><span class="pl-pds">"</span> =&gt; 0.8333333333333334,<span class="pl-pds">"</span></span>o<span class="pl-s"><span class="pl-pds"><span class="pl-c1">verall</span>"</span> =&gt; 0.8333333333333334,<span class="pl-pds">"F</span></span><span class="pl-s"><span class="pl-pds">"</span> =&gt; 1.0) │ Dict{Any,Any}[Dict(<span class="pl-pds">"</span></span>M<span class="pl-s"><span class="pl-pds">"</span> =&gt; 4.99999999 ⋯</span>
<span class="pl-s">└────────────────────┴─────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────── ⋯</span></pre></div>
<h1><a id="user-content-components" class="anchor" aria-hidden="true" href="#components"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Components</h1>
<p>Fairness.jl is divided into following components</p>
<h3><a id="user-content-fairtensor" class="anchor" aria-hidden="true" href="#fairtensor"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>FairTensor</h3>
<p>It is a 3D matrix of values of TruePositives, False Negatives, etc for each group. It greatly helps in optimization and removing the redundant calculations.</p>
<h3><a id="user-content-measures" class="anchor" aria-hidden="true" href="#measures"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Measures</h3>
<h4><a id="user-content-calcmetrics" class="anchor" aria-hidden="true" href="#calcmetrics"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>CalcMetrics</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Metric Instances</th>
</tr>
</thead>
<tbody>
<tr>
<td>True Positive</td>
<td>truepositive,  true_positive</td>
</tr>
<tr>
<td>True Negative</td>
<td>truenegative, true_negative</td>
</tr>
<tr>
<td>False Positive</td>
<td>falsepositive, false_positive</td>
</tr>
<tr>
<td>False Negative</td>
<td>falsenegative, false_negative</td>
</tr>
<tr>
<td>True Positive Rate</td>
<td>truepositive_rate, true_positive_rate, tpr, recall, sensitivity, hit_rate</td>
</tr>
<tr>
<td>True Negative Rate</td>
<td>truenegative_rate, true_negative_rate, tnr, specificity, selectivity</td>
</tr>
<tr>
<td>False Positive Rate</td>
<td>falsepositive_rate, false_positive_rate, fpr, fallout</td>
</tr>
<tr>
<td>False Negative Rate</td>
<td>falsenegative_rate, false_negative_rate, fnr, miss_rate</td>
</tr>
<tr>
<td>False Discovery Rate</td>
<td>falsediscovery_rate, false_discovery_rate, fdr</td>
</tr>
<tr>
<td>Precision</td>
<td>positivepredictive_value, positive_predictive_value, ppv</td>
</tr>
<tr>
<td>Negative Predictive Value</td>
<td>negativepredictive_value, negative_predictive_value, npv</td>
</tr>
</tbody>
</table>
<h4><a id="user-content-fairmetrics" class="anchor" aria-hidden="true" href="#fairmetrics"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>FairMetrics</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Formula</th>
<th>Value for Custom function (func)</th>
</tr>
</thead>
<tbody>
<tr>
<td>disparity</td>
<td>metric(Gᵢ)/metric(RefGrp) ∀ i</td>
<td>func(metric(Gᵢ), metric(RefGrp)) ∀ i</td>
</tr>
<tr>
<td>parity</td>
<td>[ (1-ϵ) &lt;= dispariy_value[i] &lt;= 1/(1-ϵ) ∀ i ]</td>
<td>[ func(disparity_value[i]) ∀ i ]</td>
</tr>
</tbody>
</table>
<h4><a id="user-content-boolmetrics-wip" class="anchor" aria-hidden="true" href="#boolmetrics-wip"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>BoolMetrics [WIP]</h4>
<p>These metrics shall use either parity or shall have custom implementation to return boolean values</p>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Aliases</th>
</tr>
</thead>
<tbody>
<tr>
<td>Demographic Parity</td>
<td>DemographicParity</td>
</tr>
</tbody>
</table>
<h3><a id="user-content-fairness-algorithms" class="anchor" aria-hidden="true" href="#fairness-algorithms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Fairness Algorithms</h3>
<p>These algorithms are wrappers. These help in mitigating bias and improve fairness.</p>
<table>
<thead>
<tr>
<th>Algorithm Name</th>
<th>Metric Optimised</th>
<th>Supports Multi-valued protected attribute</th>
<th>Type</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr>
<td>Reweighing</td>
<td>General</td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔️</g-emoji></td>
<td>Preprocessing</td>
<td><a href="http://doi.org/10.1007/s10115-011-0463-8" rel="nofollow">Kamiran and Calders, 2012</a></td>
</tr>
<tr>
<td>Reweighing-Sampling</td>
<td>General</td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔️</g-emoji></td>
<td>Preprocessing</td>
<td><a href="http://doi.org/10.1007/s10115-011-0463-8" rel="nofollow">Kamiran and Calders, 2012</a></td>
</tr>
<tr>
<td>Equalized Odds Algorithm</td>
<td>Equalized Odds</td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔️</g-emoji></td>
<td>Postprocessing</td>
<td><a href="https://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning" rel="nofollow">Hardt et al., 2016</a></td>
</tr>
<tr>
<td>Calibrated Equalized Odds Algorithm</td>
<td>Calibrated Equalized Odds</td>
<td><g-emoji class="g-emoji" alias="x" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png">❌</g-emoji></td>
<td>Postprocessing</td>
<td><a href="https://proceedings.neurips.cc/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf" rel="nofollow">Pleiss et al., 2017</a></td>
</tr>
<tr>
<td>LinProg Algorithm</td>
<td>Any metric</td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔️</g-emoji></td>
<td>Postprocessing</td>
<td>Our own Algorithm</td>
</tr>
<tr>
<td>Penalty Algorithm</td>
<td>Any metric</td>
<td><g-emoji class="g-emoji" alias="heavy_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png">✔️</g-emoji></td>
<td>Inprocessing</td>
<td>Our own Algorithm</td>
</tr>
</tbody>
</table>
<h1><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contributing</h1>
<ul>
<li>Various Contribution opportunities are available. Some of the possible contributions have been listed at <a href="https://github.com/ashryaagr/Fairness.jl/issues/3#issuecomment-656812338">the pinned issue</a></li>
<li>Feel free to open an issue or contact on slack. Let us know where your intersts and strengths lie and we can find possible contribution opportunities for you.</li>
</ul>
<h1><a id="user-content-citing-fairnessjl" class="anchor" aria-hidden="true" href="#citing-fairnessjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Citing Fairness.jl</h1>
<p><a href="https://doi.org/10.5281/zenodo.3977197" rel="nofollow"><img src="https://camo.githubusercontent.com/58018cf04add35b3d83e7a8f284d7256963283f7e3a3af617e2eb4f963584457/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e333937373139372e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.3977197.svg" style="max-width:100%;"></a></p>
<div class="highlight highlight-text-bibtex position-relative" data-snippet-clipboard-copy-content="@software{ashrya_agrawal_2020_3977197,
  author       = {Ashrya Agrawal and
                  Jiahao Chen and
                  Sebastian Vollmer and
                  Anthony Blaom},
  title        = {ashryaagr/Fairness.jl},
  month        = aug,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {v0.1.2},
  doi          = {10.5281/zenodo.3977197},
  url          = {https://doi.org/10.5281/zenodo.3977197}
}
"><pre><span class="pl-k">@software</span>{<span class="pl-en">ashrya_agrawal_2020_3977197</span>,
  <span class="pl-s">author</span>       = <span class="pl-s"><span class="pl-pds">{</span>Ashrya Agrawal and</span>
<span class="pl-s">                  Jiahao Chen and</span>
<span class="pl-s">                  Sebastian Vollmer and</span>
<span class="pl-s">                  Anthony Blaom<span class="pl-pds">}</span></span>,
  <span class="pl-s">title</span>        = <span class="pl-s"><span class="pl-pds">{</span>ashryaagr/Fairness.jl<span class="pl-pds">}</span></span>,
  <span class="pl-s">month</span>        = aug,
  <span class="pl-s">year</span>         = <span class="pl-c1">2020</span>,
  <span class="pl-s">publisher</span>    = <span class="pl-s"><span class="pl-pds">{</span>Zenodo<span class="pl-pds">}</span></span>,
  <span class="pl-s">version</span>      = <span class="pl-s"><span class="pl-pds">{</span>v0.1.2<span class="pl-pds">}</span></span>,
  <span class="pl-s">doi</span>          = <span class="pl-s"><span class="pl-pds">{</span>10.5281/zenodo.3977197<span class="pl-pds">}</span></span>,
  <span class="pl-s">url</span>          = <span class="pl-s"><span class="pl-pds">{</span>https://doi.org/10.5281/zenodo.3977197<span class="pl-pds">}</span></span>
}</pre></div>
</article></div>