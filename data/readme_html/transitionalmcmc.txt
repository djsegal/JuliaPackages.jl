<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-transitionalmcmcjl" class="anchor" aria-hidden="true" href="#transitionalmcmcjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>TransitionalMCMC.jl</h1>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/AnderGray/TransitionalMCMC.jl/workflows/CI/badge.svg"><img src="https://github.com/AnderGray/TransitionalMCMC.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/AnderGray/TransitionalMCMC.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/f599c1cf71dd2370109c65adb54315b7c90e83d26f62e5484552cc1ce17a0721/68747470733a2f2f636f6465636f762e696f2f67682f416e646572477261792f5472616e736974696f6e616c4d434d432e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d4c66736c4d416f577641" alt="Coverage Status" data-canonical-src="https://codecov.io/gh/AnderGray/TransitionalMCMC.jl/branch/main/graph/badge.svg?token=LfslMAoWvA" style="max-width:100%;"></a>
<a href="https://doi.org/10.5281/zenodo.4701274" rel="nofollow"><img src="https://camo.githubusercontent.com/ff93244f8b74cc0f4b2cdfdcac13159863f76c2d54adc6049b5ab01ccca09dfb/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e343730313237342e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.4701274.svg" style="max-width:100%;"></a></p>
<p>Implementation of Transitional Markov Chain Monte Carlo (TMCMC) in Julia. This implementation is heavily inspired by the implemntation of TMCMC in <a href="https://github.com/cossan-working-group/OpenCossan">OpenCOSSAN</a>.</p>
<p>The TMCMC algorithm can be used to sample from un-normalised probability density function (i.e. posterior distributions in Bayesian Updating). The TMCMC algorithm overcomes some of the issues with Metropolis Hastings:</p>
<ul>
<li>Can efficiently sample multimodal distributions</li>
<li>Works well in high dimensions (within reason)</li>
<li>Computes the evidence</li>
<li>Proposal distribution selected by algorithm</li>
<li>Easy to parallelise</li>
</ul>
<p>Instead of atempting to directly sample from the posterior, TMCMC samples from easy-to-sample "transitional" distributions. Defined by:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/dfd44356449b2be1e42ec7a95a5a9cc758ddbe594ded0a91e60943f7c8b1def7/68747470733a2f2f696d6775722e636f6d2f35703441504e442e706e67"><img src="https://camo.githubusercontent.com/dfd44356449b2be1e42ec7a95a5a9cc758ddbe594ded0a91e60943f7c8b1def7/68747470733a2f2f696d6775722e636f6d2f35703441504e442e706e67" width="300" data-canonical-src="https://imgur.com/5p4APND.png" style="max-width:100%;"></a></p>
<p>where 0 &lt;= B<sub>j</sub> &lt;= 1, is iterated in the algorithm starting from B<sub>j</sub> = 0 (prior) to B<sub>j</sub> = 1 (posterior).</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>This is a registered Julia package:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; ]
pkg&gt; add TransitionalMCMC
"><pre>julia<span class="pl-k">&gt;</span> ]
pkg<span class="pl-k">&gt;</span> add TransitionalMCMC</pre></div>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<p>Sampling <a href="https://en.wikipedia.org/wiki/Himmelblau%27s_function" rel="nofollow">Himmelblau's Function</a>:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using StatsBase, Distributions, PyPlot
using TransitionalMCMC

# Prior Bounds
lb  = -5        
ub  = 5

# Prior log Density and sampler
logprior(x) = logpdf(Uniform(lb,ub), x[1]) + logpdf(Uniform(lb,ub), x[2])
priorRnd(Nsamples) = rand(Uniform(lb,ub), Nsamples, 2)

# Log Likelihood
logLik(x) = -1 * ((x[1]^2 + x[2] - 11)^2 + (x[1] + x[2]^2 - 7)^2)

samps, Log_ev = tmcmc(logLik, logprior, priorRnd, 2000)

plt.scatter(samps[:,1], samps[:,2])
"><pre><span class="pl-k">using</span> StatsBase, Distributions, PyPlot
<span class="pl-k">using</span> TransitionalMCMC

<span class="pl-c"><span class="pl-c">#</span> Prior Bounds</span>
lb  <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">5</span>        
ub  <span class="pl-k">=</span> <span class="pl-c1">5</span>

<span class="pl-c"><span class="pl-c">#</span> Prior log Density and sampler</span>
<span class="pl-en">logprior</span>(x) <span class="pl-k">=</span> <span class="pl-c1">logpdf</span>(<span class="pl-c1">Uniform</span>(lb,ub), x[<span class="pl-c1">1</span>]) <span class="pl-k">+</span> <span class="pl-c1">logpdf</span>(<span class="pl-c1">Uniform</span>(lb,ub), x[<span class="pl-c1">2</span>])
<span class="pl-en">priorRnd</span>(Nsamples) <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">Uniform</span>(lb,ub), Nsamples, <span class="pl-c1">2</span>)

<span class="pl-c"><span class="pl-c">#</span> Log Likelihood</span>
<span class="pl-en">logLik</span>(x) <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1</span> <span class="pl-k">*</span> ((x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> x[<span class="pl-c1">2</span>] <span class="pl-k">-</span> <span class="pl-c1">11</span>)<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> (x[<span class="pl-c1">1</span>] <span class="pl-k">+</span> x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">-</span> <span class="pl-c1">7</span>)<span class="pl-k">^</span><span class="pl-c1">2</span>)

samps, Log_ev <span class="pl-k">=</span> <span class="pl-c1">tmcmc</span>(logLik, logprior, priorRnd, <span class="pl-c1">2000</span>)

plt<span class="pl-k">.</span><span class="pl-c1">scatter</span>(samps[:,<span class="pl-c1">1</span>], samps[:,<span class="pl-c1">2</span>])</pre></div>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/3a551a27733a7b3ba3c5d4c1cffa560d1ba01f408fbc66dfb6f2dd7d2bdd3bda/68747470733a2f2f696d6775722e636f6d2f79537634427a492e706e67"><img src="https://camo.githubusercontent.com/3a551a27733a7b3ba3c5d4c1cffa560d1ba01f408fbc66dfb6f2dd7d2bdd3bda/68747470733a2f2f696d6775722e636f6d2f79537634427a492e706e67" width="1500" data-canonical-src="https://imgur.com/ySv4BzI.png" style="max-width:100%;"></a></p>
<h3><a id="user-content-for-parallel-excution" class="anchor" aria-hidden="true" href="#for-parallel-excution"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>For parallel excution</h3>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using Distributed, StatsBase, Distributions, PyPlot

addprocs(4; exeflags=&quot;--project&quot;)
@everywhere begin
    using TransitionalMCMC

    # Prior Bounds
    lb, ub  = -5, 5

    # Prior log Density and sampler
    logprior(x) = logpdf(Uniform(lb, ub), x[1]) + logpdf(Uniform(lb, ub), x[2])
    priorRnd(Nsamples) = rand(Uniform(lb, ub), Nsamples, 2)

    # Log Likelihood
    function logLik(x)
        return -1 * ((x[1]^2 + x[2] - 11)^2 + (x[1] + x[2]^2 - 7)^2)
    end

end

Nsamples = 2000

samps, Log_ev = tmcmc(logLik, logprior, priorRnd, Nsamples, 5, 2)
"><pre><span class="pl-k">using</span> Distributed, StatsBase, Distributions, PyPlot

<span class="pl-c1">addprocs</span>(<span class="pl-c1">4</span>; exeflags<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>--project<span class="pl-pds">"</span></span>)
<span class="pl-c1">@everywhere</span> <span class="pl-k">begin</span>
    <span class="pl-k">using</span> TransitionalMCMC

    <span class="pl-c"><span class="pl-c">#</span> Prior Bounds</span>
    lb, ub  <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">5</span>, <span class="pl-c1">5</span>

    <span class="pl-c"><span class="pl-c">#</span> Prior log Density and sampler</span>
    <span class="pl-en">logprior</span>(x) <span class="pl-k">=</span> <span class="pl-c1">logpdf</span>(<span class="pl-c1">Uniform</span>(lb, ub), x[<span class="pl-c1">1</span>]) <span class="pl-k">+</span> <span class="pl-c1">logpdf</span>(<span class="pl-c1">Uniform</span>(lb, ub), x[<span class="pl-c1">2</span>])
    <span class="pl-en">priorRnd</span>(Nsamples) <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">Uniform</span>(lb, ub), Nsamples, <span class="pl-c1">2</span>)

    <span class="pl-c"><span class="pl-c">#</span> Log Likelihood</span>
    <span class="pl-k">function</span> <span class="pl-en">logLik</span>(x)
        <span class="pl-k">return</span> <span class="pl-k">-</span><span class="pl-c1">1</span> <span class="pl-k">*</span> ((x[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> x[<span class="pl-c1">2</span>] <span class="pl-k">-</span> <span class="pl-c1">11</span>)<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> (x[<span class="pl-c1">1</span>] <span class="pl-k">+</span> x[<span class="pl-c1">2</span>]<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">-</span> <span class="pl-c1">7</span>)<span class="pl-k">^</span><span class="pl-c1">2</span>)
    <span class="pl-k">end</span>

<span class="pl-k">end</span>

Nsamples <span class="pl-k">=</span> <span class="pl-c1">2000</span>

samps, Log_ev <span class="pl-k">=</span> <span class="pl-c1">tmcmc</span>(logLik, logprior, priorRnd, Nsamples, <span class="pl-c1">5</span>, <span class="pl-c1">2</span>)</pre></div>
<h3><a id="user-content-benchmarks" class="anchor" aria-hidden="true" href="#benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Benchmarks</h3>
<p>Found in <a href="https://github.com/AnderGray/TransitionalMCMC.jl/tree/main/slurm_benchmarks">/slurm_benchmarks</a></p>
<p>Testing scalability of <code>tmcmcHimmelblau.jl</code> with different model evaluations times</p>
<p>
  <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/bc9a2fd957f9f0f894805e61553dbd6dde37934436168162c0192ee02460b048/68747470733a2f2f696d6775722e636f6d2f51386d5a574d312e706e67"><img src="https://camo.githubusercontent.com/bc9a2fd957f9f0f894805e61553dbd6dde37934436168162c0192ee02460b048/68747470733a2f2f696d6775722e636f6d2f51386d5a574d312e706e67" width="400" data-canonical-src="https://imgur.com/Q8mZWM1.png" style="max-width:100%;"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0f092b52c31131203132124af7d73a903da968f13f178040fd6a196c6681d3fd/68747470733a2f2f696d6775722e636f6d2f50414c4b666f722e706e67"><img src="https://camo.githubusercontent.com/0f092b52c31131203132124af7d73a903da968f13f178040fd6a196c6681d3fd/68747470733a2f2f696d6775722e636f6d2f50414c4b666f722e706e67" width="400" data-canonical-src="https://imgur.com/PALKfor.png" style="max-width:100%;"></a>
</p>
<p>Testing slowdown and iteration number for various dimensions. Target is a mixture of 2 Gaussians in N dimensions, with means located at [-5, -5 , ...] and [5, 5, ...]</p>
<p>
  <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/84ad030e1f09d03e285a621fd6eadb833ab450e105f7e2be904b6e686838d63d/68747470733a2f2f696d6775722e636f6d2f4f356e775353522e706e67"><img src="https://camo.githubusercontent.com/84ad030e1f09d03e285a621fd6eadb833ab450e105f7e2be904b6e686838d63d/68747470733a2f2f696d6775722e636f6d2f4f356e775353522e706e67" width="400" data-canonical-src="https://imgur.com/O5nwSSR.png" style="max-width:100%;"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0c4fde5ebfd98defac8fa939197948ffc00307bb8c2d9968c5bae3557b0b24e9/68747470733a2f2f696d6775722e636f6d2f66634f786b6c4a2e706e67"><img src="https://camo.githubusercontent.com/0c4fde5ebfd98defac8fa939197948ffc00307bb8c2d9968c5bae3557b0b24e9/68747470733a2f2f696d6775722e636f6d2f66634f786b6c4a2e706e67" width="400" data-canonical-src="https://imgur.com/fcOxklJ.png" style="max-width:100%;"></a>
</p>
<h2><a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Todo</h2>
<ul>
<li>Plotting functions</li>
<li>Storing samples across iterations</li>
<li>Testing</li>
<li>FE example</li>
</ul>
<h2><a id="user-content-bibiography" class="anchor" aria-hidden="true" href="#bibiography"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Bibiography</h2>
<ul>
<li>J. Ching, and Y. Chen (2007). <a href="https://ascelibrary.org/doi/pdf/10.1061/(ASCE)0733-9399(2007)133%3A7(816)?casa_token=mGf_dvFGtYcAAAAA%3AvPklSPi0HXqUX9VabgqN5xILx6e8cH973IUbkgCKkRjooKku7__DhKk3yuYqzyTSIXBluhaEes2MXg&amp;" rel="nofollow">Transitional Markov Chain Monte Carlo method for Bayesian model updating, Model class selection, and Model averaging.</a> Journal of Engineering Mechanics, 133(7), 816-832. doi:10.1061/(asce)0733-9399(2007)133:7(816)</li>
<li>A. Lye, A. Cicirello, and E. Patelli (2021). <a href="https://livrepository.liverpool.ac.uk/3115734/" rel="nofollow">Sampling methods for solving Bayesian model Updating problems: A tutorial.</a> Mechanical Systems and Signal Processing, 159, 107760. doi:10.1016/j.ymssp.2021.107760</li>
<li>E. Patelli, M. Broggi, M. D. Angelis, and M. Beer (2014). <a href="https://www.researchgate.net/publication/263732354_OpenCossan_An_Efficient_Open_Tool_for_Dealing_with_Epistemic_and_Aleatory_Uncertainties" rel="nofollow">OpenCossan: An efficient open tool for dealing with epistemic AND Aleatory Uncertainties. Vulnerability, Uncertainty, and Risk.</a> doi:10.1061/9780784413609.258</li>
</ul>
</article></div>