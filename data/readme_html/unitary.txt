<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-unitaryjl" class="anchor" aria-hidden="true" href="#unitaryjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Unitary.jl</h1>
<p dir="auto">This package implements a differentiable parametrization of a group of unitary matrices as described in paper <em>Sum-Product-Transform Networks: Exploiting Symmetries using Invertible Transformations, Tomas Pevny, Vasek Smidl, Martin Trapp, Ondrej Polacek, Tomas Oberhuber, 2020</em> <a href="https://arxiv.org/abs/2005.01297" rel="nofollow">https://arxiv.org/abs/2005.01297</a></p>
<p dir="auto">The actual "Dense" node implementing <code>f(x) = σ.(W * x .+ b)</code>, where <code>W</code> is in svd form has moved to <a href="https://github.com/pevnak/SumProductTransform.jl">https://github.com/pevnak/SumProductTransform.jl</a> to keep this simple. Since in the paper, we have experimented with different ways, how to efficiently implement Dense matrices featuring efficient inversion and calculation of determinant, the repository contains a little bit more.</p>
<ul dir="auto">
<li><code>Givens</code> - representation of a unitary matrix using Givens rotations</li>
<li><code>UnitaryHouseholder</code> - representation of a unitary matrix using Householder reflections, an approach common in Machine Learning</li>
<li>LU - representation of a matrix using LU decomposition</li>
<li>LDU  - representation of a matrix using LDU decomposition</li>
</ul>
<p dir="auto">The usage is simple:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using Unitary, Flux, BenchmarkTools
using Unitary: Givens, lowup

x = randn(Float32, 50, 100)
xx = randn(Float32, 100, 50)

a = Givens(50)
@btime a * x;		
#  224.097 μs (4 allocations: 20.00 KiB)
@btime xx * a;	
#  79.517 μs (4 allocations: 20.00 KiB)

ps = Flux.params(a)
@btime gradient(() -&gt; sum(a * x), ps);	# 890.323 μs (58 allocations: 71.52 KiB)
# 891.481 μs (60 allocations: 72.42 KiB)
@btime gradient(() -&gt; sum(xx * a), ps);	# 473.158 μs (58 allocations: 71.52 KiB)
@ 468.794 μs (60 allocations: 72.42 KiB)

a = Givens(50)
@btime a * x;
# 646.874 μs (10154 allocations: 2.37 MiB)

@btime xx * a;
#  726.198 μs (10204 allocations: 2.39 MiB)

@btime gradient(() -&gt; sum(a * x), ps);  
#  103.869 ms (44538 allocations: 179.60 MiB)

@btime gradient(() -&gt; sum(xx * a), ps);
#  105.061 ms (44688 allocations: 179.67 MiB)"><pre class="notranslate"><code>using Unitary, Flux, BenchmarkTools
using Unitary: Givens, lowup

x = randn(Float32, 50, 100)
xx = randn(Float32, 100, 50)

a = Givens(50)
@btime a * x;		
#  224.097 μs (4 allocations: 20.00 KiB)
@btime xx * a;	
#  79.517 μs (4 allocations: 20.00 KiB)

ps = Flux.params(a)
@btime gradient(() -&gt; sum(a * x), ps);	# 890.323 μs (58 allocations: 71.52 KiB)
# 891.481 μs (60 allocations: 72.42 KiB)
@btime gradient(() -&gt; sum(xx * a), ps);	# 473.158 μs (58 allocations: 71.52 KiB)
@ 468.794 μs (60 allocations: 72.42 KiB)

a = Givens(50)
@btime a * x;
# 646.874 μs (10154 allocations: 2.37 MiB)

@btime xx * a;
#  726.198 μs (10204 allocations: 2.39 MiB)

@btime gradient(() -&gt; sum(a * x), ps);  
#  103.869 ms (44538 allocations: 179.60 MiB)

@btime gradient(() -&gt; sum(xx * a), ps);
#  105.061 ms (44688 allocations: 179.67 MiB)
</code></pre></div>
<p dir="auto">Matrices support only multiplication, because that is what they have been designed for, but you can always convert them to normal matrices using <code>Matrix</code> (but this is not at the moment differentiable).</p>
</article></div>