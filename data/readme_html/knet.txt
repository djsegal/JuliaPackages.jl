<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-knet" class="anchor" aria-hidden="true" href="#knet"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Knet</h1>
<p><a href="https://denizyuret.github.io/Knet.jl/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/57bae07ecd50a99519ad0516d91f4ec8f0f48e12/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg" style="max-width:100%;"></a>
<a href="https://travis-ci.org/denizyuret/Knet.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/3de116a9f18eef5255e7e5863222546d6d706d84/68747470733a2f2f7472617669732d63692e6f72672f64656e697a79757265742f4b6e65742e6a6c2e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://travis-ci.org/denizyuret/Knet.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://gitlab.com/JuliaGPU/Knet.jl/pipelines" rel="nofollow"><img src="https://camo.githubusercontent.com/ac54a589d3ae186dc08a94303e4d69659c8ee731/68747470733a2f2f6769746c61622e636f6d2f4a756c69614750552f4b6e65742e6a6c2f6261646765732f6d61737465722f706970656c696e652e737667" alt="" data-canonical-src="https://gitlab.com/JuliaGPU/Knet.jl/badges/master/pipeline.svg" style="max-width:100%;"></a>
<a href="https://ci.appveyor.com/project/denizyuret/knet-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/34dc8df5095408734faf9cf7c5bdfefaaa03f701/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6d716e303765356134786f6f367561353f7376673d74727565" alt="" data-canonical-src="https://ci.appveyor.com/api/projects/status/mqn07e5a4xoo6ua5?svg=true" style="max-width:100%;"></a>
<a href="https://cloud.drone.io/denizyuret/Knet.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/5085039274a2556527cacd9a80788c1108cc8d25/68747470733a2f2f636c6f75642e64726f6e652e696f2f6170692f6261646765732f64656e697a79757265742f4b6e65742e6a6c2f7374617475732e737667" alt="" data-canonical-src="https://cloud.drone.io/api/badges/denizyuret/Knet.jl/status.svg" style="max-width:100%;"></a>
<a href="https://cirrus-ci.com/github/denizyuret/Knet.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/1ef8da97f49d498a0454e47eab1e42cbda41241f/68747470733a2f2f6170692e6369727275732d63692e636f6d2f6769746875622f64656e697a79757265742f4b6e65742e6a6c2e737667" alt="" data-canonical-src="https://api.cirrus-ci.com/github/denizyuret/Knet.jl.svg" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/denizyuret/Knet.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/cd23c0266a5dd7a57971762bacfb1ceb69710641/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f64656e697a79757265742f4b6e65742e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://coveralls.io/repos/github/denizyuret/Knet.jl/badge.svg?branch=master" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/denizyuret/Knet.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/29ba0854e30ae288c2315fa3175790b990df2473/68747470733a2f2f636f6465636f762e696f2f67682f64656e697a79757265742f4b6e65742e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="" data-canonical-src="https://codecov.io/gh/denizyuret/Knet.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p><a href="https://denizyuret.github.io/Knet.jl/latest" rel="nofollow">Knet</a> (pronounced "kay-net") is the <a href="http://www.ku.edu.tr/en" rel="nofollow">Ko√ß
University</a> deep learning framework implemented in
<a href="http://docs.julialang.org" rel="nofollow">Julia</a> by <a href="http://www.denizyuret.com" rel="nofollow">Deniz Yuret</a> and
collaborators.  It supports GPU operation and automatic differentiation using dynamic
computational graphs for models defined in plain Julia. You can install Knet with the
following at the julia prompt: <code>using Pkg; Pkg.add("Knet")</code>. Some starting points:</p>
<ul>
<li><a href="tutorial">Tutorial:</a>
introduces Julia and Knet via examples.</li>
<li><a href="https://denizyuret.github.io/Knet.jl/latest" rel="nofollow">Documentation:</a>
installation, introduction, design, implementation, full reference and deep learning chapters.</li>
<li><a href="examples">Examples:</a>
more tutorials and example models.</li>
<li><a href="http://denizyuret.github.io/Knet.jl/latest/tutorial/#Benchmarks-1" rel="nofollow">Benchmarks:</a>
comparison of Knet's speed with TensorFlow, PyTorch, DyNet etc.</li>
<li><a href="https://goo.gl/zeUBFr" rel="nofollow">Paper:</a>
Yuret, D. "Knet: beginning deep learning with 100 lines of julia." In <em>Machine Learning Systems Workshop</em> at NIPS 2016.</li>
<li><a href="https://github.com/KnetML">KnetML:</a>
github organization with Knet repos of models, tutorials, layer collections and other resources.</li>
<li><a href="http://denizyuret.github.io/Knet.jl/latest/install.html#Using-Amazon-AWS-1" rel="nofollow">Images:</a>
Knet machine images are available for <a href="http://denizyuret.github.io/Knet.jl/latest/install.html#Using-Amazon-AWS-1" rel="nofollow">AWS</a>, <a href="https://github.com/KnetML/singularity-images">Singularity</a> and <a href="https://github.com/JuliaGPU/docker">Docker</a>.</li>
<li><a href="https://github.com/denizyuret/Knet.jl/issues">Issues:</a>
if you find a bug, please open a github issue.</li>
<li><a href="https://groups.google.com/forum/#!forum/knet-users" rel="nofollow">knet-users:</a>
if you need help or would like to request a feature, please join this mailing list.</li>
<li><a href="https://groups.google.com/forum/#!forum/knet-dev" rel="nofollow">knet-dev:</a>
if you would like to contribute to Knet development, please join this mailing list and check out these <a href="http://denizyuret.github.io/Knet.jl/latest/install.html#Tips-for-developers-1" rel="nofollow">tips</a>.</li>
<li><a href="https://julialang.slack.com/messages/CDLKQ92P3/details" rel="nofollow">knet-slack:</a> Slack channel for Knet.</li>
<li>Related work: Please check out <a href="https://github.com/FLuxML">Flux</a>, <a href="https://github.com/pluskid/Mocha.jl">Mocha</a>, <a href="https://github.com/JuliaML">JuliaML</a>, <a href="https://github.com/JuliaDiff">JuliaDiff</a>, <a href="https://github.com/JuliaGPU">JuliaGPU</a>, <a href="https://github.com/JuliaOpt">JuliaOpt</a> for related packages.</li>
</ul>
<h2><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Example</h2>
<p>Here is a simple example where we define, train and test the
<a href="http://yann.lecun.com/exdb/lenet" rel="nofollow">LeNet</a> model for the
<a href="http://yann.lecun.com/exdb/mnist" rel="nofollow">MNIST</a> handwritten digit recognition dataset from scratch
using 13 lines of code and 30 seconds of GPU computation.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Knet

<span class="pl-c"><span class="pl-c">#</span> Define convolutional layer:</span>
<span class="pl-k">struct</span> Conv; w; b; f; <span class="pl-k">end</span>
(c<span class="pl-k">::</span><span class="pl-c1">Conv</span>)(x) <span class="pl-k">=</span> c<span class="pl-k">.</span><span class="pl-c1">f</span>.(<span class="pl-c1">pool</span>(<span class="pl-c1">conv4</span>(c<span class="pl-k">.</span>w, x) <span class="pl-k">.+</span> c<span class="pl-k">.</span>b))
<span class="pl-en">Conv</span>(w1,w2,cx,cy,f<span class="pl-k">=</span>relu) <span class="pl-k">=</span> <span class="pl-c1">Conv</span>(<span class="pl-c1">param</span>(w1,w2,cx,cy), <span class="pl-c1">param0</span>(<span class="pl-c1">1</span>,<span class="pl-c1">1</span>,cy,<span class="pl-c1">1</span>), f)

<span class="pl-c"><span class="pl-c">#</span> Define dense layer:</span>
<span class="pl-k">struct</span> Dense; w; b; f; <span class="pl-k">end</span>
(d<span class="pl-k">::</span><span class="pl-c1">Dense</span>)(x) <span class="pl-k">=</span> d<span class="pl-k">.</span><span class="pl-c1">f</span>.(d<span class="pl-k">.</span>w <span class="pl-k">*</span> <span class="pl-c1">mat</span>(x) <span class="pl-k">.+</span> d<span class="pl-k">.</span>b)
<span class="pl-en">Dense</span>(i<span class="pl-k">::</span><span class="pl-c1">Int</span>,o<span class="pl-k">::</span><span class="pl-c1">Int</span>,f<span class="pl-k">=</span>relu) <span class="pl-k">=</span> <span class="pl-c1">Dense</span>(<span class="pl-c1">param</span>(o,i), <span class="pl-c1">param0</span>(o), f)

<span class="pl-c"><span class="pl-c">#</span> Define a chain of layers and a loss function:</span>
<span class="pl-k">struct</span> Chain; layers; <span class="pl-k">end</span>
(c<span class="pl-k">::</span><span class="pl-c1">Chain</span>)(x) <span class="pl-k">=</span> (<span class="pl-k">for</span> l <span class="pl-k">in</span> c<span class="pl-k">.</span>layers; x <span class="pl-k">=</span> <span class="pl-c1">l</span>(x); <span class="pl-k">end</span>; x)
(c<span class="pl-k">::</span><span class="pl-c1">Chain</span>)(x,y) <span class="pl-k">=</span> <span class="pl-c1">nll</span>(<span class="pl-c1">c</span>(x),y)

<span class="pl-c"><span class="pl-c">#</span> Load MNIST data:</span>
<span class="pl-c1">include</span>(Knet<span class="pl-k">.</span><span class="pl-c1">dir</span>(<span class="pl-s"><span class="pl-pds">"</span>data<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>mnist.jl<span class="pl-pds">"</span></span>))
dtrn, dtst <span class="pl-k">=</span> <span class="pl-c1">mnistdata</span>()

<span class="pl-c"><span class="pl-c">#</span> Define, train and test LeNet (about 30 secs on a gpu to reach 99% accuracy)</span>
LeNet <span class="pl-k">=</span> <span class="pl-c1">Chain</span>((<span class="pl-c1">Conv</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">1</span>,<span class="pl-c1">20</span>), <span class="pl-c1">Conv</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">20</span>,<span class="pl-c1">50</span>), <span class="pl-c1">Dense</span>(<span class="pl-c1">800</span>,<span class="pl-c1">500</span>), <span class="pl-c1">Dense</span>(<span class="pl-c1">500</span>,<span class="pl-c1">10</span>,identity)))
<span class="pl-c1">adam!</span>(LeNet, <span class="pl-c1">repeat</span>(dtrn,<span class="pl-c1">10</span>))
<span class="pl-c1">accuracy</span>(LeNet, dtst)</pre></div>
<h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Contributing</h2>
<p>Knet is an open-source project and we are always open to new contributions: bug reports and
fixes, feature requests and contributions, new machine learning models and operators,
inspiring examples, benchmarking results are all welcome.</p>
<p>Current contributors:</p>
<ul>
<li>Can G√ºmeli</li>
<li>Carlo Lucibello</li>
<li>Ekin Aky√ºrek</li>
<li>Ekrem Emre Yurdakul</li>
<li>Emre √únal</li>
<li>Emre Yolcu</li>
<li>Enis Berk</li>
<li>Erenay Dayanƒ±k</li>
<li>ƒ∞lker Kesen</li>
<li>Kai Xu</li>
<li>Meri√ß Melike Softa</li>
<li>Mike Innes</li>
<li>Onur Kuru</li>
<li>Ozan Arkan Can</li>
<li>√ñmer Kƒ±rnap</li>
<li>Phuoc Nguyen</li>
<li>Rene Donner</li>
<li>Tim Besard</li>
<li>Zhang Shiwei</li>
</ul>
</article></div>