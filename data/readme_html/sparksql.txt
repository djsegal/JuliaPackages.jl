<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-sparksqljl" class="anchor" aria-hidden="true" href="#sparksqljl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>SparkSQL.jl</h1>
<h1><a id="user-content-purpose" class="anchor" aria-hidden="true" href="#purpose"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Purpose</h1>
<p>Submits <em>Structured Query Language</em> (SQL), <em>Data Manipulation Language</em> (DML) and <em>Data Definition Language</em> (DDL) statements to Apache Spark.
Has functions to move data from Spark into Julia DataFrames and Julia DataFrame data into Spark.</p>
<h3><a id="user-content-use-case" class="anchor" aria-hidden="true" href="#use-case"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Use Case</h3>
<p>Apache Spark is one of the world's most popular open source big data processing engines. Spark supports programming in Java, Scala, Python, SQL, and R.
This package enables Julia programs to utilize Apache Spark for structured data processing using SQL.</p>
<p>The design goal of this package is to enable Julia centric programming using Apache Spark with just SQL.  There are only 8 functions. No need to use Java, Scala, Python or R.  Work with Spark data all from within Julia.
The SparkSQL.jl package uses the Dataset APIs internally giving Julia users the performance benefit of Spark's catalyst optimizer and tungsten engine. The earlier Spark RDD API is not supported.</p>
<p>This package is for structured and semi-structured data in Data Lakes, Lakehouses (Delta Lake) on premise and in the cloud.</p>
<h1><a id="user-content-available-functions" class="anchor" aria-hidden="true" href="#available-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Available Functions</h1>
<p>Use ? in the Julia REPL to see help for each function.</p>
<ul>
<li><code>initJVM</code>: initializes the Java Virtual Machine (JVM) in Julia.</li>
<li><code>SparkSession</code>: submits application to Apache Spark cluster with config options.</li>
<li><code>sql</code>: function to submit SQL, DDL, and DML statements to Spark.</li>
<li><code>cache</code>: function to cache Spark Dataset into memory.</li>
<li><code>createOrReplaceTempView</code>: creates temporary view that lasts the duration of the session.</li>
<li><code>createGlobalTempView</code>: creates temporary view that lasts the duration of the application.</li>
<li><code>toJuliaDF</code>: move Spark data into a Julia DataFrame.</li>
<li><code>toSparkDS</code>: move Julia DataFrame data to a Spark Dataset.</li>
</ul>
<h1><a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Quick Start</h1>
<h3><a id="user-content-install-and-setup" class="anchor" aria-hidden="true" href="#install-and-setup"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Install and Setup</h3>
<p>Download Apache Spark 3.1.1 or later and set the environmental variables for Spark and Java home:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="export SPARK_HOME=/path/to/apache/spark
export JAVA_HOME=/path/to/java
"><pre><code>export SPARK_HOME=/path/to/apache/spark
export JAVA_HOME=/path/to/java
</code></pre></div>
<h3><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h3>
<p>Start Julia with <code>"JULIA_COPY_STACKS=yes"</code> required for JVM interop:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="JULIA_COPY_STACKS=yes julia
"><pre><code>JULIA_COPY_STACKS=yes julia
</code></pre></div>
<p>In Julia include the DataFrames package.  Also include the Dates and Decimals packages if your Spark data contains dates or decimal numbers.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="using SparkSQL, DataFrames, Dates, Decimals
"><pre><code>using SparkSQL, DataFrames, Dates, Decimals
</code></pre></div>
<p>Initialize the JVM and start the Spark Session:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="initJVM()
sparkSession = SparkSession(&quot;spark://example.com:7077&quot;, &quot;Julia SparkSQL Example App&quot;)
"><pre><code>initJVM()
sparkSession = SparkSession("spark://example.com:7077", "Julia SparkSQL Example App")
</code></pre></div>
<p>Query data from Spark and load it into a Julia Dataset.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="stmt = sql(sparkSession, &quot;SELECT _c0 AS columnName1, _c1 AS columnName2 FROM CSV.`/pathToFile/fileName.csv`&quot;)
createOrReplaceTempView(stmt, &quot;TempViewName&quot;)
sqlQuery = sql(sparkSession, &quot;SELECT columnName1, columnName2 FROM TempViewName;&quot;)
juliaDataFrame = toJuliaDF(sqlQuery)
describe(juliaDataFrame)
"><pre><code>stmt = sql(sparkSession, "SELECT _c0 AS columnName1, _c1 AS columnName2 FROM CSV.`/pathToFile/fileName.csv`")
createOrReplaceTempView(stmt, "TempViewName")
sqlQuery = sql(sparkSession, "SELECT columnName1, columnName2 FROM TempViewName;")
juliaDataFrame = toJuliaDF(sqlQuery)
describe(juliaDataFrame)
</code></pre></div>
<p>Move Julia DataFrame data into an Apache Spark Dataset.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="sparkDataset = toSparkDS(sparkSession, juliaDataFrame,&quot;,&quot;)
createOrReplaceTempView(sparkDataset, &quot;tempTable&quot;)
"><pre><code>sparkDataset = toSparkDS(sparkSession, juliaDataFrame,",")
createOrReplaceTempView(sparkDataset, "tempTable")
</code></pre></div>
<p>The Dataset is a delimited string. To generate columns use the SparkSQL "split" function.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="sqlQuery = sql(sparkSession, &quot;Select split(value, ',' )[0] AS columnName1, split(value, ',' )[1] AS columnName2 from tempTable&quot;)
"><pre><code>sqlQuery = sql(sparkSession, "Select split(value, ',' )[0] AS columnName1, split(value, ',' )[1] AS columnName2 from tempTable")
</code></pre></div>
<h1><a id="user-content-spark-data-sources" class="anchor" aria-hidden="true" href="#spark-data-sources"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Spark Data Sources</h1>
<p>Supported data-sources include:</p>
<ul>
<li>File formats including: CSV, JSON, arrow, parquet</li>
<li>Data Lakes including: Hive, ORC, Avro</li>
<li>Data Lake Houses: Delta Lake, Apache Iceberg.</li>
<li>Cloud Object Stores: S3, Azure Blob Storage, Swift Object.</li>
</ul>
<h2><a id="user-content-data-source-examples" class="anchor" aria-hidden="true" href="#data-source-examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Data Source Examples</h2>
<h3><a id="user-content-csv-file-example" class="anchor" aria-hidden="true" href="#csv-file-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>CSV file example:</h3>
<p>Comma Separated Value (CSV) format.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="stmt = sql(session, &quot;SELECT * FROM CSV.`/pathToFile/fileName.csv`;&quot;)
"><pre><code>stmt = sql(session, "SELECT * FROM CSV.`/pathToFile/fileName.csv`;")
</code></pre></div>
<h3><a id="user-content-parquet-file-example" class="anchor" aria-hidden="true" href="#parquet-file-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Parquet file example:</h3>
<p>Apache Parquet format.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="stmt = sql(session, &quot;SELECT * FROM PARQUET.`/pathToFile/fileName.parquet`;&quot;)
"><pre><code>stmt = sql(session, "SELECT * FROM PARQUET.`/pathToFile/fileName.parquet`;")
</code></pre></div>
<h3><a id="user-content-delta-lake-example" class="anchor" aria-hidden="true" href="#delta-lake-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Delta Lake Example:</h3>
<p>Delta Lake is an open-source storage layer for Spark. Delta Lake offers:</p>
<ul>
<li>ACID transactions on Spark: Serializable isolation levels ensure that readers never see inconsistent data.</li>
<li>Scalable metadata handling: Leverages Sparkâ€™s distributed processing power to handle all the metadata for petabyte-scale tables with billions of files.</li>
</ul>
<p>Example shows create table (DDL) statements using Delta Lake and SparkSQL:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="sql(session, &quot;CREATE DATABASE demo;&quot;)
sql(session, &quot;USE demo;&quot;)
sql(session, &quot;CREATE TABLE tb(col STRING) USING DELTA;&quot; )
"><pre><code>sql(session, "CREATE DATABASE demo;")
sql(session, "USE demo;")
sql(session, "CREATE TABLE tb(col STRING) USING DELTA;" )
</code></pre></div>
<p>The Delta Lake feature requires adding the Delta Lake jar to the Spark jars folder.</p>
</article></div>