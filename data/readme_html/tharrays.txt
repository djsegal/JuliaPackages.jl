<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text">
<h1 dir="auto"><a id="user-content-tharrays" class="anchor" aria-hidden="true" href="#tharrays"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ThArrays</h1>
<p dir="auto">A Julia interface for PyTorch's C++ backend.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/data-efficient-ml/ThArrays.jl/workflows/Unit%20Testing/badge.svg?branch=master"><img src="https://github.com/data-efficient-ml/ThArrays.jl/workflows/Unit%20Testing/badge.svg?branch=master" alt="Unit Testing" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-features" class="anchor" aria-hidden="true" href="#features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Features</h2>
<ul dir="auto">
<li><code>ThArrays.Tensor</code>: PyTorch Tensor as an Array-like data type in
Julia</li>
<li><code>ThArrays.ThAD</code>: AD using PyTorch C++ backend</li>
<li><code>ThArrays.TrackerAD</code>: AD using Tracker.jl and PyTorch C++
backend mixed, on your choice</li>
<li><code>ThArrays.ThJIT</code>: using TorchScript in Julia</li>
</ul>
<h2 dir="auto"><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Getting Started</h2>
<ol dir="auto">
<li>
<p dir="auto">Install the package: <code>] add ThArrays</code></p>
</li>
<li>
<p dir="auto">Read the docs <a href="https://data-efficient-ml.github.io/ThArrays.jl" rel="nofollow">here</a>, or</p>
</li>
<li>
<p dir="auto">Experiment in the Julia REPL directly:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content=" julia&gt; using ThArrays

 julia&gt; t = Tensor( -rand(3, 3) )
 PyTorch.Tensor{Float64, 2}:
 -0.1428 -0.7099 -0.1446
 -0.3447 -0.0686 -0.8287
 -0.2692 -0.0501 -0.2092
 [ CPUDoubleType{3,3} ]

 julia&gt; sin(t)^2 + cos(t)^2
 PyTorch.Tensor{Float64, 2}:
  1.0000  1.0000  1.0000
  1.0000  1.0000  1.0000
  1.0000  1.0000  1.0000
 [ CPUDoubleType{3,3} ]

 julia&gt; ThAD.gradient(x-&gt;sum(sin(x)+x^2), rand(3,3))
 (PyTorch.Tensor{Float64, 2}:
  2.3776  1.5465  2.0206
  1.2542  1.2081  2.1156
  2.1034  1.1568  2.2599
 [ CPUDoubleType{3,3} ]
 ,)

 julia&gt;
"><pre> julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> ThArrays

 julia<span class="pl-k">&gt;</span> t <span class="pl-k">=</span> <span class="pl-c1">Tensor</span>( <span class="pl-k">-</span><span class="pl-c1">rand</span>(<span class="pl-c1">3</span>, <span class="pl-c1">3</span>) )
 PyTorch<span class="pl-k">.</span>Tensor{Float64, <span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-k">-</span><span class="pl-c1">0.1428</span> <span class="pl-k">-</span><span class="pl-c1">0.7099</span> <span class="pl-k">-</span><span class="pl-c1">0.1446</span>
 <span class="pl-k">-</span><span class="pl-c1">0.3447</span> <span class="pl-k">-</span><span class="pl-c1">0.0686</span> <span class="pl-k">-</span><span class="pl-c1">0.8287</span>
 <span class="pl-k">-</span><span class="pl-c1">0.2692</span> <span class="pl-k">-</span><span class="pl-c1">0.0501</span> <span class="pl-k">-</span><span class="pl-c1">0.2092</span>
 [ CPUDoubleType{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>} ]

 julia<span class="pl-k">&gt;</span> <span class="pl-c1">sin</span>(t)<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> <span class="pl-c1">cos</span>(t)<span class="pl-k">^</span><span class="pl-c1">2</span>
 PyTorch<span class="pl-k">.</span>Tensor{Float64, <span class="pl-c1">2</span>}<span class="pl-k">:</span>
  <span class="pl-c1">1.0000</span>  <span class="pl-c1">1.0000</span>  <span class="pl-c1">1.0000</span>
  <span class="pl-c1">1.0000</span>  <span class="pl-c1">1.0000</span>  <span class="pl-c1">1.0000</span>
  <span class="pl-c1">1.0000</span>  <span class="pl-c1">1.0000</span>  <span class="pl-c1">1.0000</span>
 [ CPUDoubleType{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>} ]

 julia<span class="pl-k">&gt;</span> ThAD<span class="pl-k">.</span><span class="pl-c1">gradient</span>(x<span class="pl-k">-&gt;</span><span class="pl-c1">sum</span>(<span class="pl-c1">sin</span>(x)<span class="pl-k">+</span>x<span class="pl-k">^</span><span class="pl-c1">2</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">3</span>,<span class="pl-c1">3</span>))
 (PyTorch<span class="pl-k">.</span>Tensor{Float64, <span class="pl-c1">2</span>}<span class="pl-k">:</span>
  <span class="pl-c1">2.3776</span>  <span class="pl-c1">1.5465</span>  <span class="pl-c1">2.0206</span>
  <span class="pl-c1">1.2542</span>  <span class="pl-c1">1.2081</span>  <span class="pl-c1">2.1156</span>
  <span class="pl-c1">2.1034</span>  <span class="pl-c1">1.1568</span>  <span class="pl-c1">2.2599</span>
 [ CPUDoubleType{<span class="pl-c1">3</span>,<span class="pl-c1">3</span>} ]
 ,)

 julia<span class="pl-k">&gt;</span>
</pre></div>
<p dir="auto">You can find more examples under the <code>test</code> directory.</p>
</li>
</ol>
</article></div>