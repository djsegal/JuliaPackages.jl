<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-bayesianquadrature" class="anchor" aria-hidden="true" href="#bayesianquadrature"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>BayesianQuadrature</h1>
<p><a href="https://theogf.github.io/BayesianQuadrature.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a>
<a href="https://theogf.github.io/BayesianQuadrature.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a>
<a href="https://github.com/theogf/BayesianQuadrature.jl/actions"><img src="https://github.com/theogf/BayesianQuadrature.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/theogf/BayesianQuadrature.jl?branch=main" rel="nofollow"><img src="https://camo.githubusercontent.com/87916ad3a078d1d7630a46bf85ae33a3503e6af0fb730205ef7ecfb1ebd61735/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7468656f67662f426179657369616e517561647261747572652e6a6c2f62616467652e7376673f6272616e63683d6d61696e" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/theogf/BayesianQuadrature.jl/badge.svg?branch=main" style="max-width:100%;"></a>
<a href="https://github.com/invenia/BlueStyle"><img src="https://camo.githubusercontent.com/c18fbaa52d94d16b90b19701fc90d289b8a5bb920c74c79bab200b14e75420a4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c75652d3434393564312e737667" alt="Code Style: Blue" data-canonical-src="https://img.shields.io/badge/code%20style-blue-4495d1.svg" style="max-width:100%;"></a></p>
<p>Package for implementing different methods of Bayesian quadrature.
Bayesian quadrature consists in estimating the integral <code>I = ∫ f(x) p(x) dx</code> by using Gaussian Processes where <code>p(x)</code> is assumed to be Gaussian.
More precisely we replace <code>f(x)</code> by a GP by estimating <code>f</code> for multiple samples <code>x_i</code>.
We then get a posterior distribution for the integral : <code>p(I|{x_i}) = N(m, S)</code>.</p>
<p>Given a Bayesian problem <code>p(x|y) = p(y|x) p_0(x) / p(y)</code> you can estimate <code>p(y)</code> by calling :</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using BayesianQuadrature
using Distributions
using KernelFunctions
p_0 = MvNormal(ones(2)) # As for now the prior must be a MvNormal
log_f(x) = logpdf(MvNormal(0.5 * ones(2)), x) # The logarithm of the Integrand log_f, the log-likelihood function typically
model = BayesModel(p_0, log_f) # Combine both to create the model
bquad = BayesQuad(SEKernel(); l=0.1, σ=1.0) # Will simply approximate p(y|x) with a GP (only works with SEKernel for now
sampler = PriorSampling() # Will sample from the prior p_0
p_I, _ = bquad(model, sampler; nsamples=100) # Returns a Normal distribution
@show p_I # Normal{Float64}(μ=0.07063602778449946, σ=0.0028050929209120458)
"><pre><span class="pl-k">using</span> BayesianQuadrature
<span class="pl-k">using</span> Distributions
<span class="pl-k">using</span> KernelFunctions
p_0 <span class="pl-k">=</span> <span class="pl-c1">MvNormal</span>(<span class="pl-c1">ones</span>(<span class="pl-c1">2</span>)) <span class="pl-c"><span class="pl-c">#</span> As for now the prior must be a MvNormal</span>
<span class="pl-en">log_f</span>(x) <span class="pl-k">=</span> <span class="pl-c1">logpdf</span>(<span class="pl-c1">MvNormal</span>(<span class="pl-c1">0.5</span> <span class="pl-k">*</span> <span class="pl-c1">ones</span>(<span class="pl-c1">2</span>)), x) <span class="pl-c"><span class="pl-c">#</span> The logarithm of the Integrand log_f, the log-likelihood function typically</span>
model <span class="pl-k">=</span> <span class="pl-c1">BayesModel</span>(p_0, log_f) <span class="pl-c"><span class="pl-c">#</span> Combine both to create the model</span>
bquad <span class="pl-k">=</span> <span class="pl-c1">BayesQuad</span>(<span class="pl-c1">SEKernel</span>(); l<span class="pl-k">=</span><span class="pl-c1">0.1</span>, σ<span class="pl-k">=</span><span class="pl-c1">1.0</span>) <span class="pl-c"><span class="pl-c">#</span> Will simply approximate p(y|x) with a GP (only works with SEKernel for now</span>
sampler <span class="pl-k">=</span> <span class="pl-c1">PriorSampling</span>() <span class="pl-c"><span class="pl-c">#</span> Will sample from the prior p_0</span>
p_I, _ <span class="pl-k">=</span> <span class="pl-c1">bquad</span>(model, sampler; nsamples<span class="pl-k">=</span><span class="pl-c1">100</span>) <span class="pl-c"><span class="pl-c">#</span> Returns a Normal distribution</span>
<span class="pl-c1">@show</span> p_I <span class="pl-c"><span class="pl-c">#</span> Normal{Float64}(μ=0.07063602778449946, σ=0.0028050929209120458)</span></pre></div>
</article></div>