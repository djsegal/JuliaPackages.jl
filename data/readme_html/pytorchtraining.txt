<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-pytorchtrainingjl" class="anchor" aria-hidden="true" href="#pytorchtrainingjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>PyTorchTraining.jl</h1>
<p dir="auto">This Julia package allows you to use and train PyTorch models with <a href="https://github.com/FluxML/FluxTraining.jl">FluxTraining.jl</a>.</p>
<p dir="auto"><strong>This is a prototype. A more general approach to integrating PyTorch models in the FluxML ecosystem is being created at <a href="https://github.com/rejuvyesh/PyCallChainRules.jl">PyCallChainRules.jl</a></strong></p>
<h2 dir="auto"><a id="user-content-how-do-i-use-this" class="anchor" aria-hidden="true" href="#how-do-i-use-this"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How do I use this?</h2>
<p dir="auto">You need to make 2 changes to your FluxTraining.jl setup:</p>
<ol dir="auto">
<li>add the <code>PyTorchBackend</code> callback</li>
<li>load a PyTorch <code>model</code> using PyCall.jl and pass it to <code>Learner</code></li>
</ol>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using FluxTraining, PyCall, PyTorchTraining
model = PyCall.pyimport(&quot;torchvision&quot;).models.resnet18(pretrained=true)
learner = Learner(model, data, optim, lossfn, PyTorchBackend(&quot;cuda&quot;))"><pre><span class="pl-k">using</span> FluxTraining, PyCall, PyTorchTraining
model <span class="pl-k">=</span> PyCall<span class="pl-k">.</span><span class="pl-c1">pyimport</span>(<span class="pl-s"><span class="pl-pds">"</span>torchvision<span class="pl-pds">"</span></span>)<span class="pl-k">.</span>models<span class="pl-k">.</span><span class="pl-c1">resnet18</span>(pretrained<span class="pl-k">=</span><span class="pl-c1">true</span>)
learner <span class="pl-k">=</span> <span class="pl-c1">Learner</span>(model, data, optim, lossfn, <span class="pl-c1">PyTorchBackend</span>(<span class="pl-s"><span class="pl-pds">"</span>cuda<span class="pl-pds">"</span></span>))</pre></div>
<p dir="auto">See below for a full example of finetuning a pretrained vision model.</p>
<h2 dir="auto"><a id="user-content-why-should-i-use-this" class="anchor" aria-hidden="true" href="#why-should-i-use-this"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Why should I use this?</h2>
<p dir="auto">This package could be useful for you if one or more of the following apply to you:</p>
<ul dir="auto">
<li>you want to use pretrained PyTorch models</li>
<li>you want to use research models published as PyTorch models</li>
<li>you don't want to wait for your Julia model to compile ("Time To First Gradient"): no model compile times with this package</li>
<li>you're fine with the standard ML use cases PyTorch covers</li>
<li>you want to benefit from the hundreds of person-years PyTorch people have put into hyperoptimizing these standard use cases: lower memory usage and probably better performance since you can use larger batches</li>
<li>you still want to use Julia for expensive preprocessing steps in your data pipeline</li>
</ul>
<p dir="auto">For an overview of the trade-offs in machine learning compilers that PyTorch and Flux.jl make, I suggest reading <a href="https://www.stochasticlifestyle.com/engineering-trade-offs-in-automatic-differentiation-from-tensorflow-and-pytorch-to-jax-and-julia/" rel="nofollow">Engineering Trade-Offs in Automatic Differentiation: from TensorFlow and PyTorch to Jax and Julia</a> by Chris Rackauckas.</p>
<h2 dir="auto"><a id="user-content-full-example" class="anchor" aria-hidden="true" href="#full-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Full example</h2>
<p dir="auto">This example gives the complete code for finetuning a pretrained image classifier from <code>torchvision</code> on the <a href="https://github.com/fastai/imagenette">Imagenette</a> dataset. It uses <a href="https://github.com/FluxML/FastAI.jl">FastAI.jl</a> for the data loading and preprocessing part.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using FastAI, FluxTraining, PyCall, PyTorchTraining
const torchvision = pyimport(&quot;torchvision&quot;)

function loadresnet(c::Int)
    # load pretrained resnet and replace last block with one outputting
    # `c` classes. Adapted from
    # https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html
    model = torchvision.models.resnet18(pretrained=true)
    model.fc = torch.nn.Linear(model.fc.in_features, c)
    return model
end


# Load dataset and create data loaders (FastAI.jl stuff)
data, blocks = loaddataset(&quot;imagenette2-320&quot;, (Image, Label))
method = ImageClassificationSingle(blocks, (224, 224))
dls = methoddataloaders(data, method, 64)
c = length(blocks[2].classes)

# Create a `Learner`
model = loadresnet(c)
learner = Learner(
    loadresnet(length(blocks[2].classes)),
    dls,
    ADAM(0.01),  # will be converted to `torch.optim.Adam`
    Flux.logitcrossentropy,
    PyTorchBackend()  # uses device &quot;cuda&quot; if available, else &quot;cpu&quot;
)

# Train it!

fit!(learner, 10)"><pre><span class="pl-k">using</span> FastAI, FluxTraining, PyCall, PyTorchTraining
<span class="pl-k">const</span> torchvision <span class="pl-k">=</span> <span class="pl-c1">pyimport</span>(<span class="pl-s"><span class="pl-pds">"</span>torchvision<span class="pl-pds">"</span></span>)

<span class="pl-k">function</span> <span class="pl-en">loadresnet</span>(c<span class="pl-k">::</span><span class="pl-c1">Int</span>)
    <span class="pl-c"><span class="pl-c">#</span> load pretrained resnet and replace last block with one outputting</span>
    <span class="pl-c"><span class="pl-c">#</span> `c` classes. Adapted from</span>
    <span class="pl-c"><span class="pl-c">#</span> https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html</span>
    model <span class="pl-k">=</span> torchvision<span class="pl-k">.</span>models<span class="pl-k">.</span><span class="pl-c1">resnet18</span>(pretrained<span class="pl-k">=</span><span class="pl-c1">true</span>)
    model<span class="pl-k">.</span>fc <span class="pl-k">=</span> torch<span class="pl-k">.</span>nn<span class="pl-k">.</span><span class="pl-c1">Linear</span>(model<span class="pl-k">.</span>fc<span class="pl-k">.</span>in_features, c)
    <span class="pl-k">return</span> model
<span class="pl-k">end</span>


<span class="pl-c"><span class="pl-c">#</span> Load dataset and create data loaders (FastAI.jl stuff)</span>
data, blocks <span class="pl-k">=</span> <span class="pl-c1">loaddataset</span>(<span class="pl-s"><span class="pl-pds">"</span>imagenette2-320<span class="pl-pds">"</span></span>, (Image, Label))
method <span class="pl-k">=</span> <span class="pl-c1">ImageClassificationSingle</span>(blocks, (<span class="pl-c1">224</span>, <span class="pl-c1">224</span>))
dls <span class="pl-k">=</span> <span class="pl-c1">methoddataloaders</span>(data, method, <span class="pl-c1">64</span>)
c <span class="pl-k">=</span> <span class="pl-c1">length</span>(blocks[<span class="pl-c1">2</span>]<span class="pl-k">.</span>classes)

<span class="pl-c"><span class="pl-c">#</span> Create a `Learner`</span>
model <span class="pl-k">=</span> <span class="pl-c1">loadresnet</span>(c)
learner <span class="pl-k">=</span> <span class="pl-c1">Learner</span>(
    <span class="pl-c1">loadresnet</span>(<span class="pl-c1">length</span>(blocks[<span class="pl-c1">2</span>]<span class="pl-k">.</span>classes)),
    dls,
    <span class="pl-c1">ADAM</span>(<span class="pl-c1">0.01</span>),  <span class="pl-c"><span class="pl-c">#</span> will be converted to `torch.optim.Adam`</span>
    Flux<span class="pl-k">.</span>logitcrossentropy,
    <span class="pl-c1">PyTorchBackend</span>()  <span class="pl-c"><span class="pl-c">#</span> uses device "cuda" if available, else "cpu"</span>
)

<span class="pl-c"><span class="pl-c">#</span> Train it!</span>

<span class="pl-c1">fit!</span>(learner, <span class="pl-c1">10</span>)</pre></div>
<h2 dir="auto"><a id="user-content-caveats-and-nice-to-knows" class="anchor" aria-hidden="true" href="#caveats-and-nice-to-knows"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Caveats and nice-to-knows</h2>
<p dir="auto">This package...</p>
<ul dir="auto">
<li>Uses <a href="https://github.com/JuliaPy/PyCall.jl">PyCall.jl</a> to use the Python <code>torch</code> library, but I haven't included a build step for installing it yet, so you'll have to set that up yourself for now.</li>
<li>Tries to translate Flux optimisers and loss functions to their PyTorch equivalents, but I haven't implemented most of these translations. See <code>optimisers.jl</code> and <code>loss.jl</code> for how it's done. You can either pass in loss functions that work on tensors and PyTorch optimisers directly to <code>Learner</code> or implement the methods as in the source.</li>
<li>Does not require using a custom training loop (everything is done via a callback) so it should work well for custom trainig loops like the one in <a href="https://fluxml.ai/FastAI.jl/dev/notebooks/vae.ipynb.html" rel="nofollow">this VAE tutorial</a>. Also see <code>callback.jl</code> if you want to see how it's done.</li>
<li>automatically permutes dimensions of Julia arrays before converting them to PyTorch tensors since PyTorch uses different conventions for array dimension ordering. For example the batch dimension is last in Julia, but first in PyTorch and the image channel dimension comes after the spatial dimensions in Julia but before in PyTorch. The current default rules for how PyTorchTraining.jl decides how to permute are a bit ad-hoc but extensible. See <code>tensor.jl</code>.</li>
</ul>
<h1 dir="auto"><a id="user-content-features" class="anchor" aria-hidden="true" href="#features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Features</h1>
<p dir="auto">Below a non-exhaustive list of features I have yet to add but will:</p>
<ul dir="auto">
<li>hyperparameter scheduling on <code>PyTorchOptimiser</code>s</li>
<li>compatibility with <code>Metric</code>s (without unnecessary copying)</li>
</ul>
</article></div>