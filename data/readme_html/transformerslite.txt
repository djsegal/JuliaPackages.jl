<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-transformerslite" class="anchor" aria-hidden="true" href="#transformerslite"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>TransformersLite</h1>
<p dir="auto">A basic transformer package. This repository is meant for learning
and is paired with this <a href="https://liorsinai.github.io/coding/2022/05/18/transformers.html" rel="nofollow">blog post</a>. For a much more comprehensive package with APIs for HuggingFace, optimizations and more, please see Transformers.jl at <a href="https://github.com/chengchingwen/Transformers.jl">github.com/chengchingwen/Transformers.jl</a>.</p>
<p dir="auto">This package is designed to work with <a href="https://github.com/FluxML/Flux.jl">Flux</a>. It provides a multi-head attention layer as described in the paper <a href="https://arxiv.org/abs/1706.03762" rel="nofollow">Attention is all you need</a>.
It also provides</p>
<ul dir="auto">
<li>A simple index tokenizer for mapping words to indices.</li>
<li>A wrapper for an embedding layer.</li>
<li>A wrapper for a mean layer.</li>
<li>A position encoding layer.</li>
<li>Two encompassing layers to chain these together: <code>TransformerEncoderBlock</code> and <code>TransformerClassifier</code>. Flux's <code>chain</code> function can also be used to chain the layers together.</li>
</ul>
<p dir="auto">Two implementations are provided for the 4D batch multiplication such that <code>A×B</code> results in <code>C[:,:,k,l] == A[:,:,k,l] * B[:,:,k,l]</code>.
These are <code>mul4d</code> and an extension to NNlib's <code>batched_mul</code>. The extension to <code>batched_mul</code> is about 1.5× faster than <code>mul4d</code>.</p>
<p dir="auto">An example model output looks like:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="TransformerClassifier(
  Embed((32, 7455)),                    # 238_560 parameters
  PositionEncoding(32),
  Dropout(0.1),
  TransformerEncoderBlock(
    MultiheadAttention(num_heads=4, head_size=8, 32=&gt;32)(
      denseQ = Dense(32 =&gt; 32),         # 1_056 parameters
      denseK = Dense(32 =&gt; 32),         # 1_056 parameters
      denseV = Dense(32 =&gt; 32),         # 1_056 parameters
      denseO = Dense(32 =&gt; 32),         # 1_056 parameters
    ),
    Dropout(0.1),
    LayerNorm(32),                      # 64 parameters
    Dense(32 =&gt; 128, relu),             # 4_224 parameters
    Dense(128 =&gt; 32),                   # 4_128 parameters
    Dropout(0.1),
    LayerNorm(32),                      # 64 parameters
  ),
  Dense(32 =&gt; 1),                       # 33 parameters
  FlattenLayer(),
  Dense(50 =&gt; 5),                       # 255 parameters
)        # Total: 21 trainable arrays, 251_552 parameters,
          # plus 1 non-trainable, 32_000 parameters, summarysize 1.083 MiB"><pre class="notranslate"><code>TransformerClassifier(
  Embed((32, 7455)),                    # 238_560 parameters
  PositionEncoding(32),
  Dropout(0.1),
  TransformerEncoderBlock(
    MultiheadAttention(num_heads=4, head_size=8, 32=&gt;32)(
      denseQ = Dense(32 =&gt; 32),         # 1_056 parameters
      denseK = Dense(32 =&gt; 32),         # 1_056 parameters
      denseV = Dense(32 =&gt; 32),         # 1_056 parameters
      denseO = Dense(32 =&gt; 32),         # 1_056 parameters
    ),
    Dropout(0.1),
    LayerNorm(32),                      # 64 parameters
    Dense(32 =&gt; 128, relu),             # 4_224 parameters
    Dense(128 =&gt; 32),                   # 4_128 parameters
    Dropout(0.1),
    LayerNorm(32),                      # 64 parameters
  ),
  Dense(32 =&gt; 1),                       # 33 parameters
  FlattenLayer(),
  Dense(50 =&gt; 5),                       # 255 parameters
)        # Total: 21 trainable arrays, 251_552 parameters,
          # plus 1 non-trainable, 32_000 parameters, summarysize 1.083 MiB
</code></pre></div>
<p dir="auto">Please see the <a href="/examples/">example</a> folder for utility functions, notebooks and a training script which demonstrate the module's capabilities.
These examples use tokenizers from my TokenizersLite repository at <a href="https://github.com/LiorSinai/TokenizersLite">https://github.com/LiorSinai/TokenizersLite</a>.
However any compatible tokenizer can be used.</p>
<h2 dir="auto"><a id="user-content-case-study" class="anchor" aria-hidden="true" href="#case-study"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Case study</h2>
<p dir="auto">A simple use case of Amazon Reviews from <a href="https://huggingface.co/datasets/amazon_reviews_multi" rel="nofollow">HuggingFace</a> was investigated.
The task was given a text input to predict the star rating.
A simpler task was also investigated to predict a positive or negative sentiment with 1-2 stars labelled negative, 4-5 stars labelled positive and 3 stars removed. Only the English subset of the dataset was used with 200,000 training samples and 5,000 test samples.</p>
<p dir="auto">It should be noted that this task can be solved with simpler models. A TFIDF model paired with logistic regression (≈ 10,000 weights)
achieved similar accuracy to these models with more than 240,000 weights.</p>
<p dir="auto">The accuracy achieved was 87.5% for the binary task and 49.9% for the 5 star classification task.
For the binary case, a model which scores each sentence individually and then aggregates their results with a parabolic weighted average achieved an accuracy of 89.3%.</p>
<h3 dir="auto"><a id="user-content-binary-task" class="anchor" aria-hidden="true" href="#binary-task"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Binary task</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="images/confusion_matrix_regression.png"><img src="images/confusion_matrix_regression.png" alt="confusion matrix" style="max-width: 100%;"></a></p>
<p dir="auto">The confusion matrix shows that the binary model does indeed mostly predict the correct class.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="images/probabilities_star.png"><img src="images/probabilities_star.png" alt="bar chart probabilities vs star" style="max-width: 100%;"></a></p>
<p dir="auto">The probabilities for each star are strongly biased in the right way, with 1 star ratings being mostly negative and 5 star ratings mostly positive. The model was not trained on 3 star reviews so here the distribution approaches a uniform distribution (random) with a negative skew. But that may also be a reflection of the underlying data because humans are not consistent with their ratings for 3 stars.</p>
<h3 dir="auto"><a id="user-content-5-star-classification-task" class="anchor" aria-hidden="true" href="#5-star-classification-task"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>5 star classification task</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="images/confusion_matrix_classification5.png"><img src="images/confusion_matrix_classification5.png" alt="confusion matrix" style="max-width: 100%;"></a></p>
<p dir="auto">Looking at the confusion matrix for the 5 star classification, we can see that the model struggles more with the middle ratings of 2-4.
Again this is hypothesized  to be partially because of inconsistencies in the underlying data.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="images/predictions_classification5.png"><img src="images/predictions_classification5.png" alt="bar chart predication vs ground truth" style="max-width: 100%;"></a></p>
<p dir="auto">Seeing in another view as a bar chart, for each star the most likely prediction is the star itself.
However the distributions do have a spread and have significant overlaps of confusion.</p>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">Download the GitHub repository (it is not registered). Then in the Julia REPL:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="julia&gt; ] # enter package mode
(@v1.x) pkg&gt; dev path\\to\\TransformersLite
julia&gt; using Revise # for dynamic editing of code
julia&gt; using TransformersLite"><pre class="notranslate"><code>julia&gt; ] # enter package mode
(@v1.x) pkg&gt; dev path\\to\\TransformersLite
julia&gt; using Revise # for dynamic editing of code
julia&gt; using TransformersLite
</code></pre></div>
<p dir="auto">Done.</p>
</article></div>