<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 align="center" dir="auto"><a id="user-content-gaussianvariationalinferencejl" class="anchor" aria-hidden="true" href="#gaussianvariationalinferencejl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>GaussianVariationalInference.jl</h1>
<p align="center" dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ngiann/GaussianVariationalInference.jl/blob/4d604d2f42f74c97a84685ddf13e0a9d05ff76e7/docs/src/assets/logo.png"><img src="https://github.com/ngiann/GaussianVariationalInference.jl/raw/4d604d2f42f74c97a84685ddf13e0a9d05ff76e7/docs/src/assets/logo.png" width="192" height="144" style="max-width: 100%;"></a>
</p>
<p dir="auto"><a href="https://www.repostatus.org/#active" rel="nofollow"><img src="https://camo.githubusercontent.com/2261082c77808ea734741b12e535d02d23c4101f6b8dfec807f4ddc5ef2eeec0/68747470733a2f2f7777772e7265706f7374617475732e6f72672f6261646765732f6c61746573742f6163746976652e737667" alt="Project Status: WIP – Initial development is in progress, but there has not yet been a stable, usable release suitable for the public." data-canonical-src="https://www.repostatus.org/badges/latest/active.svg" style="max-width: 100%;"></a>
<a href="https://ngiann.github.io/GaussianVariationalInference.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/4fbf1a0e9af715d83da2c6cb134932756a9f0a25d715cecf4c83b1437b7996eb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6d61737465722d626c75652e737667" alt="Documentation" data-canonical-src="https://img.shields.io/badge/docs-master-blue.svg" style="max-width: 100%;"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/62daff8b5214d2a9f183ef5861813305fc0684ec9b0239758d56c43c4fb6c68e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6e6769616e6e2f476175737369616e566172696174696f6e616c496e666572656e63652e6a6c"><img src="https://camo.githubusercontent.com/62daff8b5214d2a9f183ef5861813305fc0684ec9b0239758d56c43c4fb6c68e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6e6769616e6e2f476175737369616e566172696174696f6e616c496e666572656e63652e6a6c" alt="GitHub" data-canonical-src="https://img.shields.io/github/license/ngiann/GaussianVariationalInference.jl" style="max-width: 100%;"></a></p>
<h1 dir="auto"><a id="user-content-what-is-this" class="anchor" aria-hidden="true" href="#what-is-this"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>What is this?</h1>
<p dir="auto">A Julia package for approximating a posterior distribution with a full-covariance Gaussian distribution by optimising a variational lower bound<sup><a href="#user-content-fn-1-b4975af77ad6a514eeb032e537cea083" id="user-content-fnref-1-b4975af77ad6a514eeb032e537cea083" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>. In the near future it is planned to introduce a method for mean-field approximation. We recommend using this package for problems with a relatively small number of parameters, 2-20 parameters perhaps. The main focus of this package is to provide a method for approximating a target posterior with a Gaussian that does not need tuning learning rates (step sizes) and converges reliably.</p>
<h2 dir="auto"><a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basic usage</h2>
<p dir="auto">To install this package, please switch in the Julia REPL into package mode and add using <code>add GaussianVariationalInference</code>.</p>
<p dir="auto">The package is fairly easy to use. Currently, the only function of interest to the user is <code>VI</code>. At the very minimum, the user needs to provide a function that codes the joint log-likelihood function.</p>
<p dir="auto">Consider approximating the following target density:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using GaussianVariationalInference

logp = exampleproblem1() # target log-posterior density to approximate
x₀ = randn(2)            # random initial mean for approximating Gaussian
q, logev = VI(logp, randn(2), S = 100, iterations = 10_000, show_every = 50)

# Plot target posterior, not log-posterior!
using Plots # must be indepedently installed.
x = -3:0.02:3
contour(x, x, map(x -&gt; exp(logp(collect(x))), Iterators.product(x, x))', fill=true, c=:blues)

# Plot Gaussian approximation on top using red colour
contour!(x, x, map(x -&gt; pdf(q,(collect(x))), Iterators.product(x, x))', color=&quot;red&quot;, alpha=0.2)"><pre class="notranslate"><code>using GaussianVariationalInference

logp = exampleproblem1() # target log-posterior density to approximate
x₀ = randn(2)            # random initial mean for approximating Gaussian
q, logev = VI(logp, randn(2), S = 100, iterations = 10_000, show_every = 50)

# Plot target posterior, not log-posterior!
using Plots # must be indepedently installed.
x = -3:0.02:3
contour(x, x, map(x -&gt; exp(logp(collect(x))), Iterators.product(x, x))', fill=true, c=:blues)

# Plot Gaussian approximation on top using red colour
contour!(x, x, map(x -&gt; pdf(q,(collect(x))), Iterators.product(x, x))', color="red", alpha=0.2)
</code></pre></div>
<p dir="auto">A plot similar to the one below should appear. The  blue filled contours correspond to the exponentiated <code>logp</code>, and the red contours correspond to the produced Gaussian approximation <code>q</code>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="docs/src/exampleproblem1.png"><img src="docs/src/exampleproblem1.png" alt="image" style="max-width: 100%;"></a></p>
<p dir="auto">For further information, please consult the documentation.</p>
<p dir="auto">Should you use the software for academic purposes, please kindly consider citing the relevant paper<sup><a href="#user-content-fn-1-b4975af77ad6a514eeb032e537cea083" id="user-content-fnref-1-2-b4975af77ad6a514eeb032e537cea083" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.</p>
<h2 dir="auto"><a id="user-content-related-packages" class="anchor" aria-hidden="true" href="#related-packages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Related packages</h2>
<ul dir="auto">
<li><a href="https://github.com/TuringLang/AdvancedVI.jl">AdvancedVI.jl</a>: A library for variational Bayesian inference in Julia.</li>
<li><a href="https://github.com/tpapp/DynamicHMC.jl">DynamicHMC.jl</a>: Implementation of robust dynamic Hamiltonian Monte Carlo methods in Julia.</li>
</ul>
<section data-footnotes="" class="footnotes"><h2 id="footnote-label" class="sr-only" dir="auto">Footnotes</h2>
<ol dir="auto">
<li id="user-content-fn-1-b4975af77ad6a514eeb032e537cea083">
<p dir="auto"><a href="https://doi.org/10.1007/s10044-015-0496-9">Approximate Variational Inference Based on a Finite Sample of Gaussian Latent Variables</a>, <a href="https://arxiv.org/pdf/1906.04507.pdf">[Arxiv]</a>. <a href="#user-content-fnref-1-b4975af77ad6a514eeb032e537cea083" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref"><g-emoji class="g-emoji" alias="leftwards_arrow_with_hook" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/21a9.png">↩</g-emoji></a> <a href="#user-content-fnref-1-2-b4975af77ad6a514eeb032e537cea083" data-footnote-backref="" aria-label="Back to reference 1-2" class="data-footnote-backref"><g-emoji class="g-emoji" alias="leftwards_arrow_with_hook" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/21a9.png">↩</g-emoji><sup>2</sup></a></p>
</li>
</ol>
</section>
</article></div>