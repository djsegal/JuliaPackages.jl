<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-perftests" class="anchor" aria-hidden="true" href="#perftests"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Perftests</h1>
<p dir="auto">A redo of the main Julia <code>test/perf</code> directory.  Retooled to use <a href="https://github.com/johnmyleswhite/Benchmarks.jl"><code>Benchmarks.jl</code></a>, this repository will spit out a bunch of .csv files into the <code>test/results-$COMMIT</code> directory (Where <code>$COMMIT</code> is the commit hash of the version of Julia you are running) and display small summary statistics as it does so.</p>
<p dir="auto">To run a specific group of tests, use <code>run_perf_groups()</code>.  For example, to run and output the <code>.csv</code> files for the <code>kernel</code> and <code>simd</code> performance tests, one would write:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Perftests
run_perf_groups([&quot;kernel&quot;, &quot;simd&quot;])"><pre><span class="pl-k">using</span> Perftests
<span class="pl-c1">run_perf_groups</span>([<span class="pl-s"><span class="pl-pds">"</span>kernel<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>simd<span class="pl-pds">"</span></span>])</pre></div>
<h1 dir="auto"><a id="user-content-test-organization" class="anchor" aria-hidden="true" href="#test-organization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Test organization</h1>
<p dir="auto">Tests are organized foremost by group, then name, then variant.  Not all tests are required to have variants, but they fit into a natural hierarchy when running the same test across multiple element types, for example.  The resultant <code>.csv</code> files are named <code>$group-$name-$variant.csv</code>, for ease of access.</p>
<h1 dir="auto"><a id="user-content-test-environment" class="anchor" aria-hidden="true" href="#test-environment"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Test environment</h1>
<p dir="auto">Information about the test environment (the commit hash of this repository used to create the results, the word size of the running machine, the number of CPU cores, etc...) is saved in the <code>env.csv</code> file put into the <code>results-$COMMIT</code> directory when testing.</p>
</article></div>