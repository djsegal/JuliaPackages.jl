<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-dzoptimizationjl" class="anchor" aria-hidden="true" href="#dzoptimizationjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DZOptimization.jl</h1>
<h4><a id="user-content-copyright--2019-2021-by-david-k-zhang-released-under-the-mit-license" class="anchor" aria-hidden="true" href="#copyright--2019-2021-by-david-k-zhang-released-under-the-mit-license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Copyright © 2019-2021 by David K. Zhang. Released under the <a href="https://github.com/dzhang314/MultiFloats.jl/blob/master/LICENSE">MIT License</a>.</h4>
<p><strong>DZOptimization.jl</strong> is a Julia package for smooth nonlinear optimization that emphasizes performance, flexibility, and memory efficiency. In basic usage examples (see below), <strong>DZOptimization.jl</strong> has 6x less overhead and uses 10x less memory than <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a>.</p>
<p>Unlike traditional optimization libraries which only provide a black-box <code>optimize</code> function (e.g., <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> and <a href="https://github.com/JuliaOpt/NLopt.jl">NLopt.jl</a>), <strong>DZOptimization.jl</strong> gives you full control of the optimization loop. This allows you to:</p>
<ul>
<li>interactively monitor the progress of an optimizer,</li>
<li>interleave nonlinear optimization with other tasks,</li>
<li>save/load data in the middle of optimization,</li>
<li>run multiple optimizers in parallel, and</li>
<li>terminate optimization whenever you want (as opposed to a <a href="https://github.com/JuliaOpt/NLopt.jl#using-with-mathoptinterface">predetermined list of convergence criteria</a>).</li>
</ul>
<p><strong>DZOptimization.jl</strong> is designed to minimize overhead. It uses static data structures and in-place algorithms to ensure that memory is <strong>never</strong> dynamically allocated (outside of optimizer constructors). This makes <strong>DZOptimization.jl</strong> especially suitable for both small-scale optimization problems, since repeatedly allocating small vectors is wasteful, and large-scale optimization problems, since memory usage will never shoot up unexpectedly.</p>
<h2><a id="user-content-usage-example" class="anchor" aria-hidden="true" href="#usage-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage Example</h2>
<p>The following example illustrates the use of <code>DZOptimization.BFGSOptimizer</code> to minimize the <a href="https://en.wikipedia.org/wiki/Rosenbrock_function" rel="nofollow">Rosenbrock function</a>, starting at a random initial point.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="using DZOptimization

rosenbrock_objective(x::Vector) =
    (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2

function rosenbrock_gradient!(g::Vector, x::Vector)
    g[1] = -2 * (1 - x[1]) - 400 * x[1] * (x[2] - x[1]^2)
    g[2] = 200 * (x[2] - x[1]^2)
end

opt = BFGSOptimizer(rosenbrock_objective,
                    rosenbrock_gradient!,
                    rand(2), # starting point
                    1.0)     # initial step size

while !opt.has_converged[]
    println(opt.current_objective_value[], '\t', opt.current_point)
    step!(opt)
end
"><pre><code>using DZOptimization

rosenbrock_objective(x::Vector) =
    (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2

function rosenbrock_gradient!(g::Vector, x::Vector)
    g[1] = -2 * (1 - x[1]) - 400 * x[1] * (x[2] - x[1]^2)
    g[2] = 200 * (x[2] - x[1]^2)
end

opt = BFGSOptimizer(rosenbrock_objective,
                    rosenbrock_gradient!,
                    rand(2), # starting point
                    1.0)     # initial step size

while !opt.has_converged[]
    println(opt.current_objective_value[], '\t', opt.current_point)
    step!(opt)
end
</code></pre></div>
<h2><a id="user-content-benchmarks" class="anchor" aria-hidden="true" href="#benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Benchmarks</h2>
<p>Compared to <a href="http://julianlsolvers.github.io/Optim.jl/stable/" rel="nofollow">Optim.jl</a>, the BFGS implementation in <strong>DZOptimization.jl</strong> is 6x faster and uses 10x less memory to minimize the <a href="https://en.wikipedia.org/wiki/Rosenbrock_function" rel="nofollow">Rosenbrock function</a>.</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="using BenchmarkTools                            | using Optim
@benchmark begin                                |
    opt = BFGSOptimizer(rosenbrock_objective,   | @benchmark optimize(rosenbrock_objective,
                        rosenbrock_gradient!,   |                     rosenbrock_gradient!,
                        rand(2), 1.0)           |                     rand(2), BFGS())
    while !opt.has_converged[]; step!(opt); end |
end                                             |
                                                |
# BenchmarkTools.Trial:                         | # BenchmarkTools.Trial: 
#   memory estimate:  1.14 KiB                  | #   memory estimate:  9.88 KiB
#   allocs estimate:  12                        | #   allocs estimate:  163
#   --------------                              | #   --------------
#   minimum time:     2.800 μs (0.00% GC)       | #   minimum time:     8.599 μs (0.00% GC)
#   median time:      5.563 μs (0.00% GC)       | #   median time:      30.300 μs (0.00% GC)
#   mean time:        5.374 μs (0.64% GC)       | #   mean time:        31.826 μs (4.44% GC)
#   maximum time:     182.925 μs (95.70% GC)    | #   maximum time:     3.824 ms (98.29% GC)
"><pre><code>using BenchmarkTools                            | using Optim
@benchmark begin                                |
    opt = BFGSOptimizer(rosenbrock_objective,   | @benchmark optimize(rosenbrock_objective,
                        rosenbrock_gradient!,   |                     rosenbrock_gradient!,
                        rand(2), 1.0)           |                     rand(2), BFGS())
    while !opt.has_converged[]; step!(opt); end |
end                                             |
                                                |
# BenchmarkTools.Trial:                         | # BenchmarkTools.Trial: 
#   memory estimate:  1.14 KiB                  | #   memory estimate:  9.88 KiB
#   allocs estimate:  12                        | #   allocs estimate:  163
#   --------------                              | #   --------------
#   minimum time:     2.800 μs (0.00% GC)       | #   minimum time:     8.599 μs (0.00% GC)
#   median time:      5.563 μs (0.00% GC)       | #   median time:      30.300 μs (0.00% GC)
#   mean time:        5.374 μs (0.64% GC)       | #   mean time:        31.826 μs (4.44% GC)
#   maximum time:     182.925 μs (95.70% GC)    | #   maximum time:     3.824 ms (98.29% GC)
</code></pre></div>
</article></div>