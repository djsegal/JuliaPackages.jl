<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-dianoiaml" class="anchor" aria-hidden="true" href="#dianoiaml"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DianoiaML</h1>
<p>DianoiaML is an experimental Keras-like deep learning framework.</p>
<p>The user guide and the To-Do list can be found <a href="https://github.com/SkyWorld117/YisyAIFramework.jl/wiki">here</a>.</p>
<p>If you are interested in the <a href="https://github.com/SkyWorld117/YisyAIFramework.jl/tree/history">history versions</a>, you can also check the <a href="https://github.com/SkyWorld117/YisyAIFramework.jl/blob/master/UPDATES.md">update log</a>.</p>
<p>Latest stable version <strong>0.4.0</strong></p>
<p>Environment: Julia 1.6.1</p>
<p>Dependencies:</p>
<ul>
<li><a href="https://github.com/JuliaIO/HDF5.jl">HDF5.jl</a> 0.15.4</li>
<li><a href="https://github.com/JuliaSIMD/LoopVectorization.jl">LoopVectorization.jl</a> 0.12.18</li>
<li><a href="https://github.com/JuliaSIMD/CheapThreads.jl">CheapThreads.jl</a> 0.2.3</li>
</ul>
<p>Features:</p>
<ul>
<li>Network
<ul>
<li>Sequential</li>
<li>GAN</li>
</ul>
</li>
<li>Layer
<ul>
<li>Flatten</li>
<li>Constructive</li>
<li>Dense</li>
<li>Convolutional2D</li>
<li>MaxPooling2D <strong>(Not recommended to use for now due to a bug caused by unkown reasons)</strong></li>
<li>UpSampling2D</li>
</ul>
</li>
<li>Activation Function
<ul>
<li>ReLU</li>
<li>Sigmoid</li>
<li>Softmax</li>
<li>tanh</li>
</ul>
</li>
<li>Loss Function
<ul>
<li>Quadratic Loss</li>
<li>Categorical Cross Entropy Loss</li>
<li>Binary Cross Entropy Loss</li>
<li>Mean Squared Error</li>
</ul>
</li>
<li>Monitor
<ul>
<li>Absolute</li>
<li>Classification</li>
</ul>
</li>
<li>Optimizer
<ul>
<li>Minibatch Gradient Descent</li>
<li>Stochastic Gradient Descent</li>
<li>Adam</li>
<li>AdaBelief</li>
<li>Genetic Algorithm</li>
</ul>
</li>
<li>Tools
<ul>
<li>Model Management</li>
<li>One Hot</li>
</ul>
</li>
</ul>
<p>Please feel free to leave comments, trouble-shootings or advice (which are very valuable for me).</p>
</article></div>