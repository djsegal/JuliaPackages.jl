<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-diffeqbayesjl" class="anchor" aria-hidden="true" href="#diffeqbayesjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DiffEqBayes.jl</h1>
<p><a href="https://travis-ci.org/SciML/DiffEqBayes.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/69712bcaed8b291c495a458514bf309924e91a32/68747470733a2f2f7472617669732d63692e6f72672f5363694d4c2f44696666457142617965732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/SciML/DiffEqBayes.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/SciML/DiffEqBayes.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/ed9f4ed89851e9aec5bd3d59759ce4910fc32bb3/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f5363694d4c2f44696666457142617965732e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/SciML/DiffEqBayes.jl/badge.svg?branch=master" style="max-width:100%;"></a>
<a href="http://codecov.io/github/SciML/DiffEqBayes.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/ccdabcf4ce417ed7dbdeb7edb8ab6499a26cae80/687474703a2f2f636f6465636f762e696f2f6769746875622f5363694d4c2f44696666457142617965732e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/SciML/DiffEqBayes.jl/coverage.svg?branch=master" style="max-width:100%;"></a></p>
<p>This repository is a set of extension functionality for estimating the parameters of differential equations using Bayesian methods. It allows the choice of using <a href="https://github.com/StanJulia/CmdStan.jl">CmdStan.jl</a>, <a href="https://github.com/TuringLang/Turing.jl">Turing.jl</a>, <a href="https://github.com/tpapp/DynamicHMC.jl">DynamicHMC.jl</a> and <a href="https://github.com/marcjwilliams1/ApproxBayes.jl">ApproxBayes.jl</a> to perform a Bayesian estimation of a differential equation problem specified via the <a href="https://github.com/SciML/DifferentialEquations.jl">DifferentialEquations.jl</a> interface.</p>
<p>To begin you first need to add this repository using the following command.</p>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>DiffEqBayes<span class="pl-pds">"</span></span>)
<span class="pl-k">using</span> DiffEqBayes</pre></div>
<h3><a id="user-content-stan_inference" class="anchor" aria-hidden="true" href="#stan_inference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>stan_inference</h3>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">stan_inference</span>(prob<span class="pl-k">::</span><span class="pl-c1">DiffEqBase.DEProblem</span>,t,data,priors <span class="pl-k">=</span> <span class="pl-c1">nothing</span>;
               alg<span class="pl-k">=</span><span class="pl-c1">:rk45</span>, num_samples<span class="pl-k">=</span><span class="pl-c1">1000</span>, num_warmup<span class="pl-k">=</span><span class="pl-c1">1000</span>, 
               reltol<span class="pl-k">=</span><span class="pl-c1">1e-3</span>, abstol<span class="pl-k">=</span><span class="pl-c1">1e-6</span>, maxiter<span class="pl-k">=</span><span class="pl-c1">Int</span>(<span class="pl-c1">1e5</span>),likelihood<span class="pl-k">=</span>Normal,
               vars<span class="pl-k">=</span>(<span class="pl-c1">StanODEData</span>(),<span class="pl-c1">InverseGamma</span>(<span class="pl-c1">3</span>,<span class="pl-c1">3</span>)),nchains<span class="pl-k">=</span><span class="pl-c1">1</span>, sample_u0 <span class="pl-k">=</span> <span class="pl-c1">false</span>, 
               save_idxs <span class="pl-k">=</span> <span class="pl-c1">nothing</span>, diffeq_string <span class="pl-k">=</span> <span class="pl-c1">nothing</span>, printsummary <span class="pl-k">=</span> <span class="pl-c1">true</span>)</pre></div>
<p><code>stan_inference</code> uses <a href="https://github.com/StanJulia/CmdStan.jl">CmdStan.jl</a>
to perform the Bayesian inference. The
<a href="https://stanjulia.github.io/CmdStan.jl/stable/INSTALLATION.html" rel="nofollow">Stan installation process</a>
is required to use this function. The first argument is a <code>DEProblem</code>, <code>t</code> is the array of time
and <code>data</code> is the array where the first dimension (columns) corresponds to the
array of system values. <code>priors</code> is an array of prior distributions for each
parameter, specified via a <a href="https://juliastats.github.io/Distributions.jl/dev/" rel="nofollow">Distributions.jl</a>
type. <code>alg</code> is a choice between <code>:rk45</code> and <code>:bdf</code>, the two internal integrators
of Stan. <code>num_samples</code> is the number of samples to take per chain, and <code>num_warmup</code>
is the number of MCMC warmup steps. <code>abstol</code> and <code>reltol</code> are the keyword
arguments for the internal integrator. <code>likelihood</code> is the likelihood distribution
to use with the arguments from <code>vars</code>, and <code>vars</code> is a tuple of priors for the
distributions of the likelihood hyperparameters. The special value <code>StanODEData()</code>
in this tuple denotes the position that the ODE solution takes in the likelihood's
parameter list. With the <code>diffeq_string</code> kwarg you can pass in a complex ODE specification
if the need arises.</p>
<h3><a id="user-content-turing_inference" class="anchor" aria-hidden="true" href="#turing_inference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>turing_inference</h3>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">turing_inference</span>(prob<span class="pl-k">::</span><span class="pl-c1">DiffEqBase.DEProblem</span>,alg,t,data,priors;
                    likelihood_dist_priors <span class="pl-k">=</span> [<span class="pl-c1">InverseGamma</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>)], 
                    likelihood <span class="pl-k">=</span> (u,p,t,σ) <span class="pl-k">-&gt;</span> <span class="pl-c1">MvNormal</span>(u, σ[<span class="pl-c1">1</span>]<span class="pl-k">*</span><span class="pl-c1">ones</span>(<span class="pl-c1">length</span>(u))),
                    num_samples<span class="pl-k">=</span><span class="pl-c1">1000</span>, sampler <span class="pl-k">=</span> Turing<span class="pl-k">.</span><span class="pl-c1">NUTS</span>(<span class="pl-c1">0.65</span>),
                    syms <span class="pl-k">=</span> [Turing<span class="pl-k">.</span><span class="pl-c1">@varname</span>(theta[i]) <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">length</span>(priors)],
                    sample_u0 <span class="pl-k">=</span> <span class="pl-c1">false</span>, save_idxs <span class="pl-k">=</span> <span class="pl-c1">nothing</span>, progress <span class="pl-k">=</span> <span class="pl-c1">false</span>, kwargs<span class="pl-k">...</span>)</pre></div>
<p><code>turing_inference</code> uses <a href="https://github.com/TuringLang/Turing.jl">Turing.jl</a> to
perform its parameter inference. <code>prob</code> can be any <code>DEProblem</code> with a corresponding
<code>alg</code> choice. <code>t</code> is the array of time points and <code>data</code> is the set of
observations for the differential equation system at time point <code>t[i]</code> (or higher
dimensional). <code>priors</code> is an array of prior distributions for each
parameter, specified via a
<a href="https://juliastats.github.io/Distributions.jl/dev/" rel="nofollow">Distributions.jl</a>
type. <code>num_samples</code> is the number of samples per MCMC chain. The extra <code>kwargs</code> are given to the internal differential
equation solver.</p>
<h3><a id="user-content-dynamichmc_inference" class="anchor" aria-hidden="true" href="#dynamichmc_inference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>dynamichmc_inference</h3>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">dynamichmc_inference</span>(problem<span class="pl-k">::</span><span class="pl-c1">DiffEqBase.DEProblem</span>, algorithm, t, data,parameter_priors, 
                    parameter_transformations<span class="pl-k">=</span><span class="pl-c1">as</span>(Vector, asℝ₊, <span class="pl-c1">length</span>(parameter_priors));
                    σ_priors <span class="pl-k">=</span> <span class="pl-c1">fill</span>(<span class="pl-c1">Normal</span>(<span class="pl-c1">0</span>, <span class="pl-c1">5</span>), <span class="pl-c1">size</span>(data, <span class="pl-c1">1</span>)),
                    rng <span class="pl-k">=</span> Random<span class="pl-k">.</span>GLOBAL_RNG, num_samples <span class="pl-k">=</span> <span class="pl-c1">1000</span>,
                    AD_gradient_kind <span class="pl-k">=</span> <span class="pl-c1">Val</span>(<span class="pl-c1">:ForwardDiff</span>),solve_kwargs <span class="pl-k">=</span> (), 
                    mcmc_kwargs <span class="pl-k">=</span> (initialization <span class="pl-k">=</span> (q <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">length</span>(parameter_priors) <span class="pl-k">+</span> <span class="pl-c1">2</span>),),), sample_u0 <span class="pl-k">=</span> <span class="pl-c1">false</span>)</pre></div>
<p><code>dynamichmc_inference</code> uses <a href="https://github.com/tpapp/DynamicHMC.jl">DynamicHMC.jl</a> to
perform the bayesian parameter estimation. <code>prob</code> can be any <code>DEProblem</code>, <code>data</code> is the set
of observations for our model which is to be used in the Bayesian Inference process. <code>priors</code> represent the
choice of prior distributions for the parameters to be determined, passed as an array of <a href="https://juliastats.github.io/Distributions.jl/dev/" rel="nofollow">Distributions.jl</a>
distributions. <code>t</code> is the array of time points. <code>parameter_transformations</code> is an array of <a href="https://github.com/tpapp/ContinuousTransformations.jl">Tranformations</a>
imposed for constraining the parameter values to specific domains. <code>rng</code> is the random number generator used for MCMC. Defaults to the global one.
<code>num_samples</code> is the number of MCMC draws (default: 1000) <code>AD_gradient_kind</code> is passed on to <code>LogDensityProblems.ADgradient</code>,
make sure to <code>import</code>the corresponding library. <code>solve_kwargs</code> is passed on to <code>solve</code>
<code>mcmc_kwargs</code> are passed on as keyword arguments to <code>DynamicHMC.mcmc_with_warmup</code></p>
<h3><a id="user-content-abc_inference" class="anchor" aria-hidden="true" href="#abc_inference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>abc_inference</h3>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">abc_inference</span>(prob<span class="pl-k">::</span><span class="pl-c1">DEProblem</span>, alg, t, data, priors; ϵ<span class="pl-k">=</span><span class="pl-c1">0.001</span>,
     distancefunction <span class="pl-k">=</span> euclidean, ABCalgorithm <span class="pl-k">=</span> ABCSMC, progress <span class="pl-k">=</span> <span class="pl-c1">false</span>,
     num_samples <span class="pl-k">=</span> <span class="pl-c1">500</span>, maxiterations <span class="pl-k">=</span> <span class="pl-c1">10</span><span class="pl-k">^</span><span class="pl-c1">5</span>, kwargs<span class="pl-k">...</span>)</pre></div>
<p><code>abc_inference</code> uses <a href="https://github.com/marcjwilliams1/ApproxBayes.jl">ApproxBayes.jl</a> which uses Approximate Bayesian Computation (ABC) to
perform its parameter inference. <code>prob</code> can be any <code>DEProblem</code> with a corresponding
<code>alg</code> choice. <code>t</code> is the array of time points and <code>data[:,i]</code> is the set of
observations for the differential equation system at time point <code>t[i]</code> (or higher
dimensional). <code>priors</code> is an array of prior distributions for each
parameter, specified via a
<a href="https://juliastats.github.io/Distributions.jl/dev/" rel="nofollow">Distributions.jl</a>
type. <code>num_samples</code> is the number of posterior samples. <code>ϵ</code> is the target
distance between the data and simulated data. <code>distancefunction</code> is a distance metric specified from the
<a href="https://github.com/JuliaStats/Distances.jl">Distances.jl</a>
package, the default is <code>euclidean</code>. <code>ABCalgorithm</code> is the ABC algorithm to use, options are <code>ABCSMC</code> or <code>ABCRejection</code> from
<a href="https://github.com/marcjwilliams1/ApproxBayes.jl">ApproxBayes.jl</a>, the default
is the former which is more efficient. <code>maxiterations</code> is the maximum number of iterations before the algorithm terminates. The extra <code>kwargs</code> are given to the internal differential
equation solver.</p>
<h2><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Example</h2>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> ParameterizedFunctions, OrdinaryDiffEq, RecursiveArrayTools, Distributions
f1 <span class="pl-k">=</span> <span class="pl-c1">@ode_def</span> LotkaVolterra <span class="pl-k">begin</span>
 dx <span class="pl-k">=</span> a<span class="pl-k">*</span>x <span class="pl-k">-</span> x<span class="pl-k">*</span>y
 dy <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">3</span><span class="pl-k">*</span>y <span class="pl-k">+</span> x<span class="pl-k">*</span>y
<span class="pl-k">end</span> a

p <span class="pl-k">=</span> [<span class="pl-c1">1.5</span>]
u0 <span class="pl-k">=</span> [<span class="pl-c1">1.0</span>,<span class="pl-c1">1.0</span>]
tspan <span class="pl-k">=</span> (<span class="pl-c1">0.0</span>,<span class="pl-c1">10.0</span>)
prob1 <span class="pl-k">=</span> <span class="pl-c1">ODEProblem</span>(f1,u0,tspan,p)

σ <span class="pl-k">=</span> <span class="pl-c1">0.01</span>                         <span class="pl-c"><span class="pl-c">#</span> noise, fixed for now</span>
t <span class="pl-k">=</span> <span class="pl-c1">collect</span>(<span class="pl-c1">1.</span>:<span class="pl-c1">10.</span>)   <span class="pl-c"><span class="pl-c">#</span> observation times</span>
sol <span class="pl-k">=</span> <span class="pl-c1">solve</span>(prob1,<span class="pl-c1">Tsit5</span>())
priors <span class="pl-k">=</span> [<span class="pl-c1">Normal</span>(<span class="pl-c1">1.5</span>, <span class="pl-c1">1</span>)]
randomized <span class="pl-k">=</span> <span class="pl-c1">VectorOfArray</span>([(<span class="pl-c1">sol</span>(t[i]) <span class="pl-k">+</span> σ <span class="pl-k">*</span> <span class="pl-c1">randn</span>(<span class="pl-c1">2</span>)) <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">length</span>(t)])
data <span class="pl-k">=</span> <span class="pl-c1">convert</span>(Array,randomized)

<span class="pl-k">using</span> CmdStan <span class="pl-c"><span class="pl-c">#</span>required for using the Stan backend</span>
bayesian_result_stan <span class="pl-k">=</span> <span class="pl-c1">stan_inference</span>(prob1,t,data,priors)

bayesian_result_turing <span class="pl-k">=</span> <span class="pl-c1">turing_inference</span>(prob1,<span class="pl-c1">Tsit5</span>(),t,data,priors)

<span class="pl-k">using</span> DynamicHMC <span class="pl-c"><span class="pl-c">#</span>required for DynamicHMC backend</span>
bayesian_result_hmc <span class="pl-k">=</span> <span class="pl-c1">dynamichmc_inference</span>(prob1, <span class="pl-c1">Tsit5</span>(), t, data, priors)

bayesian_result_abc <span class="pl-k">=</span> <span class="pl-c1">abc_inference</span>(prob1, <span class="pl-c1">Tsit5</span>(), t, data, priors)</pre></div>
<h3><a id="user-content-using-save_idxs-to-declare-observables" class="anchor" aria-hidden="true" href="#using-save_idxs-to-declare-observables"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Using save_idxs to declare observables</h3>
<p>You don't always have data for all of the variables of the model. In case of certain latent variables
you can utilise the <code>save_idxs</code> kwarg to declare the oberved variables and run the inference using any
of the backends as shown below.</p>
<div class="highlight highlight-source-julia"><pre> sol <span class="pl-k">=</span> <span class="pl-c1">solve</span>(prob1,<span class="pl-c1">Tsit5</span>(),save_idxs<span class="pl-k">=</span>[<span class="pl-c1">1</span>])
 randomized <span class="pl-k">=</span> <span class="pl-c1">VectorOfArray</span>([(<span class="pl-c1">sol</span>(t[i]) <span class="pl-k">+</span> σ <span class="pl-k">*</span> <span class="pl-c1">randn</span>(<span class="pl-c1">1</span>)) <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">length</span>(t)])
 data <span class="pl-k">=</span> <span class="pl-c1">convert</span>(Array,randomized)

 <span class="pl-k">using</span> CmdStan <span class="pl-c"><span class="pl-c">#</span>required for using the Stan backend</span>
 bayesian_result_stan <span class="pl-k">=</span> <span class="pl-c1">stan_inference</span>(prob1,t,data,priors,save_idxs<span class="pl-k">=</span>[<span class="pl-c1">1</span>])

 bayesian_result_turing <span class="pl-k">=</span> <span class="pl-c1">turing_inference</span>(prob1,<span class="pl-c1">Tsit5</span>(),t,data,priors,save_idxs<span class="pl-k">=</span>[<span class="pl-c1">1</span>])
 
 <span class="pl-k">using</span> DynamicHMC <span class="pl-c"><span class="pl-c">#</span>required for DynamicHMC backend</span>
 bayesian_result_hmc <span class="pl-k">=</span> <span class="pl-c1">dynamichmc_inference</span>(prob1,<span class="pl-c1">Tsit5</span>(),t,data,priors,save_idxs <span class="pl-k">=</span> [<span class="pl-c1">1</span>])

 bayesian_result_abc <span class="pl-k">=</span> <span class="pl-c1">abc_inference</span>(prob1,<span class="pl-c1">Tsit5</span>(),t,data,priors,save_idxs<span class="pl-k">=</span>[<span class="pl-c1">1</span>])</pre></div>
</article></div>