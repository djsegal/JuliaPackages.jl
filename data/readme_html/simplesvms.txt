<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-simplesvms" class="anchor" aria-hidden="true" href="#simplesvms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>SimpleSVMs</h1>
<p><a href="https://github.com/matbesancon/SimpleSVMs.jl/actions"><img src="https://github.com/matbesancon/SimpleSVMs.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/matbesancon/SimpleSVMs.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/f7de9dc01cceb07e90a5fee5f428b737dfce24671baecef0f62befa1da4e1ced/68747470733a2f2f636f6465636f762e696f2f67682f6d6174626573616e636f6e2f53696d706c6553564d732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/matbesancon/SimpleSVMs.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<blockquote>
<p>We should have a JuMP-based SVM.</p>
</blockquote>
<p><a href="https://github.com/oxinabox">oxinabox</a></p>
<p>Implements simple Support Vector Machines using JuMP, with both L1 and L2
regularization. Since the <code>λ</code> parameter really is just a Lagrange multiplier,
penalties are implemented as constraints directly, with <code>λ</code> retrieved as a dual value.</p>
<h2><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Example</h2>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="import Random
import SimpleSVMs
import Plots
using JuMP
import Clp

Random.seed!(42)
X = vcat(randn(20, 2), randn(30,2) .+ [3.0,1.5]')
y = append!(ones(20), -ones(30))

p = Plots.scatter(X[:,1], X[:,2], color = [yi &gt; 0 ? :red : :blue for yi in y], label = &quot;&quot;)
Plots.yaxis!(p, (-2, 4.5))
for rhs in [0.5, 0.8, 1.2, 2.0, 10.0]
    global X, y
    optimizer = optimizer_with_attributes(Clp.Optimizer, &quot;LogLevel&quot; =&gt; 0)
    (m, w, b, penalty_cons) = SimpleSVMs.build_svm(SimpleSVMs.L1Penalty(rhs), X, y, optimizer)
    optimize!(m)
    loss = JuMP.objective_value(m)
    λ = -JuMP.dual(penalty_cons)
    wv = JuMP.value.(w)
    bv = JuMP.value(b)
    @info &quot;$wv $bv&quot;
    Plots.plot!(p, [0.0, 2.0], [-bv / wv[2], (-bv - 2wv[1])/wv[2]], label = &quot;RHS = $(rhs), loss = $(round(loss, digits=2)), \\lambda = $(round(λ, digits=2))&quot;)
end
Plots.title!(p, &quot;L1 loss&quot;)
Plots.savefig(&quot;example_l1.png&quot;)

import Ipopt

p = Plots.scatter(X[:,1], X[:,2], color = [yi &gt; 0 ? :red : :blue for yi in y], label = &quot;&quot;)
Plots.yaxis!(p, (-2, 4.5))
for rhs in [0.5, 0.8, 1.2, 2.0, 10.0]
    global X, y
    (m, w, b, penalty_cons) = SimpleSVMs.build_svm(SimpleSVMs.L2Penalty(rhs), X, y, Ipopt.Optimizer)
    optimize!(m)
    loss = JuMP.objective_value(m)
    λ = -JuMP.dual(penalty_cons)
    wv = JuMP.value.(w)
    bv = JuMP.value(b)
    @info &quot;$wv $bv&quot;
    Plots.plot!(p, [0.0, 2.0], [-bv / wv[2], (-bv - 2wv[1])/wv[2]], label = &quot;RHS = $(rhs), loss = $(round(loss, digits=2)), \\lambda = $(round(λ, digits=2))&quot;)
end
Plots.title!(p, &quot;L2 loss&quot;)
Plots.savefig(&quot;example_l2.png&quot;)
"><pre><span class="pl-k">import</span> Random
<span class="pl-k">import</span> SimpleSVMs
<span class="pl-k">import</span> Plots
<span class="pl-k">using</span> JuMP
<span class="pl-k">import</span> Clp

Random<span class="pl-k">.</span><span class="pl-c1">seed!</span>(<span class="pl-c1">42</span>)
X <span class="pl-k">=</span> <span class="pl-c1">vcat</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">20</span>, <span class="pl-c1">2</span>), <span class="pl-c1">randn</span>(<span class="pl-c1">30</span>,<span class="pl-c1">2</span>) <span class="pl-k">.+</span> [<span class="pl-c1">3.0</span>,<span class="pl-c1">1.5</span>]')
y <span class="pl-k">=</span> <span class="pl-c1">append!</span>(<span class="pl-c1">ones</span>(<span class="pl-c1">20</span>), <span class="pl-k">-</span><span class="pl-c1">ones</span>(<span class="pl-c1">30</span>))

p <span class="pl-k">=</span> Plots<span class="pl-k">.</span><span class="pl-c1">scatter</span>(X[:,<span class="pl-c1">1</span>], X[:,<span class="pl-c1">2</span>], color <span class="pl-k">=</span> [yi <span class="pl-k">&gt;</span> <span class="pl-c1">0</span> <span class="pl-k">?</span> <span class="pl-c1">:red</span> <span class="pl-k">:</span> <span class="pl-c1">:blue</span> <span class="pl-k">for</span> yi <span class="pl-k">in</span> y], label <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>)
Plots<span class="pl-k">.</span><span class="pl-c1">yaxis!</span>(p, (<span class="pl-k">-</span><span class="pl-c1">2</span>, <span class="pl-c1">4.5</span>))
<span class="pl-k">for</span> rhs <span class="pl-k">in</span> [<span class="pl-c1">0.5</span>, <span class="pl-c1">0.8</span>, <span class="pl-c1">1.2</span>, <span class="pl-c1">2.0</span>, <span class="pl-c1">10.0</span>]
    <span class="pl-k">global</span> X, y
    optimizer <span class="pl-k">=</span> <span class="pl-c1">optimizer_with_attributes</span>(Clp<span class="pl-k">.</span>Optimizer, <span class="pl-s"><span class="pl-pds">"</span>LogLevel<span class="pl-pds">"</span></span> <span class="pl-k">=&gt;</span> <span class="pl-c1">0</span>)
    (m, w, b, penalty_cons) <span class="pl-k">=</span> SimpleSVMs<span class="pl-k">.</span><span class="pl-c1">build_svm</span>(SimpleSVMs<span class="pl-k">.</span><span class="pl-c1">L1Penalty</span>(rhs), X, y, optimizer)
    <span class="pl-c1">optimize!</span>(m)
    loss <span class="pl-k">=</span> JuMP<span class="pl-k">.</span><span class="pl-c1">objective_value</span>(m)
    λ <span class="pl-k">=</span> <span class="pl-k">-</span>JuMP<span class="pl-k">.</span><span class="pl-c1">dual</span>(penalty_cons)
    wv <span class="pl-k">=</span> JuMP<span class="pl-k">.</span><span class="pl-c1">value</span>.(w)
    bv <span class="pl-k">=</span> JuMP<span class="pl-k">.</span><span class="pl-c1">value</span>(b)
    <span class="pl-c1">@info</span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-v">$wv</span> <span class="pl-v">$bv</span><span class="pl-pds">"</span></span>
    Plots<span class="pl-k">.</span><span class="pl-c1">plot!</span>(p, [<span class="pl-c1">0.0</span>, <span class="pl-c1">2.0</span>], [<span class="pl-k">-</span>bv <span class="pl-k">/</span> wv[<span class="pl-c1">2</span>], (<span class="pl-k">-</span>bv <span class="pl-k">-</span> <span class="pl-c1">2</span>wv[<span class="pl-c1">1</span>])<span class="pl-k">/</span>wv[<span class="pl-c1">2</span>]], label <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>RHS = <span class="pl-v">$(rhs)</span>, loss = <span class="pl-v">$(<span class="pl-c1">round</span>(loss, digits<span class="pl-k">=</span><span class="pl-c1">2</span>))</span>, <span class="pl-cce">\\</span>lambda = <span class="pl-v">$(<span class="pl-c1">round</span>(λ, digits<span class="pl-k">=</span><span class="pl-c1">2</span>))</span><span class="pl-pds">"</span></span>)
<span class="pl-k">end</span>
Plots<span class="pl-k">.</span><span class="pl-c1">title!</span>(p, <span class="pl-s"><span class="pl-pds">"</span>L1 loss<span class="pl-pds">"</span></span>)
Plots<span class="pl-k">.</span><span class="pl-c1">savefig</span>(<span class="pl-s"><span class="pl-pds">"</span>example_l1.png<span class="pl-pds">"</span></span>)

<span class="pl-k">import</span> Ipopt

p <span class="pl-k">=</span> Plots<span class="pl-k">.</span><span class="pl-c1">scatter</span>(X[:,<span class="pl-c1">1</span>], X[:,<span class="pl-c1">2</span>], color <span class="pl-k">=</span> [yi <span class="pl-k">&gt;</span> <span class="pl-c1">0</span> <span class="pl-k">?</span> <span class="pl-c1">:red</span> <span class="pl-k">:</span> <span class="pl-c1">:blue</span> <span class="pl-k">for</span> yi <span class="pl-k">in</span> y], label <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>)
Plots<span class="pl-k">.</span><span class="pl-c1">yaxis!</span>(p, (<span class="pl-k">-</span><span class="pl-c1">2</span>, <span class="pl-c1">4.5</span>))
<span class="pl-k">for</span> rhs <span class="pl-k">in</span> [<span class="pl-c1">0.5</span>, <span class="pl-c1">0.8</span>, <span class="pl-c1">1.2</span>, <span class="pl-c1">2.0</span>, <span class="pl-c1">10.0</span>]
    <span class="pl-k">global</span> X, y
    (m, w, b, penalty_cons) <span class="pl-k">=</span> SimpleSVMs<span class="pl-k">.</span><span class="pl-c1">build_svm</span>(SimpleSVMs<span class="pl-k">.</span><span class="pl-c1">L2Penalty</span>(rhs), X, y, Ipopt<span class="pl-k">.</span>Optimizer)
    <span class="pl-c1">optimize!</span>(m)
    loss <span class="pl-k">=</span> JuMP<span class="pl-k">.</span><span class="pl-c1">objective_value</span>(m)
    λ <span class="pl-k">=</span> <span class="pl-k">-</span>JuMP<span class="pl-k">.</span><span class="pl-c1">dual</span>(penalty_cons)
    wv <span class="pl-k">=</span> JuMP<span class="pl-k">.</span><span class="pl-c1">value</span>.(w)
    bv <span class="pl-k">=</span> JuMP<span class="pl-k">.</span><span class="pl-c1">value</span>(b)
    <span class="pl-c1">@info</span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-v">$wv</span> <span class="pl-v">$bv</span><span class="pl-pds">"</span></span>
    Plots<span class="pl-k">.</span><span class="pl-c1">plot!</span>(p, [<span class="pl-c1">0.0</span>, <span class="pl-c1">2.0</span>], [<span class="pl-k">-</span>bv <span class="pl-k">/</span> wv[<span class="pl-c1">2</span>], (<span class="pl-k">-</span>bv <span class="pl-k">-</span> <span class="pl-c1">2</span>wv[<span class="pl-c1">1</span>])<span class="pl-k">/</span>wv[<span class="pl-c1">2</span>]], label <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>RHS = <span class="pl-v">$(rhs)</span>, loss = <span class="pl-v">$(<span class="pl-c1">round</span>(loss, digits<span class="pl-k">=</span><span class="pl-c1">2</span>))</span>, <span class="pl-cce">\\</span>lambda = <span class="pl-v">$(<span class="pl-c1">round</span>(λ, digits<span class="pl-k">=</span><span class="pl-c1">2</span>))</span><span class="pl-pds">"</span></span>)
<span class="pl-k">end</span>
Plots<span class="pl-k">.</span><span class="pl-c1">title!</span>(p, <span class="pl-s"><span class="pl-pds">"</span>L2 loss<span class="pl-pds">"</span></span>)
Plots<span class="pl-k">.</span><span class="pl-c1">savefig</span>(<span class="pl-s"><span class="pl-pds">"</span>example_l2.png<span class="pl-pds">"</span></span>)</pre></div>
<p><a target="_blank" rel="noopener noreferrer" href="img/example_l1.png"><img src="img/example_l1.png" alt="" style="max-width:100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="img/example_l2.png"><img src="img/example_l2.png" alt="" style="max-width:100%;"></a></p>
</article></div>