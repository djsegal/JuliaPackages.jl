<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><div align="center" dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="docs/src/assets/logo.svg"><img src="docs/src/assets/logo.svg" alt="RegressionDiscontinuity.jl" width="220" style="max-width: 100%;"></a>
</div>
<h2 align="center" dir="auto"><a id="user-content-regressiondiscontinuityjl" class="anchor" aria-hidden="true" href="#regressiondiscontinuityjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>RegressionDiscontinuity.jl</h2>
<p align="center" dir="auto"> A Julia package for Regression Discontinuity analyses.</p>
<p align="center" dir="auto">
  <a href="https://github.com/nignatiadis/RegressionDiscontinuity.jl/workflows/CI/badge.svg">
    <img src="https://github.com/nignatiadis/RegressionDiscontinuity.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;">
  </a>
  <a href="https://codecov.io/gh/nignatiadis/RegressionDiscontinuity.jl/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/78108a58ac6ccb03cc28543c97d567c95aeced080f1a056209973743ab32ad44/68747470733a2f2f636f6465636f762e696f2f67682f6e69676e617469616469732f52656772657373696f6e446973636f6e74696e756974792e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/nignatiadis/RegressionDiscontinuity.jl/branch/master/graph/badge.svg" style="max-width: 100%;">
  </a>
</p>
<h2 dir="auto"><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h2>
<p dir="auto">We demonstrate the basic functionality of the package using the U.S. House Elections dataset of <a href="https://www.sciencedirect.com/science/article/abs/pii/S0304407607001121" rel="nofollow">Lee (2008)</a>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using RegressionDiscontinuity
julia&gt; data = RDData(RegressionDiscontinuity.Lee08())"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> RegressionDiscontinuity
julia<span class="pl-k">&gt;</span> data <span class="pl-k">=</span> <span class="pl-c1">RDData</span>(RegressionDiscontinuity<span class="pl-k">.</span><span class="pl-c1">Lee08</span>())</pre></div>
<h3 dir="auto"><a id="user-content-naive-local-linear-regression" class="anchor" aria-hidden="true" href="#naive-local-linear-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Naive Local Linear Regression</h3>
<p dir="auto">The following estimates the sharp RDD estimate using local linear regression
without any kind of bias correction. It uses a rectangular kernel and the
Imbens-Kalyanaraman bandwidth.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; fit(NaiveLocalLinearRD(kernel = Rectangular(), bandwidth = ImbensKalyanaraman()), data.ZsR, data.Ys)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">fit</span>(<span class="pl-c1">NaiveLocalLinearRD</span>(kernel <span class="pl-k">=</span> <span class="pl-c1">Rectangular</span>(), bandwidth <span class="pl-k">=</span> <span class="pl-c1">ImbensKalyanaraman</span>()), data<span class="pl-k">.</span>ZsR, data<span class="pl-k">.</span>Ys)</pre></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="Local linear regression for regression discontinuity design
       â‹…â‹…â‹…â‹… Naive inference (not accounting for bias)
       â‹…â‹…â‹…â‹… Rectangular kernel (U[-0.5,0.5])
       â‹…â‹…â‹…â‹… Imbens Kalyanaraman bandwidth
       â‹…â‹…â‹…â‹… Eicker White Huber variance
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                          h       Ï„Ì‚         se         bias     z   p-val  Lower 95%  Upper 95%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Sharp RD estimand  0.462024  0.08077  0.0087317  unaccounted  9.25  &lt;1e-99  0.0802225  0.0813175
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"><pre class="notranslate"><code>Local linear regression for regression discontinuity design
       â‹…â‹…â‹…â‹… Naive inference (not accounting for bias)
       â‹…â‹…â‹…â‹… Rectangular kernel (U[-0.5,0.5])
       â‹…â‹…â‹…â‹… Imbens Kalyanaraman bandwidth
       â‹…â‹…â‹…â‹… Eicker White Huber variance
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                          h       Ï„Ì‚         se         bias     z   p-val  Lower 95%  Upper 95%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Sharp RD estimand  0.462024  0.08077  0.0087317  unaccounted  9.25  &lt;1e-99  0.0802225  0.0813175
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
</code></pre></div>
<h3 dir="auto"><a id="user-content-min-max-optimal-estimator" class="anchor" aria-hidden="true" href="#min-max-optimal-estimator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Min-Max Optimal Estimator</h3>
<p dir="auto">The following estimates the sharp RDD estimate for the min-max optimal
estimator of <a href="https://arxiv.org/abs/1705.01677" rel="nofollow">Imbens and Wager (2019)</a>.</p>
<p dir="auto">The estimate assumes a bound of 14.28 on the second derivative of the conditional
mean functions for the outcome in the Lee data. The optimization uses a user specified solver. The fastest option is <a href="https://docs.mosek.com/9.2/install/installation.html" rel="nofollow">Mosek</a>, which is free for academics. An open source alternative is <a href="https://github.com/chriscoey/Hypatia.jl">Hypatia.jl</a>, but it is currently slower for this problem.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using RegressionDiscontinuity
julia&gt; using MosekTools
julia&gt; fit(ImbensWagerOptRD(B=14.28, solver=Mosek.Optimizer), data.ZsR, data.Ys)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> RegressionDiscontinuity
julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> MosekTools
julia<span class="pl-k">&gt;</span> <span class="pl-c1">fit</span>(<span class="pl-c1">ImbensWagerOptRD</span>(B<span class="pl-k">=</span><span class="pl-c1">14.28</span>, solver<span class="pl-k">=</span>Mosek<span class="pl-k">.</span>Optimizer), data<span class="pl-k">.</span>ZsR, data<span class="pl-k">.</span>Ys)</pre></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="Imbens-Wager (2019) optimized regression discontinuity design
Max Second Derivative Bound: 14.28
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                          Ï„Ì‚         se   max bias  Lower 95%  Upper 95%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Sharp RD estimand  0.0592235  0.0197343  0.0101986  0.0159069    0.10254
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"><pre class="notranslate"><code>Imbens-Wager (2019) optimized regression discontinuity design
Max Second Derivative Bound: 14.28
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                          Ï„Ì‚         se   max bias  Lower 95%  Upper 95%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Sharp RD estimand  0.0592235  0.0197343  0.0101986  0.0159069    0.10254
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
</code></pre></div>
<h3 dir="auto"><a id="user-content-noise-induced-randomization" class="anchor" aria-hidden="true" href="#noise-induced-randomization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Noise-Induced Randomization</h3>
<p dir="auto">We conduct inference using Noise-Induced Randomization (NIR), as described in <a href="https://arxiv.org/abs/2004.09458" rel="nofollow">EIWW</a>. We apply NIR, assuming the sensitivity model ğ’¯â‚€ on a regression discontinuity design artificially constructed from test scores in early childhood (data from the Early Childhood Longitudinal Study).</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using RegressionDiscontinuity
julia&gt; using Empirikos
julia&gt; using MosekTools
julia&gt; ecls_tbl = RegressionDiscontinuity.raw_table(RegressionDiscontinuity.ECLS_EIWW())
julia&gt; Zs = NormalSample.(ecls_tbl.Z, minimum(ecls_tbl.SE))
julia&gt; ZsR = RunningVariable(Zs, -0.2, :â‰¥)
julia&gt; Ys = ecls_tbl.Y
julia&gt; nir = NoiseInducedRandomization(; solver=Mosek.Optimizer)
julia&gt; nir_fit = fit(nir, ZsR, Ys)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> RegressionDiscontinuity
julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Empirikos
julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> MosekTools
julia<span class="pl-k">&gt;</span> ecls_tbl <span class="pl-k">=</span> RegressionDiscontinuity<span class="pl-k">.</span><span class="pl-c1">raw_table</span>(RegressionDiscontinuity<span class="pl-k">.</span><span class="pl-c1">ECLS_EIWW</span>())
julia<span class="pl-k">&gt;</span> Zs <span class="pl-k">=</span> <span class="pl-c1">NormalSample</span>.(ecls_tbl<span class="pl-k">.</span>Z, <span class="pl-c1">minimum</span>(ecls_tbl<span class="pl-k">.</span>SE))
julia<span class="pl-k">&gt;</span> ZsR <span class="pl-k">=</span> <span class="pl-c1">RunningVariable</span>(Zs, <span class="pl-k">-</span><span class="pl-c1">0.2</span>, :<span class="pl-k">â‰¥</span>)
julia<span class="pl-k">&gt;</span> Ys <span class="pl-k">=</span> ecls_tbl<span class="pl-k">.</span>Y
julia<span class="pl-k">&gt;</span> nir <span class="pl-k">=</span> <span class="pl-c1">NoiseInducedRandomization</span>(; solver<span class="pl-k">=</span>Mosek<span class="pl-k">.</span>Optimizer)
julia<span class="pl-k">&gt;</span> nir_fit <span class="pl-k">=</span> <span class="pl-c1">fit</span>(nir, ZsR, Ys)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="RD analysis with Noise Induced Randomization (NIR)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                            Ï„Ì‚         se   max bias  Lower 95%  Upper 95%  CI halfwidth
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Weighted RD estimand  0.355071  0.0232147  0.0109893   0.304914   0.405229     0.0501575
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"><pre>RD analysis with Noise Induced Randomization (NIR)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                            Ï„Ì‚         se   max bias  Lower <span class="pl-c1">95</span><span class="pl-k">%</span>  Upper <span class="pl-c1">95</span><span class="pl-k">%</span>  CI halfwidth
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Weighted RD estimand  <span class="pl-c1">0.355071</span>  <span class="pl-c1">0.0232147</span>  <span class="pl-c1">0.0109893</span>   <span class="pl-c1">0.304914</span>   <span class="pl-c1">0.405229</span>     <span class="pl-c1">0.0501575</span>
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</pre></div>
<h3 dir="auto"><a id="user-content-mccrary-density-test" class="anchor" aria-hidden="true" href="#mccrary-density-test"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>McCrary Density Test</h3>
<p dir="auto">The following estimates a test of manipulation of the running variable based on <a href="https://www.sciencedirect.com/science/article/abs/pii/S0304407607001133" rel="nofollow">McCrary (2008)</a>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using RegressionDiscontinuity
julia&gt; fit(McCraryTest(), data.ZsR)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> RegressionDiscontinuity
julia<span class="pl-k">&gt;</span> <span class="pl-c1">fit</span>(<span class="pl-c1">McCraryTest</span>(), data<span class="pl-k">.</span>ZsR)</pre></div>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="The McCrary (2008) test for manipulation in the
running variable for RDD.
          â‹…â‹…â‹…â‹… Bin size: 0.0112
          â‹…â‹…â‹…â‹… Bandwidth size: 0.2426
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    Î¸Ì‚         ÏƒÌ‚     z   p-val
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
McCrary Test  0.102688  0.0798507  1.29  0.1984
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"><pre class="notranslate"><code>The McCrary (2008) test for manipulation in the
running variable for RDD.
          â‹…â‹…â‹…â‹… Bin size: 0.0112
          â‹…â‹…â‹…â‹… Bandwidth size: 0.2426
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    Î¸Ì‚         ÏƒÌ‚     z   p-val
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
McCrary Test  0.102688  0.0798507  1.29  0.1984
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
</code></pre></div>
</article></div>