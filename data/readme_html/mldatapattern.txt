<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-mldatapattern" class="anchor" aria-hidden="true" href="#mldatapattern"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MLDataPattern</h1>
<p><em>Utility package for subsetting, partitioning, iterating, and
resampling of Machine Learning datasets. Aside from providing
common functionality, this library also allows for first class
support of custom user-defined data structures.</em></p>
<p><a href="LICENSE.md"><img src="https://camo.githubusercontent.com/d4d7e802861ee34f2db3a98f8558278fb2a7a106/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c6174" alt="" data-canonical-src="https://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" style="max-width:100%;"></a>
<a href="http://mldatapatternjl.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img src="https://camo.githubusercontent.com/f2d8f24c508816bc9c3a19b46c13de78f56f0fdb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e7376673f7374796c653d666c6174" alt="" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg?style=flat" style="max-width:100%;"></a>
<a href="https://travis-ci.org/JuliaML/MLDataPattern.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/60e8248ce514380152c87cf51d56a49b5729d127/68747470733a2f2f6170692e7472617669732d63692e6f72672f4a756c69614d4c2f4d4c446174615061747465726e2e6a6c2e737667" alt="" data-canonical-src="https://api.travis-ci.org/JuliaML/MLDataPattern.jl.svg" style="max-width:100%;"></a>
<a href="https://juliaci.github.io/NanosoldierReports/pkgeval_badges/report.html" rel="nofollow"><img src="https://camo.githubusercontent.com/de8cd3a56319c642d60de7717787980e74dc9904/68747470733a2f2f6a756c696163692e6769746875622e696f2f4e616e6f736f6c646965725265706f7274732f706b676576616c5f6261646765732f4d2f4d4c446174615061747465726e2e737667" alt="" data-canonical-src="https://juliaci.github.io/NanosoldierReports/pkgeval_badges/M/MLDataPattern.svg" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/JuliaML/MLDataPattern.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/a186e53a58de071142315a36ff70a2d54c3e3f09/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4a756c69614d4c2f4d4c446174615061747465726e2e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://coveralls.io/repos/github/JuliaML/MLDataPattern.jl/badge.svg?branch=master" style="max-width:100%;"></a></p>
<h2><a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Introduction</h2>
<p>Typical Machine Learning experiments require a lot of rather
mundane but error prone data handling glue code. One particularly
interesting category of data handling functionality - and the
sole focus of this package - are what we call <strong>data access
pattern</strong>. These "pattern" include <em>subsetting</em>, <em>resampling</em>,
<em>iteration</em>, and <em>partitioning</em> of various types of data sets.</p>
<p>MLDataPattern was designed around the core requirement of
providing first class support for user-defined data sources. This
idea is based on the assumption that the data source a user is
working with, is likely of some very user-specific custom type.
That said, we also put a lot of attention into first class
support for the most commonly used data container, such as
<code>Array</code>.</p>
<p>Note that this package serves as a back-end for the end-user
facing <a href="https://github.com/JuliaML/MLDataUtils.jl">MLDataUtils.jl</a>.
If you are an end-user who is mainly interested in working with
data interactively and conveniently you may want to use MLDataUtils
instead.</p>
<h2><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Example</h2>
<p>Let us take a look at a hello world example (with little
explanation) to get a feeling for how to use this package in a
typical ML scenario. Note how the code snippet below does not
reason about any training algorithm in any way. It is not the
responsibility of the access pattern to decide in what form some
algorithm needs the data. The output of the pattern depend solely
on the input. In fact, the package is designed to be data
agnostic. Instead, the focus is on efficiently chaining
subsetting operations and thus to avoid temporary allocations
where possible.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> MLDataUtils <span class="pl-c"><span class="pl-c">#</span> reexports MLDataPattern</span>

<span class="pl-c"><span class="pl-c">#</span> X is a matrix of floats</span>
<span class="pl-c"><span class="pl-c">#</span> Y is a vector of strings</span>
X, Y <span class="pl-k">=</span> MLDataUtils<span class="pl-k">.</span><span class="pl-c1">load_iris</span>()

<span class="pl-c"><span class="pl-c">#</span> The iris dataset is ordered according to their labels,</span>
<span class="pl-c"><span class="pl-c">#</span> which means that we should shuffle the dataset before</span>
<span class="pl-c"><span class="pl-c">#</span> partitioning it into training- and test-set.</span>
Xs, Ys <span class="pl-k">=</span> <span class="pl-c1">shuffleobs</span>((X, Y))
<span class="pl-c"><span class="pl-c">#</span> Notice how we use tuples to group data.</span>

<span class="pl-c"><span class="pl-c">#</span> We leave out 15 % of the data for testing</span>
(cv_X, cv_Y), (test_X, test_Y) <span class="pl-k">=</span> <span class="pl-c1">splitobs</span>((Xs, Ys); at <span class="pl-k">=</span> <span class="pl-c1">0.85</span>)

<span class="pl-c"><span class="pl-c">#</span> Next we partition the data using a 10-fold scheme.</span>
<span class="pl-c"><span class="pl-c">#</span> Notice how we do not need to splat train into X and Y</span>
<span class="pl-k">for</span> (train, (val_X, val_Y)) <span class="pl-k">in</span> <span class="pl-c1">kfolds</span>((cv_X, cv_Y); k <span class="pl-k">=</span> <span class="pl-c1">10</span>)

    <span class="pl-k">for</span> epoch <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">100</span>
        <span class="pl-c"><span class="pl-c">#</span> Iterate over the data using mini-batches of 5 observations each</span>
        <span class="pl-k">for</span> (batch_X, batch_Y) <span class="pl-k">in</span> <span class="pl-c1">eachbatch</span>(train, size <span class="pl-k">=</span> <span class="pl-c1">5</span>)
            <span class="pl-c"><span class="pl-c">#</span> ... train supervised model on minibatches here</span>
        <span class="pl-k">end</span>
    <span class="pl-k">end</span>
<span class="pl-k">end</span></pre></div>
<p>In the above code snippet, the inner loop for <code>eachbatch</code> is the
only place where data other than indices is actually being
copied. That is because <code>cv_X</code>, <code>test_X</code>, <code>val_X</code>, etc. are all
array views of type <code>SubArray</code> (the same applies to all the Y's
of course). In contrast to this, <code>batch_X</code> and <code>batch_Y</code> will be
of type <code>Array</code>. Naturally, array views only work for arrays, but
this package provides a generalization of such a "subset" for any
type of data container.</p>
<p>Furthermore both, <code>batch_X</code> and <code>batch_Y</code>, will be the same
instances each iteration with only their values changed. In other
words, they both are preallocated buffers that will be reused
each iteration and filled with the data for the current batch.
Naturally, it is not a requirement to work with buffers like
this, as stateful iterators can have undesired side effects when
used without care. This package provides different alternatives
for different use cases.</p>
<h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Documentation</h2>
<p>For a much more detailed treatment check out the <a href="http://mldatapatternjl.readthedocs.io/en/latest/" rel="nofollow">latest documentation</a></p>
<p>Additionally, you can make use of Julia's native docsystem. The
following example shows how to get additional information on
<code>kfolds</code> within Julia's REPL:</p>
<pre><code>?kfolds
</code></pre>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<p>This package is registered in <code>METADATA.jl</code> and can be installed
as usual. Just start up Julia and type the following code snippet
into the REPL. It makes use of the native Julia package manger.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>MLDataPattern<span class="pl-pds">"</span></span>)</pre></div>
<h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>License</h2>
<p>This code is free to use under the terms of the MIT license</p>

</article></div>