<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-lengthchannelsjl" class="anchor" aria-hidden="true" href="#lengthchannelsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LengthChannels.jl</h1>
<p><a href="https://travis-ci.org/baggepinnen/LengthChannels.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/648f77b884ad6693a41d2edd9bc5cec04cde25c8/68747470733a2f2f7472617669732d63692e6f72672f626167676570696e6e656e2f4c656e6774684368616e6e656c732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/baggepinnen/LengthChannels.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/baggepinnen/LengthChannels.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/0f37648678454f61ce907b4ea2f48ce5920a30d1/68747470733a2f2f636f6465636f762e696f2f67682f626167676570696e6e656e2f4c656e6774684368616e6e656c732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/baggepinnen/LengthChannels.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p>This package defines a type <code>LengthChannel{T} &lt;: AbstractChannel{T}</code> which simply adds information about the length of the channel when it is iterated. The constructor behaves the same as the constructor for <code>Channel</code>, but takes an additional integer specifying the length. This length is not to be confused with the buffer size of the channel. When a <code>LengthChannel</code> is iterated, it continues until it has iterated the specified number of elements, after that the channel may be automatically closed (keyword <code>autoclose</code>), even if there are more elements put in the channel.</p>
<p>Examples:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> LengthChannels, Test
len,bufsize <span class="pl-k">=</span> <span class="pl-c1">10</span>,<span class="pl-c1">4</span>
lc <span class="pl-k">=</span> <span class="pl-c1">LengthChannel</span><span class="pl-c1">{Int}</span>(len, bufsize) <span class="pl-k">do</span> ch
    <span class="pl-k">for</span> i <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">100</span>
        <span class="pl-c1">put!</span>(ch, i)
    <span class="pl-k">end</span>
<span class="pl-k">end</span>

<span class="pl-c1">@test</span> <span class="pl-c1">length</span>(lc) <span class="pl-k">==</span> len
cc <span class="pl-k">=</span> <span class="pl-c1">collect</span>(lc)
<span class="pl-c1">@test</span> <span class="pl-c1">length</span>(cc) <span class="pl-k">==</span> len
<span class="pl-c1">@test</span> cc <span class="pl-k">==</span> <span class="pl-c1">1</span><span class="pl-k">:</span>l
<span class="pl-c1">@test</span> <span class="pl-c1">isopen</span>(lc)</pre></div>
<p>The constructor to a <code>LengthChannel</code> takes a keyword argument <code>autoclose=false (default)</code> which determines if the channel closes automatically after having iterated for the specified length. It might be useful to keep it open if you want to iterate the specified length several times, e.g. by performing several epochs of training. Just make sure the channel is still being populated, using e.g. the <code>while true</code> pattern below.</p>
<h2><a id="user-content-use-as-buffered-iterator-for-machine-learning" class="anchor" aria-hidden="true" href="#use-as-buffered-iterator-for-machine-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Use as buffered iterator for machine learning</h2>
<p>A typical use-case for a channel with length is as a buffered dataset for training machine learning models. The following is an example that reads audio data from disk and does some light pre-processing before putting it in the channel</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> LengthChannels, Flux, Random
files      <span class="pl-k">=</span> <span class="pl-c1">readdir</span>(path_to_datafiles)
buffersize <span class="pl-k">=</span> <span class="pl-c1">10</span>
dataset <span class="pl-k">=</span> <span class="pl-c1">LengthChannel</span><span class="pl-c1">{Vector{Float32}}</span>(<span class="pl-c1">length</span>(files), buffersize, spawn<span class="pl-k">=</span><span class="pl-c1">true</span>) <span class="pl-k">do</span> ch
    <span class="pl-k">while</span> <span class="pl-c1">true</span>
        <span class="pl-k">for</span> file <span class="pl-k">in</span> <span class="pl-c1">shuffle</span>(files)
            data <span class="pl-k">=</span> <span class="pl-c1">read_from_disk</span>(file)
            data <span class="pl-k">=</span> <span class="pl-c1">pre_process</span>(data)
            <span class="pl-c1">put!</span>(ch, data)
        <span class="pl-k">end</span>
    <span class="pl-k">end</span>
<span class="pl-k">end</span></pre></div>
<p>The <code>while true</code> pattern is useful when you want to be able to iterate the channel several times over. Each time the channel above is iterated, it will produce <code>length(files)</code> values, but it can be iterated again without recreating the channel. If the <code>while true</code> loop was omitted, the channel would be closed after one full iteration.</p>
<p>A <strong>batch iterator</strong> suitable for training CNN models in Flux can be obtained like so</p>
<div class="highlight highlight-source-julia"><pre>batchsize  <span class="pl-k">=</span> <span class="pl-c1">16</span>
buffersize <span class="pl-k">=</span> <span class="pl-c1">10</span>
files      <span class="pl-k">=</span> <span class="pl-c1">readdir</span>(path_to_datafiles)
dataset <span class="pl-k">=</span> <span class="pl-c1">LengthChannel</span><span class="pl-c1">{Array{Float32,4}}</span>(<span class="pl-c1">length</span>(files)<span class="pl-k">รท</span>batchsize, buffersize, spawn<span class="pl-k">=</span><span class="pl-c1">true</span>) <span class="pl-k">do</span> ch
    batch <span class="pl-k">=</span> <span class="pl-c1">Array</span><span class="pl-c1">{Float32,4}</span>(undef,height,width,nchannels,batchsize) <span class="pl-c"><span class="pl-c">#</span> Batches in last dim</span>
    bi <span class="pl-k">=</span> <span class="pl-c1">1</span> <span class="pl-c"><span class="pl-c">#</span> Batch index</span>
    <span class="pl-k">while</span> <span class="pl-c1">true</span>
        <span class="pl-k">for</span> file <span class="pl-k">in</span> <span class="pl-c1">shuffle</span>(files)
            data <span class="pl-k">=</span> <span class="pl-c1">read_from_disk</span>(file)
            batch[:,:,:,bi] <span class="pl-k">.=</span> data
            bi <span class="pl-k">+=</span> <span class="pl-c1">1</span>
            <span class="pl-k">if</span> bi <span class="pl-k">&gt;</span> batchsize
                bi <span class="pl-k">=</span> <span class="pl-c1">1</span>
                <span class="pl-c1">put!</span>(ch, <span class="pl-c1">copy</span>(batch))
            <span class="pl-k">end</span>
        <span class="pl-k">end</span>
    <span class="pl-k">end</span>
<span class="pl-k">end</span></pre></div>
<p>where <code>height,width,nchannels</code> are integers specifying the size of your data.</p>
<h2><a id="user-content-putting-data-on-gpu" class="anchor" aria-hidden="true" href="#putting-data-on-gpu"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Putting data on GPU</h2>
<p>You may not put data on the GPU from any other thread than the main thread, hence <code>spawn=false</code> is required for a channel putting data on GPU. To still allow reading and preprocessing on a separate thread (this is more performant), we provide the wrapper constructor <code>LengthChannel{T}(f, dataset::LengthChannel)</code>, which returns a new <code>LengthChannel</code> where <code>f</code> is applied to each element of <code>dataset</code>.</p>
<p>If <code>T</code> is omitted while wrapping a channel, it is assumed that <code>f(eltype(dataset)) == typeof(f(::eltype(dataset)))</code> or in words, <code>f</code> must have a method returning the type resulting from applying <code>f</code> to an element of the wrapped channel.</p>
<p>By having <code>f=cu</code> or <code>f=gpu</code> which puts data on a GPU, you now have an efficient way of training models on the GPU, while reading data in a separate thread. Primitive benchmarking showed some 0-20% performance improvement using this strategy over putting data on the GPU as it is taken out of the dataset. If <code>cu/gpu</code> become thread-safe, this improvement may become larger.</p>
<p><em>Note:</em> If your entire dataset fit onto the GPU and you do not run out of memory while performing backpropagation, the fastest method is <em>by far</em> to keep all data on the GPU during the entire training. You can try by simply <code>gpu.(collect(dataset))</code> or <code>collect(dataset)</code> if the channel already puts data on the GPU. The function <code>fullsizeof(dataset::LengthChannel)</code> will tell you the size in bytes required to <code>collect</code> the dataset.</p>
</article></div>