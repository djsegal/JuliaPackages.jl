<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-tableio" class="anchor" aria-hidden="true" href="#tableio"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>TableIO</h1>
<p dir="auto"><a href="https://travis-ci.com/lungben/TableIO.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/373b2bb2c46c4100e6e9ffaaa9efa323e9023da2963e8d1efec6b2d0ee5c493b/68747470733a2f2f7472617669732d63692e636f6d2f6c756e6762656e2f5461626c65494f2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/lungben/TableIO.jl.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/lungben/TableIO.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/6e4585feafb37c9da9370891c748e17df57f5f8533a77ec3fc84c78c0865ce3e/68747470733a2f2f636f6465636f762e696f2f67682f6c756e6762656e2f5461626c65494f2e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/lungben/TableIO.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">A small "glue" package for reading and writing tabular data. It aims to provide a uniform api for reading and writing tabular data from and to multiple sources.
This package is "intelligent" in this sense that it automatically selects the right reading / writing methods depending on the file extension.</p>
<h2 dir="auto"><a id="user-content-supported-formats" class="anchor" aria-hidden="true" href="#supported-formats"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Supported Formats</h2>
<ul dir="auto">
<li>CSV via <a href="https://github.com/JuliaData/CSV.jl">https://github.com/JuliaData/CSV.jl</a></li>
<li>JSON via <a href="https://github.com/JuliaData/JSONTables.jl">https://github.com/JuliaData/JSONTables.jl</a></li>
<li>Zipped CSV or JSON via <a href="https://github.com/fhs/ZipFile.jl">https://github.com/fhs/ZipFile.jl</a></li>
<li>JDF via <a href="https://github.com/xiaodaigh/JDF.jl">https://github.com/xiaodaigh/JDF.jl</a></li>
<li>Parquet via <a href="https://github.com/JuliaIO/Parquet.jl">https://github.com/JuliaIO/Parquet.jl</a></li>
<li>Apache Arrow via <a href="https://github.com/JuliaData/Arrow.jl">https://github.com/JuliaData/Arrow.jl</a></li>
<li>Excel (xlsx) via <a href="https://github.com/felipenoris/XLSX.jl">https://github.com/felipenoris/XLSX.jl</a></li>
<li>SQLite via <a href="https://github.com/JuliaDatabases/SQLite.jl">https://github.com/JuliaDatabases/SQLite.jl</a></li>
<li>PostgreSQL via <a href="https://github.com/invenia/LibPQ.jl">https://github.com/invenia/LibPQ.jl</a> - note that CSV.jl is required for PostgreSQL, too.</li>
<li>Read-only: Stata (dta), SPSS (dat) and SAS (sas7bdat) via <a href="https://github.com/queryverse/StatFiles.jl">https://github.com/queryverse/StatFiles.jl</a></li>
<li>HDF5 (Pandas format) via <a href="https://github.com/JuliaPy/Pandas.jl">Pandas.jl</a> - requires Python with Pandas and PyTables installed on Python side.</li>
</ul>
<p dir="auto">The underlying packages are not direct dependencies of TableIO and are therefore not installed automatically with it.
This is for reduction of installation size and package load time.</p>
<p dir="auto">For installation of the Python requirements for Pandas HDF5 use the following Julia commands:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="ENV[&quot;PYTHON&quot;] = &quot;&quot; # to use a separate Conda environment for Julia
using Pkg
Pkg.add([&quot;PyCall&quot;, &quot;Conda&quot;, &quot;Pandas&quot;])
Pkg.build(&quot;PyCall&quot;)
using Conda
Conda.add(&quot;pandas&quot;)
Conda.add(&quot;pytables&quot;)"><pre class="notranslate"><code>ENV["PYTHON"] = "" # to use a separate Conda environment for Julia
using Pkg
Pkg.add(["PyCall", "Conda", "Pandas"])
Pkg.build("PyCall")
using Conda
Conda.add("pandas")
Conda.add("pytables")
</code></pre></div>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using Pkg
Pkg.add(&quot;TableIO&quot;)
using TableIO"><pre class="notranslate"><code>using Pkg
Pkg.add("TableIO")
using TableIO
</code></pre></div>
<p dir="auto">Before using a specific format, the corresponding package needs to be installed and imported:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="] add JDF
import JDF # or using JDF"><pre class="notranslate"><code>] add JDF
import JDF # or using JDF
</code></pre></div>
<p dir="auto">If the file format specific library is not imported and / or installed, an error message is raised.</p>
<h2 dir="auto"><a id="user-content-reading-data" class="anchor" aria-hidden="true" href="#reading-data"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Reading Data</h2>
<p dir="auto">The function</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="read_table"><pre class="notranslate"><code>read_table
</code></pre></div>
<p dir="auto">reads a data source (file or database) and returns a Table.jl interface, e.g. for creating a DataFrame.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using TableIO, DataFrames"><pre class="notranslate"><code>using TableIO, DataFrames
</code></pre></div>
<p dir="auto">CSV Format:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using CSV
df = DataFrame(read_table(&quot;my_data.csv&quot;); copycols=false) # Keyword arguments can be passed to the CSV reader (CSV.jl)
df = DataFrame(read_table(&quot;my_data.zip&quot;); copycols=false) # zipped CSV format (assuming there is only 1 file in the archive)"><pre class="notranslate"><code>using CSV
df = DataFrame(read_table("my_data.csv"); copycols=false) # Keyword arguments can be passed to the CSV reader (CSV.jl)
df = DataFrame(read_table("my_data.zip"); copycols=false) # zipped CSV format (assuming there is only 1 file in the archive)
</code></pre></div>
<p dir="auto">JSON Format:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using Dates, JSONTables
df = read_table(&quot;my_data.json&quot;) |&gt; DataFrame # note that |&gt; DataFrame(; copycols=false) gives wrong column types!
df.my_date_col = Dates.(df.my_date_col) # Dates are imported as strings by default, need to be manually converted

df = read_table(&quot;my_data.zip&quot;, &quot;my_data.json&quot;) |&gt; DataFrame"><pre class="notranslate"><code>using Dates, JSONTables
df = read_table("my_data.json") |&gt; DataFrame # note that |&gt; DataFrame(; copycols=false) gives wrong column types!
df.my_date_col = Dates.(df.my_date_col) # Dates are imported as strings by default, need to be manually converted

df = read_table("my_data.zip", "my_data.json") |&gt; DataFrame
</code></pre></div>
<p dir="auto">Binary Formats:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using JDF
df = DataFrame(read_table(&quot;my_data.jdf&quot;); copycols=false) # JDF (compressed binary format)

using Parquet
df = DataFrame(read_table(&quot;my_data.parquet&quot;); copycols=false) # Parquet

using Arrow
df = DataFrame(read_table(&quot;my_data.arrow&quot;); copycols=false) # Apache Arrow

import Pandas # using gives a naming conflict
df = DataFrame(read_table(&quot;my_data.hdf&quot;, &quot;key&quot;); copycols=false) # HDF5 (via Pandas)"><pre class="notranslate"><code>using JDF
df = DataFrame(read_table("my_data.jdf"); copycols=false) # JDF (compressed binary format)

using Parquet
df = DataFrame(read_table("my_data.parquet"); copycols=false) # Parquet

using Arrow
df = DataFrame(read_table("my_data.arrow"); copycols=false) # Apache Arrow

import Pandas # using gives a naming conflict
df = DataFrame(read_table("my_data.hdf", "key"); copycols=false) # HDF5 (via Pandas)
</code></pre></div>
<p dir="auto">Excel:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using XLSX
df = DataFrame(read_table(&quot;my_data.xlsx&quot;); copycols=false) # imports 1st sheet
df = DataFrame(read_table(&quot;my_data.xlsx&quot;, &quot;MyAwesomeSheet&quot;); copycols=false) # imports named sheet"><pre class="notranslate"><code>using XLSX
df = DataFrame(read_table("my_data.xlsx"); copycols=false) # imports 1st sheet
df = DataFrame(read_table("my_data.xlsx", "MyAwesomeSheet"); copycols=false) # imports named sheet
</code></pre></div>
<p dir="auto">SQLite:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using SQLite
df = DataFrame(read_table(&quot;my_data.db&quot;, &quot;my_table&quot;); copycols=false) # SQLite from file, table name must be given"><pre class="notranslate"><code>using SQLite
df = DataFrame(read_table("my_data.db", "my_table"); copycols=false) # SQLite from file, table name must be given
</code></pre></div>
<p dir="auto">Alternatively, SQLite database objects could be used:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using SQLite
sqlite_db = SQLite.DB(&quot;my_data.db&quot;)
df = DataFrame(read_table(sqlite_db, &quot;my_table&quot;); copycols=false) # SQLite from database connection, table name must be given"><pre class="notranslate"><code>using SQLite
sqlite_db = SQLite.DB("my_data.db")
df = DataFrame(read_table(sqlite_db, "my_table"); copycols=false) # SQLite from database connection, table name must be given
</code></pre></div>
<p dir="auto">PostgreSQL:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using LibPQ, CSV # CSV is required here because `write_table!` for PostgreSQL depends on CSV
postgres_conn = LibPQ.Connection(&quot;dbname=postgres user=postgres&quot;)
df = DataFrame(read_table(postgres_conn, &quot;my_table&quot;); copycols=false) # reading from Postgres connection"><pre class="notranslate"><code>using LibPQ, CSV # CSV is required here because `write_table!` for PostgreSQL depends on CSV
postgres_conn = LibPQ.Connection("dbname=postgres user=postgres")
df = DataFrame(read_table(postgres_conn, "my_table"); copycols=false) # reading from Postgres connection
</code></pre></div>
<p dir="auto">StatFiles.jl integration:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using StatFiles
df = DataFrame(read_table(&quot;my_data.dta&quot;); copycols=false) # Stata
df = DataFrame(read_table(&quot;my_data.sav&quot;); copycols=false) # SPSS
df = DataFrame(read_table(&quot;my_data.sas7bdat&quot;); copycols=false) # SAS"><pre class="notranslate"><code>using StatFiles
df = DataFrame(read_table("my_data.dta"); copycols=false) # Stata
df = DataFrame(read_table("my_data.sav"); copycols=false) # SPSS
df = DataFrame(read_table("my_data.sas7bdat"); copycols=false) # SAS
</code></pre></div>
<p dir="auto">For data formats supporting multiple tables inside a file, the function <code>list_tables</code> returns an alphabetically sorted list of table names.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="table_names = list_tables(filename)"><pre class="notranslate"><code>table_names = list_tables(filename)
</code></pre></div>
<h2 dir="auto"><a id="user-content-writing-data" class="anchor" aria-hidden="true" href="#writing-data"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Writing Data</h2>
<p dir="auto">The function</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="write_table!"><pre class="notranslate"><code>write_table!
</code></pre></div>
<p dir="auto">writes a Table.jl compatible data source into a file or databse.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using TableIO, DataFrames"><pre class="notranslate"><code>using TableIO, DataFrames
</code></pre></div>
<p dir="auto">CSV Format:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using CSV
write_table!(&quot;my_data.csv&quot;, df)

write_table!(&quot;my_data.zip&quot;, df) # zipped CSV. If no &quot;inner&quot; file name is given, the table is always stored in csv format with the same file name as the zip archive"><pre class="notranslate"><code>using CSV
write_table!("my_data.csv", df)

write_table!("my_data.zip", df) # zipped CSV. If no "inner" file name is given, the table is always stored in csv format with the same file name as the zip archive
</code></pre></div>
<p dir="auto">JSON Format:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using JSONTables
write_table!(&quot;my_data.json&quot;, df) # dictionary of arrays
write_table!(&quot;my_data.json&quot;, df, orientation=:objecttable) # dictionary of arrays
write_table!(&quot;my_data.json&quot;, df, orientation=:arraytable) # array of dictionaries

write_table!(&quot;my_data.zip&quot;, &quot;my_data.json&quot;, df) # need to explicitly give a file name inside zip archive, otherwise csv format is used"><pre class="notranslate"><code>using JSONTables
write_table!("my_data.json", df) # dictionary of arrays
write_table!("my_data.json", df, orientation=:objecttable) # dictionary of arrays
write_table!("my_data.json", df, orientation=:arraytable) # array of dictionaries

write_table!("my_data.zip", "my_data.json", df) # need to explicitly give a file name inside zip archive, otherwise csv format is used
</code></pre></div>
<p dir="auto">Binary Formats:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using JDF
write_table!(&quot;my_data.jdf&quot;, df) # JDF (compressed binary format)

using Parquet
write_table!(&quot;my_data.parquet&quot;, df) # Parquet - note that Date element type is not supported yet

using Arrow
write_table!(&quot;my_data.arrow&quot;, df) # Apache Arrow

import Pandas # using gives a naming conflict
write_table!(&quot;my_data.hdf&quot;, &quot;key&quot;, df) # HDF5 (via Pandas)"><pre class="notranslate"><code>using JDF
write_table!("my_data.jdf", df) # JDF (compressed binary format)

using Parquet
write_table!("my_data.parquet", df) # Parquet - note that Date element type is not supported yet

using Arrow
write_table!("my_data.arrow", df) # Apache Arrow

import Pandas # using gives a naming conflict
write_table!("my_data.hdf", "key", df) # HDF5 (via Pandas)
</code></pre></div>
<p dir="auto">Excel:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="write_table!(&quot;my_data.xlsx&quot;, &quot;test_sheet_42&quot;, df) # creates sheet with defined name"><pre class="notranslate"><code>write_table!("my_data.xlsx", "test_sheet_42", df) # creates sheet with defined name
</code></pre></div>
<p dir="auto">SQLite:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using SQLite
write_table!(&quot;my_data.db&quot;, &quot;my_table&quot;, df) # SQLite from file, table must not exist

sqlite_db = SQLite.DB(&quot;my_data.db&quot;)
write_table!(sqlite_db, &quot;my_table&quot;, df) # SQLite from database connection"><pre class="notranslate"><code>using SQLite
write_table!("my_data.db", "my_table", df) # SQLite from file, table must not exist

sqlite_db = SQLite.DB("my_data.db")
write_table!(sqlite_db, "my_table", df) # SQLite from database connection
</code></pre></div>
<p dir="auto">PostgreSQL:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using LibPQ, CSV
postgres_conn = LibPQ.Connection(&quot;dbname=postgres user=postgres&quot;)
write_table!(postgres_conn, &quot;my_table&quot;, df) # table must exist and be compatible with the input data"><pre class="notranslate"><code>using LibPQ, CSV
postgres_conn = LibPQ.Connection("dbname=postgres user=postgres")
write_table!(postgres_conn, "my_table", df) # table must exist and be compatible with the input data
</code></pre></div>
<p dir="auto">StatFiles.jl integration: <code>write_table!</code> is not supported.</p>
<p dir="auto">Additionally, it is possible to export tabular data into Julia code (<code>.jl</code> files):</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="write_table!(&quot;my_data.jl&quot;, &quot;my_table&quot;, df)"><pre class="notranslate"><code>write_table!("my_data.jl", "my_table", df)
</code></pre></div>
<p dir="auto">To read this data, the corresponding Julia source code file can be included:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="include(&quot;my_data.jl&quot;)
@assert DataFrame(my_table) == df"><pre class="notranslate"><code>include("my_data.jl")
@assert DataFrame(my_table) == df
</code></pre></div>
<h2 dir="auto"><a id="user-content-conversions" class="anchor" aria-hidden="true" href="#conversions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Conversions</h2>
<p dir="auto">It is possible to pass the output of <code>read_table</code> directly as input to <code>write_table!</code> for converting tabular data between different formats:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="name1 = joinpath(testpath, &quot;test.zip&quot;) # zipped CSV
name2 = joinpath(testpath, &quot;testx.jdf&quot;) # binary
name3 = joinpath(testpath, &quot;testx.xlsx&quot;) # Excel
name4 = joinpath(testpath, &quot;testx.db&quot;) # SQLite

write_table!(name2, read_table(name1))
write_table!(name3, read_table(name2))
write_table!(name4, &quot;my_table&quot;, read_table(name3))

df_recovered = DataFrame(read_table(name4, &quot;my_table&quot;); copycols=false)"><pre class="notranslate"><code>name1 = joinpath(testpath, "test.zip") # zipped CSV
name2 = joinpath(testpath, "testx.jdf") # binary
name3 = joinpath(testpath, "testx.xlsx") # Excel
name4 = joinpath(testpath, "testx.db") # SQLite

write_table!(name2, read_table(name1))
write_table!(name3, read_table(name2))
write_table!(name4, "my_table", read_table(name3))

df_recovered = DataFrame(read_table(name4, "my_table"); copycols=false)
</code></pre></div>
<h2 dir="auto"><a id="user-content-plutoui-integration" class="anchor" aria-hidden="true" href="#plutoui-integration"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>PlutoUI Integration</h2>
<p dir="auto">In a <a href="https://github.com/fonsp/Pluto.jl">Pluto.jl</a> notebook, TableIO can be used directly on a <a href="https://github.com/fonsp/PlutoUI.jl">PlutoUI.jl</a> FilePicker output.</p>
<p dir="auto">Example (run in a Pluto.jl notebook):</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using PlutoUI, TableIO, DataFrames
@bind f PlutoUI.FilePicker() # pick any supported file type
df = DataFrame(read_table(f); copycols=false)"><pre class="notranslate"><code>using PlutoUI, TableIO, DataFrames
@bind f PlutoUI.FilePicker() # pick any supported file type
df = DataFrame(read_table(f); copycols=false)
</code></pre></div>
<p dir="auto">This functionality works for all supported file formats if the corresponding import packages are installed.
It is not required to import them, this is done automatically.</p>
<h2 dir="auto"><a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Testing</h2>
<p dir="auto">The PostgreSQL component requires a running PostgreSQL database for unit tests. This database can be started using the following command:</p>
<p dir="auto"><code>docker run --rm --detach --name test-libpqjl -e POSTGRES_HOST_AUTH_METHOD=trust -p 5432:5432 postgres</code></p>
<h2 dir="auto"><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Disclaimer</h2>
<p dir="auto">If you encounter warnings like</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="┌ Warning: Package TableIO does not have CSV in its dependencies:
│ - If you have TableIO checked out for development and have
│   added CSV as a dependency but haven't updated your primary
│   environment's manifest file, try `Pkg.resolve()`.
│ - Otherwise you may need to report an issue with TableIO
└ Loading CSV into TableIO from project dependency, future warnings for TableIO are suppressed."><pre class="notranslate"><code>┌ Warning: Package TableIO does not have CSV in its dependencies:
│ - If you have TableIO checked out for development and have
│   added CSV as a dependency but haven't updated your primary
│   environment's manifest file, try `Pkg.resolve()`.
│ - Otherwise you may need to report an issue with TableIO
└ Loading CSV into TableIO from project dependency, future warnings for TableIO are suppressed.
</code></pre></div>
<p dir="auto">please ignore them.</p>
<p dir="auto">TableIO purposely has not included the libraries for the specific file formats as its own dependencies.</p>
</article></div>