<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-abstractdifferentiation" class="anchor" aria-hidden="true" href="#abstractdifferentiation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>AbstractDifferentiation</h1>
<p dir="auto"><a href="https://github.com/JuliaDiff/AbstractDifferentiation.jl/actions/workflows/CI.yml?query=branch%3Amaster"><img src="https://github.com/JuliaDiff/AbstractDifferentiation.jl/actions/workflows/CI.yml/badge.svg?branch=master" alt="CI" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/JuliaDiff/AbstractDifferentiation.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/9cfb431299eebbc52002a935c6d68ad20cbce627c25943039b736c39f37de296/68747470733a2f2f636f6465636f762e696f2f67682f4a756c6961446966662f4162737472616374446966666572656e74696174696f6e2e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/JuliaDiff/AbstractDifferentiation.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Motivation</h2>
<p dir="auto">This is a package that implements an abstract interface for differentiation in Julia. This is particularly useful for implementing abstract algorithms requiring derivatives, gradients, jacobians, Hessians or multiple of those without depending on specific automatic differentiation packages' user interfaces.</p>
<p dir="auto">Julia has more (automatic) differentiation packages than you can count on 2 hands. Different packages have different user interfaces. Therefore, having a backend-agnostic interface to request the function value and its gradient for example is necessary to avoid a combinatorial explosion of code when trying to support every differentiation package in Julia in every algorithm package requiring gradients. For higher order derivatives, the situation is even more dire since you can combine any 2 differentiation backends together to create a new higher-order backend.</p>
<h2 dir="auto"><a id="user-content-loading-abstractdifferentiation" class="anchor" aria-hidden="true" href="#loading-abstractdifferentiation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Loading <code>AbstractDifferentiation</code></h2>
<p dir="auto">To load <code>AbstractDifferentiation</code>, it is recommended to use</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import AbstractDifferentiation as AD"><pre><span class="pl-k">import</span> AbstractDifferentiation <span class="pl-k">as</span> AD</pre></div>
<p dir="auto">With the <code>AD</code> alias you can access names inside of <code>AbstractDifferentiation</code> using <code>AD.&lt;&gt;</code> instead of typing the long name <code>AbstractDifferentiation</code>.</p>
<h2 dir="auto"><a id="user-content-abstractdifferentiation-backends" class="anchor" aria-hidden="true" href="#abstractdifferentiation-backends"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>AbstractDifferentiation</code> backends</h2>
<p dir="auto">To use <code>AbstractDifferentiation</code>, first construct a backend instance <code>ab::AD.AbstractBackend</code> using your favorite differentiation package in Julia that supports <code>AbstractDifferentiation</code>.
In particular, you may want to use <code>AD.ReverseRuleConfigBackend(ruleconfig)</code> for any <a href="https://github.com/JuliaDiff/ChainRules.jl">ChainRules.jl</a>-compatible reverse mode differentiation package.</p>
<p dir="auto">The following backends are temporarily made available by <code>AbstractDifferentiation</code> as soon as their corresponding package is loaded (thanks to <a href="https://pkgdocs.julialang.org/dev/creating-packages/#Weak-dependencies" rel="nofollow">weak dependencies</a> on Julia â‰¥ 1.9 and <a href="https://github.com/JuliaPackaging/Requires.jl">Requires.jl</a> on older Julia versions):</p>
<ul dir="auto">
<li><code>AD.ForwardDiffBackend()</code> for <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff.jl</a></li>
<li><code>AD.FiniteDifferencesBackend()</code> for <a href="https://github.com/JuliaDiff/FiniteDifferences.jl">FiniteDifferences.jl</a></li>
<li><code>AD.ReverseDiffBackend()</code> for <a href="https://github.com/JuliaDiff/ReverseDiff.jl">ReverseDiff.jl</a></li>
<li><code>AD.TrackerBackend()</code> for <a href="https://github.com/FluxML/Tracker.jl">Tracker.jl</a></li>
<li><code>AD.ZygoteBackend()</code> for <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a>, which is a special case of <code>AD.ReverseRuleConfigBackend</code></li>
</ul>
<p dir="auto">In the long term, these backend objects (and many more) will be defined within their respective packages to enforce the <code>AbstractDifferentiation</code> interface.</p>
<p dir="auto">Here's an example:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; import AbstractDifferentiation as AD, Zygote

julia&gt; ab = AD.ZygoteBackend()
AbstractDifferentiation.ReverseRuleConfigBackend{Zygote.ZygoteRuleConfig{Zygote.Context}}(Zygote.ZygoteRuleConfig{Zygote.Context}(Zygote.Context(nothing)))

julia&gt; f(x) = log(sum(exp, x))
f (generic function with 1 method)

julia&gt; AD.gradient(ab, f, rand(10))
([0.07163448353282538, 0.08520350535348796, 0.09675622487503996, 0.1522744408520505, 0.12174662595572318, 0.07996969757526722, 0.07832665607158593, 0.11001685581681672, 0.06691909637037166, 0.1371524135968315],)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">import</span> AbstractDifferentiation <span class="pl-k">as</span> AD, Zygote

julia<span class="pl-k">&gt;</span> ab <span class="pl-k">=</span> AD<span class="pl-k">.</span><span class="pl-c1">ZygoteBackend</span>()
AbstractDifferentiation<span class="pl-k">.</span><span class="pl-c1">ReverseRuleConfigBackend</span><span class="pl-c1">{Zygote.ZygoteRuleConfig{Zygote.Context}}</span>(Zygote<span class="pl-k">.</span><span class="pl-c1">ZygoteRuleConfig</span><span class="pl-c1">{Zygote.Context}</span>(Zygote<span class="pl-k">.</span><span class="pl-c1">Context</span>(<span class="pl-c1">nothing</span>)))

julia<span class="pl-k">&gt;</span> <span class="pl-en">f</span>(x) <span class="pl-k">=</span> <span class="pl-c1">log</span>(<span class="pl-c1">sum</span>(exp, x))
f (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> AD<span class="pl-k">.</span><span class="pl-c1">gradient</span>(ab, f, <span class="pl-c1">rand</span>(<span class="pl-c1">10</span>))
([<span class="pl-c1">0.07163448353282538</span>, <span class="pl-c1">0.08520350535348796</span>, <span class="pl-c1">0.09675622487503996</span>, <span class="pl-c1">0.1522744408520505</span>, <span class="pl-c1">0.12174662595572318</span>, <span class="pl-c1">0.07996969757526722</span>, <span class="pl-c1">0.07832665607158593</span>, <span class="pl-c1">0.11001685581681672</span>, <span class="pl-c1">0.06691909637037166</span>, <span class="pl-c1">0.1371524135968315</span>],)</pre></div>
<p dir="auto">For higher order derivatives, you can build higher order backends using <code>AD.HigherOrderBackend</code>. For instance, let <code>ab_f</code> be a forward-mode automatic differentiation backend and let <code>ab_r</code> be a reverse-mode automatic differentiation backend. To construct a higher order backend for doing forward-over-reverse-mode automatic differentiation, use <code>AD.HigherOrderBackend((ab_f, ab_r))</code>. To construct a higher order backend for doing reverse-over-forward-mode automatic differentiation, use <code>AD.HigherOrderBackend((ab_r, ab_f))</code>.</p>
<h2 dir="auto"><a id="user-content-backend-agnostic-interface" class="anchor" aria-hidden="true" href="#backend-agnostic-interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Backend-agnostic interface</h2>
<p dir="auto">The following list of functions is the officially supported differentiation interface in <code>AbstractDifferentiation</code>.</p>
<h3 dir="auto"><a id="user-content-derivativegradientjacobianhessian" class="anchor" aria-hidden="true" href="#derivativegradientjacobianhessian"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Derivative/Gradient/Jacobian/Hessian</h3>
<p dir="auto">The following list of functions can be used to request the derivative, gradient, Jacobian or Hessian without the function value.</p>
<ul dir="auto">
<li><code>ds = AD.derivative(ab::AD.AbstractBackend, f, xs::Number...)</code>: computes the derivatives <code>ds</code> of <code>f</code> wrt the numbers <code>xs</code> using the backend <code>ab</code>. <code>ds</code> is a tuple of derivatives, one for each element in <code>xs</code>.</li>
<li><code>gs = AD.gradient(ab::AD.AbstractBackend, f, xs...)</code>: computes the gradients <code>gs</code> of <code>f</code> wrt the inputs <code>xs</code> using the backend <code>ab</code>. <code>gs</code> is a tuple of gradients, one for each element in <code>xs</code>.</li>
<li><code>js = AD.jacobian(ab::AD.AbstractBackend, f, xs...)</code>: computes the Jacobians <code>js</code> of <code>f</code> wrt the inputs <code>xs</code> using the backend <code>ab</code>. <code>js</code> is a tuple of Jacobians, one for each element in <code>xs</code>.</li>
<li><code>h = AD.hessian(ab::AD.AbstractBackend, f, x)</code>: computes the Hessian <code>h</code> of <code>f</code> wrt the input <code>x</code> using the backend <code>ab</code>. <code>hessian</code> currently only supports a single input.</li>
</ul>
<h3 dir="auto"><a id="user-content-value-and-derivativegradientjacobianhessian" class="anchor" aria-hidden="true" href="#value-and-derivativegradientjacobianhessian"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Value and Derivative/Gradient/Jacobian/Hessian</h3>
<p dir="auto">The following list of functions can be used to request the function value along with its derivative, gradient, Jacobian or Hessian. You can also request the function value, its gradient and Hessian for single-input functions.</p>
<ul dir="auto">
<li><code>(v, ds) = AD.value_and_derivative(ab::AD.AbstractBackend, f, xs::Number...)</code>: computes the function value <code>v = f(xs...)</code> and the derivatives <code>ds</code> of <code>f</code> wrt the numbers <code>xs</code> using the backend <code>ab</code>. <code>ds</code> is a tuple of derivatives, one for each element in <code>xs</code>.</li>
<li><code>(v, gs) = AD.value_and_gradient(ab::AD.AbstractBackend, f, xs...)</code>: computes the function value <code>v = f(xs...)</code> and the gradients <code>gs</code> of <code>f</code> wrt the inputs <code>xs</code> using the backend <code>ab</code>. <code>gs</code> is a tuple of gradients, one for each element in <code>xs</code>.</li>
<li><code>(v, js) = AD.value_and_jacobian(ab::AD.AbstractBackend, f, xs...)</code>: computes the function value <code>v = f(xs...)</code> and the Jacobians <code>js</code> of <code>f</code> wrt the inputs <code>xs</code> using the backend <code>ab</code>. <code>js</code> is a tuple of Jacobians, one for each element in <code>xs</code>.</li>
<li><code>(v, h) = AD.value_and_hessian(ab::AD.AbstractBackend, f, x)</code>: computes the function value <code>v = f(x)</code> and the Hessian <code>h</code> of <code>f</code> wrt the input <code>x</code> using the backend <code>ab</code>. <code>hessian</code> currently only supports a single input.</li>
<li><code>(v, g, h) = AD.value_gradient_and_hessian(ab::AD.AbstractBackend, f, x)</code>: computes the function value <code>v = f(x)</code> and the gradient <code>g</code> and Hessian <code>h</code> of <code>f</code> wrt the input <code>x</code> using the backend <code>ab</code>. <code>hessian</code> currently only supports a single input.</li>
</ul>
<h3 dir="auto"><a id="user-content-jacobian-vector-products-aka-pushforward" class="anchor" aria-hidden="true" href="#jacobian-vector-products-aka-pushforward"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Jacobian vector products (aka pushforward)</h3>
<p dir="auto">This operation goes by a few names. Refer to the <a href="https://juliadiff.org/ChainRulesCore.jl/stable/#The-propagators:-pushforward-and-pullback" rel="nofollow">ChainRules documentation</a> for more on terminology. For a single input, single output function <code>f</code> with a Jacobian <code>J</code>, the pushforward operator <code>pf_f</code> is equivalent to applying the function <code>v -&gt; J * v</code> on a (tangent) vector <code>v</code>.</p>
<p dir="auto">The following functions can be used to request a function that returns the pushforward operator/function. In order to request the pushforward function <code>pf_f</code> of a function <code>f</code> at the inputs <code>xs</code>, you can use either of:</p>
<ul dir="auto">
<li><code>pf_f = AD.pushforward_function(ab::AD.AbstractBackend, f, xs...)</code>: returns the pushforward function <code>pf_f</code> of the function <code>f</code> at the inputs <code>xs</code>. <code>pf_f</code> is a function that accepts the tangents <code>vs</code> as input which is a tuple of length equal to the length of the tuple <code>xs</code>. If <code>f</code> has a single input, <code>pf_f</code> can also accept a single input instead of a 1-tuple.</li>
<li><code>value_and_pf_f = AD.value_and_pushforward_function(ab::AD.AbstractBackend, f, xs...)</code>: returns a function <code>value_and_pf_f</code> which accepts the tangent <code>vs</code> as input which is a tuple of length equal to the length of the tuple <code>xs</code>. If <code>f</code> has a single input, <code>value_and_pf_f</code> can accept a single input instead of a 1-tuple. <code>value_and_pf_f</code> returns a 2-tuple, namely the value <code>f(xs...)</code> and output of the pushforward operator.</li>
</ul>
<h3 dir="auto"><a id="user-content-vector-jacobian-products-aka-pullback" class="anchor" aria-hidden="true" href="#vector-jacobian-products-aka-pullback"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Vector Jacobian products (aka pullback)</h3>
<p dir="auto">This operation goes by a few names. Refer to the <a href="https://juliadiff.org/ChainRulesCore.jl/stable/#The-propagators:-pushforward-and-pullback" rel="nofollow">ChainRules documentation</a> for more on terminology. For a single input, single output function <code>f</code> with a Jacobian <code>J</code>, the pullback operator <code>pb_f</code> is equivalent to applying the function <code>v -&gt; v' * J</code> on a (co-tangent) vector <code>v</code>.</p>
<p dir="auto">The following functions can be used to request the pullback operator/function with or without the function value. In order to request the pullback function <code>pb_f</code> of a function <code>f</code> at the inputs <code>xs</code>, you can use either of:</p>
<ul dir="auto">
<li><code>pb_f = AD.pullback_function(ab::AD.AbstractBackend, f, xs...)</code>: returns the pullback function <code>pb_f</code> of the function <code>f</code> at the inputs <code>xs</code>. <code>pb_f</code> is a function that accepts the co-tangents <code>vs</code> as input which is a tuple of length equal to the number of outputs of <code>f</code>. If <code>f</code> has a single output, <code>pb_f</code> can also accept a single input instead of a 1-tuple.</li>
<li><code>value_and_pb_f = AD.value_and_pullback_function(ab::AD.AbstractBackend, f, xs...)</code>: returns a function <code>value_and_pb_f</code> which accepts the co-tangent <code>vs</code> as input which is a tuple of length equal to the number of outputs of <code>f</code>. If <code>f</code> has a single output, <code>value_and_pb_f</code> can accept a single input instead of a 1-tuple. <code>value_and_pb_f</code> returns a 2-tuple, namely the value <code>f(xs...)</code> and output of the pullback operator.</li>
</ul>
<h3 dir="auto"><a id="user-content-lazy-operators" class="anchor" aria-hidden="true" href="#lazy-operators"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Lazy operators</h3>
<p dir="auto">You can also get a struct for the lazy derivative/gradient/Jacobian/Hessian of a function. You can then use the <code>*</code> operator to apply the lazy operator on a value or tuple of the correct shape. To get a lazy derivative/gradient/Jacobian/Hessian use any one of:</p>
<ul dir="auto">
<li><code>ld = lazy_derivative(ab::AbstractBackend, f, xs::Number...)</code>: returns an operator <code>ld</code> for multiplying by the derivative of <code>f</code> at <code>xs</code>. You can apply the operator by multiplication e.g. <code>ld * y</code> where <code>y</code> is a number if <code>f</code> has a single input, a tuple of the same length as <code>xs</code> if <code>f</code> has multiple inputs, or an array of numbers/tuples.</li>
<li><code>lg = lazy_gradient(ab::AbstractBackend, f, xs...)</code>: returns an operator <code>lg</code> for multiplying by the gradient of <code>f</code> at <code>xs</code>. You can apply the operator by multiplication e.g. <code>lg * y</code> where <code>y</code> is a number if <code>f</code> has a single input or a tuple of the same length as <code>xs</code> if <code>f</code> has multiple inputs.</li>
<li><code>lh = lazy_hessian(ab::AbstractBackend, f, x)</code>: returns an operator <code>lh</code> for multiplying by the Hessian of the scalar-valued function <code>f</code> at <code>x</code>. You can apply the operator by multiplication e.g. <code>lh * y</code> or <code>y' * lh</code> where <code>y</code> is a number or a vector of the appropriate length.</li>
<li><code>lj = lazy_jacobian(ab::AbstractBackend, f, xs...)</code>: returns an operator <code>lj</code> for multiplying by the Jacobian of <code>f</code> at <code>xs</code>. You can apply the operator by multiplication e.g. <code>lj * y</code> or <code>y' * lj</code> where <code>y</code> is a number, vector or tuple of numbers and/or vectors. If <code>f</code> has multiple inputs, <code>y</code> in <code>lj * y</code> should be a tuple. If <code>f</code> has multiply outputs, <code>y</code> in <code>y' * lj</code> should be a tuple. Otherwise, it should be a scalar or a vector of the appropriate length.</li>
</ul>
<h2 dir="auto"><a id="user-content-citing-this-package" class="anchor" aria-hidden="true" href="#citing-this-package"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Citing this package</h2>
<p dir="auto">If you use this package in your work, please cite the package:</p>
<div class="highlight highlight-text-bibtex notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="@article{schafer2021abstractdifferentiation,
  title={AbstractDifferentiation. jl: Backend-Agnostic Differentiable Programming in Julia},
  author={Sch{\&quot;a}fer, Frank and Tarek, Mohamed and White, Lyndon and Rackauckas, Chris},
  journal={NeurIPS 2021 Differentiable Programming Workshop},
  year={2021}
}"><pre><span class="pl-k">@article</span>{<span class="pl-en">schafer2021abstractdifferentiation</span>,
  <span class="pl-s">title</span>=<span class="pl-s"><span class="pl-pds">{</span>AbstractDifferentiation. jl: Backend-Agnostic Differentiable Programming in Julia<span class="pl-pds">}</span></span>,
  <span class="pl-s">author</span>=<span class="pl-s"><span class="pl-pds">{</span>Sch{\"a}fer, Frank and Tarek, Mohamed and White, Lyndon and Rackauckas, Chris<span class="pl-pds">}</span></span>,
  <span class="pl-s">journal</span>=<span class="pl-s"><span class="pl-pds">{</span>NeurIPS 2021 Differentiable Programming Workshop<span class="pl-pds">}</span></span>,
  <span class="pl-s">year</span>=<span class="pl-s"><span class="pl-pds">{</span>2021<span class="pl-pds">}</span></span>
}</pre></div>
</article></div>