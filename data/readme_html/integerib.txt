<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-integeribjl" class="anchor" aria-hidden="true" href="#integeribjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>IntegerIB.jl</h1>
<p>A julia module to apply the <strong>information bottleneck</strong> for clustering when dealing with <strong>categorical data</strong>.</p>
<table>
<thead>
<tr>
<th align="center"><strong>Travis</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://travis-ci.com/johncwok/IntegerIB.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/7e5f85a5bef8c6a5b0f87b13b6b96393f0cf15badc9509f8e291f777aa34c048/68747470733a2f2f7472617669732d63692e636f6d2f6a6f686e63776f6b2f496e746567657249422e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/johncwok/IntegerIB.jl.svg?branch=master" style="max-width:100%;"></a></td>
</tr>
</tbody>
</table>
<p>The information bottleneck concept can be used in the context of categorical data analysis to do <strong>clustering</strong>,
or in other words, to look for categories which have equivalent functions. <br>
Given a time-series, it looks for a <strong>concise representation</strong> of the data that preserves as much <strong>meaningful information</strong> as possible.
In a sense, it is a lossy compression algorithm. The information to preserve can be seen as the ability to make predictions :
given a specific <strong>context</strong>, how much of what is coming next can we predict ? <br>
The goal of this algorithm is to cluster categorical data while preserving predictive power. To learn more about the information bottleneck
you can look at <em><a href="https://arxiv.org/abs/1604.00268" rel="nofollow">https://arxiv.org/abs/1604.00268</a></em> or <em><a href="https://doi.org/10.1080/09298215.2015.1036888" rel="nofollow">https://doi.org/10.1080/09298215.2015.1036888</a></em></p>
<h2><a id="user-content-quick-overview" class="anchor" aria-hidden="true" href="#quick-overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Quick overview</h2>
<p>To do a simple IB clustering of categorical data do as follow, you just need to instantiate a model and optimize it:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="data = readdlm(&quot;/path/to/data/&quot;)
model = IB(x) #you can call IB(x, beta). beta is a real number that controls the amount of compression.
IB_optimize!(model) 
"><pre>data <span class="pl-k">=</span> <span class="pl-c1">readdlm</span>(<span class="pl-s"><span class="pl-pds">"</span>/path/to/data/<span class="pl-pds">"</span></span>)
model <span class="pl-k">=</span> <span class="pl-c1">IB</span>(x) <span class="pl-c"><span class="pl-c">#</span>you can call IB(x, beta). beta is a real number that controls the amount of compression.</span>
<span class="pl-c1">IB_optimize!</span>(model) </pre></div>
<p>Then, to see the results :</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="print_results(model)
"><pre><span class="pl-c1">print_results</span>(model)</pre></div>
<p>Rows are clusters and columns correspond to the input categories. The result is the probability <code>p(t|x)</code> of a category belonging to a given cluster. Since most of the probabilities are very low, <code>print_results</code> <strong>sets every <code>p(t|x)</code> &gt; 0.1 to 1, 0 otherwise</strong> for ease of readability (see further usage for more options).</p>
<h4><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>example:</h4>
<p>Here is a concrete example with a dataset chorales from Bach. The input categories are the 7 types of diatonic chords described in classical music theory.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="bach = CSV.read(&quot;..\\data\\bach_histogram&quot;)
pxy = Matrix(bach)./sum(Matrix(bach))
model = IB(pxy, 1000) #You can also instantiate 'model' with a probability distribution instead of a time-series.
IB_optimize!(model)
print_results(model)
"><pre>bach <span class="pl-k">=</span> CSV<span class="pl-k">.</span><span class="pl-c1">read</span>(<span class="pl-s"><span class="pl-pds">"</span>..<span class="pl-cce">\\</span>data<span class="pl-cce">\\</span>bach_histogram<span class="pl-pds">"</span></span>)
pxy <span class="pl-k">=</span> <span class="pl-c1">Matrix</span>(bach)<span class="pl-k">./</span><span class="pl-c1">sum</span>(<span class="pl-c1">Matrix</span>(bach))
model <span class="pl-k">=</span> <span class="pl-c1">IB</span>(pxy, <span class="pl-c1">1000</span>) <span class="pl-c"><span class="pl-c">#</span>You can also instantiate 'model' with a probability distribution instead of a time-series.</span>
<span class="pl-c1">IB_optimize!</span>(model)
<span class="pl-c1">print_results</span>(model)</pre></div>
<p>The output is in perfect accordance with western music theory. It tells us that we can group category 1, 3 and 6 together : this corresponds to the <code>tonic</code> function in classical harmony. Category 2 and 4 have been clustered together, this is what harmony calls <code>subdominant</code>. Finall category 5 and 7 are joined : this is the <code>dominant</code> function.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/34754896/90241511-7c625300-de2b-11ea-800d-3cee1da9fdf5.PNG"><img src="https://user-images.githubusercontent.com/34754896/90241511-7c625300-de2b-11ea-800d-3cee1da9fdf5.PNG" width="400" style="max-width:100%;"></a></p>
<h2><a id="user-content-further-usage" class="anchor" aria-hidden="true" href="#further-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Further usage</h2>
<h4><a id="user-content-types-of-algorithm" class="anchor" aria-hidden="true" href="#types-of-algorithm"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Types of algorithm:</h4>
<p>You can choose between the original IB algorithm (Tishby, 1999) which does <em>soft</em> clustering or the <em>deterministic</em> IB algorithm (DJ Strouse, 2016) doing <em>hard</em> clustering. The former seems to produce more meaningfull clustering. When instantiating a model <code>IB(x::Array{Float64,1}, β = 200, algorithm = "IB")</code>, change the argument <code>algorithm</code> to "DIB" to use the deterministic IB algorithm.</p>
<h4><a id="user-content-changing-default-parameters" class="anchor" aria-hidden="true" href="#changing-default-parameters"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Changing default parameters:</h4>
<p>The two most important parameters for this kind of IB clustering are the amount <strong>compression</strong> and the definition of <strong>relevant context</strong>.<br></p>
<ul>
<li>
<p>The amount of compression is governed by the parameter <code>β</code> which you provide when instantiating an IB model <code>IB(x::Array{Float64,1}, β = 200, algorithm = "IB")</code>. The smaller <code>β</code> is, the more compression. The higher <code>β</code>, the bigger the mutual information I(X;T) between cluster and original category is. <br>
There are two undesirable situations :</p>
<ul>
<li>if <code>β</code> is too small, maximal compression is achieved and all information is lost.</li>
<li>if <code>β</code> is too high, there is effectively no compression. With "DIB" algorithm, this can even happen even for <code>β</code> &gt; ~5. <strong>In the case of the "IB" algorithm this doesn't happen</strong>, however for <code>β</code> values &gt; ~1000, the algorithm doesnt optimize anything because all metrics are effectively 0. In practice, when using the "IB" algorithm, a high <code>β</code> value (~200) is a good starting point.<br></li>
</ul>
</li>
<li>
<p>The definition of <strong>context</strong> is essential to specify what the meaningfull information to preserve is. The default behavior is to care about predictions, context is defined  as the next element. For example, if we have a time-series <code>x = ["a","b","c","a","b"]</code>, the context vector y is <code>y = ["b","c","a","b"]</code>. We try to compress <code>x</code> in a representation that share as much informations with <code>y</code> as possible. Other definition of the context are possible : one can take the next element and the previous one. To do that that you would call :</p>
</li>
</ul>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="data = CSV.read(&quot;..\\data\\coltrane&quot;)
context = get_y(data, &quot;an&quot;) # &quot;an&quot; stands for adjacent neighbors.
model = IB(data, context, 500) # giving the context as input during instantiation.
IB_optimize!(model)
"><pre>data <span class="pl-k">=</span> CSV<span class="pl-k">.</span><span class="pl-c1">read</span>(<span class="pl-s"><span class="pl-pds">"</span>..<span class="pl-cce">\\</span>data<span class="pl-cce">\\</span>coltrane<span class="pl-pds">"</span></span>)
context <span class="pl-k">=</span> <span class="pl-c1">get_y</span>(data, <span class="pl-s"><span class="pl-pds">"</span>an<span class="pl-pds">"</span></span>) <span class="pl-c"><span class="pl-c">#</span> "an" stands for adjacent neighbors.</span>
model <span class="pl-k">=</span> <span class="pl-c1">IB</span>(data, context, <span class="pl-c1">500</span>) <span class="pl-c"><span class="pl-c">#</span> giving the context as input during instantiation.</span>
<span class="pl-c1">IB_optimize!</span>(model)</pre></div>
<h4><a id="user-content-other-functionalities" class="anchor" aria-hidden="true" href="#other-functionalities"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Other functionalities</h4>
<p>To get the value of the different <strong>metrics</strong> (<em>H(T), I(X;T), I(Y;T)</em> and <em>L</em>) use the <code>calc_metrics(model::IB)</code> function. <br></p>
<p>Since the algorithm is not 100% guaranteed to converge to a <strong>global maxima</strong>, you can use the <code>search_optima!(model::IB, n_iter = 10000)</code> to initialize and optimize your model <code>n_iter</code> times and select the optimization with the lowest <code>L</code> value. This is an in-place modification so you do not need to call <code>IB_optimize!(model::IB)</code> after calling <code>search_optima!</code>.<br></p>
<p>If you want to get the <strong>raw probabilities</strong> <code>p(t|x)</code> after optimization (<code>print_results</code> filters it for ease of readability), you can access them with :</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="pt_x = model.qt_x
"><pre>pt_x <span class="pl-k">=</span> model<span class="pl-k">.</span>qt_x</pre></div>
<p>Similarly, you can also get p(y|t) or p(t) with <code>model.qy_t</code> and <code>model.qt</code>.<br></p>
<p>Finally, the function <code>get_IB_curve(m::IB, start = 0.1, stop = 400, step = 0.05; glob = false)</code> lets you plot the <strong>"optimal" IB curve</strong>. Here is an example with the bach chorale dataset:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using Plots
bach = CSV.read(&quot;..\\data\\bach_histogram&quot;)
pxy = Matrix(bach)./sum(Matrix(bach))
model = IB(pxy, 1000)
x, y = get_IB_curve(model)
a = plot(x, y, color = &quot;black&quot;, linewidth = 2, label = &quot;Optimal IB curve&quot;, title = &quot;Optimal IB curve \n Bach's chorale dataset&quot;)
scatter!(a, x, y, color = &quot;black&quot;, markersize = 1.7, xlabel = &quot;I(X;T) \n&quot;, ylabel = &quot;- \n I(Y;T)&quot;, label = &quot;&quot;, legend = :topleft)
"><pre><span class="pl-k">using</span> Plots
bach <span class="pl-k">=</span> CSV<span class="pl-k">.</span><span class="pl-c1">read</span>(<span class="pl-s"><span class="pl-pds">"</span>..<span class="pl-cce">\\</span>data<span class="pl-cce">\\</span>bach_histogram<span class="pl-pds">"</span></span>)
pxy <span class="pl-k">=</span> <span class="pl-c1">Matrix</span>(bach)<span class="pl-k">./</span><span class="pl-c1">sum</span>(<span class="pl-c1">Matrix</span>(bach))
model <span class="pl-k">=</span> <span class="pl-c1">IB</span>(pxy, <span class="pl-c1">1000</span>)
x, y <span class="pl-k">=</span> <span class="pl-c1">get_IB_curve</span>(model)
a <span class="pl-k">=</span> <span class="pl-c1">plot</span>(x, y, color <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>black<span class="pl-pds">"</span></span>, linewidth <span class="pl-k">=</span> <span class="pl-c1">2</span>, label <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Optimal IB curve<span class="pl-pds">"</span></span>, title <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Optimal IB curve <span class="pl-cce">\n</span> Bach's chorale dataset<span class="pl-pds">"</span></span>)
<span class="pl-c1">scatter!</span>(a, x, y, color <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>black<span class="pl-pds">"</span></span>, markersize <span class="pl-k">=</span> <span class="pl-c1">1.7</span>, xlabel <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>I(X;T) <span class="pl-cce">\n</span><span class="pl-pds">"</span></span>, ylabel <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>- <span class="pl-cce">\n</span> I(Y;T)<span class="pl-pds">"</span></span>, label <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>, legend <span class="pl-k">=</span> <span class="pl-c1">:topleft</span>)</pre></div>
<p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/34754896/90395817-72438d00-e095-11ea-8872-3030db40539c.PNG"><img src="https://user-images.githubusercontent.com/34754896/90395817-72438d00-e095-11ea-8872-3030db40539c.PNG" width="600" style="max-width:100%;"></a></p>
<h4><a id="user-content-installation--import" class="anchor" aria-hidden="true" href="#installation--import"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation &amp; import:</h4>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="Using Pkg
Pkg.clone(“https://github.com/johncwok/IntegerIB.jl.git”)
Using IntegerIB
"><pre>Using Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">clone</span>(“https<span class="pl-k">:</span><span class="pl-k">//</span>github<span class="pl-k">.</span>com<span class="pl-k">/</span>johncwok<span class="pl-k">/</span>IntegerIB<span class="pl-k">.</span>jl<span class="pl-k">.</span>git”)
Using IntegerIB</pre></div>
<h2><a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Acknowledgments</h2>
<p>Special thanks to Nori jacoby from whom I learned a lot on the subject. The IB part of this code was tested with his data and reproduces his results. <br>
The present implementation is adapted from DJ Strouse's paper <a href="https://arxiv.org/abs/1604.00268" rel="nofollow">https://arxiv.org/abs/1604.00268</a> and his python implementation.</p>
<h2><a id="user-content-to-do" class="anchor" aria-hidden="true" href="#to-do"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>To-do</h2>
<ul>
<li>improve display of results (with PrettyTables.jl ?)</li>
<li>Implement simulated annealing to get global maxima in a more consistent fashion.</li>
</ul>
</article></div>