<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h2 dir="auto"><a id="user-content-automlpipeline" class="anchor" aria-hidden="true" href="#automlpipeline"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>AutoMLPipeline</h2>
<div align="center" dir="auto"> 
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1c001e84903ebd749f3c8ca99b89fe06c43a9a424936570057a39f735c066029/68747470733a2f2f76697369746f722d62616467652e6c616f62692e6963752f62616467653f706167655f69643d7070616c6d65732e4175746f4d4c506970656c696e652e6a6c"><img src="https://camo.githubusercontent.com/1c001e84903ebd749f3c8ca99b89fe06c43a9a424936570057a39f735c066029/68747470733a2f2f76697369746f722d62616467652e6c616f62692e6963752f62616467653f706167655f69643d7070616c6d65732e4175746f4d4c506970656c696e652e6a6c" alt="Visitor" data-canonical-src="https://visitor-badge.laobi.icu/badge?page_id=ppalmes.AutoMLPipeline.jl" style="max-width: 100%;"></a></p>
<p dir="auto"><a href="https://bestpractices.coreinfrastructure.org/projects/7093" rel="nofollow"><img src="https://camo.githubusercontent.com/19693115e368863f34c1ed3e1a88dcbab6dd2e6e165f759d920df819c35885ab/68747470733a2f2f626573747072616374696365732e636f7265696e6672617374727563747572652e6f72672f70726f6a656374732f373039332f6261646765" alt="OpenSSF Best Practices" data-canonical-src="https://bestpractices.coreinfrastructure.org/projects/7093/badge" style="max-width: 100%;"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/bd2787d9352ff2aa0ea7e595e07f764eae9d889c7d301e85a40b64fdfcb5ef6e/68747470733a2f2f6769746875622d726561646d652d73746174732e76657263656c2e6170702f6170693f757365726e616d653d7070616c6d657326636f756e745f707269766174653d747275652673686f775f69636f6e733d7472756526686964653d636f6e7472696273"><img src="https://camo.githubusercontent.com/bd2787d9352ff2aa0ea7e595e07f764eae9d889c7d301e85a40b64fdfcb5ef6e/68747470733a2f2f6769746875622d726561646d652d73746174732e76657263656c2e6170702f6170693f757365726e616d653d7070616c6d657326636f756e745f707269766174653d747275652673686f775f69636f6e733d7472756526686964653d636f6e7472696273" alt="Overall Stats" data-canonical-src="https://github-readme-stats.vercel.app/api?username=ppalmes&amp;count_private=true&amp;show_icons=true&amp;hide=contribs" style="max-width: 100%;"></a></p>
<hr>
<table>
<thead>
<tr>
<th align="center"><strong>Documentation</strong></th>
<th align="center"><strong>Build Status</strong></th>
<th align="center"><strong>Help</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://ibm.github.io/AutoMLPipeline.jl/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a> <a href="https://ibm.github.io/AutoMLPipeline.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://github.com/IBM/AutoMLPipeline.jl/actions/workflows/ci.yml"><img src="https://github.com/IBM/AutoMLPipeline.jl/actions/workflows/ci.yml/badge.svg" alt="" style="max-width: 100%;"></a> <a href="https://codecov.io/gh/IBM/AutoMLPipeline.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/da7967b5470bc1dc9a9ab63f2dc7f77f409bfdcf6f6c0d3ac628ce3341abce73/68747470733a2f2f636f6465636f762e696f2f67682f49424d2f4175746f4d4c506970656c696e652e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="" data-canonical-src="https://codecov.io/gh/IBM/AutoMLPipeline.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></td>
<td align="center"><a href="https://julialang.slack.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/c192b6b30d22427a9ad86f7832a70c27f8dcbb028dae7dc2ca07181ef7dd9e13/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230736c61636b2d79656c6c6f772e737667" alt="" data-canonical-src="https://img.shields.io/badge/chat-on%20slack-yellow.svg" style="max-width: 100%;"></a> <a href="https://gitter.im/AutoMLPipelineLearning/community" rel="nofollow"><img src="https://camo.githubusercontent.com/6e67a683ed2377edfcc3fe7895b2878789000869c9d9fd6b4a3b3f3ef5e2284f/68747470733a2f2f6261646765732e6769747465722e696d2f7070616c6d65732f54534d4c2e6a6c2e737667" alt="" data-canonical-src="https://badges.gitter.im/ppalmes/TSML.jl.svg" style="max-width: 100%;"></a></td>
</tr>
</tbody>
</table>
</div>
<h3 dir="auto"><a id="user-content-star-history" class="anchor" aria-hidden="true" href="#star-history"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Star History</h3>
<p dir="auto"><a href="https://star-history.com/#IBM/AutoMLPipeline.jl&amp;Date" rel="nofollow"><img src="https://camo.githubusercontent.com/e7e572564ed83f2774451e081645b135652eeeb96cbcbe6ae1fa11c25a1eecd3/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d49424d2f4175746f4d4c506970656c696e652e6a6c26747970653d44617465" alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=IBM/AutoMLPipeline.jl&amp;type=Date" style="max-width: 100%;"></a></p>
<hr>
<p dir="auto"><strong>AutoMLPipeline</strong> (AMLP) is a package
that makes it trivial to create
complex ML pipeline structures
using simple expressions. It leverages on
the built-in macro programming features of
Julia to symbolically process, manipulate
pipeline expressions, and makes it easy to
discover optimal structures for machine
learning regression and classification.</p>
<p dir="auto">To illustrate, here is a pipeline expression
and evaluation of a typical machine learning
workflow that extracts numerical features (<code>numf</code>)
for <code>ica</code> (Independent Component Analysis)
and <code>pca</code> (Principal Component Analysis)
transformations, respectively, concatenated with
the hot-bit encoding (<code>ohe</code>) of categorical
features (<code>catf</code>) of a given data for <code>rf</code> (Random Forest) modeling:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="model = (catf |&gt; ohe) + (numf |&gt; pca) + (numf |&gt; ica) |&gt; rf
fit!(model,Xtrain,Ytrain)
prediction = transform!(model,Xtest)
score(:accuracy,prediction,Ytest)
crossvalidate(model,X,Y,&quot;balanced_accuracy_score&quot;)"><pre>model <span class="pl-k">=</span> (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> pca) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> ica) <span class="pl-k">|&gt;</span> rf
<span class="pl-c1">fit!</span>(model,Xtrain,Ytrain)
prediction <span class="pl-k">=</span> <span class="pl-c1">transform!</span>(model,Xtest)
<span class="pl-c1">score</span>(<span class="pl-c1">:accuracy</span>,prediction,Ytest)
<span class="pl-c1">crossvalidate</span>(model,X,Y,<span class="pl-s"><span class="pl-pds">"</span>balanced_accuracy_score<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">Just take note that <code>+</code> has higher priority than <code>|&gt;</code> so if you
are not sure, enclose the operations inside parentheses.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="### these two expressions are the same
a |&gt; b + c; a |&gt; (b + c)

### these two expressions are the same
a + b |&gt; c; (a + b) |&gt; c"><pre><span class="pl-c"><span class="pl-c">#</span>## these two expressions are the same</span>
a <span class="pl-k">|&gt;</span> b <span class="pl-k">+</span> c; a <span class="pl-k">|&gt;</span> (b <span class="pl-k">+</span> c)

<span class="pl-c"><span class="pl-c">#</span>## these two expressions are the same</span>
a <span class="pl-k">+</span> b <span class="pl-k">|&gt;</span> c; (a <span class="pl-k">+</span> b) <span class="pl-k">|&gt;</span> c</pre></div>
<h4 dir="auto"><a id="user-content-please-read-this-automlpipeline-paper-for-benchmark-comparisons" class="anchor" aria-hidden="true" href="#please-read-this-automlpipeline-paper-for-benchmark-comparisons"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Please read this <a href="https://arxiv.org/abs/2107.01253" rel="nofollow">AutoMLPipeline Paper</a> for benchmark comparisons.</h4>
<h3 dir="auto"><a id="user-content-recorded-videoconference-presentations" class="anchor" aria-hidden="true" href="#recorded-videoconference-presentations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Recorded Video/Conference Presentations:</h3>
<ul dir="auto">
<li><a href="https://www.youtube.com/watch?v=ZRFIMGW88Co" rel="nofollow">2021 JuliaCon (<strong>Finding an Effective Strategy for AutoML Pipeline Optimization</strong>)</a></li>
<li><a href="https://www.youtube.com/watch?v=6-hJnMO0oDs" rel="nofollow">2020 JuliaCon (<strong>AutoMLPipeline: A ToolBox for Building ML Pipelines</strong>)</a></li>
<li><a href="https://www.youtube.com/watch?v=EQm5fj-4Hrw" rel="nofollow">2021 PyData Ireland Meetup (<strong>Symbolic ML Pipeline Expression and Benchmarking</strong>)</a></li>
</ul>
<h3 dir="auto"><a id="user-content-related-videoconference-presentations" class="anchor" aria-hidden="true" href="#related-videoconference-presentations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Related Video/Conference Presentations:</h3>
<ul dir="auto">
<li><a href="https://www.youtube.com/watch?v=4ayA_EWWlqk" rel="nofollow">2021 JuliaCon (<strong>Lale in Julia: A package for semi-automated data science</strong>)</a></li>
<li><a href="https://www.youtube.com/watch?v=RRY0OXc52Ns" rel="nofollow">2019 JuliaCon (<strong>TSML: Time Series Machine Learning Pipeline</strong>)</a></li>
<li><a href="https://www.youtube.com/watch?v=zkks1_SrUx0" rel="nofollow">2021 OpenSource Guild in IBM (<strong>Overview of HPC and Data Science in Julia Programming with AutoML</strong>)</a></li>
</ul>
<p dir="auto">More examples can be found in the
<a href="https://github.com/IBM/AutoMLPipeline.jl/tree/master/examples">examples</a>
folder including optimizing pipelines by multi-threading or distributed computing.</p>
<h3 dir="auto"><a id="user-content-motivations" class="anchor" aria-hidden="true" href="#motivations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Motivations</h3>
<p dir="auto">The typical workflow in machine learning
classification or prediction requires
some or combination of the following
preprocessing steps together with modeling:</p>
<ul dir="auto">
<li>feature extraction (e.g. ica, pca, svd)</li>
<li>feature transformation (e.g. normalization, scaling, ohe)</li>
<li>feature selection (anova, correlation)</li>
<li>modeling (rf, adaboost, xgboost, lm, svm, mlp)</li>
</ul>
<p dir="auto">Each step has several choices of functions
to use together with their corresponding
parameters. Optimizing the performance of the
entire pipeline is a combinatorial search
of the proper order and combination of preprocessing
steps, optimization of their corresponding
parameters, together with searching for
the optimal model and its hyper-parameters.</p>
<p dir="auto">Because of close dependencies among various
steps, we can consider the entire process
to be a pipeline optimization problem (POP).
POP requires simultaneous optimization of pipeline
structure and parameter adaptation of its elements.
As a consequence, having an elegant way to
express pipeline structure can help lessen
the complexity in the management and analysis
of the wide-array of choices of optimization routines.</p>
<p dir="auto">The target of future work will be the
implementations of different pipeline
optimization algorithms ranging from
evolutionary approaches, integer
programming (discrete choices of POP elements),
tree/graph search, and hyper-parameter search.</p>
<h3 dir="auto"><a id="user-content-package-features" class="anchor" aria-hidden="true" href="#package-features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Package Features</h3>
<ul dir="auto">
<li>Symbolic pipeline API for easy expression and high-level description of complex pipeline structures and processing workflow</li>
<li>Common API wrappers for ML libs including Scikitlearn, DecisionTree, etc</li>
<li>Easily extensible architecture by overloading just two main interfaces: fit! and transform!</li>
<li>Meta-ensembles that allow composition of ensembles of ensembles (recursively if needed) for robust prediction routines</li>
<li>Categorical and numerical feature selectors for specialized preprocessing routines based on types</li>
</ul>
<h3 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h3>
<p dir="auto">AutoMLPipeline is in the Julia Official package registry.
The latest release can be installed at the Julia
prompt using Julia's package management which is triggered
by pressing <code>]</code> at the julia prompt:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; ]
pkg&gt; update
pkg&gt; add AutoMLPipeline"><pre>julia<span class="pl-k">&gt;</span> ]
pkg<span class="pl-k">&gt;</span> update
pkg<span class="pl-k">&gt;</span> add AutoMLPipeline</pre></div>
<h3 dir="auto"><a id="user-content-sample-usage" class="anchor" aria-hidden="true" href="#sample-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Sample Usage</h3>
<p dir="auto">Below outlines some typical way to preprocess and model any dataset.</p>
<h5 dir="auto"><a id="user-content-1-load-data-extract-input-x-and-target-y" class="anchor" aria-hidden="true" href="#1-load-data-extract-input-x-and-target-y"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>1. Load Data, Extract Input (X) and Target (Y)</h5>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Make sure that the input feature is a dataframe and the target output is a 1-D vector.
using AutoMLPipeline
profbdata = getprofb()
X = profbdata[:,2:end] 
Y = profbdata[:,1] |&gt; Vector;
head(x)=first(x,5)
head(profbdata)"><pre><span class="pl-c"><span class="pl-c">#</span> Make sure that the input feature is a dataframe and the target output is a 1-D vector.</span>
<span class="pl-k">using</span> AutoMLPipeline
profbdata <span class="pl-k">=</span> <span class="pl-c1">getprofb</span>()
X <span class="pl-k">=</span> profbdata[:,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>] 
Y <span class="pl-k">=</span> profbdata[:,<span class="pl-c1">1</span>] <span class="pl-k">|&gt;</span> Vector;
<span class="pl-en">head</span>(x)<span class="pl-k">=</span><span class="pl-c1">first</span>(x,<span class="pl-c1">5</span>)
<span class="pl-c1">head</span>(profbdata)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="5×7 DataFrame. Omitted printing of 1 columns
│ Row │ Home.Away │ Favorite_Points │ Underdog_Points │ Pointspread │ Favorite_Name │ Underdog_name │
│     │ String    │ Int64           │ Int64           │ Float64     │ String        │ String        │
├─────┼───────────┼─────────────────┼─────────────────┼─────────────┼───────────────┼───────────────┤
│ 1   │ away      │ 27              │ 24              │ 4.0         │ BUF           │ MIA           │
│ 2   │ at_home   │ 17              │ 14              │ 3.0         │ CHI           │ CIN           │
│ 3   │ away      │ 51              │ 0               │ 2.5         │ CLE           │ PIT           │
│ 4   │ at_home   │ 28              │ 0               │ 5.5         │ NO            │ DAL           │
│ 5   │ at_home   │ 38              │ 7               │ 5.5         │ MIN           │ HOU           │"><pre><span class="pl-c1">5</span><span class="pl-k">×</span><span class="pl-c1">7</span> DataFrame. Omitted printing of <span class="pl-c1">1</span> columns
│ Row │ Home<span class="pl-k">.</span>Away │ Favorite_Points │ Underdog_Points │ Pointspread │ Favorite_Name │ Underdog_name │
│     │ String    │ Int64           │ Int64           │ Float64     │ String        │ String        │
├─────┼───────────┼─────────────────┼─────────────────┼─────────────┼───────────────┼───────────────┤
│ <span class="pl-c1">1</span>   │ away      │ <span class="pl-c1">27</span>              │ <span class="pl-c1">24</span>              │ <span class="pl-c1">4.0</span>         │ BUF           │ MIA           │
│ <span class="pl-c1">2</span>   │ at_home   │ <span class="pl-c1">17</span>              │ <span class="pl-c1">14</span>              │ <span class="pl-c1">3.0</span>         │ CHI           │ CIN           │
│ <span class="pl-c1">3</span>   │ away      │ <span class="pl-c1">51</span>              │ <span class="pl-c1">0</span>               │ <span class="pl-c1">2.5</span>         │ CLE           │ PIT           │
│ <span class="pl-c1">4</span>   │ at_home   │ <span class="pl-c1">28</span>              │ <span class="pl-c1">0</span>               │ <span class="pl-c1">5.5</span>         │ NO            │ DAL           │
│ <span class="pl-c1">5</span>   │ at_home   │ <span class="pl-c1">38</span>              │ <span class="pl-c1">7</span>               │ <span class="pl-c1">5.5</span>         │ MIN           │ HOU           │</pre></div>
<h4 dir="auto"><a id="user-content-2-load-filters-transformers-and-learners" class="anchor" aria-hidden="true" href="#2-load-filters-transformers-and-learners"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>2. Load Filters, Transformers, and Learners</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using AutoMLPipeline

#### Decomposition
pca = skoperator(&quot;PCA&quot;)
fa  = skoperator(&quot;FactorAnalysis&quot;)
ica = skoperator(&quot;FastICA&quot;)

#### Scaler 
rb   = skoperator(&quot;RobustScaler&quot;)
pt   = skoperator(&quot;PowerTransformer&quot;)
norm = skoperator(&quot;Normalizer&quot;)
mx   = skoperator(&quot;MinMaxScaler&quot;)
std  = skoperator(&quot;StandardScaler&quot;)

#### categorical preprocessing
ohe = OneHotEncoder()

#### Column selector
catf = CatFeatureSelector()
numf = NumFeatureSelector()
disc = CatNumDiscriminator()

#### Learners
rf       = skoperator(&quot;RandomForestClassifier&quot;)
gb       = skoperator(&quot;GradientBoostingClassifier&quot;)
lsvc     = skoperator(&quot;LinearSVC&quot;)
svc      = skoperator(&quot;SVC&quot;)
mlp      = skoperator(&quot;MLPClassifier&quot;)
ada      = skoperator(&quot;AdaBoostClassifier&quot;)
sgd      = skoperator(&quot;SGDClassifier&quot;)
skrf_reg = skoperator(&quot;RandomForestRegressor&quot;)
skgb_reg = skoperator(&quot;GradientBoostingRegressor&quot;)
jrf      = RandomForest()
tree     = PrunedTree()
vote     = VoteEnsemble()
stack    = StackEnsemble()
best     = BestLearner()"><pre><span class="pl-k">using</span> AutoMLPipeline

<span class="pl-c"><span class="pl-c">#</span>### Decomposition</span>
pca <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>PCA<span class="pl-pds">"</span></span>)
fa  <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>FactorAnalysis<span class="pl-pds">"</span></span>)
ica <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>FastICA<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">#</span>### Scaler </span>
rb   <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>RobustScaler<span class="pl-pds">"</span></span>)
pt   <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>PowerTransformer<span class="pl-pds">"</span></span>)
norm <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>Normalizer<span class="pl-pds">"</span></span>)
mx   <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>MinMaxScaler<span class="pl-pds">"</span></span>)
std  <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>StandardScaler<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">#</span>### categorical preprocessing</span>
ohe <span class="pl-k">=</span> <span class="pl-c1">OneHotEncoder</span>()

<span class="pl-c"><span class="pl-c">#</span>### Column selector</span>
catf <span class="pl-k">=</span> <span class="pl-c1">CatFeatureSelector</span>()
numf <span class="pl-k">=</span> <span class="pl-c1">NumFeatureSelector</span>()
disc <span class="pl-k">=</span> <span class="pl-c1">CatNumDiscriminator</span>()

<span class="pl-c"><span class="pl-c">#</span>### Learners</span>
rf       <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>RandomForestClassifier<span class="pl-pds">"</span></span>)
gb       <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>GradientBoostingClassifier<span class="pl-pds">"</span></span>)
lsvc     <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>LinearSVC<span class="pl-pds">"</span></span>)
svc      <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>SVC<span class="pl-pds">"</span></span>)
mlp      <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>MLPClassifier<span class="pl-pds">"</span></span>)
ada      <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>AdaBoostClassifier<span class="pl-pds">"</span></span>)
sgd      <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>SGDClassifier<span class="pl-pds">"</span></span>)
skrf_reg <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>RandomForestRegressor<span class="pl-pds">"</span></span>)
skgb_reg <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>GradientBoostingRegressor<span class="pl-pds">"</span></span>)
jrf      <span class="pl-k">=</span> <span class="pl-c1">RandomForest</span>()
tree     <span class="pl-k">=</span> <span class="pl-c1">PrunedTree</span>()
vote     <span class="pl-k">=</span> <span class="pl-c1">VoteEnsemble</span>()
stack    <span class="pl-k">=</span> <span class="pl-c1">StackEnsemble</span>()
best     <span class="pl-k">=</span> <span class="pl-c1">BestLearner</span>()</pre></div>
<p dir="auto">Note: You can get a listing of available <code>Preprocessors</code> and <code>Learners</code> by invoking the function:</p>
<ul dir="auto">
<li><code>skoperator()</code></li>
</ul>
<h4 dir="auto"><a id="user-content-3-filter-categories-and-hot-encode-them" class="anchor" aria-hidden="true" href="#3-filter-categories-and-hot-encode-them"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>3. Filter categories and hot-encode them</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="pohe = catf |&gt; ohe
tr = fit_transform!(pohe,X,Y)
head(tr)"><pre>pohe <span class="pl-k">=</span> catf <span class="pl-k">|&gt;</span> ohe
tr <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(pohe,X,Y)
<span class="pl-c1">head</span>(tr)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="5×56 DataFrame. Omitted printing of 47 columns
│ Row │ x1      │ x2      │ x3      │ x4      │ x5      │ x6      │ x7      │ x8      │ x9      │
│     │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │
├─────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ 1   │ 1.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │
│ 2   │ 0.0     │ 1.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │
│ 3   │ 0.0     │ 0.0     │ 1.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │
│ 4   │ 0.0     │ 0.0     │ 0.0     │ 1.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │
│ 5   │ 0.0     │ 0.0     │ 0.0     │ 0.0     │ 1.0     │ 0.0     │ 0.0     │ 0.0     │ 0.0     │"><pre><span class="pl-c1">5</span><span class="pl-k">×</span><span class="pl-c1">56</span> DataFrame. Omitted printing of <span class="pl-c1">47</span> columns
│ Row │ x1      │ x2      │ x3      │ x4      │ x5      │ x6      │ x7      │ x8      │ x9      │
│     │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │
├─────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ <span class="pl-c1">1</span>   │ <span class="pl-c1">1.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │
│ <span class="pl-c1">2</span>   │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">1.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │
│ <span class="pl-c1">3</span>   │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">1.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │
│ <span class="pl-c1">4</span>   │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">1.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │
│ <span class="pl-c1">5</span>   │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">1.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │ <span class="pl-c1">0.0</span>     │</pre></div>
<h4 dir="auto"><a id="user-content-4-numerical-feature-extraction-example" class="anchor" aria-hidden="true" href="#4-numerical-feature-extraction-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>4. Numerical Feature Extraction Example</h4>
<h5 dir="auto"><a id="user-content-41-filter-numeric-features-compute-ica-and-pca-features-and-combine-both-features" class="anchor" aria-hidden="true" href="#41-filter-numeric-features-compute-ica-and-pca-features-and-combine-both-features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>4.1 Filter numeric features, compute ica and pca features, and combine both features</h5>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="pdec = (numf |&gt; pca) + (numf |&gt; ica)
tr = fit_transform!(pdec,X,Y)
head(tr)"><pre>pdec <span class="pl-k">=</span> (numf <span class="pl-k">|&gt;</span> pca) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> ica)
tr <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(pdec,X,Y)
<span class="pl-c1">head</span>(tr)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="5×8 DataFrame
│ Row │ x1       │ x2       │ x3       │ x4       │ x1_1       │ x2_1       │ x3_1       │ x4_1       │
│     │ Float64  │ Float64  │ Float64  │ Float64  │ Float64    │ Float64    │ Float64    │ Float64    │
├─────┼──────────┼──────────┼──────────┼──────────┼────────────┼────────────┼────────────┼────────────┤
│ 1   │ 2.47477  │ 7.87074  │ -1.10495 │ 0.902431 │ 0.0168432  │ 0.00319873 │ -0.0467633 │ 0.026742   │
│ 2   │ -5.47113 │ -3.82946 │ -2.08342 │ 1.00524  │ -0.0327947 │ -0.0217808 │ -0.0451314 │ 0.00702006 │
│ 3   │ 30.4068  │ -10.8073 │ -6.12339 │ 0.883938 │ -0.0734292 │ 0.115776   │ -0.0425357 │ 0.0497831  │
│ 4   │ 8.18372  │ -15.507  │ -1.43203 │ 1.08255  │ -0.0656664 │ 0.0368666  │ -0.0457154 │ -0.0192752 │
│ 5   │ 16.6176  │ -6.68636 │ -1.66597 │ 0.978243 │ -0.0338749 │ 0.0643065  │ -0.0461703 │ 0.00671696 │"><pre><span class="pl-c1">5</span><span class="pl-k">×</span><span class="pl-c1">8</span> DataFrame
│ Row │ x1       │ x2       │ x3       │ x4       │ x1_1       │ x2_1       │ x3_1       │ x4_1       │
│     │ Float64  │ Float64  │ Float64  │ Float64  │ Float64    │ Float64    │ Float64    │ Float64    │
├─────┼──────────┼──────────┼──────────┼──────────┼────────────┼────────────┼────────────┼────────────┤
│ <span class="pl-c1">1</span>   │ <span class="pl-c1">2.47477</span>  │ <span class="pl-c1">7.87074</span>  │ <span class="pl-k">-</span><span class="pl-c1">1.10495</span> │ <span class="pl-c1">0.902431</span> │ <span class="pl-c1">0.0168432</span>  │ <span class="pl-c1">0.00319873</span> │ <span class="pl-k">-</span><span class="pl-c1">0.0467633</span> │ <span class="pl-c1">0.026742</span>   │
│ <span class="pl-c1">2</span>   │ <span class="pl-k">-</span><span class="pl-c1">5.47113</span> │ <span class="pl-k">-</span><span class="pl-c1">3.82946</span> │ <span class="pl-k">-</span><span class="pl-c1">2.08342</span> │ <span class="pl-c1">1.00524</span>  │ <span class="pl-k">-</span><span class="pl-c1">0.0327947</span> │ <span class="pl-k">-</span><span class="pl-c1">0.0217808</span> │ <span class="pl-k">-</span><span class="pl-c1">0.0451314</span> │ <span class="pl-c1">0.00702006</span> │
│ <span class="pl-c1">3</span>   │ <span class="pl-c1">30.4068</span>  │ <span class="pl-k">-</span><span class="pl-c1">10.8073</span> │ <span class="pl-k">-</span><span class="pl-c1">6.12339</span> │ <span class="pl-c1">0.883938</span> │ <span class="pl-k">-</span><span class="pl-c1">0.0734292</span> │ <span class="pl-c1">0.115776</span>   │ <span class="pl-k">-</span><span class="pl-c1">0.0425357</span> │ <span class="pl-c1">0.0497831</span>  │
│ <span class="pl-c1">4</span>   │ <span class="pl-c1">8.18372</span>  │ <span class="pl-k">-</span><span class="pl-c1">15.507</span>  │ <span class="pl-k">-</span><span class="pl-c1">1.43203</span> │ <span class="pl-c1">1.08255</span>  │ <span class="pl-k">-</span><span class="pl-c1">0.0656664</span> │ <span class="pl-c1">0.0368666</span>  │ <span class="pl-k">-</span><span class="pl-c1">0.0457154</span> │ <span class="pl-k">-</span><span class="pl-c1">0.0192752</span> │
│ <span class="pl-c1">5</span>   │ <span class="pl-c1">16.6176</span>  │ <span class="pl-k">-</span><span class="pl-c1">6.68636</span> │ <span class="pl-k">-</span><span class="pl-c1">1.66597</span> │ <span class="pl-c1">0.978243</span> │ <span class="pl-k">-</span><span class="pl-c1">0.0338749</span> │ <span class="pl-c1">0.0643065</span>  │ <span class="pl-k">-</span><span class="pl-c1">0.0461703</span> │ <span class="pl-c1">0.00671696</span> │</pre></div>
<h5 dir="auto"><a id="user-content-42-filter-numeric-features-transform-to-robust-and-power-transform-scaling-perform-ica-and-pca-respectively-and-combine-both" class="anchor" aria-hidden="true" href="#42-filter-numeric-features-transform-to-robust-and-power-transform-scaling-perform-ica-and-pca-respectively-and-combine-both"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>4.2 Filter numeric features, transform to robust and power transform scaling, perform ica and pca, respectively, and combine both</h5>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="ppt = (numf |&gt; rb |&gt; ica) + (numf |&gt; pt |&gt; pca)
tr = fit_transform!(ppt,X,Y)
head(tr)"><pre>ppt <span class="pl-k">=</span> (numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> ica) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> pt <span class="pl-k">|&gt;</span> pca)
tr <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(ppt,X,Y)
<span class="pl-c1">head</span>(tr)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="5×8 DataFrame
│ Row │ x1          │ x2          │ x3         │ x4        │ x1_1      │ x2_1     │ x3_1       │ x4_1      │
│     │ Float64     │ Float64     │ Float64    │ Float64   │ Float64   │ Float64  │ Float64    │ Float64   │
├─────┼─────────────┼─────────────┼────────────┼───────────┼───────────┼──────────┼────────────┼───────────┤
│ 1   │ -0.00308891 │ -0.0269009  │ -0.0166298 │ 0.0467559 │ -0.64552  │ 1.40289  │ -0.0284468 │ 0.111773  │
│ 2   │ 0.0217799   │ -0.00699717 │ 0.0329868  │ 0.0449952 │ -0.832404 │ 0.475629 │ -1.14881   │ -0.01702  │
│ 3   │ -0.115577   │ -0.0503802  │ 0.0736173  │ 0.0420466 │ 1.54491   │ 1.65258  │ -1.35967   │ -2.57866  │
│ 4   │ -0.0370057  │ 0.0190459   │ 0.065814   │ 0.0454864 │ 1.32065   │ 0.563565 │ -2.05839   │ -0.74898  │
│ 5   │ -0.0643088  │ -0.00711682 │ 0.0340452  │ 0.0459816 │ 1.1223    │ 1.45555  │ -0.88864   │ -0.776195 │"><pre><span class="pl-c1">5</span><span class="pl-k">×</span><span class="pl-c1">8</span> DataFrame
│ Row │ x1          │ x2          │ x3         │ x4        │ x1_1      │ x2_1     │ x3_1       │ x4_1      │
│     │ Float64     │ Float64     │ Float64    │ Float64   │ Float64   │ Float64  │ Float64    │ Float64   │
├─────┼─────────────┼─────────────┼────────────┼───────────┼───────────┼──────────┼────────────┼───────────┤
│ <span class="pl-c1">1</span>   │ <span class="pl-k">-</span><span class="pl-c1">0.00308891</span> │ <span class="pl-k">-</span><span class="pl-c1">0.0269009</span>  │ <span class="pl-k">-</span><span class="pl-c1">0.0166298</span> │ <span class="pl-c1">0.0467559</span> │ <span class="pl-k">-</span><span class="pl-c1">0.64552</span>  │ <span class="pl-c1">1.40289</span>  │ <span class="pl-k">-</span><span class="pl-c1">0.0284468</span> │ <span class="pl-c1">0.111773</span>  │
│ <span class="pl-c1">2</span>   │ <span class="pl-c1">0.0217799</span>   │ <span class="pl-k">-</span><span class="pl-c1">0.00699717</span> │ <span class="pl-c1">0.0329868</span>  │ <span class="pl-c1">0.0449952</span> │ <span class="pl-k">-</span><span class="pl-c1">0.832404</span> │ <span class="pl-c1">0.475629</span> │ <span class="pl-k">-</span><span class="pl-c1">1.14881</span>   │ <span class="pl-k">-</span><span class="pl-c1">0.01702</span>  │
│ <span class="pl-c1">3</span>   │ <span class="pl-k">-</span><span class="pl-c1">0.115577</span>   │ <span class="pl-k">-</span><span class="pl-c1">0.0503802</span>  │ <span class="pl-c1">0.0736173</span>  │ <span class="pl-c1">0.0420466</span> │ <span class="pl-c1">1.54491</span>   │ <span class="pl-c1">1.65258</span>  │ <span class="pl-k">-</span><span class="pl-c1">1.35967</span>   │ <span class="pl-k">-</span><span class="pl-c1">2.57866</span>  │
│ <span class="pl-c1">4</span>   │ <span class="pl-k">-</span><span class="pl-c1">0.0370057</span>  │ <span class="pl-c1">0.0190459</span>   │ <span class="pl-c1">0.065814</span>   │ <span class="pl-c1">0.0454864</span> │ <span class="pl-c1">1.32065</span>   │ <span class="pl-c1">0.563565</span> │ <span class="pl-k">-</span><span class="pl-c1">2.05839</span>   │ <span class="pl-k">-</span><span class="pl-c1">0.74898</span>  │
│ <span class="pl-c1">5</span>   │ <span class="pl-k">-</span><span class="pl-c1">0.0643088</span>  │ <span class="pl-k">-</span><span class="pl-c1">0.00711682</span> │ <span class="pl-c1">0.0340452</span>  │ <span class="pl-c1">0.0459816</span> │ <span class="pl-c1">1.1223</span>    │ <span class="pl-c1">1.45555</span>  │ <span class="pl-k">-</span><span class="pl-c1">0.88864</span>   │ <span class="pl-k">-</span><span class="pl-c1">0.776195</span> │</pre></div>
<h4 dir="auto"><a id="user-content-5-a-pipeline-for-the-voting-ensemble-classification" class="anchor" aria-hidden="true" href="#5-a-pipeline-for-the-voting-ensemble-classification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>5. A Pipeline for the Voting Ensemble Classification</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# take all categorical columns and hot-bit encode each, 
# concatenate them to the numerical features,
# and feed them to the voting ensemble
using AutoMLPipeline.Utils
pvote = (catf |&gt; ohe) + (numf) |&gt; vote
pred = fit_transform!(pvote,X,Y)
sc=score(:accuracy,pred,Y)
println(sc)
crossvalidate(pvote,X,Y,&quot;accuracy_score&quot;)"><pre><span class="pl-c"><span class="pl-c">#</span> take all categorical columns and hot-bit encode each, </span>
<span class="pl-c"><span class="pl-c">#</span> concatenate them to the numerical features,</span>
<span class="pl-c"><span class="pl-c">#</span> and feed them to the voting ensemble</span>
<span class="pl-k">using</span> AutoMLPipeline<span class="pl-k">.</span>Utils
pvote <span class="pl-k">=</span> (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf) <span class="pl-k">|&gt;</span> vote
pred <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(pvote,X,Y)
sc<span class="pl-k">=</span><span class="pl-c1">score</span>(<span class="pl-c1">:accuracy</span>,pred,Y)
<span class="pl-c1">println</span>(sc)
<span class="pl-c1">crossvalidate</span>(pvote,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="fold: 1, 0.5373134328358209
fold: 2, 0.7014925373134329
fold: 3, 0.5294117647058824
fold: 4, 0.6716417910447762
fold: 5, 0.6716417910447762
fold: 6, 0.6119402985074627
fold: 7, 0.5074626865671642
fold: 8, 0.6323529411764706
fold: 9, 0.6268656716417911
fold: 10, 0.5671641791044776
errors: 0
(mean = 0.6057287093942055, std = 0.06724940684190235, folds = 10, errors = 0)"><pre>fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.5373134328358209</span>
fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.7014925373134329</span>
fold<span class="pl-k">:</span> <span class="pl-c1">3</span>, <span class="pl-c1">0.5294117647058824</span>
fold<span class="pl-k">:</span> <span class="pl-c1">4</span>, <span class="pl-c1">0.6716417910447762</span>
fold<span class="pl-k">:</span> <span class="pl-c1">5</span>, <span class="pl-c1">0.6716417910447762</span>
fold<span class="pl-k">:</span> <span class="pl-c1">6</span>, <span class="pl-c1">0.6119402985074627</span>
fold<span class="pl-k">:</span> <span class="pl-c1">7</span>, <span class="pl-c1">0.5074626865671642</span>
fold<span class="pl-k">:</span> <span class="pl-c1">8</span>, <span class="pl-c1">0.6323529411764706</span>
fold<span class="pl-k">:</span> <span class="pl-c1">9</span>, <span class="pl-c1">0.6268656716417911</span>
fold<span class="pl-k">:</span> <span class="pl-c1">10</span>, <span class="pl-c1">0.5671641791044776</span>
errors<span class="pl-k">:</span> <span class="pl-c1">0</span>
(mean <span class="pl-k">=</span> <span class="pl-c1">0.6057287093942055</span>, std <span class="pl-k">=</span> <span class="pl-c1">0.06724940684190235</span>, folds <span class="pl-k">=</span> <span class="pl-c1">10</span>, errors <span class="pl-k">=</span> <span class="pl-c1">0</span>)</pre></div>
<p dir="auto">Note: <code>crossvalidate()</code> supports the following sklearn's performance metric</p>
<h4 dir="auto"><a id="user-content-classification" class="anchor" aria-hidden="true" href="#classification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>classification:</h4>
<ul dir="auto">
<li><code>accuracy_score</code>, <code>balanced_accuracy_score</code>, <code>cohen_kappa_score</code></li>
<li><code>jaccard_score</code>, <code>matthews_corrcoef</code>, <code>hamming_loss</code>, <code>zero_one_loss</code></li>
<li><code>f1_score</code>, <code>precision_score</code>, <code>recall_score</code>,</li>
</ul>
<h4 dir="auto"><a id="user-content-regression" class="anchor" aria-hidden="true" href="#regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>regression:</h4>
<ul dir="auto">
<li><code>mean_squared_error</code>, <code>mean_squared_log_error</code></li>
<li><code>mean_absolute_error</code>, <code>median_absolute_error</code></li>
<li><code>r2_score</code>, <code>max_error</code>, <code>mean_poisson_deviance</code></li>
<li><code>mean_gamma_deviance</code>, <code>mean_tweedie_deviance</code>,</li>
<li><code>explained_variance_score</code></li>
</ul>
<h4 dir="auto"><a id="user-content-6-use-pipelinex-instead-of-pipeline-to-print-the-corresponding-function-calls-in-6" class="anchor" aria-hidden="true" href="#6-use-pipelinex-instead-of-pipeline-to-print-the-corresponding-function-calls-in-6"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>6. Use <code>@pipelinex</code> instead of <code>@pipeline</code> to print the corresponding function calls in 6</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; @pipelinex (catf |&gt; ohe) + (numf) |&gt; vote
:(Pipeline(ComboPipeline(Pipeline(catf, ohe), numf), vote))

# another way is to use @macroexpand with @pipeline
julia&gt; @macroexpand @pipeline (catf |&gt; ohe) + (numf) |&gt; vote
:(Pipeline(ComboPipeline(Pipeline(catf, ohe), numf), vote))"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">@pipelinex</span> (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf) <span class="pl-k">|&gt;</span> vote
:(<span class="pl-c1">Pipeline</span>(<span class="pl-c1">ComboPipeline</span>(<span class="pl-c1">Pipeline</span>(catf, ohe), numf), vote))

<span class="pl-c"><span class="pl-c">#</span> another way is to use @macroexpand with @pipeline</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@macroexpand</span> <span class="pl-c1">@pipeline</span> (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf) <span class="pl-k">|&gt;</span> vote
:(<span class="pl-c1">Pipeline</span>(<span class="pl-c1">ComboPipeline</span>(<span class="pl-c1">Pipeline</span>(catf, ohe), numf), vote))</pre></div>
<h4 dir="auto"><a id="user-content-7-a-pipeline-for-the-random-forest-rf-classification" class="anchor" aria-hidden="true" href="#7-a-pipeline-for-the-random-forest-rf-classification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>7. A Pipeline for the Random Forest (RF) Classification</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# compute the pca, ica, fa of the numerical columns,
# combine them with the hot-bit encoded categorical features
# and feed all to the random forest classifier
prf = (numf |&gt; rb |&gt; pca) + (numf |&gt; rb |&gt; ica) + (numf |&gt; rb |&gt; fa) + (catf |&gt; ohe) |&gt; rf
pred = fit_transform!(prf,X,Y)
score(:accuracy,pred,Y) |&gt; println
crossvalidate(prf,X,Y,&quot;accuracy_score&quot;)"><pre><span class="pl-c"><span class="pl-c">#</span> compute the pca, ica, fa of the numerical columns,</span>
<span class="pl-c"><span class="pl-c">#</span> combine them with the hot-bit encoded categorical features</span>
<span class="pl-c"><span class="pl-c">#</span> and feed all to the random forest classifier</span>
prf <span class="pl-k">=</span> (numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> pca) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> ica) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> fa) <span class="pl-k">+</span> (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">|&gt;</span> rf
pred <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(prf,X,Y)
<span class="pl-c1">score</span>(<span class="pl-c1">:accuracy</span>,pred,Y) <span class="pl-k">|&gt;</span> println
<span class="pl-c1">crossvalidate</span>(prf,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="fold: 1, 0.6119402985074627
fold: 2, 0.7611940298507462
fold: 3, 0.6764705882352942
fold: 4, 0.6716417910447762
fold: 5, 0.6716417910447762
fold: 6, 0.6567164179104478
fold: 7, 0.6268656716417911
fold: 8, 0.7058823529411765
fold: 9, 0.6417910447761194
fold: 10, 0.6865671641791045
errors: 0
(mean = 0.6710711150131694, std = 0.04231869797446545, folds = 10, errors = 0)"><pre>fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.6119402985074627</span>
fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.7611940298507462</span>
fold<span class="pl-k">:</span> <span class="pl-c1">3</span>, <span class="pl-c1">0.6764705882352942</span>
fold<span class="pl-k">:</span> <span class="pl-c1">4</span>, <span class="pl-c1">0.6716417910447762</span>
fold<span class="pl-k">:</span> <span class="pl-c1">5</span>, <span class="pl-c1">0.6716417910447762</span>
fold<span class="pl-k">:</span> <span class="pl-c1">6</span>, <span class="pl-c1">0.6567164179104478</span>
fold<span class="pl-k">:</span> <span class="pl-c1">7</span>, <span class="pl-c1">0.6268656716417911</span>
fold<span class="pl-k">:</span> <span class="pl-c1">8</span>, <span class="pl-c1">0.7058823529411765</span>
fold<span class="pl-k">:</span> <span class="pl-c1">9</span>, <span class="pl-c1">0.6417910447761194</span>
fold<span class="pl-k">:</span> <span class="pl-c1">10</span>, <span class="pl-c1">0.6865671641791045</span>
errors<span class="pl-k">:</span> <span class="pl-c1">0</span>
(mean <span class="pl-k">=</span> <span class="pl-c1">0.6710711150131694</span>, std <span class="pl-k">=</span> <span class="pl-c1">0.04231869797446545</span>, folds <span class="pl-k">=</span> <span class="pl-c1">10</span>, errors <span class="pl-k">=</span> <span class="pl-c1">0</span>)</pre></div>
<h4 dir="auto"><a id="user-content-8-a-pipeline-for-the-linear-support-vector-for-classification-lsvc" class="anchor" aria-hidden="true" href="#8-a-pipeline-for-the-linear-support-vector-for-classification-lsvc"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>8. A Pipeline for the Linear Support Vector for Classification (LSVC)</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="plsvc = ((numf |&gt; rb |&gt; pca)+(numf |&gt; rb |&gt; fa)+(numf |&gt; rb |&gt; ica)+(catf |&gt; ohe )) |&gt; lsvc
pred = fit_transform!(plsvc,X,Y)
score(:accuracy,pred,Y) |&gt; println
crossvalidate(plsvc,X,Y,&quot;accuracy_score&quot;)"><pre>plsvc <span class="pl-k">=</span> ((numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> pca)<span class="pl-k">+</span>(numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> fa)<span class="pl-k">+</span>(numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> ica)<span class="pl-k">+</span>(catf <span class="pl-k">|&gt;</span> ohe )) <span class="pl-k">|&gt;</span> lsvc
pred <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(plsvc,X,Y)
<span class="pl-c1">score</span>(<span class="pl-c1">:accuracy</span>,pred,Y) <span class="pl-k">|&gt;</span> println
<span class="pl-c1">crossvalidate</span>(plsvc,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="fold: 1, 0.6567164179104478
fold: 2, 0.7164179104477612
fold: 3, 0.8235294117647058
fold: 4, 0.7164179104477612
fold: 5, 0.7313432835820896
fold: 6, 0.6567164179104478
fold: 7, 0.7164179104477612
fold: 8, 0.7352941176470589
fold: 9, 0.746268656716418
fold: 10, 0.6865671641791045
errors: 0
(mean = 0.7185689201053556, std = 0.04820829087095355, folds = 10, errors = 0)"><pre>fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.6567164179104478</span>
fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.7164179104477612</span>
fold<span class="pl-k">:</span> <span class="pl-c1">3</span>, <span class="pl-c1">0.8235294117647058</span>
fold<span class="pl-k">:</span> <span class="pl-c1">4</span>, <span class="pl-c1">0.7164179104477612</span>
fold<span class="pl-k">:</span> <span class="pl-c1">5</span>, <span class="pl-c1">0.7313432835820896</span>
fold<span class="pl-k">:</span> <span class="pl-c1">6</span>, <span class="pl-c1">0.6567164179104478</span>
fold<span class="pl-k">:</span> <span class="pl-c1">7</span>, <span class="pl-c1">0.7164179104477612</span>
fold<span class="pl-k">:</span> <span class="pl-c1">8</span>, <span class="pl-c1">0.7352941176470589</span>
fold<span class="pl-k">:</span> <span class="pl-c1">9</span>, <span class="pl-c1">0.746268656716418</span>
fold<span class="pl-k">:</span> <span class="pl-c1">10</span>, <span class="pl-c1">0.6865671641791045</span>
errors<span class="pl-k">:</span> <span class="pl-c1">0</span>
(mean <span class="pl-k">=</span> <span class="pl-c1">0.7185689201053556</span>, std <span class="pl-k">=</span> <span class="pl-c1">0.04820829087095355</span>, folds <span class="pl-k">=</span> <span class="pl-c1">10</span>, errors <span class="pl-k">=</span> <span class="pl-c1">0</span>)</pre></div>
<h4 dir="auto"><a id="user-content-9-a-pipeline-for-random-forest-regression" class="anchor" aria-hidden="true" href="#9-a-pipeline-for-random-forest-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>9. A Pipeline for Random Forest Regression</h4>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="iris = getiris()
Xreg = iris[:,1:3]
Yreg = iris[:,4] |&gt; Vector
pskrfreg = (catf |&gt; ohe) + (numf) |&gt; skrf_reg
res=crossvalidate(pskrfreg,Xreg,Yreg,&quot;mean_absolute_error&quot;,10)"><pre>iris <span class="pl-k">=</span> <span class="pl-c1">getiris</span>()
Xreg <span class="pl-k">=</span> iris[:,<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">3</span>]
Yreg <span class="pl-k">=</span> iris[:,<span class="pl-c1">4</span>] <span class="pl-k">|&gt;</span> Vector
pskrfreg <span class="pl-k">=</span> (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf) <span class="pl-k">|&gt;</span> skrf_reg
res<span class="pl-k">=</span><span class="pl-c1">crossvalidate</span>(pskrfreg,Xreg,Yreg,<span class="pl-s"><span class="pl-pds">"</span>mean_absolute_error<span class="pl-pds">"</span></span>,<span class="pl-c1">10</span>)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="fold: 1, 0.1827433333333334
fold: 2, 0.18350888888888886
fold: 3, 0.11627222222222248
fold: 4, 0.1254152380952376
fold: 5, 0.16502333333333377
fold: 6, 0.10900222222222226
fold: 7, 0.12561111111111076
fold: 8, 0.14243000000000025
fold: 9, 0.12130555555555576
fold: 10, 0.18811111111111098
errors: 0
(mean = 0.1459423015873016, std = 0.030924217263958102, folds = 10, errors = 0)"><pre>fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.1827433333333334</span>
fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.18350888888888886</span>
fold<span class="pl-k">:</span> <span class="pl-c1">3</span>, <span class="pl-c1">0.11627222222222248</span>
fold<span class="pl-k">:</span> <span class="pl-c1">4</span>, <span class="pl-c1">0.1254152380952376</span>
fold<span class="pl-k">:</span> <span class="pl-c1">5</span>, <span class="pl-c1">0.16502333333333377</span>
fold<span class="pl-k">:</span> <span class="pl-c1">6</span>, <span class="pl-c1">0.10900222222222226</span>
fold<span class="pl-k">:</span> <span class="pl-c1">7</span>, <span class="pl-c1">0.12561111111111076</span>
fold<span class="pl-k">:</span> <span class="pl-c1">8</span>, <span class="pl-c1">0.14243000000000025</span>
fold<span class="pl-k">:</span> <span class="pl-c1">9</span>, <span class="pl-c1">0.12130555555555576</span>
fold<span class="pl-k">:</span> <span class="pl-c1">10</span>, <span class="pl-c1">0.18811111111111098</span>
errors<span class="pl-k">:</span> <span class="pl-c1">0</span>
(mean <span class="pl-k">=</span> <span class="pl-c1">0.1459423015873016</span>, std <span class="pl-k">=</span> <span class="pl-c1">0.030924217263958102</span>, folds <span class="pl-k">=</span> <span class="pl-c1">10</span>, errors <span class="pl-k">=</span> <span class="pl-c1">0</span>)</pre></div>
<p dir="auto">Note: More examples can be found in the <em>test</em> directory of the package. Since
the code is written in Julia, you are highly encouraged to read the source
code and feel free to extend or adapt the package to your problem. Please
feel free to submit PRs to improve the package features.</p>
<h4 dir="auto"><a id="user-content-10-performance-comparison-of-several-learners" class="anchor" aria-hidden="true" href="#10-performance-comparison-of-several-learners"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>10. Performance Comparison of Several Learners</h4>
<h5 dir="auto"><a id="user-content-101-sequential-processing" class="anchor" aria-hidden="true" href="#101-sequential-processing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>10.1 Sequential Processing</h5>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Random
using DataFrames

Random.seed!(1)
jrf  = RandomForest()
tree = PrunedTree()
disc = CatNumDiscriminator()
ada  = skoperator(&quot;AdaBoostClassifier&quot;)
sgd  = skoperator(&quot;SGDClassifier&quot;)
std  = skoperator(&quot;StandardScaler&quot;)
lsvc = skoperator(&quot;LinearSVC&quot;)

learners = DataFrame()
for learner in [jrf,ada,sgd,tree,lsvc]
   pcmc = @pipeline disc |&gt; ((catf |&gt; ohe) + (numf |&gt; std)) |&gt; learner
   println(learner.name[1:end-4])
   mean,sd,_ = crossvalidate(pcmc,X,Y,&quot;accuracy_score&quot;,10)
   global learners = vcat(learners,DataFrame(name=learner.name[1:end-4],mean=mean,sd=sd))
end;
@show learners;"><pre><span class="pl-k">using</span> Random
<span class="pl-k">using</span> DataFrames

Random<span class="pl-k">.</span><span class="pl-c1">seed!</span>(<span class="pl-c1">1</span>)
jrf  <span class="pl-k">=</span> <span class="pl-c1">RandomForest</span>()
tree <span class="pl-k">=</span> <span class="pl-c1">PrunedTree</span>()
disc <span class="pl-k">=</span> <span class="pl-c1">CatNumDiscriminator</span>()
ada  <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>AdaBoostClassifier<span class="pl-pds">"</span></span>)
sgd  <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>SGDClassifier<span class="pl-pds">"</span></span>)
std  <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>StandardScaler<span class="pl-pds">"</span></span>)
lsvc <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>LinearSVC<span class="pl-pds">"</span></span>)

learners <span class="pl-k">=</span> <span class="pl-c1">DataFrame</span>()
<span class="pl-k">for</span> learner <span class="pl-k">in</span> [jrf,ada,sgd,tree,lsvc]
   pcmc <span class="pl-k">=</span> <span class="pl-c1">@pipeline</span> disc <span class="pl-k">|&gt;</span> ((catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> std)) <span class="pl-k">|&gt;</span> learner
   <span class="pl-c1">println</span>(learner<span class="pl-k">.</span>name[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">4</span>])
   mean,sd,_ <span class="pl-k">=</span> <span class="pl-c1">crossvalidate</span>(pcmc,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>,<span class="pl-c1">10</span>)
   <span class="pl-k">global</span> learners <span class="pl-k">=</span> <span class="pl-c1">vcat</span>(learners,<span class="pl-c1">DataFrame</span>(name<span class="pl-k">=</span>learner<span class="pl-k">.</span>name[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">4</span>],mean<span class="pl-k">=</span>mean,sd<span class="pl-k">=</span>sd))
<span class="pl-k">end</span>;
<span class="pl-c1">@show</span> learners;</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="learners = 5×3 DataFrame
│ Row │ name                   │ mean     │ sd        │
│     │ String                 │ Float64  │ Float64   │
├─────┼────────────────────────┼──────────┼───────────┤
│ 1   │ rf                     │ 0.653424 │ 0.0754433 │
│ 2   │ AdaBoostClassifier     │ 0.69504  │ 0.0514792 │
│ 3   │ SGDClassifier          │ 0.694908 │ 0.0641564 │
│ 4   │ prunetree              │ 0.621927 │ 0.0578242 │
│ 5   │ LinearSVC              │ 0.726097 │ 0.0498317 │"><pre>learners <span class="pl-k">=</span> <span class="pl-c1">5</span><span class="pl-k">×</span><span class="pl-c1">3</span> DataFrame
│ Row │ name                   │ mean     │ sd        │
│     │ String                 │ Float64  │ Float64   │
├─────┼────────────────────────┼──────────┼───────────┤
│ <span class="pl-c1">1</span>   │ rf                     │ <span class="pl-c1">0.653424</span> │ <span class="pl-c1">0.0754433</span> │
│ <span class="pl-c1">2</span>   │ AdaBoostClassifier     │ <span class="pl-c1">0.69504</span>  │ <span class="pl-c1">0.0514792</span> │
│ <span class="pl-c1">3</span>   │ SGDClassifier          │ <span class="pl-c1">0.694908</span> │ <span class="pl-c1">0.0641564</span> │
│ <span class="pl-c1">4</span>   │ prunetree              │ <span class="pl-c1">0.621927</span> │ <span class="pl-c1">0.0578242</span> │
│ <span class="pl-c1">5</span>   │ LinearSVC              │ <span class="pl-c1">0.726097</span> │ <span class="pl-c1">0.0498317</span> │</pre></div>
<h5 dir="auto"><a id="user-content-102-parallel-processing" class="anchor" aria-hidden="true" href="#102-parallel-processing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>10.2 Parallel Processing</h5>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Random
using DataFrames
using Distributed

nprocs() == 1 &amp;&amp; addprocs()
@everywhere using DataFrames
@everywhere using AutoMLPipeline

@everywhere profbdata = getprofb()
@everywhere X = profbdata[:,2:end] 
@everywhere Y = profbdata[:,1] |&gt; Vector;

@everywhere jrf  = RandomForest()
@everywhere ohe  = OneHotEncoder()
@everywhere catf = CatFeatureSelector()
@everywhere numf = NumFeatureSelector()
@everywhere tree = PrunedTree()
@everywhere disc = CatNumDiscriminator()
@everywhere ada  = skoperator(&quot;AdaBoostClassifier&quot;)
@everywhere sgd  = skoperator(&quot;SGDClassifier&quot;)
@everywhere std  = skoperator(&quot;StandardScaler&quot;)
@everywhere lsvc = skoperator(&quot;LinearSVC&quot;)

learners = @sync @distributed (vcat) for learner in [jrf,ada,sgd,tree,lsvc]
   pcmc = disc |&gt; ((catf |&gt; ohe) + (numf |&gt; std)) |&gt; learner
   println(learner.name[1:end-4])
   mean,sd,_ = crossvalidate(pcmc,X,Y,&quot;accuracy_score&quot;,10)
   DataFrame(name=learner.name[1:end-4],mean=mean,sd=sd)
end
@show learners;"><pre><span class="pl-k">using</span> Random
<span class="pl-k">using</span> DataFrames
<span class="pl-k">using</span> Distributed

<span class="pl-c1">nprocs</span>() <span class="pl-k">==</span> <span class="pl-c1">1</span> <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">addprocs</span>()
<span class="pl-c1">@everywhere</span> <span class="pl-k">using</span> DataFrames
<span class="pl-c1">@everywhere</span> <span class="pl-k">using</span> AutoMLPipeline

<span class="pl-c1">@everywhere</span> profbdata <span class="pl-k">=</span> <span class="pl-c1">getprofb</span>()
<span class="pl-c1">@everywhere</span> X <span class="pl-k">=</span> profbdata[:,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>] 
<span class="pl-c1">@everywhere</span> Y <span class="pl-k">=</span> profbdata[:,<span class="pl-c1">1</span>] <span class="pl-k">|&gt;</span> Vector;

<span class="pl-c1">@everywhere</span> jrf  <span class="pl-k">=</span> <span class="pl-c1">RandomForest</span>()
<span class="pl-c1">@everywhere</span> ohe  <span class="pl-k">=</span> <span class="pl-c1">OneHotEncoder</span>()
<span class="pl-c1">@everywhere</span> catf <span class="pl-k">=</span> <span class="pl-c1">CatFeatureSelector</span>()
<span class="pl-c1">@everywhere</span> numf <span class="pl-k">=</span> <span class="pl-c1">NumFeatureSelector</span>()
<span class="pl-c1">@everywhere</span> tree <span class="pl-k">=</span> <span class="pl-c1">PrunedTree</span>()
<span class="pl-c1">@everywhere</span> disc <span class="pl-k">=</span> <span class="pl-c1">CatNumDiscriminator</span>()
<span class="pl-c1">@everywhere</span> ada  <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>AdaBoostClassifier<span class="pl-pds">"</span></span>)
<span class="pl-c1">@everywhere</span> sgd  <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>SGDClassifier<span class="pl-pds">"</span></span>)
<span class="pl-c1">@everywhere</span> std  <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>StandardScaler<span class="pl-pds">"</span></span>)
<span class="pl-c1">@everywhere</span> lsvc <span class="pl-k">=</span> <span class="pl-c1">skoperator</span>(<span class="pl-s"><span class="pl-pds">"</span>LinearSVC<span class="pl-pds">"</span></span>)

learners <span class="pl-k">=</span> <span class="pl-c1">@sync</span> <span class="pl-c1">@distributed</span> (vcat) <span class="pl-k">for</span> learner <span class="pl-k">in</span> [jrf,ada,sgd,tree,lsvc]
   pcmc <span class="pl-k">=</span> disc <span class="pl-k">|&gt;</span> ((catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> std)) <span class="pl-k">|&gt;</span> learner
   <span class="pl-c1">println</span>(learner<span class="pl-k">.</span>name[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">4</span>])
   mean,sd,_ <span class="pl-k">=</span> <span class="pl-c1">crossvalidate</span>(pcmc,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>,<span class="pl-c1">10</span>)
   <span class="pl-c1">DataFrame</span>(name<span class="pl-k">=</span>learner<span class="pl-k">.</span>name[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span><span class="pl-k">-</span><span class="pl-c1">4</span>],mean<span class="pl-k">=</span>mean,sd<span class="pl-k">=</span>sd)
<span class="pl-k">end</span>
<span class="pl-c1">@show</span> learners;</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="      From worker 3:    AdaBoostClassifier
      From worker 4:    SGDClassifier
      From worker 5:    prunetree
      From worker 2:    rf
      From worker 6:    LinearSVC
      From worker 4:    fold: 1, 0.6716417910447762
      From worker 5:    fold: 1, 0.6567164179104478
      From worker 6:    fold: 1, 0.6865671641791045
      From worker 2:    fold: 1, 0.7164179104477612
      From worker 4:    fold: 2, 0.7164179104477612
      From worker 5:    fold: 2, 0.6119402985074627
      From worker 6:    fold: 2, 0.8059701492537313
      From worker 2:    fold: 2, 0.6716417910447762
      From worker 4:    fold: 3, 0.6764705882352942
      ....

learners = 5×3 DataFrame
│ Row │ name                   │ mean     │ sd        │
│     │ String                 │ Float64  │ Float64   │
├─────┼────────────────────────┼──────────┼───────────┤
│ 1   │ rf                     │ 0.647388 │ 0.0764844 │
│ 2   │ AdaBoostClassifier     │ 0.712862 │ 0.0471003 │
│ 3   │ SGDClassifier          │ 0.710009 │ 0.05173   │
│ 4   │ prunetree              │ 0.60428  │ 0.0403121 │
│ 5   │ LinearSVC              │ 0.726383 │ 0.0467506 │"><pre>      From worker <span class="pl-c1">3</span><span class="pl-k">:</span>    AdaBoostClassifier
      From worker <span class="pl-c1">4</span><span class="pl-k">:</span>    SGDClassifier
      From worker <span class="pl-c1">5</span><span class="pl-k">:</span>    prunetree
      From worker <span class="pl-c1">2</span><span class="pl-k">:</span>    rf
      From worker <span class="pl-c1">6</span><span class="pl-k">:</span>    LinearSVC
      From worker <span class="pl-c1">4</span><span class="pl-k">:</span>    fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.6716417910447762</span>
      From worker <span class="pl-c1">5</span><span class="pl-k">:</span>    fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.6567164179104478</span>
      From worker <span class="pl-c1">6</span><span class="pl-k">:</span>    fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.6865671641791045</span>
      From worker <span class="pl-c1">2</span><span class="pl-k">:</span>    fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.7164179104477612</span>
      From worker <span class="pl-c1">4</span><span class="pl-k">:</span>    fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.7164179104477612</span>
      From worker <span class="pl-c1">5</span><span class="pl-k">:</span>    fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.6119402985074627</span>
      From worker <span class="pl-c1">6</span><span class="pl-k">:</span>    fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.8059701492537313</span>
      From worker <span class="pl-c1">2</span><span class="pl-k">:</span>    fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.6716417910447762</span>
      From worker <span class="pl-c1">4</span><span class="pl-k">:</span>    fold<span class="pl-k">:</span> <span class="pl-c1">3</span>, <span class="pl-c1">0.6764705882352942</span>
      <span class="pl-k">....</span>

learners <span class="pl-k">=</span> <span class="pl-c1">5</span><span class="pl-k">×</span><span class="pl-c1">3</span> DataFrame
│ Row │ name                   │ mean     │ sd        │
│     │ String                 │ Float64  │ Float64   │
├─────┼────────────────────────┼──────────┼───────────┤
│ <span class="pl-c1">1</span>   │ rf                     │ <span class="pl-c1">0.647388</span> │ <span class="pl-c1">0.0764844</span> │
│ <span class="pl-c1">2</span>   │ AdaBoostClassifier     │ <span class="pl-c1">0.712862</span> │ <span class="pl-c1">0.0471003</span> │
│ <span class="pl-c1">3</span>   │ SGDClassifier          │ <span class="pl-c1">0.710009</span> │ <span class="pl-c1">0.05173</span>   │
│ <span class="pl-c1">4</span>   │ prunetree              │ <span class="pl-c1">0.60428</span>  │ <span class="pl-c1">0.0403121</span> │
│ <span class="pl-c1">5</span>   │ LinearSVC              │ <span class="pl-c1">0.726383</span> │ <span class="pl-c1">0.0467506</span> │</pre></div>
<h4 dir="auto"><a id="user-content-11-automatic-selection-of-best-learner" class="anchor" aria-hidden="true" href="#11-automatic-selection-of-best-learner"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>11. Automatic Selection of Best Learner</h4>
<p dir="auto">You can use <code>*</code> operation as a selector function which outputs the result of the best learner.
If we use the same pre-processing pipeline in 10, we expect that the average performance of
best learner which is <code>lsvc</code> will be around 73.0.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="Random.seed!(1)
pcmc = disc |&gt; ((catf |&gt; ohe) + (numf |&gt; std)) |&gt; (jrf * ada * sgd * tree * lsvc)
crossvalidate(pcmc,X,Y,&quot;accuracy_score&quot;,10)"><pre>Random<span class="pl-k">.</span><span class="pl-c1">seed!</span>(<span class="pl-c1">1</span>)
pcmc <span class="pl-k">=</span> disc <span class="pl-k">|&gt;</span> ((catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> std)) <span class="pl-k">|&gt;</span> (jrf <span class="pl-k">*</span> ada <span class="pl-k">*</span> sgd <span class="pl-k">*</span> tree <span class="pl-k">*</span> lsvc)
<span class="pl-c1">crossvalidate</span>(pcmc,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>,<span class="pl-c1">10</span>)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="fold: 1, 0.7164179104477612
fold: 2, 0.7910447761194029
fold: 3, 0.6911764705882353
fold: 4, 0.7761194029850746
fold: 5, 0.6567164179104478
fold: 6, 0.7014925373134329
fold: 7, 0.6417910447761194
fold: 8, 0.7058823529411765
fold: 9, 0.746268656716418
fold: 10, 0.835820895522388
errors: 0
(mean = 0.7262730465320456, std = 0.060932268798867976, folds = 10, errors = 0)"><pre>fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.7164179104477612</span>
fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.7910447761194029</span>
fold<span class="pl-k">:</span> <span class="pl-c1">3</span>, <span class="pl-c1">0.6911764705882353</span>
fold<span class="pl-k">:</span> <span class="pl-c1">4</span>, <span class="pl-c1">0.7761194029850746</span>
fold<span class="pl-k">:</span> <span class="pl-c1">5</span>, <span class="pl-c1">0.6567164179104478</span>
fold<span class="pl-k">:</span> <span class="pl-c1">6</span>, <span class="pl-c1">0.7014925373134329</span>
fold<span class="pl-k">:</span> <span class="pl-c1">7</span>, <span class="pl-c1">0.6417910447761194</span>
fold<span class="pl-k">:</span> <span class="pl-c1">8</span>, <span class="pl-c1">0.7058823529411765</span>
fold<span class="pl-k">:</span> <span class="pl-c1">9</span>, <span class="pl-c1">0.746268656716418</span>
fold<span class="pl-k">:</span> <span class="pl-c1">10</span>, <span class="pl-c1">0.835820895522388</span>
errors<span class="pl-k">:</span> <span class="pl-c1">0</span>
(mean <span class="pl-k">=</span> <span class="pl-c1">0.7262730465320456</span>, std <span class="pl-k">=</span> <span class="pl-c1">0.060932268798867976</span>, folds <span class="pl-k">=</span> <span class="pl-c1">10</span>, errors <span class="pl-k">=</span> <span class="pl-c1">0</span>)</pre></div>
<h4 dir="auto"><a id="user-content-12-learners-as-transformers" class="anchor" aria-hidden="true" href="#12-learners-as-transformers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>12. Learners as Transformers</h4>
<p dir="auto">It is also possible to use learners in the middle of expression to serve
as transformers and their outputs become inputs to the final learner as illustrated
below.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="expr = ( 
             ((numf |&gt; rb)+(catf |&gt; ohe) |&gt; gb) + 
             ((numf |&gt; rb)+(catf |&gt; ohe) |&gt; rf) 
       ) |&gt; ohe |&gt; ada;                
crossvalidate(expr,X,Y,&quot;accuracy_score&quot;)"><pre>expr <span class="pl-k">=</span> ( 
             ((numf <span class="pl-k">|&gt;</span> rb)<span class="pl-k">+</span>(catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">|&gt;</span> gb) <span class="pl-k">+</span> 
             ((numf <span class="pl-k">|&gt;</span> rb)<span class="pl-k">+</span>(catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">|&gt;</span> rf) 
       ) <span class="pl-k">|&gt;</span> ohe <span class="pl-k">|&gt;</span> ada;                
<span class="pl-c1">crossvalidate</span>(expr,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="fold: 1, 0.6567164179104478
fold: 2, 0.5522388059701493
fold: 3, 0.7205882352941176
fold: 4, 0.7313432835820896
fold: 5, 0.6567164179104478
fold: 6, 0.6119402985074627
fold: 7, 0.6119402985074627
fold: 8, 0.6470588235294118
fold: 9, 0.6716417910447762
fold: 10, 0.6119402985074627
errors: 0
(mean = 0.6472124670763829, std = 0.053739947087648336, folds = 10, errors = 0)"><pre>fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.6567164179104478</span>
fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.5522388059701493</span>
fold<span class="pl-k">:</span> <span class="pl-c1">3</span>, <span class="pl-c1">0.7205882352941176</span>
fold<span class="pl-k">:</span> <span class="pl-c1">4</span>, <span class="pl-c1">0.7313432835820896</span>
fold<span class="pl-k">:</span> <span class="pl-c1">5</span>, <span class="pl-c1">0.6567164179104478</span>
fold<span class="pl-k">:</span> <span class="pl-c1">6</span>, <span class="pl-c1">0.6119402985074627</span>
fold<span class="pl-k">:</span> <span class="pl-c1">7</span>, <span class="pl-c1">0.6119402985074627</span>
fold<span class="pl-k">:</span> <span class="pl-c1">8</span>, <span class="pl-c1">0.6470588235294118</span>
fold<span class="pl-k">:</span> <span class="pl-c1">9</span>, <span class="pl-c1">0.6716417910447762</span>
fold<span class="pl-k">:</span> <span class="pl-c1">10</span>, <span class="pl-c1">0.6119402985074627</span>
errors<span class="pl-k">:</span> <span class="pl-c1">0</span>
(mean <span class="pl-k">=</span> <span class="pl-c1">0.6472124670763829</span>, std <span class="pl-k">=</span> <span class="pl-c1">0.053739947087648336</span>, folds <span class="pl-k">=</span> <span class="pl-c1">10</span>, errors <span class="pl-k">=</span> <span class="pl-c1">0</span>)</pre></div>
<p dir="auto">One can even include selector function as part of transformer preprocessing routine:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="pjrf = disc |&gt; ((catf |&gt; ohe) + (numf |&gt; std)) |&gt; 
         ((jrf * ada ) + (sgd * tree * lsvc)) |&gt; ohe |&gt; ada
crossvalidate(pjrf,X,Y,&quot;accuracy_score&quot;)"><pre>pjrf <span class="pl-k">=</span> disc <span class="pl-k">|&gt;</span> ((catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> std)) <span class="pl-k">|&gt;</span> 
         ((jrf <span class="pl-k">*</span> ada ) <span class="pl-k">+</span> (sgd <span class="pl-k">*</span> tree <span class="pl-k">*</span> lsvc)) <span class="pl-k">|&gt;</span> ohe <span class="pl-k">|&gt;</span> ada
<span class="pl-c1">crossvalidate</span>(pjrf,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="fold: 1, 0.7164179104477612
fold: 2, 0.7164179104477612
fold: 3, 0.7941176470588235
fold: 4, 0.7761194029850746
fold: 5, 0.6268656716417911
fold: 6, 0.6716417910447762
fold: 7, 0.7611940298507462
fold: 8, 0.7352941176470589
fold: 9, 0.7761194029850746
fold: 10, 0.6865671641791045
errors: 0
(mean = 0.7260755048287972, std = 0.0532393731318768, folds = 10, errors = 0)"><pre>fold<span class="pl-k">:</span> <span class="pl-c1">1</span>, <span class="pl-c1">0.7164179104477612</span>
fold<span class="pl-k">:</span> <span class="pl-c1">2</span>, <span class="pl-c1">0.7164179104477612</span>
fold<span class="pl-k">:</span> <span class="pl-c1">3</span>, <span class="pl-c1">0.7941176470588235</span>
fold<span class="pl-k">:</span> <span class="pl-c1">4</span>, <span class="pl-c1">0.7761194029850746</span>
fold<span class="pl-k">:</span> <span class="pl-c1">5</span>, <span class="pl-c1">0.6268656716417911</span>
fold<span class="pl-k">:</span> <span class="pl-c1">6</span>, <span class="pl-c1">0.6716417910447762</span>
fold<span class="pl-k">:</span> <span class="pl-c1">7</span>, <span class="pl-c1">0.7611940298507462</span>
fold<span class="pl-k">:</span> <span class="pl-c1">8</span>, <span class="pl-c1">0.7352941176470589</span>
fold<span class="pl-k">:</span> <span class="pl-c1">9</span>, <span class="pl-c1">0.7761194029850746</span>
fold<span class="pl-k">:</span> <span class="pl-c1">10</span>, <span class="pl-c1">0.6865671641791045</span>
errors<span class="pl-k">:</span> <span class="pl-c1">0</span>
(mean <span class="pl-k">=</span> <span class="pl-c1">0.7260755048287972</span>, std <span class="pl-k">=</span> <span class="pl-c1">0.0532393731318768</span>, folds <span class="pl-k">=</span> <span class="pl-c1">10</span>, errors <span class="pl-k">=</span> <span class="pl-c1">0</span>)</pre></div>
<p dir="auto">Note: The <code>ohe</code> is necessary in both examples
because the outputs of the learners and selector function are categorical
values that need to be hot-bit encoded before feeding to the final <code>ada</code> learner.</p>
<h4 dir="auto"><a id="user-content-13-tree-visualization-of-the-pipeline-structure" class="anchor" aria-hidden="true" href="#13-tree-visualization-of-the-pipeline-structure"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>13. Tree Visualization of the Pipeline Structure</h4>
<p dir="auto">You can visualize the pipeline by using AbstractTrees Julia package.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# package installation 
using Pkg
Pkg.update()
Pkg.add(&quot;AbstractTrees&quot;) 

# load the packages
using AbstractTrees
using AutoMLPipeline

expr = @pipelinex (catf |&gt; ohe) + (numf |&gt; pca) + (numf |&gt; ica) |&gt; rf
:(Pipeline(ComboPipeline(Pipeline(catf, ohe), Pipeline(numf, pca), Pipeline(numf, ica)), rf))

print_tree(stdout, expr)"><pre><span class="pl-c"><span class="pl-c">#</span> package installation </span>
<span class="pl-k">using</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">update</span>()
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>AbstractTrees<span class="pl-pds">"</span></span>) 

<span class="pl-c"><span class="pl-c">#</span> load the packages</span>
<span class="pl-k">using</span> AbstractTrees
<span class="pl-k">using</span> AutoMLPipeline

expr <span class="pl-k">=</span> <span class="pl-c1">@pipelinex</span> (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> pca) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> ica) <span class="pl-k">|&gt;</span> rf
:(<span class="pl-c1">Pipeline</span>(<span class="pl-c1">ComboPipeline</span>(<span class="pl-c1">Pipeline</span>(catf, ohe), <span class="pl-c1">Pipeline</span>(numf, pca), <span class="pl-c1">Pipeline</span>(numf, ica)), rf))

<span class="pl-c1">print_tree</span>(<span class="pl-c1">stdout</span>, expr)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content=":(Pipeline(ComboPipeline(Pipeline(catf, ohe), Pipeline(numf, pca), Pipeline(numf, ica)), rf))
├─ :Pipeline
├─ :(ComboPipeline(Pipeline(catf, ohe), Pipeline(numf, pca), Pipeline(numf, ica)))
│  ├─ :ComboPipeline
│  ├─ :(Pipeline(catf, ohe))
│  │  ├─ :Pipeline
│  │  ├─ :catf
│  │  └─ :ohe
│  ├─ :(Pipeline(numf, pca))
│  │  ├─ :Pipeline
│  │  ├─ :numf
│  │  └─ :pca
│  └─ :(Pipeline(numf, ica))
│     ├─ :Pipeline
│     ├─ :numf
│     └─ :ica
└─ :rf"><pre>:(<span class="pl-c1">Pipeline</span>(<span class="pl-c1">ComboPipeline</span>(<span class="pl-c1">Pipeline</span>(catf, ohe), <span class="pl-c1">Pipeline</span>(numf, pca), <span class="pl-c1">Pipeline</span>(numf, ica)), rf))
├─ <span class="pl-c1">:Pipeline</span>
├─ :(<span class="pl-c1">ComboPipeline</span>(<span class="pl-c1">Pipeline</span>(catf, ohe), <span class="pl-c1">Pipeline</span>(numf, pca), <span class="pl-c1">Pipeline</span>(numf, ica)))
│  ├─ <span class="pl-c1">:ComboPipeline</span>
│  ├─ :(<span class="pl-c1">Pipeline</span>(catf, ohe))
│  │  ├─ <span class="pl-c1">:Pipeline</span>
│  │  ├─ <span class="pl-c1">:catf</span>
│  │  └─ <span class="pl-c1">:ohe</span>
│  ├─ :(<span class="pl-c1">Pipeline</span>(numf, pca))
│  │  ├─ <span class="pl-c1">:Pipeline</span>
│  │  ├─ <span class="pl-c1">:numf</span>
│  │  └─ <span class="pl-c1">:pca</span>
│  └─ :(<span class="pl-c1">Pipeline</span>(numf, ica))
│     ├─ <span class="pl-c1">:Pipeline</span>
│     ├─ <span class="pl-c1">:numf</span>
│     └─ <span class="pl-c1">:ica</span>
└─ <span class="pl-c1">:rf</span></pre></div>
<h3 dir="auto"><a id="user-content-extending-automlpipeline" class="anchor" aria-hidden="true" href="#extending-automlpipeline"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Extending AutoMLPipeline</h3>
<p dir="auto">If you want to add your own filter or transformer or learner,
take note that filters and transformers process the<br>
input features but ignores the output argument. On the other hand,
learners process both their input and output arguments during <code>fit!</code>
while <code>transform!</code> expects one input argument in all cases.
First step is to import the abstract types and define your own mutable structure
as subtype of either Learner or Transformer. Next is to import the <code>fit!</code> and
<code>transform!</code> functions so that you can overload them. Also, you must
load the DataFrames package because it is the main format for data processing.
Finally, implement your own <code>fit</code> and <code>transform</code> and export them.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using DataFrames
using AutoMLPipeline.AbsTypes

# import functions for overloading
import AutoMLPipeline.AbsTypes: fit!, transform!   

# export the new definitions for dynamic dispatch
export fit!, transform!, MyFilter

# define your filter structure
mutable struct MyFilter &lt;: Transformer
  name::String
  model::Dict
  args::Dict
  function MyFilter(args::Dict())
      ....
  end
end

# define your fit! function. 
function fit!(fl::MyFilter, inputfeatures::DataFrame, target::Vector=Vector())
     ....
end

#define your transform! function
function transform!(fl::MyFilter, inputfeatures::DataFrame)::DataFrame
     ....
end"><pre><span class="pl-k">using</span> DataFrames
<span class="pl-k">using</span> AutoMLPipeline<span class="pl-k">.</span>AbsTypes

<span class="pl-c"><span class="pl-c">#</span> import functions for overloading</span>
<span class="pl-k">import</span> AutoMLPipeline<span class="pl-k">.</span>AbsTypes<span class="pl-k">:</span> fit!, transform!   

<span class="pl-c"><span class="pl-c">#</span> export the new definitions for dynamic dispatch</span>
<span class="pl-k">export</span> fit!, transform!, MyFilter

<span class="pl-c"><span class="pl-c">#</span> define your filter structure</span>
<span class="pl-k">mutable struct</span> MyFilter <span class="pl-k">&lt;:</span> <span class="pl-c1">Transformer</span>
  name<span class="pl-k">::</span><span class="pl-c1">String</span>
  model<span class="pl-k">::</span><span class="pl-c1">Dict</span>
  args<span class="pl-k">::</span><span class="pl-c1">Dict</span>
  <span class="pl-k">function</span> <span class="pl-en">MyFilter</span>(args<span class="pl-k">::</span><span class="pl-c1">Dict</span>())
      <span class="pl-k">....</span>
  <span class="pl-k">end</span>
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span> define your fit! function. </span>
<span class="pl-k">function</span> <span class="pl-en">fit!</span>(fl<span class="pl-k">::</span><span class="pl-c1">MyFilter</span>, inputfeatures<span class="pl-k">::</span><span class="pl-c1">DataFrame</span>, target<span class="pl-k">::</span><span class="pl-c1">Vector</span><span class="pl-k">=</span><span class="pl-c1">Vector</span>())
     <span class="pl-k">....</span>
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span>define your transform! function</span>
<span class="pl-k">function</span> <span class="pl-en">transform!</span>(fl<span class="pl-k">::</span><span class="pl-c1">MyFilter</span>, inputfeatures<span class="pl-k">::</span><span class="pl-c1">DataFrame</span>)<span class="pl-k">::</span><span class="pl-c1">DataFrame</span>
     <span class="pl-k">....</span>
<span class="pl-k">end</span></pre></div>
<p dir="auto">Note that the main format to exchange data is dataframe which requires <code>transform!</code>
output to return a dataframe. The features as input for fit! and transform! shall
be in dataframe format too. This is necessary so that
the pipeline passes the dataframe format consistently to
its corresponding filters/transformers/learners. Once you have
this transformer, you can use it as part of the pipeline
together with the other learners and transformers.</p>
<h3 dir="auto"><a id="user-content-feature-requests-and-contributions" class="anchor" aria-hidden="true" href="#feature-requests-and-contributions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Feature Requests and Contributions</h3>
<p dir="auto">We welcome contributions, feature requests, and suggestions. Here is the link to open an <a href="https://github.com/IBM/AutoMLPipeline.jl/issues">issue</a> for any problems you encounter. If you want to contribute, please follow the guidelines in <a href="https://github.com/IBM/AutoMLPipeline.jl/blob/master/CONTRIBUTORS.md">contributors page</a>.</p>
<h3 dir="auto"><a id="user-content-help-usage" class="anchor" aria-hidden="true" href="#help-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Help usage</h3>
<p dir="auto">Usage questions can be posted in:</p>
<ul dir="auto">
<li><a href="https://julialang.org/community/" rel="nofollow">Julia Community</a></li>
<li><a href="https://gitter.im/AutoMLPipelineLearning/community" rel="nofollow">Gitter AutoMLPipeline Community</a></li>
<li><a href="https://discourse.julialang.org/" rel="nofollow">Julia Discourse forum</a></li>
</ul>
</article></div>