<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-tensorflow" class="anchor" aria-hidden="true" href="#tensorflow"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>TensorFlow</h1>
<p><a href="https://travis-ci.org/malmaud/TensorFlow.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/6a2d0ec68a1cf11b310c494a78481a6adecddf3a/68747470733a2f2f7472617669732d63692e6f72672f6d616c6d6175642f54656e736f72466c6f772e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/malmaud/TensorFlow.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="http://codecov.io/github/malmaud/TensorFlow.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/49900f96ab6b2c5bf63855586666c2969884aa50/687474703a2f2f636f6465636f762e696f2f6769746875622f6d616c6d6175642f54656e736f72466c6f772e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/malmaud/TensorFlow.jl/coverage.svg?branch=master" style="max-width:100%;"></a>
<a href="https://doi.org/10.21105/joss.01002" rel="nofollow"><img src="https://camo.githubusercontent.com/e91398cc0b1de49d2e8fdbd2aba866b2b5cf098f/687474703a2f2f6a6f73732e7468656f6a2e6f72672f7061706572732f31302e32313130352f6a6f73732e30313030322f7374617475732e737667" alt="DOI" data-canonical-src="http://joss.theoj.org/papers/10.21105/joss.01002/status.svg" style="max-width:100%;"></a></p>
<p>A wrapper around <a href="https://www.tensorflow.org/" rel="nofollow">TensorFlow</a>, a popular open source machine learning framework from Google.</p>
<h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Documentation</h2>
<p><a href="https://malmaud.github.io/TensorFlow.jl/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/57bae07ecd50a99519ad0516d91f4ec8f0f48e12/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg" style="max-width:100%;"></a></p>
<p>Other resources:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=n2MwJ1guGVQ&amp;t=2s" rel="nofollow">TensorFlow Dev Summit 2019 presentation</a></li>
<li><a href="https://www.youtube.com/watch?v=MaCf1PtHEJo" rel="nofollow">JuliaCon 2017 presentation</a></li>
</ul>
<h2><a id="user-content-why-use-tensorflowjl" class="anchor" aria-hidden="true" href="#why-use-tensorflowjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Why use TensorFlow.jl?</h2>
<p>See a <a href="https://github.com/malmaud/TensorFlow.jl/blob/master/docs/src/why_julia.md">list of advantages</a>
over the Python API.</p>
<h2><a id="user-content-whats-changed-recently" class="anchor" aria-hidden="true" href="#whats-changed-recently"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>What's changed recently?</h2>
<p>See <a href="https://github.com/malmaud/TensorFlow.jl/blob/master/NEWS.md">NEWS</a>.</p>
<h2><a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Basic usage</h2>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> TensorFlow
<span class="pl-k">using</span> Test

sess <span class="pl-k">=</span> TensorFlow<span class="pl-k">.</span><span class="pl-c1">Session</span>()

x <span class="pl-k">=</span> TensorFlow<span class="pl-k">.</span><span class="pl-c1">constant</span>(Float64[<span class="pl-c1">1</span>,<span class="pl-c1">2</span>])
y <span class="pl-k">=</span> TensorFlow<span class="pl-k">.</span><span class="pl-c1">Variable</span>(Float64[<span class="pl-c1">3</span>,<span class="pl-c1">4</span>])
z <span class="pl-k">=</span> TensorFlow<span class="pl-k">.</span><span class="pl-c1">placeholder</span>(Float64)

w <span class="pl-k">=</span> <span class="pl-c1">exp</span>(x <span class="pl-k">+</span> z <span class="pl-k">+</span> <span class="pl-k">-</span>y)

<span class="pl-c1">run</span>(sess, TensorFlow<span class="pl-k">.</span><span class="pl-c1">global_variables_initializer</span>())
res <span class="pl-k">=</span> <span class="pl-c1">run</span>(sess, w, <span class="pl-c1">Dict</span>(z<span class="pl-k">=&gt;</span>Float64[<span class="pl-c1">1</span>,<span class="pl-c1">2</span>]))
<span class="pl-c1">@test</span> res[<span class="pl-c1">1</span>] <span class="pl-k">â‰ˆ</span> <span class="pl-c1">exp</span>(<span class="pl-k">-</span><span class="pl-c1">1</span>)</pre></div>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>Install via</p>
<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>TensorFlow<span class="pl-pds">"</span></span>)</pre></div>
<p>To enable support for GPU usage on Linux, set an environment variable <code>TF_USE_GPU</code> to "1" and then rebuild the package. eg</p>
<div class="highlight highlight-source-julia"><pre>ENV[<span class="pl-s"><span class="pl-pds">"</span>TF_USE_GPU<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>1<span class="pl-pds">"</span></span>
Pkg<span class="pl-k">.</span><span class="pl-c1">build</span>(<span class="pl-s"><span class="pl-pds">"</span>TensorFlow<span class="pl-pds">"</span></span>)</pre></div>
<p>CUDA 8.0 and cudnn are required for GPU usage.
If you need to use a different version of CUDA, or if you want GPU support on Mac OS X, you can <a href="#optional-using-a-custom-tensorflow-binary">compile libtensorflow from source</a>.</p>
<p>Initial precompilation (eg, the first time you type <code>using TensorFlow</code>) can take around five minutes, so please be patient. Subsequent load times will only be a few seconds.</p>
<h2><a id="user-content-installation-via-docker" class="anchor" aria-hidden="true" href="#installation-via-docker"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation via Docker</h2>
<p>Simply run <code>docker run -it malmaud/julia:tf</code> to open a Julia REPL that already
has TensorFlow installed:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> TensorFlow
julia<span class="pl-k">&gt;</span></pre></div>
<p>For a version of TensorFlow.jl that utilizes GPUs, use <code>nvidia-docker run -it malmaud/julia:tf_gpu</code>.
Download <a href="https://github.com/NVIDIA/nvidia-docker">nvidia-docker</a> if you don't
already have it.</p>
<h2><a id="user-content-logistic-regression-example" class="anchor" aria-hidden="true" href="#logistic-regression-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Logistic regression example</h2>
<p>Realistic demonstration of using variable scopes and advanced optimizers</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> TensorFlow
<span class="pl-k">using</span> Distributions
<span class="pl-k">using</span> Printf

<span class="pl-c"><span class="pl-c">#</span> Generate some synthetic data</span>
x <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">100</span>, <span class="pl-c1">50</span>)
w <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">50</span>, <span class="pl-c1">10</span>)
y_prob <span class="pl-k">=</span> <span class="pl-c1">exp</span>.(x<span class="pl-k">*</span>w)
y_prob <span class="pl-k">./=</span> <span class="pl-c1">sum</span>(y_prob,dims<span class="pl-k">=</span><span class="pl-c1">2</span>)

<span class="pl-k">function</span> <span class="pl-en">draw</span>(probs)
    y <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">size</span>(probs))
    <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">size</span>(probs, <span class="pl-c1">1</span>)
        idx <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">Categorical</span>(probs[i, :]))
        y[i, idx] <span class="pl-k">=</span> <span class="pl-c1">1</span>
    <span class="pl-k">end</span>
    <span class="pl-k">return</span> y
<span class="pl-k">end</span>

y <span class="pl-k">=</span> <span class="pl-c1">draw</span>(y_prob)

<span class="pl-c"><span class="pl-c">#</span> Build the model</span>
sess <span class="pl-k">=</span> <span class="pl-c1">Session</span>(<span class="pl-c1">Graph</span>())

X <span class="pl-k">=</span> <span class="pl-c1">placeholder</span>(Float64, shape<span class="pl-k">=</span>[<span class="pl-k">-</span><span class="pl-c1">1</span>, <span class="pl-c1">50</span>])
Y_obs <span class="pl-k">=</span> <span class="pl-c1">placeholder</span>(Float64, shape<span class="pl-k">=</span>[<span class="pl-k">-</span><span class="pl-c1">1</span>, <span class="pl-c1">10</span>])

<span class="pl-c1">variable_scope</span>(<span class="pl-s"><span class="pl-pds">"</span>logisitic_model<span class="pl-pds">"</span></span>; initializer<span class="pl-k">=</span><span class="pl-c1">Normal</span>(<span class="pl-c1">0</span>, <span class="pl-c1">.001</span>)) <span class="pl-k">do</span>
    <span class="pl-k">global</span> W <span class="pl-k">=</span> <span class="pl-c1">get_variable</span>(<span class="pl-s"><span class="pl-pds">"</span>W<span class="pl-pds">"</span></span>, [<span class="pl-c1">50</span>, <span class="pl-c1">10</span>], Float64)
    <span class="pl-k">global</span> B <span class="pl-k">=</span> <span class="pl-c1">get_variable</span>(<span class="pl-s"><span class="pl-pds">"</span>B<span class="pl-pds">"</span></span>, [<span class="pl-c1">10</span>], Float64)
<span class="pl-k">end</span>

Y<span class="pl-k">=</span>nn<span class="pl-k">.</span><span class="pl-c1">softmax</span>(X<span class="pl-k">*</span>W <span class="pl-k">+</span> B)

Loss <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">reduce_sum</span>(<span class="pl-c1">log</span>(Y)<span class="pl-k">.*</span>Y_obs)
optimizer <span class="pl-k">=</span> train<span class="pl-k">.</span><span class="pl-c1">AdamOptimizer</span>()
minimize_op <span class="pl-k">=</span> train<span class="pl-k">.</span><span class="pl-c1">minimize</span>(optimizer, Loss)
saver <span class="pl-k">=</span> train<span class="pl-k">.</span><span class="pl-c1">Saver</span>()

<span class="pl-c"><span class="pl-c">#</span> Run training</span>
<span class="pl-c1">run</span>(sess, <span class="pl-c1">global_variables_initializer</span>())
checkpoint_path <span class="pl-k">=</span> <span class="pl-c1">mktempdir</span>()
<span class="pl-c1">@info</span>(<span class="pl-s"><span class="pl-pds">"</span>Checkpoint files saved in <span class="pl-v">$checkpoint_path</span><span class="pl-pds">"</span></span>)
<span class="pl-k">for</span> epoch <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">100</span>
    cur_loss, _ <span class="pl-k">=</span> <span class="pl-c1">run</span>(sess, [Loss, minimize_op], <span class="pl-c1">Dict</span>(X<span class="pl-k">=&gt;</span>x, Y_obs<span class="pl-k">=&gt;</span>y))
    <span class="pl-c1">println</span>(<span class="pl-c1">@sprintf</span>(<span class="pl-s"><span class="pl-pds">"</span>Current loss is %.2f.<span class="pl-pds">"</span></span>, cur_loss))
    train<span class="pl-k">.</span><span class="pl-c1">save</span>(saver, sess, <span class="pl-c1">joinpath</span>(checkpoint_path, <span class="pl-s"><span class="pl-pds">"</span>logistic<span class="pl-pds">"</span></span>), global_step<span class="pl-k">=</span>epoch)
<span class="pl-k">end</span></pre></div>
<h2><a id="user-content-troubleshooting" class="anchor" aria-hidden="true" href="#troubleshooting"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Troubleshooting</h2>
<p>If you see issues from the ccall or python interop, try updating TensorFlow both in Julia and in the global python install:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> Pkg<span class="pl-k">.</span><span class="pl-c1">build</span>(<span class="pl-s"><span class="pl-pds">"</span>TensorFlow<span class="pl-pds">"</span></span>)</pre></div>
<div class="highlight highlight-source-shell"><pre>$ pip install --upgrade tensorflow</pre></div>
<h2><a id="user-content-citing" class="anchor" aria-hidden="true" href="#citing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Citing</h2>
<p>If you use this software in your research, we would really appreciate if you cite us.</p>
<pre><code>Malmaud, J. &amp; White, L. (2018). TensorFlow.jl: An Idiomatic Julia Front End for TensorFlow. Journal of Open Source Software, 3(31), 1002, https://doi.org/10.21105/joss.01002
</code></pre>
<h2><a id="user-content-optional-using-a-custom-tensorflow-binary" class="anchor" aria-hidden="true" href="#optional-using-a-custom-tensorflow-binary"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Optional: Using a custom TensorFlow binary</h2>
<p>To build TensorFlow from source, or if you already have a TensorFlow binary that you wish to use, follow <a href="https://malmaud.github.io/TensorFlow.jl/latest/build_from_source.html" rel="nofollow">these instructions</a>. This is recommended by Google for maximum performance, and is currently needed for Mac OS X GPU support.</p>
<p>For Linux users, a convenience script is included to use Docker to easily build the library. Just install docker and run <code>julia build_libtensorflow.so</code> from the "deps" directory of the TensorFlow.jl package. Note that this method may not link to all libraries available on the target system such as Intel MKL.</p>
</article></div>