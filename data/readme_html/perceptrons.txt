<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-perceptronsjl" class="anchor" aria-hidden="true" href="#perceptronsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Perceptrons.jl</h1>
<p>A package with several types of Perceptron classifiers. Perceptrons are fast classifiers and can be used even for big data. Up to now, this package contains a linear perceptron, voted perceptron and a Kernel perceptron for binary classification problems. This project will have the following perceptron classifiers: Multiclass, Kernel, Structured, Voted, Average and Sparse. Some state-of-the-art must be included after these.</p>
<p><a href="https://travis-ci.org/lalvim/Perceptrons.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/38a06ea20c99c55ad572c0955ac533b82bc4c650/68747470733a2f2f7472617669732d63692e6f72672f6c616c76696d2f50657263657074726f6e732e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/lalvim/Perceptrons.jl.svg?branch=master" style="max-width:100%;"></a></p>
<p><a href="https://coveralls.io/github/lalvim/Perceptrons.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/0ccec524373b2f239286bd200ada8efc12aed668/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6c616c76696d2f50657263657074726f6e732e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/lalvim/Perceptrons.jl/badge.svg?branch=master&amp;service=github" style="max-width:100%;"></a></p>
<p><a href="http://codecov.io/github/lalvim/Perceptrons.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/8d76b5c44dd2cab579de39c60bb7b2ec25dcdb0f/687474703a2f2f636f6465636f762e696f2f6769746875622f6c616c76696d2f50657263657074726f6e732e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/lalvim/Perceptrons.jl/coverage.svg?branch=master" style="max-width:100%;"></a></p>
<h1><a id="user-content-install" class="anchor" aria-hidden="true" href="#install"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Install</h1>
<pre><code>Pkg.add("Perceptrons")
</code></pre>
<h1><a id="user-content-using" class="anchor" aria-hidden="true" href="#using"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Using</h1>
<pre><code>using Perceptrons
</code></pre>
<h1><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples</h1>
<pre><code>using Perceptrons

# training a linear perceptron (solving the OR problem)
X_train        = [1.0 1.0; 0.0 1.0; 1.0 0.0; 0.0 0.0]
Y_train        = [1; 1; 1; 0.0]
X_test         = [.8 .9; .01 1; .9 0.2; 0.1 0.2]

model          = Perceptrons.fit(X_train,Y_train)
Y_pred         = Perceptrons.predict(model,X_test)

println("[Perceptron] accuracy : $(acc(Y_train,Y_pred))")

# training a voted perceptron (solving the OR problem)
model   = Perceptrons.fit(X_train,Y_train,centralize=true,mode="voted")
Y_pred  = Perceptrons.predict(model,X_test)

println("[Voted Perceptron] accuracy : $(acc(Y_train,Y_pred))")

# training a averaged perceptron (solving the OR problem)
model   = Perceptrons.fit(X_train,Y_train,centralize=true,mode="averaged")
Y_pred  = Perceptrons.predict(model,X_test)

println("[Averaged Perceptron] accuracy : $(acc(Y_train,Y_pred))")

# training a kernel perceptron (solving the XOR problem)
X_train = [1.0 1.0; 0.0 1.0; 1.0 0.0; 0.0 0.0]
Y_train = [0.0 ; 1.0; 1.0; 0.0]
X_test  = X_train .+ .03 # adding noise

model   = Perceptrons.fit(X_train,Y_train,centralize=true,mode="kernel",kernel="rbf",width=.01)
Y_pred  = Perceptrons.predict(model,X_test)

println("[Kernel Perceptron] accuracy : $(acc(Y_train,Y_pred))")


# if you want to save your model
Perceptrons.save(model,filename=joinpath(homedir(),"perceptron_model.jld"))

# if you want to load back your model
model = Perceptrons.load(filename=joinpath(homedir(),"perceptron_model.jld"))
</code></pre>
<h1><a id="user-content-what-is-implemented" class="anchor" aria-hidden="true" href="#what-is-implemented"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>What is Implemented</h1>
<ul>
<li>Voted Perceptron</li>
<li>Averaged Perceptron</li>
<li>Kernel Perceptron</li>
<li>Linear Perceptron</li>
</ul>
<h1><a id="user-content-what-is-upcoming" class="anchor" aria-hidden="true" href="#what-is-upcoming"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>What is Upcoming</h1>
<ul>
<li>Multiclass Perceptron</li>
<li>Structured Perceptron</li>
<li>Sparse Perceptron</li>
</ul>
<h1><a id="user-content-method-description" class="anchor" aria-hidden="true" href="#method-description"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Method Description</h1>
<ul>
<li>
<p>Perceptrons.fit - learns from input data and its related single target</p>
<ul>
<li>X::Matrix{:&lt;AbstractFloat} - A matrix that columns are the features and rows are the samples</li>
<li>Y::Vector{:&lt;AbstractFloat} - A vector with float values.</li>
<li>copydata::Bool = true: If you want to use the same input matrix or a copy.</li>
<li>centralize::Bool = true: If you want to z-score columns. Recommended if not z-scored yet.</li>
<li>mode::AbstractString =  "linear": modes are "linear", "kernel", "voted" and "averaged" perceptron.</li>
<li>kernel::AbstractString = "rbf": If you want to apply a nonlinear Perceptron with gaussian Kernel.</li>
<li>width::AbstractFloat = 1.0: Rbf Kernel width (Only if kernel="rbf").</li>
<li>alpha::Real = 1.0e-2: learning rate.</li>
<li>shuffle_epoch::Bool = true: Shuffle dataset for each epoch. Improves convergency.</li>
<li>random_state::Int = 42: Use a seed to force same results trhough the same dataset.</li>
<li>max_epochs::Int = 5: Maximum epochs.</li>
</ul>
</li>
<li>
<p>Perceptrons.predict - predicts using the learnt model extracted from fit.</p>
<ul>
<li>model::Perceptrons.Model - A Perceptron model learnt from fit.</li>
<li>X::Matrix{:&lt;AbstractFloat} - A matrix that columns are the features and rows are the samples.</li>
<li>copydata::Bool = true - If you want to use the same input matrix or a copy.</li>
</ul>
</li>
</ul>
<h1><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>References</h1>
<p>TODO</p>
<h1><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>License</h1>
<p>The Perceptrons.jl is free software: you can redistribute it and/or modify it under the terms of the MIT "Expat"
License. A copy of this license is provided in <code>LICENSE.md</code></p>
</article></div>