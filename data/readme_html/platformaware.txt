<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-platformawarejl" class="anchor" aria-hidden="true" href="#platformawarejl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>PlatformAware.jl</h1>
<p dir="auto"><a href="https://github.com/decarvalhojunior-fh/PlatformAware.jl/actions/workflows/TagBot.yml"><img src="https://github.com/PlatformAwareProgramming/PlatformAware.jl/actions/workflows/TagBot.yml/badge.svg" alt="TagBot" style="max-width: 100%;"></a>
<a href="https://github.com/PlatformAwareProgramming/PlatformAware.jl/actions/workflows/CompatHelper.yml"><img src="https://github.com/PlatformAwareProgramming/PlatformAware.jl/actions/workflows/CompatHelper.yml/badge.svg" alt="CompatHelper" style="max-width: 100%;"></a></p>
<p dir="auto"><em>A package for improving the practice of <strong>platform-aware programming</strong> in Julia</em>.</p>
<p dir="auto">It helps HPC package developers write code for different versions of computationally intensive functions (kernels) according to different assumptions about the features of the execution platform.</p>
<h1 dir="auto"><a id="user-content-what-is-platform-aware-programming-" class="anchor" aria-hidden="true" href="#what-is-platform-aware-programming-"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>What is platform-aware programming ?</h1>
<p dir="auto">We define platform-aware programming as the practice of coding computationally intensive functions, called <em>kernels</em>, using the most appropriate abstractions and programming interfaces, as well as performance tuning techniques, to take better advantage of the features of the target execution platform. This is a well-known practice in programming for HPC applications.</p>
<p dir="auto">Platform-aware programming is especially suitable when the developer is interested in employing heterogeneous computing resources, such as accelerators (e.g., GPUs, FPGAs, and MICs), especially in conjunction with multicore and cluster computing.</p>
<p dir="auto">For example, suppose a package developer is interested in providing a specialized kernel implementation for <a href="https://www.nvidia.com/en-us/data-center/a100" rel="nofollow">NVIDIA A100 Tensor Core GPUs</a>, meeting the demand from users of a specific cloud provider offering virtual machines with accelerators of this model. The developer would like to use CUDA programming with this device's supported <em>computing capability</em> (8.0). However, other users may require support from other cloud providers that support different accelerator models, from different vendors (for example, <a href="https://www.amd.com/en/products/server-accelerators/amd-instinct-mi210" rel="nofollow">AMD Instinctâ„¢ MI210</a> and <a href="https://www.intel.com/content/www/us/en/products/details/fpga/agilex/f-series.html" rel="nofollow">IntelÂ® Agilexâ„¢ F-Series FPGA and SoC FPGA</a>). In this scenario, the developer will face the challenge of coding and deploying for multiple devices. This is a typical platform-aware programming scenario where <em>PlatformAware.jl</em> should be useful, which is becoming increasingly common as the use of heterogeneous computing platforms increases to accelerate AI and data analytics applications.</p>
<h2 dir="auto"><a id="user-content-target-users" class="anchor" aria-hidden="true" href="#target-users"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Target users</h2>
<p dir="auto"><em>PlatformAware.jl</em> is aimed primarily at <strong><em>package developers</em></strong> dealing with HPC concerns, especially using heterogenous computing resources.
We assume that <strong><em>package users</em></strong> are only interested in using package operations without being concerned about how they are implemented.</p>
<h1 dir="auto"><a id="user-content-usage-tutorial" class="anchor" aria-hidden="true" href="#usage-tutorial"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage tutorial</h1>
<p dir="auto">We present a simple example that readers may reproduce to test <em>PlatformAware.jl</em> features.</p>
<p dir="auto">Consider the problem of performing a convolution operation using a Fast Fourier Transform (FFT). To do this, the user can implement a <code>fftconv</code> function that uses a <code>fft</code> function offered by a user-defined package called <em>MyFFT.jl</em>, capable of performing the FFT on an accelerator (e.g., GPU) if it is present.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using MyFFT
fftconv(X,K) = fft(X) .* conj.(fft(K)) "><pre><span class="pl-k">using</span> MyFFT
<span class="pl-en">fftconv</span>(X,K) <span class="pl-k">=</span> <span class="pl-c1">fft</span>(X) <span class="pl-k">.*</span> <span class="pl-c1">conj</span>.(<span class="pl-c1">fft</span>(K)) </pre></div>
<p dir="auto">This tutorial shows how to create <em>MyFFT.jl</em>, demonstrating the basics of how to install <em>PlatformAware.jl</em> and how to use it to create a platform-aware package.</p>
<h2 dir="auto"><a id="user-content-creating-the-myfftjl-project" class="anchor" aria-hidden="true" href="#creating-the-myfftjl-project"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Creating the <em>MyFFT.jl</em> project</h2>
<p dir="auto">In the Julia REPL, as shown in the screenshot below, run <code>] generate MyFFT.jl</code> to create a new project called <em>MyFFT.jl</em>, run <code>ðŸ”™cd("MyFFT.jl")</code> to move to the directory of the created project, and <code>] activate .</code> to enable the current project (<em>MyFFT.jl</em>) in the current Julia REPL session.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/PlatformAwareProgramming/PlatformAware.jl/master/docs/src/images/f1.png"><img src="https://raw.githubusercontent.com/PlatformAwareProgramming/PlatformAware.jl/master/docs/src/images/f1.png" alt="f1" style="max-width: 100%;"></a></p>
<p dir="auto">These operations create a standard <em>"hello world"</em> project, with the contents of the following snapshot:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/PlatformAwareProgramming/PlatformAware.jl/master/docs/src/images/f2.png"><img src="https://raw.githubusercontent.com/PlatformAwareProgramming/PlatformAware.jl/master/docs/src/images/f2.png" alt="f2" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-installing-platformawarejl" class="anchor" aria-hidden="true" href="#installing-platformawarejl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installing <em>PlatformAware.jl</em></h2>
<p dir="auto">Before coding the platform-aware package, it is necessary to add <em>PlatormAware.jl</em> as a dependency of <em>MyFFT.jl</em> by running the following command in the Julia REPL:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="] add PlatformAware"><pre>] add PlatformAware</pre></div>
<p dir="auto">Now, load the <em>PlatfomAware.jl</em> package (<code>using PlatformAware</code> or <code>import PlatformAware</code>) and read the output message:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/PlatformAwareProgramming/PlatformAware.jl/master/docs/src/images/f3.png"><img src="https://raw.githubusercontent.com/PlatformAwareProgramming/PlatformAware.jl/master/docs/src/images/f3.png" alt="f3" style="max-width: 100%;"></a></p>
<p dir="auto"><em>Platform.toml</em> is the <em>platform description file</em>, containing a set of key-value pairs, each describing a feature of the underlying platform. It must be created by the user running <code>PlatformWare.setup()</code>, which performs a sequence of feature detection operations on the platform.</p>
<p dir="auto"><em>Platform.toml</em> is written in a human-editable format. Therefore, it can be modified by users to add undetected platform features or ignore detected features.</p>
<h2 dir="auto"><a id="user-content-sketching-the-myfftjl-code" class="anchor" aria-hidden="true" href="#sketching-the-myfftjl-code"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Sketching the <em>MyFFT.jl</em> code</h2>
<p dir="auto">In order to implement the <em>fft</em> kernel function, we edit  the <em>src/MyFFT.jl</em> file. First, we sketch the code of the <em>fft</em> kernel methods:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="module MyFFT

  import PlatformAware

  # setup platorm features (parameters)
  @platform feature clear
  @platform feature accelerator_count
  @platform feature accelerator_api

  # Fallback kernel
  @platform default fft(X) = ...

  # OpenCL kernel, to be called 
  @platform aware fft({accelerator_count::(@atleast 1), accelerator_api::(@api OpenCL)}, X) = ...

  # CUDA kernel
  @platform aware fft({accelerator_count::(@atleast 1), accelerator_api::(@api CUDA)},X) = ...

  export fft

end"><pre><span class="pl-k">module</span> MyFFT

  <span class="pl-k">import</span> PlatformAware

  <span class="pl-c"><span class="pl-c">#</span> setup platorm features (parameters)</span>
  <span class="pl-c1">@platform</span> feature clear
  <span class="pl-c1">@platform</span> feature accelerator_count
  <span class="pl-c1">@platform</span> feature accelerator_api

  <span class="pl-c"><span class="pl-c">#</span> Fallback kernel</span>
  <span class="pl-c1">@platform</span> default <span class="pl-en">fft</span>(X) <span class="pl-k">=</span> <span class="pl-k">...</span>

  <span class="pl-c"><span class="pl-c">#</span> OpenCL kernel, to be called </span>
  <span class="pl-c1">@platform</span> aware <span class="pl-en">fft</span>({accelerator_count<span class="pl-k">::</span><span class="pl-c1">(@atleast 1)</span>, accelerator_api<span class="pl-k">::</span><span class="pl-c1">(@api OpenCL)</span>}, X) <span class="pl-k">=</span> <span class="pl-k">...</span>

  <span class="pl-c"><span class="pl-c">#</span> CUDA kernel</span>
  <span class="pl-c1">@platform</span> aware <span class="pl-en">fft</span>({accelerator_count<span class="pl-k">::</span><span class="pl-c1">(@atleast 1)</span>, accelerator_api<span class="pl-k">::</span><span class="pl-c1">(@api CUDA)</span>},X) <span class="pl-k">=</span> <span class="pl-k">...</span>

  <span class="pl-k">export</span> fft

<span class="pl-k">end</span></pre></div>
<p dir="auto">The sequence of <code>@platorm feature</code> macro declarations specifies the set of platform parameters that will be used by subsequent kernel method declarations, that is, the assumptions that will be made to distinguish them. You can refer to <a href="https://docs.google.com/spreadsheets/d/1n-c4b7RxUduaKV43XrTnt54w-SR1AXgVNI7dN2OkEUc/edit?usp=sharing" rel="nofollow">this table</a> for a list of all supported <em><strong>platform parameters</strong></em>. By default, they are all included. In the case of <code>fft</code>, the kernel methods are differentiated using only two parameters: <code>accelerator_count</code> and <code>accelerator_api</code>. They denote, respectively, assumptions about the number of accelerator devices and the native API they support.</p>
<p dir="auto">The <code>@platorm default</code> macro declares the <em>default kernel method</em>, which will be called if none of the assumptions of other kernel methods declared using <code>@platform aware</code> macro calls are valid. The default kernel must be unique to avoid ambiguity.</p>
<p dir="auto">Finally, the kernels for accelerators that support OpenCL and CUDA APIs are declared using the macro <code>@platform aware</code>. The list of platform parameters is declared just before the regular parameters, such as <code>X</code>, in braces. Their types denote assumptions. For example, <code>@atleast 1</code> denotes a quantifier representing one or more units of a resource, while<code> @api CUDA</code> and <code>@api OpenCL</code> denote types of qualifiers that refer to the CUDA and OpenCL APIs.</p>
<p dir="auto">The programmer must be careful not to declare kernel methods with overlapping assumptions in order to avoid ambiguities.</p>
<h2 dir="auto"><a id="user-content-other-dependencies" class="anchor" aria-hidden="true" href="#other-dependencies"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Other dependencies</h2>
<p dir="auto">Before adding the code for the kernels, add the code to load their dependencies. This can be done directly by adding the following code to the <em>src/MyFFT.jl</em> file, right after <code>import PlatformAware</code>:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import CUDA
import OpenCL
import CLFFT
import FFTW"><pre><span class="pl-k">import</span> CUDA
<span class="pl-k">import</span> OpenCL
<span class="pl-k">import</span> CLFFT
<span class="pl-k">import</span> FFTW</pre></div>
<p dir="auto">Also, you should add <em>CUDA.jl</em>, <em>OpenCL.jl</em>, <em>CLFFT.jl</em>, and <em>FFFT.jl</em> as dependencies of <em>MyFFT.jl</em>. To do this, execute the following commands in the Julia REPL:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="] add CUDA OpenCL CLFFT FFTW"><pre>] add CUDA OpenCL CLFFT FFTW</pre></div>
<blockquote>
<p dir="auto"><strong>NOTE</strong>: <a href="https://github.com/JuliaGPU/CLFFT.jl"><em>CLFFT.jl</em></a> is not available on JuliaHub due to compatibility issues with recent versions of Julia. We're working with the CLFFT.jl maintainers to address this issue. If you have an error with the CLFFT dependency, point to our <em>CLFFT.jl</em> fork by running <code>add https://github.com/JuliaGPU/CLFFT.jl#master</code>.</p>
</blockquote>
<p dir="auto">As a performance optimization, we can take advantage of platform-aware features to selectively load dependencies, speeding up the loading of <em>MyFFT.jl</em>. To do this, we first declare a kernel function called <code>which_api</code> in <em>src/MyFFT.jl</em>, right after the <code>@platform feature</code> declaration:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="@platform default which_api() = :fftw
@platform aware which_api({accelerator_api::(@api CUDA)}) = :cufft
@platform aware which_api({accelerator_api::(@api OpenCL)}) = :clfft"><pre><span class="pl-c1">@platform</span> default <span class="pl-en">which_api</span>() <span class="pl-k">=</span> <span class="pl-c1">:fftw</span>
<span class="pl-c1">@platform</span> aware <span class="pl-en">which_api</span>({accelerator_api<span class="pl-k">::</span><span class="pl-c1">(@api CUDA)</span>}) <span class="pl-k">=</span> <span class="pl-c1">:cufft</span>
<span class="pl-c1">@platform</span> aware <span class="pl-en">which_api</span>({accelerator_api<span class="pl-k">::</span><span class="pl-c1">(@api OpenCL)</span>}) <span class="pl-k">=</span> <span class="pl-c1">:clfft</span></pre></div>
<p dir="auto">Next, we add the code for selective dependency loading:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="api = which_api()
if (api == :cufft) 
    import CUDA
elseif (api == :clfft) 
    import OpenCL
    import CLFFT
else # api == :fftw 
    import FFTW
end"><pre>api <span class="pl-k">=</span> <span class="pl-c1">which_api</span>()
<span class="pl-k">if</span> (api <span class="pl-k">==</span> <span class="pl-c1">:cufft</span>) 
    <span class="pl-k">import</span> CUDA
<span class="pl-k">elseif</span> (api <span class="pl-k">==</span> <span class="pl-c1">:clfft</span>) 
    <span class="pl-k">import</span> OpenCL
    <span class="pl-k">import</span> CLFFT
<span class="pl-k">else</span> <span class="pl-c"><span class="pl-c">#</span> api == :fftw </span>
    <span class="pl-k">import</span> FFTW
<span class="pl-k">end</span></pre></div>
<h2 dir="auto"><a id="user-content-full-srcmyfftjl-code" class="anchor" aria-hidden="true" href="#full-srcmyfftjl-code"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Full <em>src/MyFFT.jl</em> code</h2>
<p dir="auto">Finally, we present the complete code for <em>src/MyFFT.jl</em>, with the implementation of the kernel methods:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="module MyFFT

    using PlatformAware

    @platform feature clear
    @platform feature accelerator_count
    @platform feature accelerator_api

    @platform default which_api() = :fftw
    @platform aware which_api({accelerator_count::(@atleast 1), accelerator_api::(@api CUDA)}) = :cufft
    @platform aware which_api({accelerator_count::(@atleast 1), accelerator_api::(@api OpenCL)}) = :clfft

    api = which_api()
    @info &quot;seleted FFT API&quot; api
    
    if (api == :cufft) 
        using CUDA; const cufft = CUDA.CUFFT
    elseif (api == :clfft) 
        using OpenCL
        using CLFFT; const clfft = CLFFT
    else # api == :fftw 
        using FFTW; const fftw = FFTW
    end

    # Fallback kernel
    @platform default fft(X) = fftw.fft(X)

    # OpenCL kernel
    @platform aware function fft({accelerator_count::(@atleast 1), accelerator_api::(@api OpenCL)}, X)
        T = eltype(X)
        _, ctx, queue = cl.create_compute_context()
        bufX = cl.Buffer(T, ctx, :copy, hostbuf=X)
        p = clfft.Plan(T, ctx, size(X))
        clfft.set_layout!(p, :interleaved, :interleaved)
        clfft.set_result!(p, :inplace)
        clfft.bake!(p, queue)
        clfft.enqueue_transform(p, :forward, [queue], bufX, nothing)
        reshape(cl.read(queue, bufX), size(X))
    end

    # CUDA kernel
    @platform aware fft({accelerator_count::(@atleast 1), accelerator_api::(@api CUDA)},X) = cufft.fft(X |&gt; CuArray)

    export fft

end # module MyFFT"><pre><span class="pl-k">module</span> MyFFT

    <span class="pl-k">using</span> PlatformAware

    <span class="pl-c1">@platform</span> feature clear
    <span class="pl-c1">@platform</span> feature accelerator_count
    <span class="pl-c1">@platform</span> feature accelerator_api

    <span class="pl-c1">@platform</span> default <span class="pl-en">which_api</span>() <span class="pl-k">=</span> <span class="pl-c1">:fftw</span>
    <span class="pl-c1">@platform</span> aware <span class="pl-en">which_api</span>({accelerator_count<span class="pl-k">::</span><span class="pl-c1">(@atleast 1)</span>, accelerator_api<span class="pl-k">::</span><span class="pl-c1">(@api CUDA)</span>}) <span class="pl-k">=</span> <span class="pl-c1">:cufft</span>
    <span class="pl-c1">@platform</span> aware <span class="pl-en">which_api</span>({accelerator_count<span class="pl-k">::</span><span class="pl-c1">(@atleast 1)</span>, accelerator_api<span class="pl-k">::</span><span class="pl-c1">(@api OpenCL)</span>}) <span class="pl-k">=</span> <span class="pl-c1">:clfft</span>

    api <span class="pl-k">=</span> <span class="pl-c1">which_api</span>()
    <span class="pl-c1">@info</span> <span class="pl-s"><span class="pl-pds">"</span>seleted FFT API<span class="pl-pds">"</span></span> api
    
    <span class="pl-k">if</span> (api <span class="pl-k">==</span> <span class="pl-c1">:cufft</span>) 
        <span class="pl-k">using</span> CUDA; <span class="pl-k">const</span> cufft <span class="pl-k">=</span> CUDA<span class="pl-k">.</span>CUFFT
    <span class="pl-k">elseif</span> (api <span class="pl-k">==</span> <span class="pl-c1">:clfft</span>) 
        <span class="pl-k">using</span> OpenCL
        <span class="pl-k">using</span> CLFFT; <span class="pl-k">const</span> clfft <span class="pl-k">=</span> CLFFT
    <span class="pl-k">else</span> <span class="pl-c"><span class="pl-c">#</span> api == :fftw </span>
        <span class="pl-k">using</span> FFTW; <span class="pl-k">const</span> fftw <span class="pl-k">=</span> FFTW
    <span class="pl-k">end</span>

    <span class="pl-c"><span class="pl-c">#</span> Fallback kernel</span>
    <span class="pl-c1">@platform</span> default <span class="pl-en">fft</span>(X) <span class="pl-k">=</span> fftw<span class="pl-k">.</span><span class="pl-c1">fft</span>(X)

    <span class="pl-c"><span class="pl-c">#</span> OpenCL kernel</span>
    <span class="pl-c1">@platform</span> aware <span class="pl-k">function</span> <span class="pl-en">fft</span>({accelerator_count<span class="pl-k">::</span><span class="pl-c1">(@atleast 1)</span>, accelerator_api<span class="pl-k">::</span><span class="pl-c1">(@api OpenCL)</span>}, X)
        T <span class="pl-k">=</span> <span class="pl-c1">eltype</span>(X)
        _, ctx, queue <span class="pl-k">=</span> cl<span class="pl-k">.</span><span class="pl-c1">create_compute_context</span>()
        bufX <span class="pl-k">=</span> cl<span class="pl-k">.</span><span class="pl-c1">Buffer</span>(T, ctx, <span class="pl-c1">:copy</span>, hostbuf<span class="pl-k">=</span>X)
        p <span class="pl-k">=</span> clfft<span class="pl-k">.</span><span class="pl-c1">Plan</span>(T, ctx, <span class="pl-c1">size</span>(X))
        clfft<span class="pl-k">.</span><span class="pl-c1">set_layout!</span>(p, <span class="pl-c1">:interleaved</span>, <span class="pl-c1">:interleaved</span>)
        clfft<span class="pl-k">.</span><span class="pl-c1">set_result!</span>(p, <span class="pl-c1">:inplace</span>)
        clfft<span class="pl-k">.</span><span class="pl-c1">bake!</span>(p, queue)
        clfft<span class="pl-k">.</span><span class="pl-c1">enqueue_transform</span>(p, <span class="pl-c1">:forward</span>, [queue], bufX, <span class="pl-c1">nothing</span>)
        <span class="pl-c1">reshape</span>(cl<span class="pl-k">.</span><span class="pl-c1">read</span>(queue, bufX), <span class="pl-c1">size</span>(X))
    <span class="pl-k">end</span>

    <span class="pl-c"><span class="pl-c">#</span> CUDA kernel</span>
    <span class="pl-c1">@platform</span> aware <span class="pl-en">fft</span>({accelerator_count<span class="pl-k">::</span><span class="pl-c1">(@atleast 1)</span>, accelerator_api<span class="pl-k">::</span><span class="pl-c1">(@api CUDA)</span>},X) <span class="pl-k">=</span> cufft<span class="pl-k">.</span><span class="pl-c1">fft</span>(X <span class="pl-k">|&gt;</span> CuArray)

    <span class="pl-k">export</span> fft

<span class="pl-k">end</span> <span class="pl-c"><span class="pl-c">#</span> module MyFFT</span></pre></div>
<h2 dir="auto"><a id="user-content-running-and-testing-the-fft-kernel-methods" class="anchor" aria-hidden="true" href="#running-and-testing-the-fft-kernel-methods"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Running and testing the <em>fft</em> kernel methods</h2>
<p dir="auto">To test <em>fft</em> in a convolution, open a Julia REPL session in the <em>MyFFT.jl</em> directory and execute the following commands:</p>
<blockquote>
<p dir="auto"><strong>NOTE</strong>: If you receive an ambiguity error after executing <em>fftconv</em>, don't panic ! Read the next paragraphs.</p>
</blockquote>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content=" import Pkg; Pkg.activate(&quot;.&quot;)
 using MyFFT
 
 function fftconv(img,krn) 
   padkrn = zeros(size(img))
   copyto!(padkrn,CartesianIndices(krn),krn,CartesianIndices(krn))
   fft(img) .* conj.(fft(padkrn))  
 end
 
 img = rand(Float64,(20,20,20))  # image
 krn = rand(Float64,(4,4,4))     # kernel
 
 fftconv(img,krn) "><pre> <span class="pl-k">import</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">activate</span>(<span class="pl-s"><span class="pl-pds">"</span>.<span class="pl-pds">"</span></span>)
 <span class="pl-k">using</span> MyFFT
 
 <span class="pl-k">function</span> <span class="pl-en">fftconv</span>(img,krn) 
   padkrn <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(<span class="pl-c1">size</span>(img))
   <span class="pl-c1">copyto!</span>(padkrn,<span class="pl-c1">CartesianIndices</span>(krn),krn,<span class="pl-c1">CartesianIndices</span>(krn))
   <span class="pl-c1">fft</span>(img) <span class="pl-k">.*</span> <span class="pl-c1">conj</span>.(<span class="pl-c1">fft</span>(padkrn))  
 <span class="pl-k">end</span>
 
 img <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float64,(<span class="pl-c1">20</span>,<span class="pl-c1">20</span>,<span class="pl-c1">20</span>))  <span class="pl-c"><span class="pl-c">#</span> image</span>
 krn <span class="pl-k">=</span> <span class="pl-c1">rand</span>(Float64,(<span class="pl-c1">4</span>,<span class="pl-c1">4</span>,<span class="pl-c1">4</span>))     <span class="pl-c"><span class="pl-c">#</span> kernel</span>
 
 <span class="pl-c1">fftconv</span>(img,krn) </pre></div>
<p dir="auto">The <em>fft</em> kernel method that corresponds to the current <em>Platform.toml</em> will be selected. If <em>Platform.toml</em> was not created before, the default kernel method will be selected. The reader can consult the <em>Platform.toml</em> file to find out about the platform features detected by <em>PlatformAware.setup()</em>. The reader can also see the selected FFT API in the logging messages after <code>using MyFFT</code>.</p>
<p dir="auto">By carefully modifying the <em>Platform.toml</em> file, the reader can test all kernel methods. For example, if an NVIDIA GPU was recognized by <em>PlatformAware.setup()</em>, the <code>accelerator_api</code> entry in <em>Platform.toml</em> will probably include the supported CUDA and OpenCL versions. For example, for an NVIDIA GeForce 940MX GPU, <code>accelerator_api = "CUDA_5_0;OpenCL_3_0;unset;unset;OpenGL_4_6;Vulkan_1_3;DirectX_11_0"</code>. This may lead to an ambiguity error, as multiple dispatch will not be able to distinguish between the OpenCL and CUDA kernel methods based on the <code>accelerator_api</code> parameter alone. In this case, there are two alternatives:</p>
<ul dir="auto">
<li>To edit <em>Platform.toml</em> by setting CUDA or OpenCL platform type (e.g. <code>CUDA_5_0</code> or <code>OpenCL_3_0</code>) to <code>unset</code> in the <code>accelerator_api</code> entry, making it possible to select manually the kernel method that will be selected;</li>
<li>To modify the CUDA kernel signature by including, for example, <code>accelerator_manufacturer::NVIDIA</code> in the list of platform parameters, so that NVIDIA GPUs will give preference to CUDA and OpenCL will be applied to accelerators of other vendors (recommended).</li>
</ul>
<h2 dir="auto"><a id="user-content-a-general-guideline" class="anchor" aria-hidden="true" href="#a-general-guideline"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>A general guideline</h2>
<p dir="auto">Therefore, we suggest the following general guideline for package developers who want to take advantage of <em>PlatformWare.jl</em>.</p>
<ol dir="auto">
<li>
<p dir="auto">Identify the <em>kernel functions</em>, that is, the functions with high computational requirements in your package, which are the natural candidates to exploit parallel computing, acceleration resources, or both.</p>
</li>
<li>
<p dir="auto">Provide a default (fallback) method for each kernel function, using the <code>@platform default</code> macro.</p>
</li>
<li>
<p dir="auto">Identify the target execution platforms to which you want to provide specialized methods for each kernel function. You can choose a set of execution platforms for all kernels, or you can select one or more platforms for each kernel independently. For helping your choice, look at the following information sources:</p>
<ul dir="auto">
<li>the <a href="https://docs.google.com/spreadsheets/d/1n-c4b7RxUduaKV43XrTnt54w-SR1AXgVNI7dN2OkEUc/edit?usp=sharing" rel="nofollow">table of supported <em>platform <strong>parameters</strong></em></a>, which will help you to know which assumptions <em>PlatformAware.jl</em> already allow you to make about the target execution platorm;</li>
<li>the database of supported <em>platform <strong>features</strong></em>, where the features of the models of processors and accelerators that are currently suported by <em>PlatformAware.jl</em> are described:
<ul dir="auto">
<li>AMD <a href="https://github.com/PlatformAwareProgramming/PlatformAware.jl/blob/master/src/features/qualifiers/amd/db-accelerators.AMD.csv">accelerators</a> and <a href="https://github.com/PlatformAwareProgramming/PlatformAware.jl/blob/master/src/features/qualifiers/amd/db-processors.AMD.csv">processors</a>;</li>
<li>Intel <a href="https://github.com/PlatformAwareProgramming/PlatformAware.jl/blob/master/src/features/qualifiers/intel/db-accelerators.Intel.csv">accelerators</a> and <a href="https://github.com/PlatformAwareProgramming/PlatformAware.jl/blob/master/src/features/qualifiers/intel/db-processors.Intel.csv">processors</a>;</li>
<li>NVIDIA <a href="https://github.com/PlatformAwareProgramming/PlatformAware.jl/blob/master/src/features/qualifiers/nvidia/db-accelerators.NVIDIA.csv">accelerators</a>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">For each platform you select, define a set of assumptions about its features that will guide your implementation decisions. In fact, it is possible to define different assumptions for the same platform, leading to multiple implementations of a kernel for the same platform. For example, you might decide to implement different parallel algorithms to solve a problem according to the number of nodes and the interconnection characteristics of a cluster.</p>
</li>
<li>
<p dir="auto">Provide platform-aware methods for each kernel function using the <code>@platform aware</code> macro.</p>
</li>
<li>
<p dir="auto">After implementing and testing all platform-aware methods, you have a list of platform parameters that were used to make assumptions about the target execution platform(s). You can optionally instruct the <em>PlatformAware.jl</em> to use only that parameters by using the <code>@platform feature</code> macro.</p>
</li>
</ol>
<h1 dir="auto"><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributing</h1>
<p dir="auto">Contributions are very welcome, as are feature requests and suggestions.</p>
<p dir="auto">Please <a href="https://github.com/PlatformAwareProgramming/PlatformAware.jl">open an issue</a> if you encounter any problems.</p>
<h1 dir="auto"><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>License</h1>
<p dir="auto"><em>PlatformAware.jl</em> is licensed under the <a href="https://github.com/PlatformAwareProgramming/PlatformAware.jl/blob/master/LICENSE">MIT License</a></p>
</article></div>