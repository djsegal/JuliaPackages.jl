<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-discretevalueiteration" class="anchor" aria-hidden="true" href="#discretevalueiteration"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>DiscreteValueIteration</h1>
<p><a href="https://travis-ci.org/JuliaPOMDP/DiscreteValueIteration.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/7b54cdc71c4f4f5750b2ae8568e35d53882d33ce/68747470733a2f2f7472617669732d63692e6f72672f4a756c6961504f4d44502f446973637265746556616c7565497465726174696f6e2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/JuliaPOMDP/DiscreteValueIteration.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/JuliaPOMDP/DiscreteValueIteration.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/fd70fd3cbdf286dc579bda836855304478d9adec/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4a756c6961504f4d44502f446973637265746556616c7565497465726174696f6e2e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/JuliaPOMDP/DiscreteValueIteration.jl/badge.svg?branch=master" style="max-width:100%;"></a></p>
<p>This package implements the discrete value iteration algorithm in Julia for solving Markov decision processes (MDPs).
The user should define the problem with <a href="https://github.com/JuliaPOMDP/QuickPOMDPs.jl">QuickPOMDPs.jl</a> or according to the API in <a href="https://github.com/JuliaPOMDP/POMDPs.jl">POMDPs.jl</a>. Examples of
problem definitions can be found in <a href="https://github.com/JuliaPOMDP/POMDPModels.jl">POMDPModels.jl</a>. For an extensive tutorial, see <a href="https://github.com/JuliaPOMDP/POMDPExamples.jl">these</a> notebooks.</p>
<p>There are two solvers in the package. The "vanilla" <a href="src/vanilla.jl"><code>ValueIterationSolver</code></a> calls functions from the POMDPs.jl interface in every iteration, while the <a href="src/sparse.jl"><code>SparseValueIterationSolver</code></a> first creates sparse transition and reward matrices and then performs value iteration with the new matrix representation. While both solvers take advantage of sparsity, the <code>SparseValueIterationSolver</code> is generally faster because of low-level optimizations, while the <code>ValueIterationSolver</code> has the advantage that it does not require allocation of transition matrices (which could potentially be too large to fit in memory).</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>Start Julia and make sure you have the JuliaPOMDP registry:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">import</span> POMDPs
POMDPs<span class="pl-k">.</span><span class="pl-c1">add_registry</span>()</pre></div>
<p>Then install using the standard package manager:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>DiscreteValueIteration<span class="pl-pds">"</span></span>)</pre></div>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<p>Given an MDP <code>mdp</code> defined with <a href="https://github.com/JuliaPOMDP/QuickPOMDPs.jl">QuickPOMDPs.jl</a> or the POMDPs.jl interface, use</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> DiscreteValueIteration

solver <span class="pl-k">=</span> <span class="pl-c1">ValueIterationSolver</span>(max_iterations<span class="pl-k">=</span><span class="pl-c1">100</span>, belres<span class="pl-k">=</span><span class="pl-c1">1e-6</span>, verbose<span class="pl-k">=</span><span class="pl-c1">true</span>) <span class="pl-c"><span class="pl-c">#</span> creates the solver</span>
<span class="pl-c1">solve</span>(solver, mdp) <span class="pl-c"><span class="pl-c">#</span> runs value iterations</span></pre></div>
<p>To extract the policy for a given state, simply call the action function:</p>
<div class="highlight highlight-source-julia"><pre>a <span class="pl-k">=</span> <span class="pl-c1">action</span>(policy, s) <span class="pl-c"><span class="pl-c">#</span> returns the optimal action for state s</span></pre></div>
<p>Or to extract the value, use</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">value</span>(policy, s) <span class="pl-c"><span class="pl-c">#</span> returns the optimal value at state s</span></pre></div>
<h3><a id="user-content-requirements-for-problems-defined-using-the-pomdpsjl-interface" class="anchor" aria-hidden="true" href="#requirements-for-problems-defined-using-the-pomdpsjl-interface"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Requirements for problems defined using the POMDPs.jl interface</h3>
<p>If you are using the POMDPs.jl interface instead of QuickPOMDPs.jl, you can see the requirements for using these solvers with</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> POMDPs
<span class="pl-k">using</span> DiscreteValueIteration
<span class="pl-c1">@requirements_info</span> <span class="pl-c1">ValueIterationSolver</span>() <span class="pl-c1">YourMDP</span>()
<span class="pl-c1">@requirements_info</span> <span class="pl-c1">SparseValueIterationSolver</span>() <span class="pl-c1">YourMDP</span>()</pre></div>
<p>This should return a list of the following functions to be implemented for your MDP:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">discount</span>(<span class="pl-k">::</span><span class="pl-c1">MDP</span>)
<span class="pl-c1">n_states</span>(<span class="pl-k">::</span><span class="pl-c1">MDP</span>)
<span class="pl-c1">n_actions</span>(<span class="pl-k">::</span><span class="pl-c1">MDP</span>)
<span class="pl-c1">transition</span>(<span class="pl-k">::</span><span class="pl-c1">MDP</span>, <span class="pl-k">::</span><span class="pl-c1">State</span>, <span class="pl-k">::</span><span class="pl-c1">Action</span>)
<span class="pl-c1">reward</span>(<span class="pl-k">::</span><span class="pl-c1">MDP</span>, <span class="pl-k">::</span><span class="pl-c1">State</span>, <span class="pl-k">::</span><span class="pl-c1">Action</span>, <span class="pl-k">::</span><span class="pl-c1">State</span>)
<span class="pl-c1">stateindex</span>(<span class="pl-k">::</span><span class="pl-c1">MDP</span>, <span class="pl-k">::</span><span class="pl-c1">State</span>)
<span class="pl-c1">actionindex</span>(<span class="pl-k">::</span><span class="pl-c1">MDP</span>, <span class="pl-k">::</span><span class="pl-c1">Action</span>)
<span class="pl-c1">actions</span>(<span class="pl-k">::</span><span class="pl-c1">MDP</span>, <span class="pl-k">::</span><span class="pl-c1">State</span>)
<span class="pl-c1">support</span>(<span class="pl-k">::</span><span class="pl-c1">StateDistribution</span>)
<span class="pl-c1">pdf</span>(<span class="pl-k">::</span><span class="pl-c1">StateDistribution</span>, <span class="pl-k">::</span><span class="pl-c1">State</span>)
<span class="pl-c1">states</span>(<span class="pl-k">::</span><span class="pl-c1">MDP</span>)
<span class="pl-c1">actions</span>(<span class="pl-k">::</span><span class="pl-c1">MDP</span>)</pre></div>
</article></div>