<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-foldscuda" class="anchor" aria-hidden="true" href="#foldscuda"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>FoldsCUDA</h1>
<p dir="auto"><a href="https://juliafolds.github.io/FoldsCUDA.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://buildkite.com/julialang/foldscuda-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/06413c8090bf2a2ec191d324e9563d7073e6b1e0bb660284a72d343b7e70bb56/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f63343139366566326661353838343534633134366261623030303164306638646538373661613836346162376335646538302e7376673f6272616e63683d6d6173746572" alt="Buildkite status" data-canonical-src="https://badge.buildkite.com/c4196ef2fa588454c146bab0001d0f8de876aa864ab7c5de80.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://github.com/JuliaFolds/FoldsCUDA.jl/actions?query=workflow%3A%22Run+tests+w%2Fo+GPU%22"><img src="https://github.com/JuliaFolds/FoldsCUDA.jl/workflows/Run%20tests%20w/o%20GPU/badge.svg" alt="Run tests w/o GPU" style="max-width: 100%;"></a></p>
<p dir="auto">FoldsCUDA.jl provides
<a href="https://github.com/JuliaFolds/Transducers.jl">Transducers.jl</a>-compatible
fold (reduce) implemented using
<a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a>.  This brings the
transducers and reducing function combinators implemented in
Transducers.jl to GPU.  Furthermore, using
<a href="https://github.com/JuliaFolds/FLoops.jl">FLoops.jl</a>, you can write
parallel <code>for</code> loops that run on GPU.</p>
<h2 dir="auto"><a id="user-content-api" class="anchor" aria-hidden="true" href="#api"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>API</h2>
<p dir="auto">FoldsCUDA exports <code>CUDAEx</code>, a parallel loop
<a href="https://juliafolds.github.io/Transducers.jl/dev/explanation/glossary/#glossary-executor" rel="nofollow">executor</a>.
It can be used with the parallel <code>for</code> loop created with
<a href="https://github.com/JuliaFolds/FLoops.jl"><code>FLoops.@floop</code></a>,
<code>Base</code>-like high-level parallel API in
<a href="https://github.com/JuliaFolds/Folds.jl">Folds.jl</a>, and extensible
transducers provided by
<a href="https://github.com/JuliaFolds/Transducers.jl">Transducers.jl</a>.</p>
<h2 dir="auto"><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h2>
<h3 dir="auto"><a id="user-content-findmax-using-floopsjl" class="anchor" aria-hidden="true" href="#findmax-using-floopsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>findmax</code> using FLoops.jl</h3>
<p dir="auto">You can pass CUDA executor <code>FoldsCUDA.CUDAEx()</code> to <code>@floop</code> to run a
parallel <code>for</code> loop on GPU:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using FoldsCUDA, CUDA, FLoops

julia&gt; using GPUArrays: @allowscalar

julia&gt; xs = CUDA.rand(10^8);

julia&gt; @allowscalar xs[100] = 2;

julia&gt; @allowscalar xs[200] = 2;

julia&gt; @floop CUDAEx() for (x, i) in zip(xs, eachindex(xs))
           @reduce() do (imax = -1; i), (xmax = -Inf32; x)
               if xmax &lt; x
                   xmax = x
                   imax = i
               end
           end
       end

julia&gt; xmax
2.0f0

julia&gt; imax  # the *first* position for the largest value
100"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> FoldsCUDA, CUDA, FLoops

julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> GPUArrays<span class="pl-k">:</span> <span class="pl-c1">@allowscalar</span>

julia<span class="pl-k">&gt;</span> xs <span class="pl-k">=</span> CUDA<span class="pl-k">.</span><span class="pl-c1">rand</span>(<span class="pl-c1">10</span><span class="pl-k">^</span><span class="pl-c1">8</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@allowscalar</span> xs[<span class="pl-c1">100</span>] <span class="pl-k">=</span> <span class="pl-c1">2</span>;

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@allowscalar</span> xs[<span class="pl-c1">200</span>] <span class="pl-k">=</span> <span class="pl-c1">2</span>;

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@floop</span> <span class="pl-c1">CUDAEx</span>() <span class="pl-k">for</span> (x, i) <span class="pl-k">in</span> <span class="pl-c1">zip</span>(xs, <span class="pl-c1">eachindex</span>(xs))
           <span class="pl-c1">@reduce</span>() <span class="pl-k">do</span> (imax <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1</span>; i), (xmax <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">Inf32</span>; x)
               <span class="pl-k">if</span> xmax <span class="pl-k">&lt;</span> x
                   xmax <span class="pl-k">=</span> x
                   imax <span class="pl-k">=</span> i
               <span class="pl-k">end</span>
           <span class="pl-k">end</span>
       <span class="pl-k">end</span>

julia<span class="pl-k">&gt;</span> xmax
<span class="pl-c1">2.0f0</span>

julia<span class="pl-k">&gt;</span> imax  <span class="pl-c"><span class="pl-c">#</span> the *first* position for the largest value</span>
<span class="pl-c1">100</span></pre></div>
<h3 dir="auto"><a id="user-content-extrema-using-transducersteerf" class="anchor" aria-hidden="true" href="#extrema-using-transducersteerf"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>extrema</code> using <code>Transducers.TeeRF</code></h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Transducers, Folds

julia&gt; @allowscalar xs[300] = -0.5;

julia&gt; Folds.reduce(TeeRF(min, max), xs, CUDAEx())
(-0.5f0, 2.0f0)

julia&gt; Folds.reduce(TeeRF(min, max), (2x for x in xs), CUDAEx())  # iterator comprehension works
(-1.0f0, 4.0f0)

julia&gt; Folds.reduce(TeeRF(min, max), Map(x -&gt; 2x)(xs), CUDAEx())  # equivalent, using a transducer
(-1.0f0, 4.0f0)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Transducers, Folds

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@allowscalar</span> xs[<span class="pl-c1">300</span>] <span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">0.5</span>;

julia<span class="pl-k">&gt;</span> Folds<span class="pl-k">.</span><span class="pl-c1">reduce</span>(<span class="pl-c1">TeeRF</span>(min, max), xs, <span class="pl-c1">CUDAEx</span>())
(<span class="pl-k">-</span><span class="pl-c1">0.5f0</span>, <span class="pl-c1">2.0f0</span>)

julia<span class="pl-k">&gt;</span> Folds<span class="pl-k">.</span><span class="pl-c1">reduce</span>(<span class="pl-c1">TeeRF</span>(min, max), (<span class="pl-c1">2</span>x <span class="pl-k">for</span> x <span class="pl-k">in</span> xs), <span class="pl-c1">CUDAEx</span>())  <span class="pl-c"><span class="pl-c">#</span> iterator comprehension works</span>
(<span class="pl-k">-</span><span class="pl-c1">1.0f0</span>, <span class="pl-c1">4.0f0</span>)

julia<span class="pl-k">&gt;</span> Folds<span class="pl-k">.</span><span class="pl-c1">reduce</span>(<span class="pl-c1">TeeRF</span>(min, max), <span class="pl-c1">Map</span>(x <span class="pl-k">-&gt;</span> <span class="pl-c1">2</span>x)(xs), <span class="pl-c1">CUDAEx</span>())  <span class="pl-c"><span class="pl-c">#</span> equivalent, using a transducer</span>
(<span class="pl-k">-</span><span class="pl-c1">1.0f0</span>, <span class="pl-c1">4.0f0</span>)</pre></div>
<h3 dir="auto"><a id="user-content-more-examples" class="anchor" aria-hidden="true" href="#more-examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>More examples</h3>
<p dir="auto">For more examples, see the
<a href="https://juliafolds.github.io/FoldsCUDA.jl/dev/examples/" rel="nofollow">examples section in the documentation</a>.</p>
</article></div>