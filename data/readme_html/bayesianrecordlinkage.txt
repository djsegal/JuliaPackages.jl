<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-bayesianrecordlinkage" class="anchor" aria-hidden="true" href="#bayesianrecordlinkage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>BayesianRecordLinkage</h1>
<p>Collection of methods for performing Bayesian inference for large-scale record linkage problems as described in <a href="https://arxiv.org/abs/1905.05337" rel="nofollow">Scaling Bayesian Probabilistic Record Linkage with Post-Hoc Blocking: An Application to the California Great Registers</a>.</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="pkg&gt; add https://github.com/brendanstats/AssignmentSolver.jl
pkg&gt; add https://github.com/brendanstats/BayesianRecordLinkage.jl
"><pre>pkg<span class="pl-k">&gt;</span> add https<span class="pl-k">:</span><span class="pl-k">//</span>github<span class="pl-k">.</span>com<span class="pl-k">/</span>brendanstats<span class="pl-k">/</span>AssignmentSolver<span class="pl-k">.</span>jl
pkg<span class="pl-k">&gt;</span> add https<span class="pl-k">:</span><span class="pl-k">//</span>github<span class="pl-k">.</span>com<span class="pl-k">/</span>brendanstats<span class="pl-k">/</span>BayesianRecordLinkage<span class="pl-k">.</span>jl</pre></div>
<h3><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Dependencies</h3>
<p>In addition to the <code>AssignmentSolver</code> module the following packages are loaded: <code>Distributions</code>, <code>DataStructures</code>, <code>StatsBase</code>, <code>StatsFuns</code>, <code>SparseArrays</code>, <code>SpecialFunctions</code>, <code>Dates</code>.  These should be installed automatically by the package manager but can be installed with the following line if necessary.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="pkg&gt; add Distributions DataStructures StatsBase StatsFuns SparseArrays SpecialFunctions Dates
"><pre>pkg<span class="pl-k">&gt;</span> add Distributions DataStructures StatsBase StatsFuns SparseArrays SpecialFunctions Dates</pre></div>
<h1><a id="user-content-methods" class="anchor" aria-hidden="true" href="#methods"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Methods</h1>
<p>The package implements a variety of methds described in <a href="https://arxiv.org/abs/1905.05337" rel="nofollow">McVeigh, Spahn, &amp; Murray (2019)</a> that allow probabilistic Bayesian record linkage models to be estimated for datasets involving hundreds of thousands or millions of records.  Throughout a conditional independece model for record linkage employing categorical comparison vectors is assumed.  This model is identical to the one outlined in Sadinle (2017).</p>
<h2><a id="user-content-penalized-likelihood-estimator" class="anchor" aria-hidden="true" href="#penalized-likelihood-estimator"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Penalized-likelihood Estimator</h2>
<p>The <code>penalized_likelihood_search_hungarian</code> and <code>penalized_likelihood_search_auction</code> functions allow for a sequence of model estimates with the number of links subject to increasingly large penalty terms. The information from this sequence can then be used in construting a set of post-hoc blocks.  The <code>penalized_likelihood_search_hungarian</code> function relies on a Hungarian algorithm to solve assignment problems internally while <code>penalized_likelihood_search_auction</code> relies on an auction algorith.  In most cases the auction algorithm will be dramatically more computationally efficient and it is therefore recommended that the <code>penalized_likelihood_search_auction</code> function be used.</p>
<h2><a id="user-content-post-hoc-blocking-with-restricted-markov-chain-monte-carlo-algorithm" class="anchor" aria-hidden="true" href="#post-hoc-blocking-with-restricted-markov-chain-monte-carlo-algorithm"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Post-hoc Blocking with Restricted Markov chain Monte Carlo algorithm</h2>
<p>The <code>mh_gibbs_trace</code> and <code>mh_gibbs_count</code> functions implement an MCMC sampler for estimating a posterior distribution over the linkage structure and the model parameters.  <code>mh_gibbs_trace</code> retirns the full trace of the linkage structure, storing link persistence, when specifc record pairs are added and deleted, whereas <code>mh_gibbs_count</code> stores only the number of MCMC iterations in which each record pair is presemt.  Both functions save a full trace of the other model parameters.  Additionally, both return a set of three objects.  The first returned object (of type <code>ParameterChain</code>) contains the trace (or counts) of the link structure and the trace of the other model parameters.  The second returned object contains the frequencies with which updates were performed for each post-hoc block. The third returned object contains the link structure (of type <code>LinkMatrix</code>) after the final step of the sampler.</p>
<h3><a id="user-content-mcmc-moves" class="anchor" aria-hidden="true" href="#mcmc-moves"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>MCMC Moves</h3>
<p>Within the MCMC sampler the model parameters are updated, conditional on the linkage structure via a gibbs update.  For singleton post-hoc blocks, those containing only a single record pair, a gibbs update to the linkage structure within the block is also possible.  For larger post-hoc blocks locally balanced moves <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2019.1585255" rel="nofollow">Zanella 2019</a> are used.</p>
<h1><a id="user-content-prior-distributions-over-linkage-structure" class="anchor" aria-hidden="true" href="#prior-distributions-over-linkage-structure"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Prior Distributions over Linkage Structure</h1>
<p>Currently functions are provided to evaluate two prior distributions over the linkage structure, the beta prior for bipartite matchings (Sadinle 2017) and a prior which applies an exponential penalty (Green and Mardia 2006).</p>
<h1><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Example</h1>
<p>Here we provide an example</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="########################################
#Setup
########################################
using BayesianRecordLinkage, DelimitedFiles, StringDistances, Random

########################################
# Comparison Vector Generation
########################################
## Load data
dataA, varA = readdlm(&quot;data/dataA.txt&quot;, '\t', String, header = true)
dataB, varB = readdlm(&quot;data/dataB.txt&quot;, '\t', String, header = true)

nA = size(dataA, 1)
nB = size(dataB, 1)

## Find fields to compare
gnameInd = findfirst(x -&gt; x == &quot;gname&quot;, vec(varA))
fnameInd = findfirst(x -&gt; x == &quot;fname&quot;, vec(varA))
ageInd = findfirst(x -&gt; x == &quot;age&quot;, vec(varA))
occupInd = findfirst(x -&gt; x == &quot;occup&quot;, vec(varA))

## Define function to generate an ordinal comparison between two strings using a Levenshtein sting distance
function levOrd(s1::String, s2::String)
    levsim = compare(s1, s2, Levenshtein())
    if levsim == 1.0
        return Int8(1)
    elseif levsim &gt;= 0.75
        return Int8(2)
    elseif levsim &gt;= 0.5
        return Int8(3)
    else
        return Int8(4)
    end
end

## Define function to generate an ordinal comparison between two strings using exact matching
function boolOrd(s1::String, s2::String)
    if s1 == &quot;NA&quot; || s2 == &quot;NA&quot;
        return Int8(0)
    elseif s1 == s2
        return Int8(1)
    else
        return Int8(2)
    end
end

## Generate ordinal comparisons
ordArray = Array{Int8}(undef, nA, nB, 4)
for jj in 1:nB, ii in 1:nA
    ordArray[ii, jj, 1] = levOrd(dataA[ii, gnameInd], dataB[jj, gnameInd])
    ordArray[ii, jj, 2] = levOrd(dataA[ii, fnameInd], dataB[jj, fnameInd])
    ordArray[ii, jj, 3] = boolOrd(dataA[ii, ageInd], dataB[jj, ageInd])
    ordArray[ii, jj, 4] = boolOrd(dataA[ii, occupInd], dataB[jj, occupInd])
end

## Load into a ComparsionSummary object
compsum = ComparisonSummary(ordArray)

########################################
#Penalized-Likelihood Estimation
########################################

## Set Penalized Likelihood Parameters
maxIter = 30 #Maximum number of interations
minincr = 0.1 #Increment of penalty
penalty0 = 0.0 #Starting penalty value
epsscale = 0.1 #Epsilon scaling value used within auction algorithm

## Define flat prios 
priorM = fill(1.0, sum(compsum.nlevels))
priorU = fill(1.0, sum(compsum.nlevels))

## Compute prior modes for each model parameter, assumes a Dirichlet prior.
pM0 = prior_mode(priorM, compsum)
pU0 = prior_mode(compsum.counts, compsum)

## Run penalized likelihood estimator
penlikseq, penalties, iter = penalized_likelihood_search_auction(pM0, pU0, compsum, priorM, priorU, penalty0, minincr, maxIter = maxIter, cluster = false, update = false, epsiscale = 0.1, verbose = false)

########################################
#Post-hoc Blocking
########################################

## Set Post-hoc Blocking Parameters
npairscompThreshold = 2500 #maximum number of record pairs allowed in a post-hoc block (50^2)
threshold0 = 0.0 #Initial weight threshold for clustering
thresholdInc = 0.01 #Threshold increment for breaking larger blocks

## Find post-hoc blocks using maximum weights across penalized likelihood sequence as edge weights
maxW = maximum_weights_vector(penlikseq.pM, penlikseq.pU, compsum)
weightMat = penalized_weights_matrix(maxW, compsum, 0.0)
rowLabels, colLabels, maxLabel, clusterThresholds = iterative_bipartite_cluster2(weightMat, npairscompThreshold, threshold0, thresholdInc)
cc = ConnectedComponents(rowLabels, colLabels, maxLabel)
phblocks = PosthocBlocks(cc, compsum)

########################################
#Restricted MCMC
########################################

## Initialize using solution found with penalty = maximum posthoc blocking threshold
matchidx = findfirst(penalties .&gt; maximum(clusterThresholds))
rows, cols = get_steplinks(matchidx, penlikseq)
C0 = LinkMatrix(BayesianRecordLinkage.tuple2links(rows, cols, compsum.nrow), compsum.ncol)

## Set seed
Random.seed!(29279)

## Set flat prior over the share of record pairs linked
lpriorC(nadd::Integer, C::LinkMatrix) = betabipartite_logratiopn(nadd, C, 1.0, 1.0)

## Run restricted MCMC sampler
postchain, transC, C = mh_gibbs_trace(25000, C0, compsum, phblocks, priorM, priorU, lpriorC, randomwalk1_locally_balanced_barker_update!)

## Compute frequency with which each record pair is linked and return counts for all pairs with nonzero counts
cts = get_linkcounts(postchain)
cts = cts[cts[:, 3] .&gt; 12500, :] #reduce to just record pairs linked more than half the time (the Bayes estimator)
Cbayes =  LinkMatrix(nA, nB, cts[:, 1], cts[:, 2])
ntp = count(Cbayes.row2col[1:300] .== 1:300) #Example constructed so that rows 1:300 in A match rows 1:300 in B
nfp = Cbayes.nlink - ntp

println(&quot;Precision: $(ntp / Cbayes.nlink)&quot;)
println(&quot;Recall: $(ntp / 300)&quot;)
"><pre><span class="pl-c"><span class="pl-c">#</span>#######################################</span>
<span class="pl-c"><span class="pl-c">#</span>Setup</span>
<span class="pl-c"><span class="pl-c">#</span>#######################################</span>
<span class="pl-k">using</span> BayesianRecordLinkage, DelimitedFiles, StringDistances, Random

<span class="pl-c"><span class="pl-c">#</span>#######################################</span>
<span class="pl-c"><span class="pl-c">#</span> Comparison Vector Generation</span>
<span class="pl-c"><span class="pl-c">#</span>#######################################</span>
<span class="pl-c"><span class="pl-c">#</span># Load data</span>
dataA, varA <span class="pl-k">=</span> <span class="pl-c1">readdlm</span>(<span class="pl-s"><span class="pl-pds">"</span>data/dataA.txt<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\t</span><span class="pl-pds">'</span></span>, String, header <span class="pl-k">=</span> <span class="pl-c1">true</span>)
dataB, varB <span class="pl-k">=</span> <span class="pl-c1">readdlm</span>(<span class="pl-s"><span class="pl-pds">"</span>data/dataB.txt<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\t</span><span class="pl-pds">'</span></span>, String, header <span class="pl-k">=</span> <span class="pl-c1">true</span>)

nA <span class="pl-k">=</span> <span class="pl-c1">size</span>(dataA, <span class="pl-c1">1</span>)
nB <span class="pl-k">=</span> <span class="pl-c1">size</span>(dataB, <span class="pl-c1">1</span>)

<span class="pl-c"><span class="pl-c">#</span># Find fields to compare</span>
gnameInd <span class="pl-k">=</span> <span class="pl-c1">findfirst</span>(x <span class="pl-k">-&gt;</span> x <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>gname<span class="pl-pds">"</span></span>, <span class="pl-c1">vec</span>(varA))
fnameInd <span class="pl-k">=</span> <span class="pl-c1">findfirst</span>(x <span class="pl-k">-&gt;</span> x <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>fname<span class="pl-pds">"</span></span>, <span class="pl-c1">vec</span>(varA))
ageInd <span class="pl-k">=</span> <span class="pl-c1">findfirst</span>(x <span class="pl-k">-&gt;</span> x <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>age<span class="pl-pds">"</span></span>, <span class="pl-c1">vec</span>(varA))
occupInd <span class="pl-k">=</span> <span class="pl-c1">findfirst</span>(x <span class="pl-k">-&gt;</span> x <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>occup<span class="pl-pds">"</span></span>, <span class="pl-c1">vec</span>(varA))

<span class="pl-c"><span class="pl-c">#</span># Define function to generate an ordinal comparison between two strings using a Levenshtein sting distance</span>
<span class="pl-k">function</span> <span class="pl-en">levOrd</span>(s1<span class="pl-k">::</span><span class="pl-c1">String</span>, s2<span class="pl-k">::</span><span class="pl-c1">String</span>)
    levsim <span class="pl-k">=</span> <span class="pl-c1">compare</span>(s1, s2, <span class="pl-c1">Levenshtein</span>())
    <span class="pl-k">if</span> levsim <span class="pl-k">==</span> <span class="pl-c1">1.0</span>
        <span class="pl-k">return</span> <span class="pl-c1">Int8</span>(<span class="pl-c1">1</span>)
    <span class="pl-k">elseif</span> levsim <span class="pl-k">&gt;=</span> <span class="pl-c1">0.75</span>
        <span class="pl-k">return</span> <span class="pl-c1">Int8</span>(<span class="pl-c1">2</span>)
    <span class="pl-k">elseif</span> levsim <span class="pl-k">&gt;=</span> <span class="pl-c1">0.5</span>
        <span class="pl-k">return</span> <span class="pl-c1">Int8</span>(<span class="pl-c1">3</span>)
    <span class="pl-k">else</span>
        <span class="pl-k">return</span> <span class="pl-c1">Int8</span>(<span class="pl-c1">4</span>)
    <span class="pl-k">end</span>
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span># Define function to generate an ordinal comparison between two strings using exact matching</span>
<span class="pl-k">function</span> <span class="pl-en">boolOrd</span>(s1<span class="pl-k">::</span><span class="pl-c1">String</span>, s2<span class="pl-k">::</span><span class="pl-c1">String</span>)
    <span class="pl-k">if</span> s1 <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>NA<span class="pl-pds">"</span></span> <span class="pl-k">||</span> s2 <span class="pl-k">==</span> <span class="pl-s"><span class="pl-pds">"</span>NA<span class="pl-pds">"</span></span>
        <span class="pl-k">return</span> <span class="pl-c1">Int8</span>(<span class="pl-c1">0</span>)
    <span class="pl-k">elseif</span> s1 <span class="pl-k">==</span> s2
        <span class="pl-k">return</span> <span class="pl-c1">Int8</span>(<span class="pl-c1">1</span>)
    <span class="pl-k">else</span>
        <span class="pl-k">return</span> <span class="pl-c1">Int8</span>(<span class="pl-c1">2</span>)
    <span class="pl-k">end</span>
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span># Generate ordinal comparisons</span>
ordArray <span class="pl-k">=</span> <span class="pl-c1">Array</span><span class="pl-c1">{Int8}</span>(undef, nA, nB, <span class="pl-c1">4</span>)
<span class="pl-k">for</span> jj <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>nB, ii <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>nA
    ordArray[ii, jj, <span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">levOrd</span>(dataA[ii, gnameInd], dataB[jj, gnameInd])
    ordArray[ii, jj, <span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">levOrd</span>(dataA[ii, fnameInd], dataB[jj, fnameInd])
    ordArray[ii, jj, <span class="pl-c1">3</span>] <span class="pl-k">=</span> <span class="pl-c1">boolOrd</span>(dataA[ii, ageInd], dataB[jj, ageInd])
    ordArray[ii, jj, <span class="pl-c1">4</span>] <span class="pl-k">=</span> <span class="pl-c1">boolOrd</span>(dataA[ii, occupInd], dataB[jj, occupInd])
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span># Load into a ComparsionSummary object</span>
compsum <span class="pl-k">=</span> <span class="pl-c1">ComparisonSummary</span>(ordArray)

<span class="pl-c"><span class="pl-c">#</span>#######################################</span>
<span class="pl-c"><span class="pl-c">#</span>Penalized-Likelihood Estimation</span>
<span class="pl-c"><span class="pl-c">#</span>#######################################</span>

<span class="pl-c"><span class="pl-c">#</span># Set Penalized Likelihood Parameters</span>
maxIter <span class="pl-k">=</span> <span class="pl-c1">30</span> <span class="pl-c"><span class="pl-c">#</span>Maximum number of interations</span>
minincr <span class="pl-k">=</span> <span class="pl-c1">0.1</span> <span class="pl-c"><span class="pl-c">#</span>Increment of penalty</span>
penalty0 <span class="pl-k">=</span> <span class="pl-c1">0.0</span> <span class="pl-c"><span class="pl-c">#</span>Starting penalty value</span>
epsscale <span class="pl-k">=</span> <span class="pl-c1">0.1</span> <span class="pl-c"><span class="pl-c">#</span>Epsilon scaling value used within auction algorithm</span>

<span class="pl-c"><span class="pl-c">#</span># Define flat prios </span>
priorM <span class="pl-k">=</span> <span class="pl-c1">fill</span>(<span class="pl-c1">1.0</span>, <span class="pl-c1">sum</span>(compsum<span class="pl-k">.</span>nlevels))
priorU <span class="pl-k">=</span> <span class="pl-c1">fill</span>(<span class="pl-c1">1.0</span>, <span class="pl-c1">sum</span>(compsum<span class="pl-k">.</span>nlevels))

<span class="pl-c"><span class="pl-c">#</span># Compute prior modes for each model parameter, assumes a Dirichlet prior.</span>
pM0 <span class="pl-k">=</span> <span class="pl-c1">prior_mode</span>(priorM, compsum)
pU0 <span class="pl-k">=</span> <span class="pl-c1">prior_mode</span>(compsum<span class="pl-k">.</span>counts, compsum)

<span class="pl-c"><span class="pl-c">#</span># Run penalized likelihood estimator</span>
penlikseq, penalties, iter <span class="pl-k">=</span> <span class="pl-c1">penalized_likelihood_search_auction</span>(pM0, pU0, compsum, priorM, priorU, penalty0, minincr, maxIter <span class="pl-k">=</span> maxIter, cluster <span class="pl-k">=</span> <span class="pl-c1">false</span>, update <span class="pl-k">=</span> <span class="pl-c1">false</span>, epsiscale <span class="pl-k">=</span> <span class="pl-c1">0.1</span>, verbose <span class="pl-k">=</span> <span class="pl-c1">false</span>)

<span class="pl-c"><span class="pl-c">#</span>#######################################</span>
<span class="pl-c"><span class="pl-c">#</span>Post-hoc Blocking</span>
<span class="pl-c"><span class="pl-c">#</span>#######################################</span>

<span class="pl-c"><span class="pl-c">#</span># Set Post-hoc Blocking Parameters</span>
npairscompThreshold <span class="pl-k">=</span> <span class="pl-c1">2500</span> <span class="pl-c"><span class="pl-c">#</span>maximum number of record pairs allowed in a post-hoc block (50^2)</span>
threshold0 <span class="pl-k">=</span> <span class="pl-c1">0.0</span> <span class="pl-c"><span class="pl-c">#</span>Initial weight threshold for clustering</span>
thresholdInc <span class="pl-k">=</span> <span class="pl-c1">0.01</span> <span class="pl-c"><span class="pl-c">#</span>Threshold increment for breaking larger blocks</span>

<span class="pl-c"><span class="pl-c">#</span># Find post-hoc blocks using maximum weights across penalized likelihood sequence as edge weights</span>
maxW <span class="pl-k">=</span> <span class="pl-c1">maximum_weights_vector</span>(penlikseq<span class="pl-k">.</span>pM, penlikseq<span class="pl-k">.</span>pU, compsum)
weightMat <span class="pl-k">=</span> <span class="pl-c1">penalized_weights_matrix</span>(maxW, compsum, <span class="pl-c1">0.0</span>)
rowLabels, colLabels, maxLabel, clusterThresholds <span class="pl-k">=</span> <span class="pl-c1">iterative_bipartite_cluster2</span>(weightMat, npairscompThreshold, threshold0, thresholdInc)
cc <span class="pl-k">=</span> <span class="pl-c1">ConnectedComponents</span>(rowLabels, colLabels, maxLabel)
phblocks <span class="pl-k">=</span> <span class="pl-c1">PosthocBlocks</span>(cc, compsum)

<span class="pl-c"><span class="pl-c">#</span>#######################################</span>
<span class="pl-c"><span class="pl-c">#</span>Restricted MCMC</span>
<span class="pl-c"><span class="pl-c">#</span>#######################################</span>

<span class="pl-c"><span class="pl-c">#</span># Initialize using solution found with penalty = maximum posthoc blocking threshold</span>
matchidx <span class="pl-k">=</span> <span class="pl-c1">findfirst</span>(penalties <span class="pl-k">.&gt;</span> <span class="pl-c1">maximum</span>(clusterThresholds))
rows, cols <span class="pl-k">=</span> <span class="pl-c1">get_steplinks</span>(matchidx, penlikseq)
C0 <span class="pl-k">=</span> <span class="pl-c1">LinkMatrix</span>(BayesianRecordLinkage<span class="pl-k">.</span><span class="pl-c1">tuple2links</span>(rows, cols, compsum<span class="pl-k">.</span>nrow), compsum<span class="pl-k">.</span>ncol)

<span class="pl-c"><span class="pl-c">#</span># Set seed</span>
Random<span class="pl-k">.</span><span class="pl-c1">seed!</span>(<span class="pl-c1">29279</span>)

<span class="pl-c"><span class="pl-c">#</span># Set flat prior over the share of record pairs linked</span>
<span class="pl-en">lpriorC</span>(nadd<span class="pl-k">::</span><span class="pl-c1">Integer</span>, C<span class="pl-k">::</span><span class="pl-c1">LinkMatrix</span>) <span class="pl-k">=</span> <span class="pl-c1">betabipartite_logratiopn</span>(nadd, C, <span class="pl-c1">1.0</span>, <span class="pl-c1">1.0</span>)

<span class="pl-c"><span class="pl-c">#</span># Run restricted MCMC sampler</span>
postchain, transC, C <span class="pl-k">=</span> <span class="pl-c1">mh_gibbs_trace</span>(<span class="pl-c1">25000</span>, C0, compsum, phblocks, priorM, priorU, lpriorC, randomwalk1_locally_balanced_barker_update!)

<span class="pl-c"><span class="pl-c">#</span># Compute frequency with which each record pair is linked and return counts for all pairs with nonzero counts</span>
cts <span class="pl-k">=</span> <span class="pl-c1">get_linkcounts</span>(postchain)
cts <span class="pl-k">=</span> cts[cts[:, <span class="pl-c1">3</span>] <span class="pl-k">.&gt;</span> <span class="pl-c1">12500</span>, :] <span class="pl-c"><span class="pl-c">#</span>reduce to just record pairs linked more than half the time (the Bayes estimator)</span>
Cbayes <span class="pl-k">=</span>  <span class="pl-c1">LinkMatrix</span>(nA, nB, cts[:, <span class="pl-c1">1</span>], cts[:, <span class="pl-c1">2</span>])
ntp <span class="pl-k">=</span> <span class="pl-c1">count</span>(Cbayes<span class="pl-k">.</span>row2col[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">300</span>] <span class="pl-k">.==</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">300</span>) <span class="pl-c"><span class="pl-c">#</span>Example constructed so that rows 1:300 in A match rows 1:300 in B</span>
nfp <span class="pl-k">=</span> Cbayes<span class="pl-k">.</span>nlink <span class="pl-k">-</span> ntp

<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span>Precision: <span class="pl-v">$(ntp <span class="pl-k">/</span> Cbayes<span class="pl-k">.</span>nlink)</span><span class="pl-pds">"</span></span>)
<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span>Recall: <span class="pl-v">$(ntp <span class="pl-k">/</span> <span class="pl-c1">300</span>)</span><span class="pl-pds">"</span></span>)</pre></div>
<h2><a id="user-content-blocking-or-indexing" class="anchor" aria-hidden="true" href="#blocking-or-indexing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Blocking or Indexing</h2>
<p>The <code>SparseComparisonSummary</code> type is avaiable for problems where comparison vectors are not computed for all possible record pairs.  An example of this is shown below, note that the example was constructed for simplicty and more efficient methods of blockng or indexing should be used in practice.  The <code>SparseComparisonSummary</code> object can then be used in place of a standard <code>ComparisonSummary</code> object.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="## Generate ordinal comparisons
indsA = Int32[]
indsB = Int32[]
for jj in 1:nB, ii in 1:nA
    gnameComp = compare(dataA[ii, gnameInd], dataB[jj, gnameInd], Levenshtein())
    fnameComp = compare(dataA[ii, fnameInd], dataB[jj, fnameInd], Levenshtein())
    if (gnameComp &gt; 0.6) || (fnameComp &gt; 0.6)
        push!(indsA, ii)
        push!(indsB, jj)
    end
end

## Generate ordinal comparisons
ordArray = Array{Int8}(undef, length(indsA), 4)
for ii in 1:length(indsA)
    ordArray[ii, 1] = levOrd(dataA[indsA[ii], gnameInd], dataB[indsB[ii], gnameInd])
    ordArray[ii, 2] = levOrd(dataA[indsA[ii], fnameInd], dataB[indsB[ii], fnameInd])
    ordArray[ii, 3] = boolOrd(dataA[indsA[ii], ageInd], dataB[indsB[ii], ageInd])
    ordArray[ii, 4] = boolOrd(dataA[indsA[ii], occupInd], dataB[indsB[ii], occupInd])
end

spcompsum = SparseComparisonSummary(indsA, indsB, ordArray, size(dataA, 1), size(dataB, 1), [4, 4, 2, 2])
"><pre><span class="pl-c"><span class="pl-c">#</span># Generate ordinal comparisons</span>
indsA <span class="pl-k">=</span> Int32[]
indsB <span class="pl-k">=</span> Int32[]
<span class="pl-k">for</span> jj <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>nB, ii <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>nA
    gnameComp <span class="pl-k">=</span> <span class="pl-c1">compare</span>(dataA[ii, gnameInd], dataB[jj, gnameInd], <span class="pl-c1">Levenshtein</span>())
    fnameComp <span class="pl-k">=</span> <span class="pl-c1">compare</span>(dataA[ii, fnameInd], dataB[jj, fnameInd], <span class="pl-c1">Levenshtein</span>())
    <span class="pl-k">if</span> (gnameComp <span class="pl-k">&gt;</span> <span class="pl-c1">0.6</span>) <span class="pl-k">||</span> (fnameComp <span class="pl-k">&gt;</span> <span class="pl-c1">0.6</span>)
        <span class="pl-c1">push!</span>(indsA, ii)
        <span class="pl-c1">push!</span>(indsB, jj)
    <span class="pl-k">end</span>
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span># Generate ordinal comparisons</span>
ordArray <span class="pl-k">=</span> <span class="pl-c1">Array</span><span class="pl-c1">{Int8}</span>(undef, <span class="pl-c1">length</span>(indsA), <span class="pl-c1">4</span>)
<span class="pl-k">for</span> ii <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">length</span>(indsA)
    ordArray[ii, <span class="pl-c1">1</span>] <span class="pl-k">=</span> <span class="pl-c1">levOrd</span>(dataA[indsA[ii], gnameInd], dataB[indsB[ii], gnameInd])
    ordArray[ii, <span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-c1">levOrd</span>(dataA[indsA[ii], fnameInd], dataB[indsB[ii], fnameInd])
    ordArray[ii, <span class="pl-c1">3</span>] <span class="pl-k">=</span> <span class="pl-c1">boolOrd</span>(dataA[indsA[ii], ageInd], dataB[indsB[ii], ageInd])
    ordArray[ii, <span class="pl-c1">4</span>] <span class="pl-k">=</span> <span class="pl-c1">boolOrd</span>(dataA[indsA[ii], occupInd], dataB[indsB[ii], occupInd])
<span class="pl-k">end</span>

spcompsum <span class="pl-k">=</span> <span class="pl-c1">SparseComparisonSummary</span>(indsA, indsB, ordArray, <span class="pl-c1">size</span>(dataA, <span class="pl-c1">1</span>), <span class="pl-c1">size</span>(dataB, <span class="pl-c1">1</span>), [<span class="pl-c1">4</span>, <span class="pl-c1">4</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>])</pre></div>
<h1><a id="user-content-custom-types" class="anchor" aria-hidden="true" href="#custom-types"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Custom Types</h1>
<h2><a id="user-content-comparisonsummary" class="anchor" aria-hidden="true" href="#comparisonsummary"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ComparisonSummary</h2>
<ul>
<li><code>obsidx::Array{T, 2}</code>: mapping from record pair to comparison vector, indicates which column of obsvecs contains the original record pair</li>
<li><code>obsvecs::Array{G, 2}</code>: comparison vectors observed in data, each column corresponds to an observed comparison vector. Zero entries indicate a missing value for the comparison-feature pair.</li>
<li><code>obsvecct::Array{Int64, 1}</code>: number of observations of each comparison vector, length = size(obsvecs, 2)</li>
<li><code>counts::Array{Int64, 1}</code>: vector storing counts of all comparisons for all levels of all fields, length = sum(nlevels)</li>
<li><code>obsct::Array{Int64, 1}</code>: number of observations for each comparison field, length(obsct) = ncomp)</li>
<li><code>misct::Array{Int64, 1}</code>: number of comparisons missing for each comparison, length(obsct) = ncomp, obsct[ii] + misct[ii] = npairs)</li>
<li><code>nlevels::Array{Int64, 1}</code>: number of levels allowed for each comparison</li>
<li><code>cmap::Array{Int64, 1}</code>: which comparison does counts[ii] correspond to</li>
<li><code>levelmap::Array{Int64, 1}</code>: which level does counts[ii] correspond to</li>
<li><code>cadj::Array{Int64, 1}</code>: cadj[ii] + jj yields the index in counts for the jjth level of comparison ii, length(cadj) = ncomp, use range(cadj[ii] + 1, nlevels[ii]) to get indexes for counts of comparison ii</li>
<li><code>nrow::Int64</code>: number of records in first data base, first dimension of input Array</li>
<li><code>ncol::Int64</code>: number of records in second data base, second dimension of input Array</li>
<li><code>npairs::Int64</code>: number of records pairs = nrow * ncol</li>
<li><code>ncomp::Int64</code>: number of comparisons, computed as third dimension of input Array</li>
</ul>
<h2><a id="user-content-sparsecomparisonsummary" class="anchor" aria-hidden="true" href="#sparsecomparisonsummary"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>SparseComparisonSummary</h2>
<ul>
<li><code>obsidx::SparseMatrixCSC{Tv, Ti}</code>: mapping from record pair to comparison vector, indicates which column of obsvecs contains the original record pair</li>
<li><code>obsvecs::Array{G, 2}</code>: comparison vectors observed in data, each column corresponds to an observed comparison vector.  Zero entries indicate a missing value for the comparison-feature pair.</li>
<li><code>obsvecct::Array{Int64, 1}</code>: number of observations of each comparison vector, length = size(obsvecs, 2)</li>
<li><code>counts::Array{Int64, 1}</code>: vector storing counts of all comparisons for all levels of all fields, length = sum(nlevels)</li>
<li><code>obsct::Array{Int64, 1}</code>: number of observations for each comparison field, length(obsct) = ncomp)</li>
<li><code>misct::Array{Int64, 1}</code>: number of comparisons missing for each comparison, length(obsct) = ncomp, obsct[ii] + misct[ii] = npairs)</li>
<li><code>nlevels::Array{Int64, 1}</code>: number of levels allowed for each comparison</li>
<li><code>cmap::Array{Int64, 1}</code>: which comparison does counts[ii] correspond to</li>
<li><code>levelmap::Array{Int64, 1}</code>: which level does counts[ii] correspond to</li>
<li><code>cadj::Array{Int64, 1}</code>: cadj[ii] + jj yields the index in counts for the jjth level of comparison ii, length(cadj) = ncomp, use range(cadj[ii] + 1, nlevels[ii]) to get indexes for counts of comparison ii</li>
<li><code>nrow::Int64</code>: number of records in first data base, first dimension of input Array</li>
<li><code>ncol::Int64</code>: number of records in second data base, second dimension of input Array</li>
<li><code>npairs::Int64</code>: number of records pairs = nrow * ncol</li>
<li><code>ncomp::Int64</code>: number of comparisons, computed as third dimension of input Array</li>
</ul>
<h2><a id="user-content-linkmatrix" class="anchor" aria-hidden="true" href="#linkmatrix"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LinkMatrix</h2>
<p>The <code>LinkMatrix</code> type stores the current state of the linkage structure and has the following fields:</p>
<ul>
<li><code>row2col::Array{G, 1}</code>: Mapping from row to column.  row2ccol[ii] = jj if row ii is linked to column jj.  If row ii is unlinked then row2col[ii] == 0.</li>
<li><code>col2row::Array{G, 1}</code>: Mapping from column to row.  col2row[jj] = ii if column jj is linked to row ii.  If column jj is unlinked then col2row[jj] == 0.</li>
<li><code>nlink::G</code>: Number of record pairs counted as links.</li>
<li><code>nrow::G</code>: Number of rows equal, nrow == length(row2col).</li>
<li><code>ncol::G</code>: Number of columns, ncol == length(col2row)</li>
</ul>
<h2><a id="user-content-connectedcomponents" class="anchor" aria-hidden="true" href="#connectedcomponents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ConnectedComponents</h2>
<ul>
<li><code>rowLabels::Array{G, 1}</code>: Component assignment of row, zero indicates no edges from row.</li>
<li><code>colLabels::Array{G, 1}</code>: Component assignment of col, zero indicates no edges from column.</li>
<li><code>rowperm::Array{G, 1}</code>: Permutation which will reorder rows so that labels are ascending.</li>
<li><code>colperm::Array{G, 1}</code>: Permutation which will reorder columns so that labels are ascending.</li>
<li><code>rowcounts::Array{G, 1}</code>: Number of rows contained in each component, because counts forunassigned (label == 0) rows are included rowcounts[kk + 1] contains the count for component kk.</li>
<li><code>colcounts::Array{G, 1}</code>: Number of columns contained in each component, because counts forunassigned (label == 0) columns are included colcounts[kk + 1] contains the count for component kk.</li>
<li><code>cumrows::Array{G, 1}</code>: Cumulative sum of <code>rowcounts</code>.</li>
<li><code>cumcols::Array{G, 1}</code>: Cumulative sum of <code>colcounts</code>.</li>
<li><code>nrow::G</code>: Number of rows (nodes from first group).</li>
<li><code>ncol::G</code>: Number of columns (nodes from second group).</li>
<li><code>ncomponents::G</code>: Number of components.</li>
</ul>
<h2><a id="user-content-posthocblocks" class="anchor" aria-hidden="true" href="#posthocblocks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>PosthocBlocks</h2>
<ul>
<li><code>block2rows::Dict{G, Array{G, 1}}</code>: Mapping from block to set of rows contained in the block.</li>
<li><code>block2cols::Dict{G, Array{G, 1}}</code>: Mapping from block to set of columns contained in the block.</li>
<li><code>blocknrows::Array{G, 1}</code>: Number of rows contained in the block, blocknrows[kk] == length(block2rows[kk]).</li>
<li><code>blockncols::Array{G, 1}</code>: Number of columns contained in the block, blockncols[kk] == length(block2cols[kk])</li>
<li><code>blocksingleton::Array{Bool, 1}</code>: blocksingleton[kk] == true if blocknrows[kk] == 1 and block2cols[kk] == 1.</li>
<li><code>blocknnz::Array{Int, 1}</code>: Number of non-zero entries contained in the block.  This will be blocknrows[kk] * blockncols[kk] unless the constructure is run with a <code>SparseComparisonSummary</code> in which case the number of non-zero entries in the sparse matrix region corresponding to the block will be counted.</li>
<li><code>nrow::G</code>: Number of rows in array containing blocks, all entries in block2rows should be &lt;= nrow.</li>
<li><code>ncol::G</code>:  Number of columns in array containing blocks, all entries in block2cols should be &lt;= ncol.</li>
<li><code>nblock::G</code>: Number of blocks, nblock == maximum(keys(block2rows)) == maximum(keys(block2cols))</li>
<li><code>nnz::Int</code>: Total number of entires, equal to sum(blocknnz).</li>
</ul>
<h2><a id="user-content-parameterchain" class="anchor" aria-hidden="true" href="#parameterchain"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ParameterChain</h2>
<p>The <code>ParameterChain</code> type will store a trace of both the linkage structure and the model parameters when the <code>linktrace</code> field is set to <code>true</code>.  When the <code>linktrace</code> field is set to false then only counts of the frequency with which a given record pair was linked will be stores.  The type contains the following fields:</p>
<ul>
<li><code>C::Array{G, 2}</code>: Either row and column indices paired with link counts or indicies paired with steps / iterations in which they appeared.</li>
<li><code>nlinks::Union{Array{G, 1}, Array{G, 2}}</code>: Total number of links at each step / iteration.</li>
<li><code>pM::Array{T, 2}</code>: M parameters at each iteration, size(pM, 1) == nsteps</li>
<li><code>pU::Array{T, 2}</code>: U parameters at each iteration, size(pU, 1) == nsteps</li>
<li><code>nsteps::Int</code>: Total number of steps / iterations</li>
<li><code>linktrace::Bool</code>: Indicator if <code>C</code> contains link counts or a trace of the entire link structure.</li>
</ul>
<h1><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>References</h1>
<ol>
<li>Green, P. J. and Mardia, K. V. 2006,  Bayesian alignment using hierarchical models, with applications in protein bioinformatics, Biometrika, 93(2):235–254.</li>
<li>McVeigh, B.S., Spahn, B.T. and Murray, J.S., 2019, Scaling Bayesian Probabilistic Record Linkage with Post-Hoc Blocking: An Application to the California Great Registers, arXiv preprint arXiv:1905.05337</li>
<li>Mauricio Sadinle 2017, Bayesian Estimation of Bipartite Matchings for Record Linkage, Journal of the American Statistical Association, 112:518, 600-612, DOI: 10.1080/01621459.2016.1148612</li>
<li>Giacomo Zanella 2019, Informed Proposals for Local MCMC in Discrete Spaces, Journal of the American Statistical Association, DOI: 10.1080/01621459.2019.1585255</li>
</ol>
</article></div>