<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-litehfjl" class="anchor" aria-hidden="true" href="#litehfjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>LiteHF.jl</h1>
<p dir="auto"><a href="https://juliahep.github.io/LiteHF.jl/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/JuliaHEP/LiteHF.jl/actions"><img src="https://github.com/JuliaHEP/LiteHF.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/JuliaHEP/LiteHF.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/4e018aba6373d343131d333c129ca6b8dae6bb22a31a1eba35a75d9b5b755382/68747470733a2f2f636f6465636f762e696f2f67682f4a756c69614845502f4c69746548462e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="Codecov" data-canonical-src="https://codecov.io/gh/JuliaHEP/LiteHF.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a>
<a href="https://zenodo.org/badge/latestdoi/482332815" rel="nofollow"><img src="https://camo.githubusercontent.com/2ee4d4aa0e8606cb7b71575a14ca3305d72e30a1430a9d6d2cd58a253d556e32/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3438323333323831352e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/482332815.svg" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>TODO</h2>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> Implement teststatistics helper functions</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox"> Re-structre the <code>PyHFModel</code> such that the <code>POI</code> component can be swapped out.</li>
</ul>
<h2 dir="auto"><a id="user-content-load-pyhf-json" class="anchor" aria-hidden="true" href="#load-pyhf-json"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Load <code>pyhf</code> JSON:</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LiteHF, Optim

dict = load_pyhfjson(&quot;./test/sample.json&quot;);

pyhfmodel = build_pyhf(dict);
LL = pyhf_logjointof(pyhfmodel)

@show Optim.maximizer(maximize(LL, pyhfmodel.inits))
# 2-element Vector{Float64}:
#   1.3064374172547253
#  -0.060413406717672286
@show pyhfmodel.prior_names
# (:mu, :theta)"><pre><span class="pl-k">using</span> LiteHF, Optim

dict <span class="pl-k">=</span> <span class="pl-c1">load_pyhfjson</span>(<span class="pl-s"><span class="pl-pds">"</span>./test/sample.json<span class="pl-pds">"</span></span>);

pyhfmodel <span class="pl-k">=</span> <span class="pl-c1">build_pyhf</span>(dict);
LL <span class="pl-k">=</span> <span class="pl-c1">pyhf_logjointof</span>(pyhfmodel)

<span class="pl-c1">@show</span> Optim<span class="pl-k">.</span><span class="pl-c1">maximizer</span>(<span class="pl-c1">maximize</span>(LL, pyhfmodel<span class="pl-k">.</span>inits))
<span class="pl-c"><span class="pl-c">#</span> 2-element Vector{Float64}:</span>
<span class="pl-c"><span class="pl-c">#</span>   1.3064374172547253</span>
<span class="pl-c"><span class="pl-c">#</span>  -0.060413406717672286</span>
<span class="pl-c1">@show</span> pyhfmodel<span class="pl-k">.</span>prior_names
<span class="pl-c"><span class="pl-c">#</span> (:mu, :theta)</span></pre></div>
<h2 dir="auto"><a id="user-content-pyhf-json--turingjl" class="anchor" aria-hidden="true" href="#pyhf-json--turingjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>pyhf</code> JSON + Turing.jl:</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LiteHF, Turing, Optim

dict = load_pyhfjson(&quot;./test/sample.json&quot;);

const pyhfmodel = build_pyhf(dict);
# unpack `NamedTuple` into just an array of prior distributions
const priors_array = collect(values(priors(pyhfmodel)))

@model function mymodel(observed)
    αs ~ arraydist(priors_array)
    expected = pyhfmodel.expected(αs)
    @. observed ~ Poisson(expected)
end

observed_data = [34,22,13,11];
@show optimize(mymodel(observed_data), MAP(), inits(pyhfmodel))
#ModeResult with maximized lp of -13.51
# 2-element Named Vector{Float64}
# A               │ 
# ────────────────┼───────────
# Symbol(&quot;αs[1]&quot;) │    1.30648
# Symbol(&quot;αs[2]&quot;) │ -0.0605151"><pre><span class="pl-k">using</span> LiteHF, Turing, Optim

dict <span class="pl-k">=</span> <span class="pl-c1">load_pyhfjson</span>(<span class="pl-s"><span class="pl-pds">"</span>./test/sample.json<span class="pl-pds">"</span></span>);

<span class="pl-k">const</span> pyhfmodel <span class="pl-k">=</span> <span class="pl-c1">build_pyhf</span>(dict);
<span class="pl-c"><span class="pl-c">#</span> unpack `NamedTuple` into just an array of prior distributions</span>
<span class="pl-k">const</span> priors_array <span class="pl-k">=</span> <span class="pl-c1">collect</span>(<span class="pl-c1">values</span>(<span class="pl-c1">priors</span>(pyhfmodel)))

<span class="pl-c1">@model</span> <span class="pl-k">function</span> <span class="pl-en">mymodel</span>(observed)
    αs <span class="pl-k">~</span> <span class="pl-c1">arraydist</span>(priors_array)
    expected <span class="pl-k">=</span> pyhfmodel<span class="pl-k">.</span><span class="pl-c1">expected</span>(αs)
    <span class="pl-c1">@.</span> observed <span class="pl-k">~</span> <span class="pl-c1">Poisson</span>(expected)
<span class="pl-k">end</span>

observed_data <span class="pl-k">=</span> [<span class="pl-c1">34</span>,<span class="pl-c1">22</span>,<span class="pl-c1">13</span>,<span class="pl-c1">11</span>];
<span class="pl-c1">@show</span> <span class="pl-c1">optimize</span>(<span class="pl-c1">mymodel</span>(observed_data), <span class="pl-c1">MAP</span>(), <span class="pl-c1">inits</span>(pyhfmodel))
<span class="pl-c"><span class="pl-c">#</span>ModeResult with maximized lp of -13.51</span>
<span class="pl-c"><span class="pl-c">#</span> 2-element Named Vector{Float64}</span>
<span class="pl-c"><span class="pl-c">#</span> A               │ </span>
<span class="pl-c"><span class="pl-c">#</span> ────────────────┼───────────</span>
<span class="pl-c"><span class="pl-c">#</span> Symbol("αs[1]") │    1.30648</span>
<span class="pl-c"><span class="pl-c">#</span> Symbol("αs[2]") │ -0.0605151</span></pre></div>
<h2 dir="auto"><a id="user-content-pyhf-json--batjl" class="anchor" aria-hidden="true" href="#pyhf-json--batjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>pyhf</code> JSON + BAT.jl:</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using LiteHF, BAT

pydict = load_pyhfjson(&quot;./test/sample.json&quot;);

pyhfmodel = build_pyhf(pydict);

LL = pyhf_logjointof(pyhfmodel)

mylikelihood(αs) = BAT.LogDVal(LL(αs))
posterior = PosteriorDensity(mylikelihood, priors(pyhfmodel))

@show bat_findmode(posterior).result
# (mu = 1.3064647047644158, theta = -0.06049852104383994)"><pre><span class="pl-k">using</span> LiteHF, BAT

pydict <span class="pl-k">=</span> <span class="pl-c1">load_pyhfjson</span>(<span class="pl-s"><span class="pl-pds">"</span>./test/sample.json<span class="pl-pds">"</span></span>);

pyhfmodel <span class="pl-k">=</span> <span class="pl-c1">build_pyhf</span>(pydict);

LL <span class="pl-k">=</span> <span class="pl-c1">pyhf_logjointof</span>(pyhfmodel)

<span class="pl-en">mylikelihood</span>(αs) <span class="pl-k">=</span> BAT<span class="pl-k">.</span><span class="pl-c1">LogDVal</span>(<span class="pl-c1">LL</span>(αs))
posterior <span class="pl-k">=</span> <span class="pl-c1">PosteriorDensity</span>(mylikelihood, <span class="pl-c1">priors</span>(pyhfmodel))

<span class="pl-c1">@show</span> <span class="pl-c1">bat_findmode</span>(posterior)<span class="pl-k">.</span>result
<span class="pl-c"><span class="pl-c">#</span> (mu = 1.3064647047644158, theta = -0.06049852104383994)</span></pre></div>
<h2 dir="auto"><a id="user-content-manual-example" class="anchor" aria-hidden="true" href="#manual-example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Manual Example</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Turing, LiteHF, Optim

###### Dummy data ######
const v_data = [34,22,13,11] # observed data
const v_sig = [2,3,4,5] # signal
const v_bg = [30,19,9,4] # BKG
const variations = [1,2,3,3]

###### Background and Signal modifier definitions ######
const bkgmodis =[
                 Histosys(v_bg .+ variations, v_bg .- variations),
                 Normsys(1.1, 0.9)
                ]
const bkgexp = ExpCounts(v_bg, [&quot;theta1&quot;, &quot;theta2&quot;], bkgmodis)

const sigmodis = [Normfactor()];
const sigexp = ExpCounts(v_sig, [&quot;mu&quot;], sigmodis);


###### Expected counts as a function of μ and θs
function expected_bincounts2(μ, θs)
    sigexp((mu = μ, )) + bkgexp((theta1=θs[1], theta2=θs[2]))
end

###### Turing.jl models
@model function binned_b(bincounts)
    μ ~ Turing.Flat()
    θs ~ filldist(Normal(), 2)

    expected = expected_bincounts2(μ, θs)
    @. bincounts ~ Poisson(expected)
end

###### Feed observed data to model to construct a posterior/likelihood object
const mymodel = binned_b(v_data);

###### Inference
chain_map = optimize(mymodel, MAP(), [1,1,1]) # initial guesses
display(chain_map)"><pre><span class="pl-k">using</span> Turing, LiteHF, Optim

<span class="pl-c"><span class="pl-c">#</span>##### Dummy data ######</span>
<span class="pl-k">const</span> v_data <span class="pl-k">=</span> [<span class="pl-c1">34</span>,<span class="pl-c1">22</span>,<span class="pl-c1">13</span>,<span class="pl-c1">11</span>] <span class="pl-c"><span class="pl-c">#</span> observed data</span>
<span class="pl-k">const</span> v_sig <span class="pl-k">=</span> [<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">4</span>,<span class="pl-c1">5</span>] <span class="pl-c"><span class="pl-c">#</span> signal</span>
<span class="pl-k">const</span> v_bg <span class="pl-k">=</span> [<span class="pl-c1">30</span>,<span class="pl-c1">19</span>,<span class="pl-c1">9</span>,<span class="pl-c1">4</span>] <span class="pl-c"><span class="pl-c">#</span> BKG</span>
<span class="pl-k">const</span> variations <span class="pl-k">=</span> [<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>,<span class="pl-c1">3</span>]

<span class="pl-c"><span class="pl-c">#</span>##### Background and Signal modifier definitions ######</span>
<span class="pl-k">const</span> bkgmodis <span class="pl-k">=</span>[
                 <span class="pl-c1">Histosys</span>(v_bg <span class="pl-k">.+</span> variations, v_bg <span class="pl-k">.-</span> variations),
                 <span class="pl-c1">Normsys</span>(<span class="pl-c1">1.1</span>, <span class="pl-c1">0.9</span>)
                ]
<span class="pl-k">const</span> bkgexp <span class="pl-k">=</span> <span class="pl-c1">ExpCounts</span>(v_bg, [<span class="pl-s"><span class="pl-pds">"</span>theta1<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>theta2<span class="pl-pds">"</span></span>], bkgmodis)

<span class="pl-k">const</span> sigmodis <span class="pl-k">=</span> [<span class="pl-c1">Normfactor</span>()];
<span class="pl-k">const</span> sigexp <span class="pl-k">=</span> <span class="pl-c1">ExpCounts</span>(v_sig, [<span class="pl-s"><span class="pl-pds">"</span>mu<span class="pl-pds">"</span></span>], sigmodis);


<span class="pl-c"><span class="pl-c">#</span>##### Expected counts as a function of μ and θs</span>
<span class="pl-k">function</span> <span class="pl-en">expected_bincounts2</span>(μ, θs)
    <span class="pl-c1">sigexp</span>((mu <span class="pl-k">=</span> μ, )) <span class="pl-k">+</span> <span class="pl-c1">bkgexp</span>((theta1<span class="pl-k">=</span>θs[<span class="pl-c1">1</span>], theta2<span class="pl-k">=</span>θs[<span class="pl-c1">2</span>]))
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span>##### Turing.jl models</span>
<span class="pl-c1">@model</span> <span class="pl-k">function</span> <span class="pl-en">binned_b</span>(bincounts)
    μ <span class="pl-k">~</span> Turing<span class="pl-k">.</span><span class="pl-c1">Flat</span>()
    θs <span class="pl-k">~</span> <span class="pl-c1">filldist</span>(<span class="pl-c1">Normal</span>(), <span class="pl-c1">2</span>)

    expected <span class="pl-k">=</span> <span class="pl-c1">expected_bincounts2</span>(μ, θs)
    <span class="pl-c1">@.</span> bincounts <span class="pl-k">~</span> <span class="pl-c1">Poisson</span>(expected)
<span class="pl-k">end</span>

<span class="pl-c"><span class="pl-c">#</span>##### Feed observed data to model to construct a posterior/likelihood object</span>
<span class="pl-k">const</span> mymodel <span class="pl-k">=</span> <span class="pl-c1">binned_b</span>(v_data);

<span class="pl-c"><span class="pl-c">#</span>##### Inference</span>
chain_map <span class="pl-k">=</span> <span class="pl-c1">optimize</span>(mymodel, <span class="pl-c1">MAP</span>(), [<span class="pl-c1">1</span>,<span class="pl-c1">1</span>,<span class="pl-c1">1</span>]) <span class="pl-c"><span class="pl-c">#</span> initial guesses</span>
<span class="pl-c1">display</span>(chain_map)</pre></div>
<p dir="auto">Result:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="ModeResult with maximized lp of -13.23
3-element Named Vector{Float64}
A               │ 
────────────────┼───────────
:μ              │     1.0383
Symbol(&quot;θs[1]&quot;) │   0.032979
Symbol(&quot;θs[2]&quot;) │ -0.0352236⏎  "><pre class="notranslate"><code>ModeResult with maximized lp of -13.23
3-element Named Vector{Float64}
A               │ 
────────────────┼───────────
:μ              │     1.0383
Symbol("θs[1]") │   0.032979
Symbol("θs[2]") │ -0.0352236⏎  
</code></pre></div>
</article></div>