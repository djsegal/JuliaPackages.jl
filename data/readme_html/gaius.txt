<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-gaiusjl" class="anchor" aria-hidden="true" href="#gaiusjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Gaius.jl</h1>
<p dir="auto"><em>Because Caesar.jl was taken</em></p>
<p dir="auto"><a href="https://github.com/MasonProtter/Gaius.jl/actions?query=workflow%3ACI"><img src="https://github.com/MasonProtter/Gaius.jl/workflows/CI/badge.svg" alt="Continuous Integration" title="Continuous Integration" style="max-width: 100%;"></a>
<a href="https://github.com/MasonProtter/Gaius.jl/actions?query=workflow%3A%22CI+%28Julia+nightly%29%22"><img src="https://github.com/MasonProtter/Gaius.jl/workflows/CI%20(Julia%20nightly)/badge.svg" alt="Continuous Integration (Julia nightly)" title="Continuous Integration (Julia nightly)" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/MasonProtter/Gaius.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/6e8a3e91209b2344244f26df59bf3e5a2fafa0d0a16775b255e082e2bbfeb18c/68747470733a2f2f636f6465636f762e696f2f67682f4d61736f6e50726f747465722f47616975732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Code Coverage" title="Code Coverage" data-canonical-src="https://codecov.io/gh/MasonProtter/Gaius.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">Gaius.jl is a multi-threaded BLAS-like library using a divide-and-conquer
strategy to parallelism, and built on top of the <strong>fantastic</strong>
<a href="https://github.com/chriselrod/LoopVectorization.jl">LoopVectorization.jl</a>.
Gaius spawns threads using Julia's depth first parallel task runtime and so
Gaius's routines may be fearlessly nested inside multi-threaded Julia programs.</p>
<p dir="auto">Gaius is <em>not</em> stable or well tested. Only use it if you're adventurous.</p>
<p dir="auto">Note: Gaius is not actively maintained and I do not anticipate doing further
work on it. However, you may find it useful as a relatively simple playground
for learning about the implementation of linear algebra routines.</p>
<p dir="auto">There are other, more promising projects that may result in a
scalable, multi-threaded pure Julia BLAS library such as:</p>
<ol dir="auto">
<li><a href="https://github.com/mcabbott/Tullio.jl">Tullio.jl</a></li>
<li><a href="https://github.com/JuliaLinearAlgebra/Octavian.jl">Octavian.jl</a></li>
</ol>
<p dir="auto">In general:</p>
<ul dir="auto">
<li>Octavian is the most performant.</li>
<li>Tullio is the most flexible.</li>
</ul>
<h2 dir="auto"><a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick Start</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Gaius

julia&gt; Gaius.mul!(C, A, B) # (multi-threaded) multiply A×B and store the result in C (overwriting the contents of C)

julia&gt; Gaius.mul(A, B) # (multi-threaded) multiply A×B and return the result

julia&gt; Gaius.mul_serial!(C, A, B) # (single-threaded) multiply A×B and store the result in C (overwriting the contents of C)

julia&gt; Gaius.mul_serial(A, B) # (single-threaded) multiply A×B and return the result"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Gaius

julia<span class="pl-k">&gt;</span> Gaius<span class="pl-k">.</span><span class="pl-c1">mul!</span>(C, A, B) <span class="pl-c"><span class="pl-c">#</span> (multi-threaded) multiply A×B and store the result in C (overwriting the contents of C)</span>

julia<span class="pl-k">&gt;</span> Gaius<span class="pl-k">.</span><span class="pl-c1">mul</span>(A, B) <span class="pl-c"><span class="pl-c">#</span> (multi-threaded) multiply A×B and return the result</span>

julia<span class="pl-k">&gt;</span> Gaius<span class="pl-k">.</span><span class="pl-c1">mul_serial!</span>(C, A, B) <span class="pl-c"><span class="pl-c">#</span> (single-threaded) multiply A×B and store the result in C (overwriting the contents of C)</span>

julia<span class="pl-k">&gt;</span> Gaius<span class="pl-k">.</span><span class="pl-c1">mul_serial</span>(A, B) <span class="pl-c"><span class="pl-c">#</span> (single-threaded) multiply A×B and return the result</span></pre></div>
<p dir="auto">Remember to start Julia with multiple threads with e.g. one of the following:</p>
<ul dir="auto">
<li><code>julia -t auto</code></li>
<li><code>julia -t 4</code></li>
<li>Set the <code>JULIA_NUM_THREADS</code> environment variable to <code>4</code> <strong>before</strong> starting Julia</li>
</ul>
<p dir="auto">The functions in this list are part of the public API of Gaius:</p>
<ul dir="auto">
<li><code>Gaius.mul!</code></li>
<li><code>Gaius.mul</code></li>
<li><code>Gaius.mul_serial!</code></li>
<li><code>Gaius.mul_serial</code></li>
</ul>
<p dir="auto">All other functions are internal (private).</p>
<h2 dir="auto"><a id="user-content-matrix-multiplication" class="anchor" aria-hidden="true" href="#matrix-multiplication"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Matrix Multiplication</h2>
<p dir="auto">Currently, fast, native matrix-multiplication is only implemented
between matrices of types <code>Matrix{&lt;:Union{Float64, Float32, Int64, Int32, Int16}}</code>, and <code>StructArray{Complex}</code>. Support for other other
commonly encountered numeric <code>struct</code> types such as <code>Rational</code> and
<code>Dual</code> numbers is planned.</p>
<h3 dir="auto"><a id="user-content-using-gaius" class="anchor" aria-hidden="true" href="#using-gaius"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Using Gaius</h3>
<details>
<summary>Click to expand:</summary>
<p dir="auto">Gaius defines the public functions <code>Gaius.mul</code> and
<code>Gaius.mul!</code>. <code>Gaius.mul</code> is to be used like the regular <code>*</code>
operator between two matrices whereas <code>Gaius.mul!</code> takes in three
matrices <code>C, A, B</code> and stores <code>A*B</code> in <code>C</code> overwriting the contents of
<code>C</code>.</p>
<p dir="auto">The functions <code>Gaius.mul</code> and <code>Gaius.mul!</code> use multithreading. If you
want to run the single-threaded variants, use <code>Gais.mul_serial</code> and
<code>Gaius.mul_serial!</code> respectively.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Gaius, BenchmarkTools, LinearAlgebra

julia&gt; A, B, C = rand(104, 104), rand(104, 104), zeros(104, 104);

julia&gt; @btime mul!($C, $A, $B); # from LinearAlgebra
  68.529 μs (0 allocations: 0 bytes)

julia&gt; @btime mul!($C, $A, $B); #from Gaius
  31.220 μs (80 allocations: 10.20 KiB)"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Gaius, BenchmarkTools, LinearAlgebra

julia<span class="pl-k">&gt;</span> A, B, C <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">104</span>, <span class="pl-c1">104</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">104</span>, <span class="pl-c1">104</span>), <span class="pl-c1">zeros</span>(<span class="pl-c1">104</span>, <span class="pl-c1">104</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">mul!</span>(<span class="pl-k">$</span>C, <span class="pl-k">$</span>A, <span class="pl-k">$</span>B); <span class="pl-c"><span class="pl-c">#</span> from LinearAlgebra</span>
  <span class="pl-c1">68.529</span> μs (<span class="pl-c1">0</span> allocations<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">mul!</span>(<span class="pl-k">$</span>C, <span class="pl-k">$</span>A, <span class="pl-k">$</span>B); <span class="pl-c"><span class="pl-c">#</span>from Gaius</span>
  <span class="pl-c1">31.220</span> μs (<span class="pl-c1">80</span> allocations<span class="pl-k">:</span> <span class="pl-c1">10.20</span> KiB)</pre></div>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Gaius, BenchmarkTools

julia&gt; A, B = rand(104, 104), rand(104, 104);

julia&gt; @btime $A * $B;
  68.949 μs (2 allocations: 84.58 KiB)

julia&gt; @btime let * = Gaius.mul # Locally use Gaius.mul as * operator.
           $A * $B
       end;
  32.950 μs (82 allocations: 94.78 KiB)

julia&gt; versioninfo()
Julia Version 1.4.0-rc2.0
Commit b99ed72c95* (2020-02-24 16:51 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: AMD Ryzen 5 2600 Six-Core Processor
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, znver1)
Environment:
  JULIA_NUM_THREADS = 6"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Gaius, BenchmarkTools

julia<span class="pl-k">&gt;</span> A, B <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">104</span>, <span class="pl-c1">104</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">104</span>, <span class="pl-c1">104</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">$</span>A <span class="pl-k">*</span> <span class="pl-k">$</span>B;
  <span class="pl-c1">68.949</span> μs (<span class="pl-c1">2</span> allocations<span class="pl-k">:</span> <span class="pl-c1">84.58</span> KiB)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">let</span> <span class="pl-k">*</span> <span class="pl-k">=</span> Gaius<span class="pl-k">.</span>mul <span class="pl-c"><span class="pl-c">#</span> Locally use Gaius.mul as * operator.</span>
           <span class="pl-k">$</span>A <span class="pl-k">*</span> <span class="pl-k">$</span>B
       <span class="pl-k">end</span>;
  <span class="pl-c1">32.950</span> μs (<span class="pl-c1">82</span> allocations<span class="pl-k">:</span> <span class="pl-c1">94.78</span> KiB)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">versioninfo</span>()
Julia Version <span class="pl-c1">1.4</span>.<span class="pl-c1">0</span><span class="pl-k">-</span>rc2.<span class="pl-c1">0</span>
Commit b99ed72c95<span class="pl-k">*</span> (<span class="pl-c1">2020</span><span class="pl-k">-</span><span class="pl-c1">02</span><span class="pl-k">-</span><span class="pl-c1">24</span> <span class="pl-c1">16</span><span class="pl-k">:</span><span class="pl-c1">51</span> UTC)
Platform Info<span class="pl-k">:</span>
  OS<span class="pl-k">:</span> Linux (x86_64<span class="pl-k">-</span>pc<span class="pl-k">-</span>linux<span class="pl-k">-</span>gnu)
  CPU<span class="pl-k">:</span> AMD Ryzen <span class="pl-c1">5</span> <span class="pl-c1">2600</span> Six<span class="pl-k">-</span>Core Processor
  WORD_SIZE<span class="pl-k">:</span> <span class="pl-c1">64</span>
  LIBM<span class="pl-k">:</span> libopenlibm
  LLVM<span class="pl-k">:</span> libLLVM<span class="pl-k">-</span><span class="pl-c1">8.0</span>.<span class="pl-c1">1</span> (ORCJIT, znver1)
Environment<span class="pl-k">:</span>
  JULIA_NUM_THREADS <span class="pl-k">=</span> <span class="pl-c1">6</span></pre></div>
<p dir="auto">Multi-threading in Gaius works by recursively splitting matrices
into sub-blocks to operate on. You can change the matrix sub-block
size by calling <code>mul!</code> with the <code>block_size</code> keyword argument. If left
unspecified, Gaius will use a (very rough) heuristic to choose a good
block size based on the size of the input matrices.</p>
<p dir="auto">The size heuristics I use are likely not yet optimal for everyone's
machines.</p>
</details>
<h3 dir="auto"><a id="user-content-complex-numbers" class="anchor" aria-hidden="true" href="#complex-numbers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Complex Numbers</h3>
<details>
<summary>Click to expand:</summary>
<p dir="auto">Gaius supports the multiplication of matrices of complex numbers,
but they must first by converted explicity to structs of arrays using
StructArrays.jl (otherwise the multiplication will be done by OpenBLAS):</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Gaius, StructArrays

julia&gt; begin
           n = 150
           A = randn(ComplexF64, n, n)
           B = randn(ComplexF64, n, n)
           C = zeros(ComplexF64, n, n)


           SA =  StructArray(A)
           SB =  StructArray(B)
           SC = StructArray(C)

           @btime mul!($SC, $SA, $SB)
           @btime         mul!($C, $A, $B)
           SC ≈ C
       end
   515.587 μs (80 allocations: 10.53 KiB)
   546.481 μs (0 allocations: 0 bytes)
 true"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Gaius, StructArrays

julia<span class="pl-k">&gt;</span> <span class="pl-k">begin</span>
           n <span class="pl-k">=</span> <span class="pl-c1">150</span>
           A <span class="pl-k">=</span> <span class="pl-c1">randn</span>(ComplexF64, n, n)
           B <span class="pl-k">=</span> <span class="pl-c1">randn</span>(ComplexF64, n, n)
           C <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(ComplexF64, n, n)


           SA <span class="pl-k">=</span>  <span class="pl-c1">StructArray</span>(A)
           SB <span class="pl-k">=</span>  <span class="pl-c1">StructArray</span>(B)
           SC <span class="pl-k">=</span> <span class="pl-c1">StructArray</span>(C)

           <span class="pl-c1">@btime</span> <span class="pl-c1">mul!</span>(<span class="pl-k">$</span>SC, <span class="pl-k">$</span>SA, <span class="pl-k">$</span>SB)
           <span class="pl-c1">@btime</span>         <span class="pl-c1">mul!</span>(<span class="pl-k">$</span>C, <span class="pl-k">$</span>A, <span class="pl-k">$</span>B)
           SC <span class="pl-k">≈</span> C
       <span class="pl-k">end</span>
   <span class="pl-c1">515.587</span> μs (<span class="pl-c1">80</span> allocations<span class="pl-k">:</span> <span class="pl-c1">10.53</span> KiB)
   <span class="pl-c1">546.481</span> μs (<span class="pl-c1">0</span> allocations<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes)
 <span class="pl-c1">true</span></pre></div>
</details>
<h3 dir="auto"><a id="user-content-benchmarks" class="anchor" aria-hidden="true" href="#benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Benchmarks</h3>
<h4 dir="auto"><a id="user-content-floating-point-performance" class="anchor" aria-hidden="true" href="#floating-point-performance"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Floating Point Performance</h4>
<details>
<summary>Click to expand:</summary>
<p dir="auto">The following benchmarks were run on this</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; versioninfo()
Julia Version 1.4.0-rc2.0
Commit b99ed72c95* (2020-02-24 16:51 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: AMD Ryzen 5 2600 Six-Core Processor
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, znver1)
Environment:
  JULIA_NUM_THREADS = 6"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">versioninfo</span>()
Julia Version <span class="pl-c1">1.4</span>.<span class="pl-c1">0</span><span class="pl-k">-</span>rc2.<span class="pl-c1">0</span>
Commit b99ed72c95<span class="pl-k">*</span> (<span class="pl-c1">2020</span><span class="pl-k">-</span><span class="pl-c1">02</span><span class="pl-k">-</span><span class="pl-c1">24</span> <span class="pl-c1">16</span><span class="pl-k">:</span><span class="pl-c1">51</span> UTC)
Platform Info<span class="pl-k">:</span>
  OS<span class="pl-k">:</span> Linux (x86_64<span class="pl-k">-</span>pc<span class="pl-k">-</span>linux<span class="pl-k">-</span>gnu)
  CPU<span class="pl-k">:</span> AMD Ryzen <span class="pl-c1">5</span> <span class="pl-c1">2600</span> Six<span class="pl-k">-</span>Core Processor
  WORD_SIZE<span class="pl-k">:</span> <span class="pl-c1">64</span>
  LIBM<span class="pl-k">:</span> libopenlibm
  LLVM<span class="pl-k">:</span> libLLVM<span class="pl-k">-</span><span class="pl-c1">8.0</span>.<span class="pl-c1">1</span> (ORCJIT, znver1)
Environment<span class="pl-k">:</span>
  JULIA_NUM_THREADS <span class="pl-k">=</span> <span class="pl-c1">6</span></pre></div>
<p dir="auto">and compared to <a href="https://github.com/xianyi/OpenBLAS">OpenBLAS</a> running with
<code>6</code> threads (<code>BLAS.set_num_threads(6)</code>). I would be keenly interested in seeing
analogous benchmarks on a machine with an AVX512 instruction set and/or
<a href="https://software.intel.com/en-us/mkl" rel="nofollow">Intel's MKL</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="assets/F64_mul.png"><img src="assets/F64_mul.png" alt="Float64 Matrix Multiplication" title="Float64 Matrix Multiplication" style="max-width: 100%;"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="assets/F32_mul.png"><img src="assets/F32_mul.png" alt="Float32 Matrix Multiplication" title="Float32 Matrix Multiplication" style="max-width: 100%;"></a></p>
<p dir="auto"><em>Note that these are log-log plots.</em></p>
<p dir="auto">Gaius outperforms <a href="https://github.com/xianyi/OpenBLAS">OpenBLAS</a> over a large
range of matrix sizes, but
does begin to appreciably fall behind around <code>800 x 800</code> matrices for
<code>Float64</code> and <code>650 x 650</code> matrices for <code>Float32</code>. I believe there is a
large amount of performance left on the table in Gaius and I look
forward to beating OpenBLAS for more matrix sizes.</p>
</details>
<h4 dir="auto"><a id="user-content-complex-floating-point-performance" class="anchor" aria-hidden="true" href="#complex-floating-point-performance"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Complex Floating Point Performance</h4>
<details>
<summary>Click to expand:</summary>
<p dir="auto">Here is Gaius operating on <code>Complex{Float64}</code> structs-of-arrays
competeing relatively evenly against OpenBLAS operating on
<code>Complex{Float64}</code> arrays-of-structs:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="assets/C64_mul.png"><img src="assets/C64_mul.png" alt="Complex{Float64} Matrix Multiplication" title="Complex{Float64} Matrix Multiplication" style="max-width: 100%;"></a></p>
<p dir="auto">I think with some work, we can do much better.</p>
</details>
<h4 dir="auto"><a id="user-content-integer-performance" class="anchor" aria-hidden="true" href="#integer-performance"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Integer Performance</h4>
<details>
<summary>Click to expand:</summary>
<p dir="auto">These benchmarks compare Gaius (on the same machine as above) and
compare against Julia's generic matrix multiplication implementation
(OpenBLAS does not provide integer mat-mul) which is not
multi-threaded.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="assets/I64_mul.png"><img src="assets/I64_mul.png" alt="Int64 Matrix Multiplication" title="Int64 Matrix Multiplication" style="max-width: 100%;"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="assets/I32_mul.png"><img src="assets/I32_mul.png" alt="Int32 Matrix Multiplication" title="Int32 Matrix Multiplication" style="max-width: 100%;"></a></p>
<p dir="auto"><em>Note that these are log-log plots.</em></p>
<p dir="auto">Benchmarks performed on a machine with the AVX512 instruction set show an
<a href="https://github.com/chriselrod/LoopVectorization.jl">even greater performance gain</a>.</p>
<p dir="auto">If you find yourself in a high performance situation where you want to
multiply matrices of integers, I think this provides a compelling
use-case for Gaius since it will outperform it's competition at
<em>any</em> matrix size and for large matrices will benefit from
multi-threading.</p>
</details>
<h2 dir="auto"><a id="user-content-other-blas-routines" class="anchor" aria-hidden="true" href="#other-blas-routines"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Other BLAS Routines</h2>
<p dir="auto">I have not yet worked on implementing other standard BLAS routines
with this strategy, but doing so should be relatively straightforward.</p>
<h2 dir="auto"><a id="user-content-safety" class="anchor" aria-hidden="true" href="#safety"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Safety</h2>
<p dir="auto"><em>If you must break the law, do it to seize power; in all other cases observe it.</em></p>
<p dir="auto">-Gaius Julius Caesar</p>
<p dir="auto">If you use only the functions <code>Gaius.mul!</code>, <code>Gaius.mul</code>,
<code>Gaius.mul_serial!</code>, and <code>Gaius.mul_serial</code>,
automatic array size-checking will occur before
the matrix multiplication begins. This can be turned off in
<code>mul!</code> by calling <code>Gaius.mul!(C, A, B; sizecheck=false)</code>, in
which case no sizechecks will occur on the arrays before the matrix
multiplication occurs and all sorts of bad, segfaulty things can
happen.</p>
<p dir="auto">All other functions in this package are to be considered <em>internal</em>
and should not be expected to check for safety or obey the law. The
functions <code>Gaius.gemm_kernel!</code> and <code>Gaius.add_gemm_kernel!</code> may be of
utility, but be warned that they do not check array sizes.</p>
</article></div>