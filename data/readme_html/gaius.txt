<div id="readme" class="org" data-path="README.org"><article class="markdown-body entry-content" itemprop="text"><div>
  <p><i>Because Caesar.jl was taken</i></p>
</div>
<h1><a id="user-content-gaiusjl" class="anchor" aria-hidden="true" href="#gaiusjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Gaius.jl</h1>
<p>Gaius.jl is a multi-threaded BLAS-like library using a
  divide-and-conquer strategy to parallelism, and built on top of the
  <b>fantastic</b> <a href="https://github.com/chriselrod/LoopVectorization.jl">LoopVectorization.jl</a>. Gaius.jl spawns threads using
  Julia’s depth first parallel task runtime and so Gaius.jl’s routines
  may be fearlessly nested inside multi-threaded julia programs.</p>
<p>Gaius is <b>not</b> stable or well tested. Only use it if you’re
  adventurous.</p>
<h2><a id="user-content-matrix-multiplication" class="anchor" aria-hidden="true" href="#matrix-multiplication"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Matrix Multiplication</h2>
<p>Currently, fast, native matrix-multiplication is only implemented
  between matrices of types <code>Matrix{&lt;:Union{Float64, Float32, Int64,
  Int32, Int16}}</code>, and <code>StructArray{Complex}</code>. Support for other other
  commonly encountered numeric <code>struct</code> types such as <code>Rational</code> and
  <code>Dual</code> numbers is planned.</p>
<h3><a id="user-content-using-gaiusjl" class="anchor" aria-hidden="true" href="#using-gaiusjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Using Gaius.jl</h3>
<details><summary>Click me!</summary>
<p>
</p><p>Gaius.jl exports the functions <code>blocked_mul</code> and
  <code>blocked_mul!</code>. <code>blocked_mul</code> is to be used like the regular <code>*</code>
  operator between two matrices whereas <code>bloked_mul!</code> takes in three
  matrices <code>C, A, B</code> and stores <code>A*B</code> in <code>C</code> overwriting the contents of
  <code>C</code>.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Gaius, BenchmarkTools, LinearAlgebra

julia<span class="pl-k">&gt;</span> A, B, C <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">104</span>, <span class="pl-c1">104</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">104</span>, <span class="pl-c1">104</span>), <span class="pl-c1">zeros</span>(<span class="pl-c1">104</span>, <span class="pl-c1">104</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">mul!</span>(<span class="pl-k">$</span>C, <span class="pl-k">$</span>A, <span class="pl-k">$</span>B); <span class="pl-c"><span class="pl-c">#</span> from LinearAlgebra</span>
  <span class="pl-c1">68.529</span> μs (<span class="pl-c1">0</span> allocations<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-c1">blocked_mul!</span>(<span class="pl-k">$</span>C, <span class="pl-k">$</span>A, <span class="pl-k">$</span>B); <span class="pl-c"><span class="pl-c">#</span>from Gaius</span>
  <span class="pl-c1">31.220</span> μs (<span class="pl-c1">80</span> allocations<span class="pl-k">:</span> <span class="pl-c1">10.20</span> KiB)</pre></div>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Gaius, BenchmarkTools

julia<span class="pl-k">&gt;</span> A, B <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">104</span>, <span class="pl-c1">104</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">104</span>, <span class="pl-c1">104</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">$</span>A <span class="pl-k">*</span> <span class="pl-k">$</span>B;
  <span class="pl-c1">68.949</span> μs (<span class="pl-c1">2</span> allocations<span class="pl-k">:</span> <span class="pl-c1">84.58</span> KiB)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@btime</span> <span class="pl-k">let</span> <span class="pl-k">*</span> <span class="pl-k">=</span> Gaius<span class="pl-k">.</span>blocked_mul <span class="pl-c"><span class="pl-c">#</span> Locally use Gaius.blocked_mul as * operator.</span>
           <span class="pl-k">$</span>A <span class="pl-k">*</span> <span class="pl-k">$</span>B
       <span class="pl-k">end</span>;
  <span class="pl-c1">32.950</span> μs (<span class="pl-c1">82</span> allocations<span class="pl-k">:</span> <span class="pl-c1">94.78</span> KiB)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">versioninfo</span>()
Julia Version <span class="pl-c1">1.4.0</span><span class="pl-k">-</span>rc2<span class="pl-c1">.0</span>
Commit b99ed72c95<span class="pl-k">*</span> (<span class="pl-c1">2020</span><span class="pl-k">-</span><span class="pl-c1">02</span><span class="pl-k">-</span><span class="pl-c1">24</span> <span class="pl-c1">16</span><span class="pl-k">:</span><span class="pl-c1">51</span> UTC)
Platform Info<span class="pl-k">:</span>
  OS<span class="pl-k">:</span> Linux (x86_64<span class="pl-k">-</span>pc<span class="pl-k">-</span>linux<span class="pl-k">-</span>gnu)
  CPU<span class="pl-k">:</span> AMD Ryzen <span class="pl-c1">5</span> <span class="pl-c1">2600</span> Six<span class="pl-k">-</span>Core Processor
  WORD_SIZE<span class="pl-k">:</span> <span class="pl-c1">64</span>
  LIBM<span class="pl-k">:</span> libopenlibm
  LLVM<span class="pl-k">:</span> libLLVM<span class="pl-k">-</span><span class="pl-c1">8.0.1</span> (ORCJIT, znver1)
Environment<span class="pl-k">:</span>
  JULIA_NUM_THREADS <span class="pl-k">=</span> <span class="pl-c1">6</span></pre></div>
<p>Multi-threading in Gaius.jl works by recursively splitting matrices
  into sub-blocks to operate on. You can change the matrix sub-block
  size by calling <code>mul!</code> with the <code>block_size</code> keyword argument. If left
  unspecified, Gaius will use a (very rough) heuristic to choose a good
  block size based on the size of the input matrices.</p>
<p>The size heuristics I use are likely not yet optimal for everyone’s
  machines.</p>
</details>
<p></p>
<h3><a id="user-content-complex-numbers" class="anchor" aria-hidden="true" href="#complex-numbers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Complex Numbers</h3>
<details><summary>Click me!</summary>
<p>
</p><p>Gaius.jl supports the multiplication of matrices of complex numbers,
  but they must first by converted explicity to structs of arrays using
  StructArrays.jl (otherwise the multiplication will be done by OpenBLAS):</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Gaius, StructArrays

julia<span class="pl-k">&gt;</span> <span class="pl-k">begin</span>
           n <span class="pl-k">=</span> <span class="pl-c1">150</span>
           A <span class="pl-k">=</span> <span class="pl-c1">randn</span>(ComplexF64, n, n)
           B <span class="pl-k">=</span> <span class="pl-c1">randn</span>(ComplexF64, n, n)
           C <span class="pl-k">=</span> <span class="pl-c1">zeros</span>(ComplexF64, n, n)


           SA <span class="pl-k">=</span>  <span class="pl-c1">StructArray</span>(A)
           SB <span class="pl-k">=</span>  <span class="pl-c1">StructArray</span>(B)
           SC <span class="pl-k">=</span> <span class="pl-c1">StructArray</span>(C)

           <span class="pl-c1">@btime</span> <span class="pl-c1">blocked_mul!</span>(<span class="pl-k">$</span>SC, <span class="pl-k">$</span>SA, <span class="pl-k">$</span>SB)
           <span class="pl-c1">@btime</span>         <span class="pl-c1">mul!</span>(<span class="pl-k">$</span>C, <span class="pl-k">$</span>A, <span class="pl-k">$</span>B)
           SC <span class="pl-k">≈</span> C
       <span class="pl-k">end</span> 
   <span class="pl-c1">515.587</span> μs (<span class="pl-c1">80</span> allocations<span class="pl-k">:</span> <span class="pl-c1">10.53</span> KiB)
   <span class="pl-c1">546.481</span> μs (<span class="pl-c1">0</span> allocations<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes)
 <span class="pl-c1">true</span></pre></div>
</details>
<p></p>
<h3><a id="user-content-benchmarks" class="anchor" aria-hidden="true" href="#benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Benchmarks</h3>
<h4><a id="user-content-floating-point-performance" class="anchor" aria-hidden="true" href="#floating-point-performance"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Floating Point Performance</h4>
<details><summary>Click me!</summary>
<p>
</p><p>The following benchmarks were run on this</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">versioninfo</span>()
Julia Version <span class="pl-c1">1.4.0</span><span class="pl-k">-</span>rc2<span class="pl-c1">.0</span>
Commit b99ed72c95<span class="pl-k">*</span> (<span class="pl-c1">2020</span><span class="pl-k">-</span><span class="pl-c1">02</span><span class="pl-k">-</span><span class="pl-c1">24</span> <span class="pl-c1">16</span><span class="pl-k">:</span><span class="pl-c1">51</span> UTC)
Platform Info<span class="pl-k">:</span>
  OS<span class="pl-k">:</span> Linux (x86_64<span class="pl-k">-</span>pc<span class="pl-k">-</span>linux<span class="pl-k">-</span>gnu)
  CPU<span class="pl-k">:</span> AMD Ryzen <span class="pl-c1">5</span> <span class="pl-c1">2600</span> Six<span class="pl-k">-</span>Core Processor
  WORD_SIZE<span class="pl-k">:</span> <span class="pl-c1">64</span>
  LIBM<span class="pl-k">:</span> libopenlibm
  LLVM<span class="pl-k">:</span> libLLVM<span class="pl-k">-</span><span class="pl-c1">8.0.1</span> (ORCJIT, znver1)
Environment<span class="pl-k">:</span>
  JULIA_NUM_THREADS <span class="pl-k">=</span> <span class="pl-c1">6</span></pre></div>
<p>and compared to <a href="https://github.com/xianyi/OpenBLAS">OpenBLAS</a> running with <code>6</code> threads
  (<code>BLAS.set_num_threads(6)</code>). I would be keenly interested in seeing
  analogous benchmarks on a machine with an AVX512 instruction set and / or <a href="https://software.intel.com/en-us/mkl" rel="nofollow">Intel’s MKL</a>.</p>
<p><a target="_blank" rel="noopener noreferrer" href="assets/F64_mul.png"><img src="assets/F64_mul.png" alt="assets/F64_mul.png" style="max-width:100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="assets/F32_mul.png"><img src="assets/F32_mul.png" alt="assets/F32_mul.png" style="max-width:100%;"></a></p>
<p><i>Note that these are log-log plots</i></p>
<p>Gaius.jl outperforms <a href="https://github.com/xianyi/OpenBLAS">OpenBLAS</a> over a large range of matrix sizes, but
  does begin to appreciably fall behind around <code>800 x 800</code> matrices for
  <code>Float64</code> and <code>650 x 650</code> matrices for <code>Float32</code>. I believe there is a
  large amount of performance left on the table in Gaius.jl and I look
  forward to beating OpenBLAS for more matrix sizes.</p>
</details>
<p></p>
<h4><a id="user-content-complex-floating-point-performance" class="anchor" aria-hidden="true" href="#complex-floating-point-performance"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Complex Floating Point Performance</h4>
<details><summary>Click me!</summary>
<p>
</p><p>Here is Gaius operating on <code>Complex{Float64}</code> structs-of-arrays
  competeing relatively evenly against OpenBLAS operating on <code>Complex{Float64}</code> arrays-of-structs:</p>
<p><a target="_blank" rel="noopener noreferrer" href="assets/C64_mul.png"><img src="assets/C64_mul.png" alt="assets/C64_mul.png" style="max-width:100%;"></a></p>
<p>I think with some work, we can do much better.</p>
</details>
<p></p>
<h4><a id="user-content-integer-performance" class="anchor" aria-hidden="true" href="#integer-performance"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Integer Performance</h4>
<details><summary>Click me!</summary>
<p>
</p><p>These benchmarks compare Gaius.jl (on the same machine as above) and
  compare against julia’s generic matrix multiplication implementation
  (OpenBLAS does not provide integer mat-mul) which is not
  multi-threaded.</p>
<p><a target="_blank" rel="noopener noreferrer" href="assets/I64_mul.png"><img src="assets/I64_mul.png" alt="assets/I64_mul.png" style="max-width:100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="assets/I32_mul.png"><img src="assets/I32_mul.png" alt="assets/I32_mul.png" style="max-width:100%;"></a></p>
<p><i>Note that these are log-log plots</i></p>
<p>Benchmarks performed on am achine with the AVX512 instruction set show
  an <a href="https://github.com/chriselrod/LoopVectorization.jl">even greater performance gain.</a></p>
<p>If you find yourself in a high performance situation where you want to
  multiply matrices of integers, I think this provides a compelling
  use-case for Gaius.jl since it will outperform it’s competition at
  <b>any</b> matrix size and for large matrices will benefit from
  multi-threading.</p>
</details>
<p></p>
<h2><a id="user-content-other-blas-routines" class="anchor" aria-hidden="true" href="#other-blas-routines"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Other BLAS Routines</h2>
<p>I have not yet worked on implementing other standard BLAS routines
  with this strategy, but doing so should be relatively straightforward.</p>
<h2><a id="user-content-safety" class="anchor" aria-hidden="true" href="#safety"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Safety</h2>
<p><i>If you must break the law, do it to seize power; in all other cases observe it.</i></p>
<p>-Gaius Julius Caesar</p>
<p>If you use only the functions <code>Gaius.blocked_mul!</code> and
  <code>Gaius.blocked_mul</code>, automatic array size-checking will occur before
  the matrix multiplication begins. This can be turned off in
  <code>blocked_mul!</code> by calling <code>Gaius.mul!(C, A, B, sizecheck=false)</code>, in
  which case no sizechecks will occur on the arrays before the matrix
  multiplication occurs and all sorts of bad, segfaulty things can
  happen.</p>
<p>All other functions in this package are to be considered <i>internal</i>
  and should not be expected to check for safety or obey the law. The
  functions <code>Gaius.gemm_kernel!</code> and <code>Gaius.add_gemm_kernel!</code> may be of
  utility, but be warned that they do not check array sizes.</p>
</article></div>