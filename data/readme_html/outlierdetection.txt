<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><p><g-emoji class="g-emoji" alias="construction" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png">üöß</g-emoji> <em>Experimental</em>, install from master branch until 0.2 is released and expect breaking changes <g-emoji class="g-emoji" alias="construction" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png">üöß</g-emoji></p>
<h1 align="center"><a id="user-content-outlierdetectionjl" class="anchor" aria-hidden="true" href="#outlierdetectionjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>OutlierDetection.jl</h1>
<p align="center">
  <a href="https://discord.gg/F5MPPS9t4h" rel="nofollow">
    <img src="https://camo.githubusercontent.com/e1833c7e063a9706c5c5916d41ea2475f7e0e002dc2b5cf4ff83ddec9a0db8c0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230646973636f72642d3732383964612e7376673f73616e6974697a653d74727565" alt="Chat" data-canonical-src="https://img.shields.io/badge/chat-on%20discord-7289da.svg?sanitize=true" style="max-width:100%;">
  </a>
  <a href="https://davnn.github.io/OutlierDetection.jl/stable" rel="nofollow">
    <img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Documentation (stable)" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;">
  </a>
  <a href="https://davnn.github.io/OutlierDetection.jl/dev" rel="nofollow">
    <img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Documentation (dev)" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;">
  </a>
  <a href="https://github.com/davnn/OutlierDetection.jl/actions">
    <img src="https://github.com/davnn/OutlierDetection.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width:100%;">
  </a>
  <a href="https://codecov.io/gh/davnn/OutlierDetection.jl" rel="nofollow">
    <img src="https://camo.githubusercontent.com/aa3e4c1ff1197189dd474feef9ffda5c166a337004f2f500d5b901872716d32c/68747470733a2f2f636f6465636f762e696f2f67682f6461766e6e2f4f75746c696572446574656374696f6e2e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/davnn/OutlierDetection.jl/branch/master/graph/badge.svg" style="max-width:100%;">
  </a>
  
  <a href="#contributors-">
    <img src="https://camo.githubusercontent.com/f5edd68bc6c40ecc3d9661c833045b103bb3fdfe8b1f605ac6fa589d7757115e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616c6c5f636f6e7472696275746f72732d312d677265656e2e7376673f7374796c653d666c61742d737175617265" alt="All Contributors" data-canonical-src="https://img.shields.io/badge/all_contributors-1-green.svg?style=flat-square" style="max-width:100%;">
  </a>
    
</p>
<p><em>OutlierDetection.jl</em> is a Julia toolkit for detecting outlying objects, also known as <em>anomalies</em>. This package is an effort to make Julia a first-class citizen in the Outlier- and Anomaly-Detection community. <em>Why should you use this package?</em></p>
<ul>
<li>Provides a unified API for outlier detection in Julia</li>
<li>Provides access to state-of-the-art outlier detection algorithms</li>
<li>Seamlessly integrates with Julia's existing machine learning ecosystem</li>
</ul>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p>It is recommended to use <a href="https://julialang.github.io/Pkg.jl" rel="nofollow">Pkg.jl</a> for installation. Follow the command below to install the latest official release or use <code>] add OutlierDetection</code> in the Julia REPL.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="import Pkg;
Pkg.add(&quot;OutlierDetection&quot;)
"><pre><span class="pl-k">import</span> Pkg;
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>OutlierDetection<span class="pl-pds">"</span></span>)</pre></div>
<p>If you would like to modify the package locally, you can use <code>Pkg.develop(OutlierDetection)</code> or <code>] dev OutlierDetection</code> in the Julia REPL. This fetches a full clone of the package to <code>~/.julia/dev/</code> (the path can be changed by setting the environment variable <code>JULIA_PKG_DEVDIR</code>).</p>
<h2><a id="user-content-api" class="anchor" aria-hidden="true" href="#api"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>API</h2>
<p>You typically want to interface with OutlierDetection.jl through the <a href="#mlj-api">MLJ-API</a>. However, it's also possible to use OutlierDetection.jl without MLJ. The main parts of the API are the functions <code>fit</code>, <code>score</code>, and <code>detect</code>. Note that the raw API uses the columns-as-observations convention for improved performance, and we transpose the input data.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using OutlierDetection
using OutlierDetectionData: ODDS

# create a detector (a collection of hyperparameteres)
lof = LOF()

# download and open the thyroid benchmark dataset
X, y = ODDS.load(&quot;thyroid&quot;)

# use 50% of the data for training
n_train = Int(length(y) * 0.5)
train, test = eachindex(y)[1:n_train], eachindex(y)[n_train+1:end]

# learn a model from data
model = fit(lof, X[train, :])

# predict outlier scores with learned model
train_scores, test_scores = score(lof, model, X[test, :])

# transform scores to binary labels
clf = Class()
yÃÇ = detect(clf, train_scores, test_scores)
"><pre><span class="pl-k">using</span> OutlierDetection
<span class="pl-k">using</span> OutlierDetectionData<span class="pl-k">:</span> ODDS

<span class="pl-c"><span class="pl-c">#</span> create a detector (a collection of hyperparameteres)</span>
lof <span class="pl-k">=</span> <span class="pl-c1">LOF</span>()

<span class="pl-c"><span class="pl-c">#</span> download and open the thyroid benchmark dataset</span>
X, y <span class="pl-k">=</span> ODDS<span class="pl-k">.</span><span class="pl-c1">load</span>(<span class="pl-s"><span class="pl-pds">"</span>thyroid<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">#</span> use 50% of the data for training</span>
n_train <span class="pl-k">=</span> <span class="pl-c1">Int</span>(<span class="pl-c1">length</span>(y) <span class="pl-k">*</span> <span class="pl-c1">0.5</span>)
train, test <span class="pl-k">=</span> <span class="pl-c1">eachindex</span>(y)[<span class="pl-c1">1</span><span class="pl-k">:</span>n_train], <span class="pl-c1">eachindex</span>(y)[n_train<span class="pl-k">+</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span>]

<span class="pl-c"><span class="pl-c">#</span> learn a model from data</span>
model <span class="pl-k">=</span> <span class="pl-c1">fit</span>(lof, X[train, :])

<span class="pl-c"><span class="pl-c">#</span> predict outlier scores with learned model</span>
train_scores, test_scores <span class="pl-k">=</span> <span class="pl-c1">score</span>(lof, model, X[test, :])

<span class="pl-c"><span class="pl-c">#</span> transform scores to binary labels</span>
clf <span class="pl-k">=</span> <span class="pl-c1">Class</span>()
yÃÇ <span class="pl-k">=</span> <span class="pl-c1">detect</span>(clf, train_scores, test_scores)</pre></div>
<h2><a id="user-content-mlj-api" class="anchor" aria-hidden="true" href="#mlj-api"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>MLJ API</h2>
<p>The main difference between the raw API and MLJ is, besides method naming differences, the introduction of a <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/machines/" rel="nofollow"><code>machine</code></a>. In the raw API, we explicitly pass the results of fitting a detector (models) to further <code>score</code> calls. Machines allow us to hide that complexity by binding data directly to detectors and automatically passing fit results to further <code>transform</code> (unsupervised) or <code>predict</code> (supervised) calls. Under the hood, <code>transform</code> and <code>predict</code> pass the input data and previous fit result to <code>score</code>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using MLJ # or using MLJBase
using OutlierDetection
using OutlierDetectionData: ODDS

# download and open the thyroid benchmark dataset
X, y = ODDS.load(&quot;thyroid&quot;);

# use 50% of the data for training
n_train = Int(length(y) * 0.5)
train, test = eachindex(y)[1:n_train], eachindex(y)[n_train+1:end]

# create a pipeline consisting of a detector and classifier
pipe = @pipeline LOF() Class()

# create a machine by binding the pipeline to data
mach = machine(pipe, X)

# learn from data
fit!(mach, rows=train)

# predict labels with learned machine
yÃÇ = transform(mach, rows=test)
"><pre><span class="pl-k">using</span> MLJ <span class="pl-c"><span class="pl-c">#</span> or using MLJBase</span>
<span class="pl-k">using</span> OutlierDetection
<span class="pl-k">using</span> OutlierDetectionData<span class="pl-k">:</span> ODDS

<span class="pl-c"><span class="pl-c">#</span> download and open the thyroid benchmark dataset</span>
X, y <span class="pl-k">=</span> ODDS<span class="pl-k">.</span><span class="pl-c1">load</span>(<span class="pl-s"><span class="pl-pds">"</span>thyroid<span class="pl-pds">"</span></span>);

<span class="pl-c"><span class="pl-c">#</span> use 50% of the data for training</span>
n_train <span class="pl-k">=</span> <span class="pl-c1">Int</span>(<span class="pl-c1">length</span>(y) <span class="pl-k">*</span> <span class="pl-c1">0.5</span>)
train, test <span class="pl-k">=</span> <span class="pl-c1">eachindex</span>(y)[<span class="pl-c1">1</span><span class="pl-k">:</span>n_train], <span class="pl-c1">eachindex</span>(y)[n_train<span class="pl-k">+</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">end</span>]

<span class="pl-c"><span class="pl-c">#</span> create a pipeline consisting of a detector and classifier</span>
pipe <span class="pl-k">=</span> <span class="pl-c1">@pipeline</span> <span class="pl-c1">LOF</span>() <span class="pl-c1">Class</span>()

<span class="pl-c"><span class="pl-c">#</span> create a machine by binding the pipeline to data</span>
mach <span class="pl-k">=</span> <span class="pl-c1">machine</span>(pipe, X)

<span class="pl-c"><span class="pl-c">#</span> learn from data</span>
<span class="pl-c1">fit!</span>(mach, rows<span class="pl-k">=</span>train)

<span class="pl-c"><span class="pl-c">#</span> predict labels with learned machine</span>
yÃÇ <span class="pl-k">=</span> <span class="pl-c1">transform</span>(mach, rows<span class="pl-k">=</span>test)</pre></div>
<h2><a id="user-content-algorithms-also-known-as-detectors" class="anchor" aria-hidden="true" href="#algorithms-also-known-as-detectors"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Algorithms (also known as Detectors)</h2>
<p>Algorithms marked with '‚úì' are implemented in Julia. Algorithms marked with '‚úì (py)' are implemented in Python (thanks to the wonderful <a href="https://github.com/yzhao062/pyod">PyOD library</a>) with an existing Julia interface through <a href="https://github.com/JuliaPy/PyCall.jl">PyCall</a>. If you would like to know more, open the <a href="https://davnn.github.io/OutlierDetection.jl/dev/API/detectors/" rel="nofollow">detector reference</a>. Note: If you would like to use a Python-variant of an algorithm, prepend the algorithm name with <code>Py</code>, e.g., <code>PyLOF</code> is the Python variant of <code>LOF</code>.</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
<th align="center">Year</th>
<th align="center">Status</th>
<th>Authors</th>
</tr>
</thead>
<tbody>
<tr>
<td>LMDD</td>
<td>Linear deviation-based outlier detection</td>
<td align="center">1996</td>
<td align="center">‚úì (py)</td>
<td>Arning et al.</td>
</tr>
<tr>
<td>KNN</td>
<td>Distance-based outliers</td>
<td align="center">1997</td>
<td align="center">‚úì</td>
<td>Knorr and Ng</td>
</tr>
<tr>
<td>MCD</td>
<td>Minimum covariance determinant</td>
<td align="center">1999</td>
<td align="center">‚úì (py)</td>
<td>Rousseeuw and Driessen</td>
</tr>
<tr>
<td>KNN</td>
<td>Distance to the k-th nearest neighbor</td>
<td align="center">2000</td>
<td align="center">‚úì</td>
<td>Ramaswamy</td>
</tr>
<tr>
<td>LOF</td>
<td>Local outlier factor</td>
<td align="center">2000</td>
<td align="center">‚úì</td>
<td>Breunig et al.</td>
</tr>
<tr>
<td>OCSVM</td>
<td>One-Class support vector machine</td>
<td align="center">2001</td>
<td align="center">‚úì (py)</td>
<td>Sch√∂lkopf et al.</td>
</tr>
<tr>
<td>KNN</td>
<td>Sum of distances to the k-nearest neighbors</td>
<td align="center">2002</td>
<td align="center">‚úì</td>
<td>Angiulli and Pizzuti</td>
</tr>
<tr>
<td>COF</td>
<td>Connectivity-based outlier factor</td>
<td align="center">2002</td>
<td align="center">‚úì</td>
<td>Tang et al.</td>
</tr>
<tr>
<td>LOCI</td>
<td>Local correlation integral</td>
<td align="center">2003</td>
<td align="center">‚úì (py)</td>
<td>Papadimitirou et al.</td>
</tr>
<tr>
<td>CBLOF</td>
<td>Cluster-based local outliers</td>
<td align="center">2003</td>
<td align="center">‚úì (py)</td>
<td>He et al.</td>
</tr>
<tr>
<td>PCA</td>
<td>Principal component analysis</td>
<td align="center">2003</td>
<td align="center">‚úì (py)</td>
<td>Shyu et al.</td>
</tr>
<tr>
<td>IForest</td>
<td>Isolation forest</td>
<td align="center">2008</td>
<td align="center">‚úì (py)</td>
<td>Liu et al.</td>
</tr>
<tr>
<td>ABOD</td>
<td>Angle-based outlier detection</td>
<td align="center">2009</td>
<td align="center">‚úì</td>
<td>Kriegel et al.</td>
</tr>
<tr>
<td>SOD</td>
<td>Subspace outlier detection</td>
<td align="center">2009</td>
<td align="center">‚úì (py)</td>
<td>Kriegel et al.</td>
</tr>
<tr>
<td>HBOS</td>
<td>Histogram-based outlier score</td>
<td align="center">2012</td>
<td align="center">‚úì (py)</td>
<td>Goldstein and Dengel</td>
</tr>
<tr>
<td>SOS</td>
<td>Stochastic outlier selection</td>
<td align="center">2012</td>
<td align="center">‚úì (py)</td>
<td>Janssens et al.</td>
</tr>
<tr>
<td>AE</td>
<td>Auto-encoder reconstruction loss outliers</td>
<td align="center">2015</td>
<td align="center">‚úì</td>
<td>Aggarwal</td>
</tr>
<tr>
<td>ABOD</td>
<td>Stable angle-based outlier detection</td>
<td align="center">2015</td>
<td align="center">‚úì</td>
<td>Li et al.</td>
</tr>
<tr>
<td>LODA</td>
<td>Lightweight on-line detector of anomalies</td>
<td align="center">2016</td>
<td align="center">‚úì (py)</td>
<td>Pevn√Ω</td>
</tr>
<tr>
<td>DeepSAD</td>
<td>Deep semi-supervised anomaly detection</td>
<td align="center">2019</td>
<td align="center">‚úì</td>
<td>Ruff et al.</td>
</tr>
<tr>
<td>COPOD</td>
<td>Copula-based outlier detection</td>
<td align="center">2020</td>
<td align="center">‚úì (py)</td>
<td>Li et al.</td>
</tr>
<tr>
<td>ROD</td>
<td>Rotation-based outlier detection</td>
<td align="center">2020</td>
<td align="center">‚úì (py)</td>
<td>Almardeny et al.</td>
</tr>
<tr>
<td>ESAD</td>
<td>End-to-end semi-supervised anomaly detection</td>
<td align="center">2020</td>
<td align="center">‚úì</td>
<td>Huang et al.</td>
</tr>
</tbody>
</table>
<p>If there are already so many algorithms available in Python - <em>why Julia, you might ask?</em> Let's have some fun!</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using OutlierDetection, MLJ
using BenchmarkTools: @benchmark
X = rand(100000, 10);
lof = machine(LOF(k=5, algorithm=:balltree, leafsize=30, parallel=true), X) |&gt; fit!
pylof = machine(PyLOF(n_neighbors=5, algorithm=&quot;ball_tree&quot;, leaf_size=30, n_jobs=-1), X) |&gt; fit!
"><pre><span class="pl-k">using</span> OutlierDetection, MLJ
<span class="pl-k">using</span> BenchmarkTools<span class="pl-k">:</span> <span class="pl-c1">@benchmark</span>
X <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">100000</span>, <span class="pl-c1">10</span>);
lof <span class="pl-k">=</span> <span class="pl-c1">machine</span>(<span class="pl-c1">LOF</span>(k<span class="pl-k">=</span><span class="pl-c1">5</span>, algorithm<span class="pl-k">=</span><span class="pl-c1">:balltree</span>, leafsize<span class="pl-k">=</span><span class="pl-c1">30</span>, parallel<span class="pl-k">=</span><span class="pl-c1">true</span>), X) <span class="pl-k">|&gt;</span> fit!
pylof <span class="pl-k">=</span> <span class="pl-c1">machine</span>(<span class="pl-c1">PyLOF</span>(n_neighbors<span class="pl-k">=</span><span class="pl-c1">5</span>, algorithm<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>ball_tree<span class="pl-pds">"</span></span>, leaf_size<span class="pl-k">=</span><span class="pl-c1">30</span>, n_jobs<span class="pl-k">=</span><span class="pl-k">-</span><span class="pl-c1">1</span>), X) <span class="pl-k">|&gt;</span> fit!</pre></div>
<p>Julia enables you to implement your favorite algorithm in no time and it will be fast, <em>blazingly fast</em>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="@benchmark transform(lof, X)
&gt; median time:      807.962 ms (0.00% GC)
"><pre><span class="pl-c1">@benchmark</span> <span class="pl-c1">transform</span>(lof, X)
<span class="pl-k">&gt;</span> median time<span class="pl-k">:</span>      <span class="pl-c1">807.962</span> ms (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)</pre></div>
<p>Interoperating with Python is easy!</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="@benchmark transform(pylof, X)
&gt; median time:      31.077 s (0.00% GC)
"><pre><span class="pl-c1">@benchmark</span> <span class="pl-c1">transform</span>(pylof, X)
<span class="pl-k">&gt;</span> median time<span class="pl-k">:</span>      <span class="pl-c1">31.077</span> s (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)</pre></div>
<h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contributing</h2>
<p>OutlierDetection.jl is a community effort and your help is extremely welcome! See our <a href="https://davnn.github.io/OutlierDetection.jl/dev/getting-started/contributing/" rel="nofollow">contribution guide</a> for more information how to contribute to the project.</p>
<h3><a id="user-content-inclusion-guidelines" class="anchor" aria-hidden="true" href="#inclusion-guidelines"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Inclusion Guidelines</h3>
<p>We are excited to make Julia a first-class citizen in the outlier detection community and happily accept algorithm contributions to OutlierDetection.jl.</p>
<p>We consider well-established algorithms for inclusion. A rule of thumb is at least two years since publication, 100+ citations, and wide use and usefulness. Algorithms that do not meet the inclusion criteria can simply extend our API. The external algorithms can also be listed in our documentation if the authors wish so.</p>
<p>Additionally, algorithms that implement functionality that is useful on their own should live in their own package, wrapped by OutlierDetection.jl. Algorithms that build primarily on top of existing packages can be implemented directly in OutlierDetection.jl.</p>
<h2><a id="user-content-contributors-" class="anchor" aria-hidden="true" href="#contributors-"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contributors <g-emoji class="g-emoji" alias="sparkles" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png">‚ú®</g-emoji></h2>
<p>Thanks go to these wonderful people (<a href="https://allcontributors.org/docs/en/emoji-key" rel="nofollow">emoji key</a>):</p>



<table>
  <tbody><tr>
    <td align="center"><a href="http://fastpaced.com" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/1233304?v=4?s=100" width="100px;" alt="" style="max-width:100%;"><br><sub><b>David Muhr</b></sub></a><br><a href="https://github.com/davnn/OutlierDetection.jl/commits?author=davnn" title="Code"><g-emoji class="g-emoji" alias="computer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png">üíª</g-emoji></a> <a href="https://github.com/davnn/OutlierDetection.jl/commits?author=davnn" title="Tests"><g-emoji class="g-emoji" alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png">‚ö†Ô∏è</g-emoji></a> <a href="https://github.com/davnn/OutlierDetection.jl/commits?author=davnn" title="Documentation"><g-emoji class="g-emoji" alias="book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png">üìñ</g-emoji></a> <a href="#maintenance-davnn" title="Maintenance"><g-emoji class="g-emoji" alias="construction" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png">üöß</g-emoji></a></td>
  </tr>
</tbody></table>



<p>This project follows the <a href="https://github.com/all-contributors/all-contributors">all-contributors</a> specification. Contributions of any kind welcome!</p>
</article></div>