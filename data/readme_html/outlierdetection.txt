<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-outlierdetectionjl" class="anchor" aria-hidden="true" href="#outlierdetectionjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>OutlierDetection.jl</h1>
<p dir="auto"><a href="https://julialang.slack.com/archives/C02EXTD7WGG" rel="nofollow"><img src="https://camo.githubusercontent.com/7109ef8b5b69db9f6b643803b0888595aaf28f1ed35505b7130497dd6afbea46/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736c61636b2d6a756c69616c616e672f6f75746c696572646574656374696f6e2d626c75652e7376673f6c6f676f3d736c61636b" alt="Chat" data-canonical-src="https://img.shields.io/badge/slack-julialang/outlierdetection-blue.svg?logo=slack" style="max-width: 100%;"></a>
<a href="https://OutlierDetectionJL.github.io/OutlierDetection.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Documentation (dev)" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/OutlierDetectionJL/OutlierDetection.jl/actions"><img src="https://github.com/OutlierDetectionJL/OutlierDetection.jl/workflows/CI/badge.svg" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/OutlierDetectionJL/OutlierDetection.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/826b362173f37b52825a72c8f8226de864ede7ebf536e6f856748884fc84c637/68747470733a2f2f636f6465636f762e696f2f67682f4f75746c696572446574656374696f6e4a4c2f4f75746c696572446574656374696f6e2e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/OutlierDetectionJL/OutlierDetection.jl/branch/master/graph/badge.svg" style="max-width: 100%;"></a> 
<a href="#contributors-"><img src="https://camo.githubusercontent.com/87951bc87eb4d4e9f8a51c8d25c37f5a579ab214ff609b5dbf7d273271daad18/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616c6c5f636f6e7472696275746f72732d362d6f72616e67652e7376673f7374796c653d666c61742d737175617265" alt="All Contributors" data-canonical-src="https://img.shields.io/badge/all_contributors-6-orange.svg?style=flat-square" style="max-width: 100%;"></a></p>

<p dir="auto"><em>OutlierDetection.jl</em> is a Julia toolkit for detecting outlying objects, also known as <em>anomalies</em>. This package is an effort to make Julia a first-class citizen in the Outlier- and Anomaly-Detection community. <em>Why should you use this package?</em></p>
<ul dir="auto">
<li>Provides a unified API for outlier detection in Julia</li>
<li>Provides access to state-of-the-art outlier detection algorithms</li>
<li>Seamlessly integrates with Julia's existing machine learning ecosystem</li>
</ul>
<p dir="auto"><strong>Citing</strong></p>
<p dir="auto">If you use <em>OutlierDetection.jl</em> in a scientific publication, we appreciate citations to:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="@article{muhr2022outlierdetection,
  title={OutlierDetection.jl: A modular outlier detection ecosystem for the Julia programming language},
  author={Muhr, David and Affenzeller, Michael and Blaom, Anthony D},
  journal={arXiv preprint arXiv:2211.04550},
  year={2022}
}"><pre class="notranslate"><code>@article{muhr2022outlierdetection,
  title={OutlierDetection.jl: A modular outlier detection ecosystem for the Julia programming language},
  author={Muhr, David and Affenzeller, Michael and Blaom, Anthony D},
  journal={arXiv preprint arXiv:2211.04550},
  year={2022}
}
</code></pre></div>
<p dir="auto">or</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="Muhr, David, Michael Affenzeller, and Anthony D. Blaom. &quot;OutlierDetection.jl: A modular outlier detection ecosystem for the Julia programming language.&quot; arXiv preprint arXiv:2211.04550 (2022)."><pre class="notranslate"><code>Muhr, David, Michael Affenzeller, and Anthony D. Blaom. "OutlierDetection.jl: A modular outlier detection ecosystem for the Julia programming language." arXiv preprint arXiv:2211.04550 (2022).
</code></pre></div>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">It is recommended to use <a href="https://julialang.github.io/Pkg.jl" rel="nofollow">Pkg.jl</a> for installation. Follow the command below to install the latest official release or use <code>] add OutlierDetection</code> in the Julia REPL.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="import Pkg
Pkg.add(&quot;OutlierDetection&quot;)"><pre><span class="pl-k">import</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>OutlierDetection<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto">If you would like to modify the package locally, you can use <code>Pkg.develop("OutlierDetection")</code> or <code>] dev OutlierDetection</code> in the Julia REPL. This fetches a full clone of the package to <code>~/.julia/dev/</code> (the path can be changed by setting the environment variable <code>JULIA_PKG_DEVDIR</code>).</p>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto"><em>OutlierDetection.jl</em> is built on top of <a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> and provides many <code>Detector</code> implementations for MLJ. A <code>Detector</code> simply assigns a real-valued score to each sample, which is defined to be increasing with increasing outlierness. The detectors live in sub-packages of <a href="https://github.com/OutlierDetectionJL/">OutlierDetectionJL</a>, e.g. <a href="https://github.com/OutlierDetectionJL/OutlierDetectionNeighbors.jl">OutlierDetectionNeighbors</a>,and can be loaded directly with MLJ, as shown below.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using MLJ
using OutlierDetection
using OutlierDetectionData: ODDS

# download and open the thyroid benchmark dataset
X, y = ODDS.load(&quot;thyroid&quot;)

# use 50% of the data for training
train, test = partition(eachindex(y), 0.5, shuffle=true)

# load the detector
KNN = @iload KNNDetector pkg=OutlierDetectionNeighbors

# instantiate a detector with default parameters, returning scores
knn = KNN()

# bind the detector to data and learn a model with all data
knn_raw = machine(knn, X) |&gt; fit!

# transform data to raw outlier scores based on the test data; note that there
# is no `predict` defined for raw detectors
transform(knn_raw, rows=test)

# OutlierDetection.jl provides helper functions to normalize the scores,
# for example using min-max scaling based on the training scores
knn_probas = machine(ProbabilisticDetector(knn), X) |&gt; fit!

# predict outlier probabilities based on the test data
predict(knn_probas, rows=test)

# OutlierDetection.jl also provides helper functions to turn scores into classes,
# for example by imposing a threshold based on the training data percentiles
knn_classifier = machine(DeterministicDetector(knn), X) |&gt; fit!

# predict outlier classes based on the test data
predict(knn_classifier, rows=test)"><pre><span class="pl-k">using</span> MLJ
<span class="pl-k">using</span> OutlierDetection
<span class="pl-k">using</span> OutlierDetectionData<span class="pl-k">:</span> ODDS

<span class="pl-c"><span class="pl-c">#</span> download and open the thyroid benchmark dataset</span>
X, y <span class="pl-k">=</span> ODDS<span class="pl-k">.</span><span class="pl-c1">load</span>(<span class="pl-s"><span class="pl-pds">"</span>thyroid<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">#</span> use 50% of the data for training</span>
train, test <span class="pl-k">=</span> <span class="pl-c1">partition</span>(<span class="pl-c1">eachindex</span>(y), <span class="pl-c1">0.5</span>, shuffle<span class="pl-k">=</span><span class="pl-c1">true</span>)

<span class="pl-c"><span class="pl-c">#</span> load the detector</span>
KNN <span class="pl-k">=</span> <span class="pl-c1">@iload</span> KNNDetector pkg<span class="pl-k">=</span>OutlierDetectionNeighbors

<span class="pl-c"><span class="pl-c">#</span> instantiate a detector with default parameters, returning scores</span>
knn <span class="pl-k">=</span> <span class="pl-c1">KNN</span>()

<span class="pl-c"><span class="pl-c">#</span> bind the detector to data and learn a model with all data</span>
knn_raw <span class="pl-k">=</span> <span class="pl-c1">machine</span>(knn, X) <span class="pl-k">|&gt;</span> fit!

<span class="pl-c"><span class="pl-c">#</span> transform data to raw outlier scores based on the test data; note that there</span>
<span class="pl-c"><span class="pl-c">#</span> is no `predict` defined for raw detectors</span>
<span class="pl-c1">transform</span>(knn_raw, rows<span class="pl-k">=</span>test)

<span class="pl-c"><span class="pl-c">#</span> OutlierDetection.jl provides helper functions to normalize the scores,</span>
<span class="pl-c"><span class="pl-c">#</span> for example using min-max scaling based on the training scores</span>
knn_probas <span class="pl-k">=</span> <span class="pl-c1">machine</span>(<span class="pl-c1">ProbabilisticDetector</span>(knn), X) <span class="pl-k">|&gt;</span> fit!

<span class="pl-c"><span class="pl-c">#</span> predict outlier probabilities based on the test data</span>
<span class="pl-c1">predict</span>(knn_probas, rows<span class="pl-k">=</span>test)

<span class="pl-c"><span class="pl-c">#</span> OutlierDetection.jl also provides helper functions to turn scores into classes,</span>
<span class="pl-c"><span class="pl-c">#</span> for example by imposing a threshold based on the training data percentiles</span>
knn_classifier <span class="pl-k">=</span> <span class="pl-c1">machine</span>(<span class="pl-c1">DeterministicDetector</span>(knn), X) <span class="pl-k">|&gt;</span> fit!

<span class="pl-c"><span class="pl-c">#</span> predict outlier classes based on the test data</span>
<span class="pl-c1">predict</span>(knn_classifier, rows<span class="pl-k">=</span>test)</pre></div>
<p dir="auto">It is also possible to use <em>OutlierDetection.jl</em> without MLJ, however, note that more explicit steps are necessary.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using OutlierDetection: fit, transform, scale_minmax, classify_quantile, outlier_fraction
using OutlierDetectionNeighbors: KNNDetector # explicitly import detector
using OutlierDetectionData: ODDS

X, y = ODDS.load(&quot;thyroid&quot;)
knn = KNNDetector()

# explicit conversion to a native array is necessary
# note that we are using the transposed data, because column-major data is expected
Xmatrix = Matrix(X)'

# explicit fit result and training scores
model, scores_train = fit(knn, Xmatrix[:, 11:end]; verbosity = 0)

# transform the first 10 points to scores (not used for training)
scores_test = transform(knn, model, Xmatrix[:, 1:10])

# explicitly normalize train and test scores
proba_train, proba_test = scale_minmax((scores_train, scores_test))

# explicitly convert scores to labels (&gt; 95th percentile would be an outlier)
labels_train, labels_test = classify_quantile(0.95)((scores_train, scores_test))"><pre><span class="pl-k">using</span> OutlierDetection<span class="pl-k">:</span> fit, transform, scale_minmax, classify_quantile, outlier_fraction
<span class="pl-k">using</span> OutlierDetectionNeighbors<span class="pl-k">:</span> KNNDetector <span class="pl-c"><span class="pl-c">#</span> explicitly import detector</span>
<span class="pl-k">using</span> OutlierDetectionData<span class="pl-k">:</span> ODDS

X, y <span class="pl-k">=</span> ODDS<span class="pl-k">.</span><span class="pl-c1">load</span>(<span class="pl-s"><span class="pl-pds">"</span>thyroid<span class="pl-pds">"</span></span>)
knn <span class="pl-k">=</span> <span class="pl-c1">KNNDetector</span>()

<span class="pl-c"><span class="pl-c">#</span> explicit conversion to a native array is necessary</span>
<span class="pl-c"><span class="pl-c">#</span> note that we are using the transposed data, because column-major data is expected</span>
Xmatrix <span class="pl-k">=</span> <span class="pl-c1">Matrix</span>(X)<span class="pl-k">'</span>

<span class="pl-c"><span class="pl-c">#</span> explicit fit result and training scores</span>
model, scores_train <span class="pl-k">=</span> <span class="pl-c1">fit</span>(knn, Xmatrix[:, <span class="pl-c1">11</span><span class="pl-k">:</span><span class="pl-c1">end</span>]; verbosity <span class="pl-k">=</span> <span class="pl-c1">0</span>)

<span class="pl-c"><span class="pl-c">#</span> transform the first 10 points to scores (not used for training)</span>
scores_test <span class="pl-k">=</span> <span class="pl-c1">transform</span>(knn, model, Xmatrix[:, <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">10</span>])

<span class="pl-c"><span class="pl-c">#</span> explicitly normalize train and test scores</span>
proba_train, proba_test <span class="pl-k">=</span> <span class="pl-c1">scale_minmax</span>((scores_train, scores_test))

<span class="pl-c"><span class="pl-c">#</span> explicitly convert scores to labels (&gt; 95th percentile would be an outlier)</span>
labels_train, labels_test <span class="pl-k">=</span> <span class="pl-c1">classify_quantile</span>(<span class="pl-c1">0.95</span>)((scores_train, scores_test))</pre></div>
<h2 dir="auto"><a id="user-content-algorithms-also-known-as-detectors" class="anchor" aria-hidden="true" href="#algorithms-also-known-as-detectors"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Algorithms (also known as Detectors)</h2>
<p dir="auto">Algorithms marked with '‚úì' are implemented in Julia. Algorithms marked with '‚úì (py)' are implemented in Python (thanks to the wonderful <a href="https://github.com/yzhao062/pyod">PyOD library</a>) with an existing Julia interface through <a href="https://github.com/JuliaPy/PyCall.jl">PyCall</a>. If you would like to know more, open the <a href="https://OutlierDetectionJL.github.io/OutlierDetection.jl/dev/API/detectors/" rel="nofollow">detector reference</a>.</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
<th align="center">Year</th>
<th align="center">Status</th>
<th>Authors</th>
</tr>
</thead>
<tbody>
<tr>
<td>LMDD</td>
<td>Linear deviation-based outlier detection</td>
<td align="center">1996</td>
<td align="center">‚úì (py)</td>
<td>Arning et al.</td>
</tr>
<tr>
<td>KNN</td>
<td>Distance-based outliers</td>
<td align="center">1997</td>
<td align="center">‚úì</td>
<td>Knorr and Ng</td>
</tr>
<tr>
<td>MCD</td>
<td>Minimum covariance determinant</td>
<td align="center">1999</td>
<td align="center">‚úì (py)</td>
<td>Rousseeuw and Driessen</td>
</tr>
<tr>
<td>KNN</td>
<td>Distance to the k-th nearest neighbor</td>
<td align="center">2000</td>
<td align="center">‚úì</td>
<td>Ramaswamy</td>
</tr>
<tr>
<td>LOF</td>
<td>Local outlier factor</td>
<td align="center">2000</td>
<td align="center">‚úì</td>
<td>Breunig et al.</td>
</tr>
<tr>
<td>OCSVM</td>
<td>One-Class support vector machine</td>
<td align="center">2001</td>
<td align="center">‚úì (py)</td>
<td>Sch√∂lkopf et al.</td>
</tr>
<tr>
<td>KNN</td>
<td>Sum of distances to the k-nearest neighbors</td>
<td align="center">2002</td>
<td align="center">‚úì</td>
<td>Angiulli and Pizzuti</td>
</tr>
<tr>
<td>COF</td>
<td>Connectivity-based outlier factor</td>
<td align="center">2002</td>
<td align="center">‚úì</td>
<td>Tang et al.</td>
</tr>
<tr>
<td>LOCI</td>
<td>Local correlation integral</td>
<td align="center">2003</td>
<td align="center">‚úì (py)</td>
<td>Papadimitirou et al.</td>
</tr>
<tr>
<td>CBLOF</td>
<td>Cluster-based local outliers</td>
<td align="center">2003</td>
<td align="center">‚úì (py)</td>
<td>He et al.</td>
</tr>
<tr>
<td>PCA</td>
<td>Principal component analysis</td>
<td align="center">2003</td>
<td align="center">‚úì (py)</td>
<td>Shyu et al.</td>
</tr>
<tr>
<td>IForest</td>
<td>Isolation forest</td>
<td align="center">2008</td>
<td align="center">‚úì (py)</td>
<td>Liu et al.</td>
</tr>
<tr>
<td>ABOD</td>
<td>Angle-based outlier detection</td>
<td align="center">2009</td>
<td align="center">‚úì</td>
<td>Kriegel et al.</td>
</tr>
<tr>
<td>SOD</td>
<td>Subspace outlier detection</td>
<td align="center">2009</td>
<td align="center">‚úì (py)</td>
<td>Kriegel et al.</td>
</tr>
<tr>
<td>HBOS</td>
<td>Histogram-based outlier score</td>
<td align="center">2012</td>
<td align="center">‚úì (py)</td>
<td>Goldstein and Dengel</td>
</tr>
<tr>
<td>SOS</td>
<td>Stochastic outlier selection</td>
<td align="center">2012</td>
<td align="center">‚úì (py)</td>
<td>Janssens et al.</td>
</tr>
<tr>
<td>AE</td>
<td>Auto-encoder reconstruction loss outliers</td>
<td align="center">2015</td>
<td align="center">‚úì</td>
<td>Aggarwal</td>
</tr>
<tr>
<td>ABOD</td>
<td>Stable angle-based outlier detection</td>
<td align="center">2015</td>
<td align="center">‚úì</td>
<td>Li et al.</td>
</tr>
<tr>
<td>LODA</td>
<td>Lightweight on-line detector of anomalies</td>
<td align="center">2016</td>
<td align="center">‚úì (py)</td>
<td>Pevn√Ω</td>
</tr>
<tr>
<td>DeepSAD</td>
<td>Deep semi-supervised anomaly detection</td>
<td align="center">2019</td>
<td align="center">‚úì</td>
<td>Ruff et al.</td>
</tr>
<tr>
<td>COPOD</td>
<td>Copula-based outlier detection</td>
<td align="center">2020</td>
<td align="center">‚úì (py)</td>
<td>Li et al.</td>
</tr>
<tr>
<td>ROD</td>
<td>Rotation-based outlier detection</td>
<td align="center">2020</td>
<td align="center">‚úì (py)</td>
<td>Almardeny et al.</td>
</tr>
<tr>
<td>ESAD</td>
<td>End-to-end semi-supervised anomaly detection</td>
<td align="center">2020</td>
<td align="center">‚úì</td>
<td>Huang et al.</td>
</tr>
</tbody>
</table>
<p dir="auto">If there are already so many algorithms available in Python - <em>why Julia, you might ask?</em> Let's have some fun!</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using OutlierDetection, MLJ
using BenchmarkTools: @benchmark
X = rand(10, 100000)
LOF =  @iload LOFDetector pkg=OutlierDetectionNeighbors
PyLOF =  @iload LOFDetector pkg=OutlierDetectionPython
lof = machine(LOF(k=5, algorithm=:kdtree, leafsize=30, parallel=true), X) |&gt; fit!
pylof = machine(PyLOF(n_neighbors=5, algorithm=&quot;kd_tree&quot;, leaf_size=30, n_jobs=-1), X) |&gt; fit!"><pre><span class="pl-k">using</span> OutlierDetection, MLJ
<span class="pl-k">using</span> BenchmarkTools<span class="pl-k">:</span> <span class="pl-c1">@benchmark</span>
X <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">10</span>, <span class="pl-c1">100000</span>)
LOF <span class="pl-k">=</span>  <span class="pl-c1">@iload</span> LOFDetector pkg<span class="pl-k">=</span>OutlierDetectionNeighbors
PyLOF <span class="pl-k">=</span>  <span class="pl-c1">@iload</span> LOFDetector pkg<span class="pl-k">=</span>OutlierDetectionPython
lof <span class="pl-k">=</span> <span class="pl-c1">machine</span>(<span class="pl-c1">LOF</span>(k<span class="pl-k">=</span><span class="pl-c1">5</span>, algorithm<span class="pl-k">=</span><span class="pl-c1">:kdtree</span>, leafsize<span class="pl-k">=</span><span class="pl-c1">30</span>, parallel<span class="pl-k">=</span><span class="pl-c1">true</span>), X) <span class="pl-k">|&gt;</span> fit!
pylof <span class="pl-k">=</span> <span class="pl-c1">machine</span>(<span class="pl-c1">PyLOF</span>(n_neighbors<span class="pl-k">=</span><span class="pl-c1">5</span>, algorithm<span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>kd_tree<span class="pl-pds">"</span></span>, leaf_size<span class="pl-k">=</span><span class="pl-c1">30</span>, n_jobs<span class="pl-k">=</span><span class="pl-k">-</span><span class="pl-c1">1</span>), X) <span class="pl-k">|&gt;</span> fit!</pre></div>
<p dir="auto">Julia enables you to implement your favorite algorithm in no time, and it will be fast, <em>blazingly fast</em>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="@benchmark transform(lof, X)
&gt; median time:      341.464 ms (0.00% GC)"><pre><span class="pl-c1">@benchmark</span> <span class="pl-c1">transform</span>(lof, X)
<span class="pl-k">&gt;</span> median time<span class="pl-k">:</span>      <span class="pl-c1">341.464</span> ms (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)</pre></div>
<p dir="auto">Interoperating with Python is easy!</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="@benchmark transform(pylof, X)
&gt; median time:      7.934 s (0.00% GC)"><pre><span class="pl-c1">@benchmark</span> <span class="pl-c1">transform</span>(pylof, X)
<span class="pl-k">&gt;</span> median time<span class="pl-k">:</span>      <span class="pl-c1">7.934</span> s (<span class="pl-c1">0.00</span><span class="pl-k">%</span> GC)</pre></div>
<h2 dir="auto"><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributing</h2>
<p dir="auto">OutlierDetection.jl is a community effort and your help is extremely welcome! See our <a href="https://OutlierDetectionJL.github.io/OutlierDetection.jl/dev/documentation/contributing/" rel="nofollow">contribution guide</a> for more information how to contribute to the project.</p>
<h2 dir="auto"><a id="user-content-contributors-" class="anchor" aria-hidden="true" href="#contributors-"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributors <g-emoji class="g-emoji" alias="sparkles" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png">‚ú®</g-emoji></h2>
<p dir="auto">Thanks go to these wonderful people (<a href="https://allcontributors.org/docs/en/emoji-key" rel="nofollow">emoji key</a>):</p>



<table>
  <tbody>
    <tr>
      <td align="center" valign="top" width="14.28%"><a href="http://fastpaced.com" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/1233304?v=4?s=100" width="100px;" alt="David Muhr" style="max-width: 100%;"><br><sub><b>David Muhr</b></sub></a><br><a href="https://github.com/OutlierDetectionJL/OutlierDetection.jl/commits?author=davnn" title="Code"><g-emoji class="g-emoji" alias="computer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png">üíª</g-emoji></a> <a href="https://github.com/OutlierDetectionJL/OutlierDetection.jl/commits?author=davnn" title="Tests"><g-emoji class="g-emoji" alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png">‚ö†Ô∏è</g-emoji></a> <a href="https://github.com/OutlierDetectionJL/OutlierDetection.jl/commits?author=davnn" title="Documentation"><g-emoji class="g-emoji" alias="book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png">üìñ</g-emoji></a> <a href="#maintenance-davnn" title="Maintenance"><g-emoji class="g-emoji" alias="construction" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png">üöß</g-emoji></a></td>
      <td align="center" valign="top" width="14.28%"><a href="https://github.com/PallHaraldsson"><img src="https://avatars.githubusercontent.com/u/8005416?v=4?s=100" width="100px;" alt="P√°ll Haraldsson" style="max-width: 100%;"><br><sub><b>P√°ll Haraldsson</b></sub></a><br><a href="https://github.com/OutlierDetectionJL/OutlierDetection.jl/commits?author=PallHaraldsson" title="Documentation"><g-emoji class="g-emoji" alias="book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png">üìñ</g-emoji></a></td>
      <td align="center" valign="top" width="14.28%"><a href="http://ablaom.github.io" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/30517088?v=4?s=100" width="100px;" alt="Anthony Blaom, PhD" style="max-width: 100%;"><br><sub><b>Anthony Blaom, PhD</b></sub></a><br><a href="https://github.com/OutlierDetectionJL/OutlierDetection.jl/commits?author=ablaom" title="Code"><g-emoji class="g-emoji" alias="computer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png">üíª</g-emoji></a></td>
      <td align="center" valign="top" width="14.28%"><a href="https://github.com/pitmonticone"><img src="https://avatars.githubusercontent.com/u/38562595?v=4?s=100" width="100px;" alt="Pietro Monticone" style="max-width: 100%;"><br><sub><b>Pietro Monticone</b></sub></a><br><a href="https://github.com/OutlierDetectionJL/OutlierDetection.jl/commits?author=pitmonticone" title="Documentation"><g-emoji class="g-emoji" alias="book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png">üìñ</g-emoji></a></td>
      <td align="center" valign="top" width="14.28%"><a href="https://github.com/rolling-robot"><img src="https://avatars.githubusercontent.com/u/18036097?v=4?s=100" width="100px;" alt="Petr Mukhachev" style="max-width: 100%;"><br><sub><b>Petr Mukhachev</b></sub></a><br><a href="https://github.com/OutlierDetectionJL/OutlierDetection.jl/commits?author=rolling-robot" title="Documentation"><g-emoji class="g-emoji" alias="book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png">üìñ</g-emoji></a></td>
      <td align="center" valign="top" width="14.28%"><a href="https://github.com/tylerjthomas9"><img src="https://avatars.githubusercontent.com/u/36181311?v=4?s=100" width="100px;" alt="Tyler Thomas" style="max-width: 100%;"><br><sub><b>Tyler Thomas</b></sub></a><br><a href="https://github.com/OutlierDetectionJL/OutlierDetection.jl/commits?author=tylerjthomas9" title="Code"><g-emoji class="g-emoji" alias="computer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png">üíª</g-emoji></a></td>
    </tr>
  </tbody>
</table>



<p dir="auto">This project follows the <a href="https://github.com/all-contributors/all-contributors">all-contributors</a> specification. Contributions of any kind welcome!</p>
</article></div>