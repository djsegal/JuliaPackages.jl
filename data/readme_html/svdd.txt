<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-svddjl" class="anchor" aria-hidden="true" href="#svddjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>SVDD.jl</h1>
<p><em>A Julia package for Support Vector Data Description.</em></p>
<p><a href="https://englhardt.github.io/SVDD.jl/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/f07c2e354ad35198b8734533f591ad793422103c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6d61737465722d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-master-blue.svg" style="max-width:100%;"></a>
<a href="https://travis-ci.com/englhardt/SVDD.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/a722e444f99ca7392a64c72cd6d5b4ae8e1979c4/68747470733a2f2f7472617669732d63692e636f6d2f656e676c68617264742f535644442e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/englhardt/SVDD.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/englhardt/SVDD.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/44a3da96acb74a3bf339ac5d9c5191d332ab9b77/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f656e676c68617264742f535644442e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/englhardt/SVDD.jl/badge.svg?branch=master" style="max-width:100%;"></a></p>
<p>This package implements one-class classifiers and based on support vector data description.
The package has been developed as part of a benchmark suite for <a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)" rel="nofollow">active-learning</a> strategies for one-class classification. For more information about this research project, see the <a href="https://www.ipd.kit.edu/ocal/" rel="nofollow">OCAL project</a> website, and the companion paper.</p>
<blockquote>
<p>Holger Trittenbach, Adrian Englhardt, Klemens Böhm, "An Overview and a Benchmark of Active Learning for One-Class Classification" <a href="https://arxiv.org/abs/1808.04759v2" rel="nofollow">arXiv:1808.04759v2</a>, 14 May 2019</p>
</blockquote>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<p>This package works with Julia 1.0 or newer.
This package is not registered yet. Please use the following command to add the package with Pkg3.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>https://github.com/englhardt/SVDD.jl.git<span class="pl-pds">"</span></span>)</pre></div>
<p>The results presented in the arXiv paper base on a previous version of the package and on Julia 0.6.
To reproduce the experiment results from the arXiv paper, use the old package manager (with Pkg.clone) and checkout SVDD.jl at tag <code>v0.1.0</code>.</p>
<h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Overview</h2>
<p><a href="https://en.wikipedia.org/wiki/One-class_classification" rel="nofollow">One-class classifiers</a> learn to identify if objects belong to a specific class, often used for outlier detection.
The package implements several one-class classifiers, and strategies to initialize parameters.
The jupyter notebook in <code>examples</code> gives a jump start on how to use this package.</p>
<p><a target="_blank" rel="noopener noreferrer" href="examples/SVDD_example.jpg"><img src="examples/SVDD_example.jpg" alt="SVDD" style="max-width:100%;"></a></p>
<h3><a id="user-content-classifiers" class="anchor" aria-hidden="true" href="#classifiers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Classifiers</h3>
<p>Currently, the classifiers have been implemented as optimization problems based on <a href="https://github.com/JuliaOpt/JuMP.jl">JuMP</a>.
The package includes:</p>
<ul>
<li>Vanilla Support Vector Data Description (VanillaSVDD) [1]</li>
<li>SVDD with negative examples (SVDDNeg) [1]</li>
<li>Semi-supervised Anomaly Detection (SSAD) [2]</li>
</ul>
<h3><a id="user-content-parameter-initialization" class="anchor" aria-hidden="true" href="#parameter-initialization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Parameter Initialization</h3>
<p>There are two types of parameters to estimate for the classifiers: cost parameters and a kernel function.
The packages includes the following strategies to initialize parameters.</p>
<ul>
<li><em>Gauss Kernel gamma</em>
<ul>
<li>Rule of Scott [3]</li>
<li>Rule of Silverman [4]</li>
<li>Mean criterion [5]</li>
<li>Modified mean criterion [6]</li>
<li>Wang data shifting [7]</li>
<li>Fixed Gamma</li>
</ul>
</li>
<li><em>Cost parameters C</em>
<ul>
<li>Rule of Tax [1]</li>
<li>Binary Search</li>
<li>Fixed C</li>
</ul>
</li>
</ul>
<h3><a id="user-content-conventions" class="anchor" aria-hidden="true" href="#conventions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conventions</h3>
<ul>
<li><em>Classification scores:</em> The classifiers return scores by the following convention:
<ul>
<li>score &gt; 0 for outliers</li>
<li>score &lt;= 0 for inliers</li>
</ul>
</li>
<li><em>Data Format:</em> The data is expected to be in column major order, i.e., first array dimension is the attribute, second is the observation.
<ul>
<li><code>[1 2 3 4; 5 6 7 8]</code> is a 2x4 Array with 2 attributes and 4 observations</li>
</ul>
</li>
</ul>
<h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Authors</h2>
<p>We welcome contributions and bug reports.</p>
<p>This package is developed and maintained by <a href="https://github.com/holtri/">Holger Trittenbach</a> and <a href="https://github.com/englhardt">Adrian Englhardt</a>.</p>
<h2><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>References</h2>
<p>[1] Tax, David MJ, and Robert PW Duin. "Support vector data description." Machine learning 54.1 (2004): 45-66.<br>
[2] Görnitz, Nico, et al. "Toward supervised anomaly detection." Journal of Artificial Intelligence Research 46 (2013): 235-262.<br>
[3] Scott, David W. Multivariate density estimation: theory, practice, and visualization. John Wiley &amp; Sons, 2015.<br>
[4] Silverman, Bernard W. Density estimation for statistics and data analysis. Routledge, 2018.<br>
[5] Chaudhuri, Arin, et al. "The mean and median criteria for kernel bandwidth selection for support vector data description." 2017 IEEE International Conference on Data Mining Workshops (ICDMW). IEEE, 2017.<br>
[6] Liao, Yuwei, et al. "A new bandwidth selection criterion for using SVDD to analyze hyperspectral data." Algorithms and Technologies for Multispectral, Hyperspectral, and Ultraspectral Imagery XXIV. Vol. 10644. International Society for Optics and Photonics, 2018.<br>
[7] Wang, Siqi, et al. "Hyperparameter selection of one-class support vector machine by self-adaptive data shifting." Pattern Recognition 74 (2018): 198-211.</p>
</article></div>