<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-leafareaindex" class="anchor" aria-hidden="true" href="#leafareaindex"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>LeafAreaIndex</h1>
<p dir="auto"><a href="https://travis-ci.org/ETC-UA/LeafAreaIndex.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/2d59d604556c5857bc137cc0d84f5c50ae811a94cda080c8552757d560964b29/68747470733a2f2f7472617669732d63692e6f72672f4554432d55412f4c65616641726561496e6465782e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/ETC-UA/LeafAreaIndex.jl.svg?branch=master" style="max-width: 100%;"></a>
<a href="https://ci.appveyor.com/project/ETCUA/LeafAreaIndex-jl/branch/master" rel="nofollow"><img src="https://camo.githubusercontent.com/3b65f49ee887565f3bc9503d66aa4f7b3c736057069570dd231edae3eee45093/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f4554432d55412f4c65616641726561496e6465782e6a6c3f6272616e63683d6d6173746572267376673d74727565" alt="Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/ETC-UA/LeafAreaIndex.jl?branch=master&amp;svg=true" style="max-width: 100%;"></a></p>
<p dir="auto">Tools to work with <a href="http://en.wikipedia.org/wiki/Hemispherical_photography" rel="nofollow">hemispherical pictures</a> for the determination of <a href="http://en.wikipedia.org/wiki/Leaf_area_index" rel="nofollow">Leaf Area Index (LAI)</a>.</p>
<p dir="auto">View the full documentation on (<a href="https://etc-ua.github.io/LeafAreaIndex.jl" rel="nofollow">https://etc-ua.github.io/LeafAreaIndex.jl</a>).</p>
<h1 dir="auto"><a id="user-content-quick-introduction" class="anchor" aria-hidden="true" href="#quick-introduction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick introduction</h1>
<p dir="auto">Install the package through</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="Pkg.clone(&quot;https://github.com/ETC-UA/LeafAreaIndex.jl&quot;)"><pre class="notranslate"><code>Pkg.clone("https://github.com/ETC-UA/LeafAreaIndex.jl")
</code></pre></div>
<p dir="auto">The basic type used by this package is a PolarImage. You construct a PolarImage from a CameraLens type and an Image (or in general, an AbstractMatrix). Note that for LAI calculations typically only the blue channel of the image is used.</p>
<p dir="auto">You can load the image eg. with the Images package:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using Images
img = imread(&quot;image.jpg&quot;)
imgblue = blue(img) #take the blue channel"><pre class="notranslate"><code>using Images
img = imread("image.jpg")
imgblue = blue(img) #take the blue channel
</code></pre></div>
<p dir="auto">or in case you have the raw image from the camera, we provide a more accurate, dedicated function to extract the pixels from the blue channel (using <code>dcraw</code> under the hood):</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using LeafAreaIndex
imgblue = rawblueread(&quot;image.NEF&quot;)"><pre class="notranslate"><code>using LeafAreaIndex
imgblue = rawblueread("image.NEF")
</code></pre></div>
<p dir="auto">Because the mapping of pixels on the image to coordinates in the scene is dependent on your camera setup, you must construct a configuration object with this information.
A CameraLens type is constructed given an image size, the coordinates of the lens center and the (inverse) projection function. The projection function maps polar distance ρ [in pixels] on the image to the zenith angle θ [in radians] of the scene and is usually not linear. This project function depends on the specific (fish-eye) used and is usually polynomial approximated up to 2nd order as f(ρ/ρmax) = a₁θ + a₂θ² with ρmax the maximum visible radius. More general you can submit a vector <code>A</code> with the polynomial coefficients. The maximum radius ρmax and the lens center depends on the combination of camera together with the lens (and the image size depends obviously on the camera).</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="using LeafAreaIndex
mycameralens = CameraLens( (height, width), (centeri, centerj), ρmax, A)"><pre class="notranslate"><code>using LeafAreaIndex
mycameralens = CameraLens( (height, width), (centeri, centerj), ρmax, A)
</code></pre></div>
<p dir="auto">The basic PolarImage type is then constructed:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="polarimg = PolarImage(imgblue, mycameralens)"><pre class="notranslate"><code>polarimg = PolarImage(imgblue, mycameralens)
</code></pre></div>
<p dir="auto">The first processing step is automatic thresholding (default method Ridler Calvard):</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="thresh = threshold(polarimg)"><pre class="notranslate"><code>thresh = threshold(polarimg)
</code></pre></div>
<p dir="auto">In the second step the (effective) LAI is estimated through the inversion model. The default method assumes an ellipsoidal leave angle distribution and uses a non-linear optimization method.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="LAIe = inverse(polarimg, thresh)"><pre class="notranslate"><code>LAIe = inverse(polarimg, thresh)
</code></pre></div>
<p dir="auto">Finally, the clumping factor can be estimated with the method of Lang Xiang (default with 45ᵒ segments in full view angle):</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="clump = langxiang(polarimg, thresh)"><pre class="notranslate"><code>clump = langxiang(polarimg, thresh)
</code></pre></div>
<p dir="auto">With clumping correction we obtain <code>LAI = LAIe / clump</code>.</p>
<h2 dir="auto"><a id="user-content-further-methods" class="anchor" aria-hidden="true" href="#further-methods"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Further methods</h2>
<p dir="auto">For images taken (always vertically upwards) on a domain with a <em>slope</em> of eg 10ᵒ and sloping downward to the East, you must include this information in your PolarImage with the <code>Slope(inclination, direction)</code> function:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="myslope = SlopeParams(10/180*pi, pi/2)
polarimg = PolarImage(imgblue, mycameralens, myslope)"><pre class="notranslate"><code>myslope = SlopeParams(10/180*pi, pi/2)
polarimg = PolarImage(imgblue, mycameralens, myslope)
</code></pre></div>
<p dir="auto">For downward taken (crop) images, create a <code>mask</code> to cut out the photographer's shoes and use the <code>RedMax()</code> method instead of thresholding to separate soil from (green) plant material</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="mymask = MaskParams(pi/3, -2*pi/3, -pi/3)
polarimg = PolarImage(imgblue, mycameralens, mymask)
LAIe = inverse(polarimg, RedMax())"><pre class="notranslate"><code>mymask = MaskParams(pi/3, -2*pi/3, -pi/3)
polarimg = PolarImage(imgblue, mycameralens, mymask)
LAIe = inverse(polarimg, RedMax())
</code></pre></div>
<p dir="auto">Besides the default Ridler Calvard method, two more automatic <em>thresholding</em>methods Edge Detection and Minimum algorithm can be used:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="thresh  = threshold(polarimg, RidlerCalvard())
thresh2 = threshold(polarimg, EdgeDetection())
thresh3 = threshold(polarimg, MinimumThreshold())"><pre class="notranslate"><code>thresh  = threshold(polarimg, RidlerCalvard())
thresh2 = threshold(polarimg, EdgeDetection())
thresh3 = threshold(polarimg, MinimumThreshold())
</code></pre></div>
<p dir="auto">Further <em>LAI</em> estimation methods for the inversion model are available:
* The <code>EllipsLUT</code> also assumes an ellipsoidal leaf angle distribution, but uses a Lookup Table approach instead of optimization approach.
* The <code>Zenith57</code> method uses a ring around the view angle of 57ᵒ (1 rad) where the ALIA influence is minimal;
* The <code>Miller</code> method integrates several zenith rings assuming a constant leaf angle; and
* The <code>Lang</code> method uses a first order regression on the Miller method.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="LAI  = inverse(polarimg, thresh, EllipsOpt())
LAI2 = inverse(polarimg, thresh, EllipsLUT())
LAI3 = inverse(polarimg, thresh, Zenith57())
LAI4 = inverse(polarimg, thresh, Miller())
LAI5 = inverse(polarimg, thresh, Lang())"><pre class="notranslate"><code>LAI  = inverse(polarimg, thresh, EllipsOpt())
LAI2 = inverse(polarimg, thresh, EllipsLUT())
LAI3 = inverse(polarimg, thresh, Zenith57())
LAI4 = inverse(polarimg, thresh, Miller())
LAI5 = inverse(polarimg, thresh, Lang())
</code></pre></div>
<p dir="auto">For the <em>clumping</em> factor, besides the method from Lang &amp; Xiang, also the (experimental) method from Chen &amp; Chilar is available:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="clump2 = chencihlar(polarimg, thresh, 0, pi/2)"><pre class="notranslate"><code>clump2 = chencihlar(polarimg, thresh, 0, pi/2)
</code></pre></div>
<h2 dir="auto"><a id="user-content-lower-level-methods" class="anchor" aria-hidden="true" href="#lower-level-methods"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Lower level methods</h2>
<p dir="auto">Under the hood several lower level methods are used to access pixels and calculated gapfractions. We suggest to look at the code for their definition and usage.</p>
<p dir="auto">To access the pixels in a particular zenith range, <code>pixels(polarimg, pi/6, pi/3)</code> will return a vector with pixels quickly, sorted by increasing ρ (and then by polar angles ϕ for identical ρ). A shortcut <code>pixels(polarimg)</code> is translated to <code>pixels(polarimg, 0, pi/2)</code>.</p>
<p dir="auto">The <code>segments</code> function can further split these ring pixels in n segments (eg. for clumping calculation). It returns a vector with n elements, each again a vector with the segment pixels.</p>
<p dir="auto">For the <em>gapfraction</em>, we suggest (see online documentation) to use the contact frequencies <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="d852fd18f8adc0680dbcc95e6fdd55fc">$K(\theta_V) = -\ln[T(\theta_v)] \cos\theta_V$</math-renderer> for LAI inversion calculations, with <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="d852fd18f8adc0680dbcc95e6fdd55fc">$T$</math-renderer> the gapfraction and <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="d852fd18f8adc0680dbcc95e6fdd55fc">$\theta_V$</math-renderer> the view angle. The input N determines the number of rings between view angles θ1 and θ2 for a polar image with a certain threshold. The function returns a vector with angle edges of the rings, the weighted average midpoint angle for each ring and the contact frequency for each ring.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="θedges, θmid, K = contactfreqs(polimg, θ1, θ2, N, thresh)"><pre class="notranslate"><code>θedges, θmid, K = contactfreqs(polimg, θ1, θ2, N, thresh)
</code></pre></div>
<p dir="auto">In case of problems or suggestion, don't hesitate to submit an issue through the issue tracker or code suggestions through a pull request.</p>
<h2 dir="auto">
<a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Documentation</h2>
<p dir="auto">View the full documentation on (<a href="https://etc-ua.github.io/LeafAreaIndex.jl" rel="nofollow">https://etc-ua.github.io/LeafAreaIndex.jl</a>).</p>
</article></div>