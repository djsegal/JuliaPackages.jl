<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-leafareaindex" class="anchor" aria-hidden="true" href="#leafareaindex"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>LeafAreaIndex</h1>
<p><a href="https://travis-ci.org/ETC-UA/LeafAreaIndex.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/bf80c5ab8547e6139e78d8f76dad45b9f0444dca/68747470733a2f2f7472617669732d63692e6f72672f4554432d55412f4c65616641726561496e6465782e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/ETC-UA/LeafAreaIndex.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://ci.appveyor.com/project/ETCUA/LeafAreaIndex-jl/branch/master" rel="nofollow"><img src="https://camo.githubusercontent.com/3764f10e49d530adb46e1535503871ea3ec4c597/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f4554432d55412f4c65616641726561496e6465782e6a6c3f6272616e63683d6d6173746572267376673d74727565" alt="Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/ETC-UA/LeafAreaIndex.jl?branch=master&amp;svg=true" style="max-width:100%;"></a></p>
<p>Tools to work with <a href="http://en.wikipedia.org/wiki/Hemispherical_photography" rel="nofollow">hemispherical pictures</a> for the determination of <a href="http://en.wikipedia.org/wiki/Leaf_area_index" rel="nofollow">Leaf Area Index (LAI)</a>.</p>
<p>View the full documentation on (<a href="https://etc-ua.github.io/LeafAreaIndex.jl" rel="nofollow">https://etc-ua.github.io/LeafAreaIndex.jl</a>).</p>
<h1><a id="user-content-quick-introduction" class="anchor" aria-hidden="true" href="#quick-introduction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Quick introduction</h1>
<p>Install the package through</p>
<pre><code>Pkg.clone("https://github.com/ETC-UA/LeafAreaIndex.jl")
</code></pre>
<p>The basic type used by this package is a PolarImage. You construct a PolarImage from a CameraLens type and an Image (or in general, an AbstractMatrix). Note that for LAI calculations typically only the blue channel of the image is used.</p>
<p>You can load the image eg. with the Images package:</p>
<pre><code>using Images
img = imread("image.jpg")
imgblue = blue(img) #take the blue channel
</code></pre>
<p>or in case you have the raw image from the camera, we provide a more accurate, dedicated function to extract the pixels from the blue channel (using <code>dcraw</code> under the hood):</p>
<pre><code>using LeafAreaIndex
imgblue = rawblueread("image.NEF")
</code></pre>
<p>A CameraLens type is constructed given an image size, the coordinates of the lens center and the (inverse) projection function.
(The projection function maps polar distance ρ [in pixels] on the image to the zenith angle θ [in radians] of the scene and is usually not linear.)</p>
<p>The basic PolarImage type is then constructed:</p>
<pre><code>using LeafAreaIndex
mycameralens = CameraLens(height, width, centeri, centerj, funcθρ, funcρtoθ)
polarimg = PolarImage(imgblue, mycameralens)
</code></pre>
<p>The first processing step is automatical thresholding (default method Ridler Calvard):</p>
<pre><code>thresh = threshold(polarimg)
</code></pre>
<p>In the second step LAI is estimated through the inversion model. The default method assumes an ellipsoidal leave angle distribution and uses an optimization method.</p>
<pre><code>LAI = inverse(polarimg, thresh)
</code></pre>
<p>Finally, the clumping factor can be estimated with the method of Lang Xiang with 45ᵒ segments between view angles θ1 and θ2:</p>
<pre><code>clump = langxiang45(polarimg, thresh, 0, pi/2)
</code></pre>
<h2><a id="user-content-further-methods" class="anchor" aria-hidden="true" href="#further-methods"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Further methods</h2>
<p>For images taken (always vertically upwards) on a domain with a <em>slope</em> of eg 10ᵒ and sloping downward to the East, you must include this information in your PolarImage with the <code>Slope(inclination, direction)</code> function:</p>
<pre><code>myslope = Slope(10/180*pi, pi/2)
polarimg = PolarImage(imgblue, mycameralens, myslope)
</code></pre>
<p>For downward taken (crop) images, create a <code>mask</code> to cut out the photographer's shoes and use the <code>RedMax()</code> method instead of thresholding to separate soil from (green) plant material</p>
<pre><code>mymask = Mask(pi/3, -2*pi/3, -pi/3)
polarimg = PolarImage(imgblue, mycameralens, myslope)
LAI = inverse(polarimg, RedMax())
</code></pre>
<p>Besides the default Ridler Calvard method, two more automatic <em>thresholding</em>methods Edge Detection and Minimum algorithm can be used:</p>
<pre><code>thresh  = threshold(polarimg, RidlerCalvard())
thresh2 = threshold(polarimg, EdgeDetection())
thresh3 = threshold(polarimg, MinimumThreshold())
</code></pre>
<p>Further <em>LAI</em> estimation methods for the inversion model are available:
* The <code>EllipsLUT</code> also assumes an ellipsoidal leaf angle distribution, but uses a Lookup Table approach instead of optimization approach.
* The <code>Zenith57</code> method uses a ring around the view angle of 57ᵒ (1 rad) where the ALIA influence is minimal;
* The <code>Miller</code> method integrates several zenith rings assuming a constant leaf angle; and
* The <code>Lang</code> method uses a first order regression on the Miller method.</p>
<pre><code>LAI  = inverse(polarimg, thresh, EllipsOpt())
LAI2 = inverse(polarimg, thresh, EllipsLUT())
LAI3 = inverse(polarimg, thresh, Zenith57())
LAI4 = inverse(polarimg, thresh, Miller())
LAI5 = inverse(polarimg, thresh, Lang())
</code></pre>
<p>For the <em>clumping</em> factor, besides the method from Lang &amp; Xiang, also the method from Chen &amp; Chilar is available:</p>
<pre><code>clump2 = chencihlar(polarimg, thresh, 0, pi/2)
</code></pre>
<h2><a id="user-content-lower-level-methods" class="anchor" aria-hidden="true" href="#lower-level-methods"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Lower level methods</h2>
<p>Under the hood several lower level methods are used to access pixels and calculated gapfractions. We suggest to look at the code for their definition and usage.</p>
<p>To access the pixels in a particular zenith range, <code>pixels(polarimg, pi/6, pi/3)</code> will return a vector with pixels quickly, sorted by increasing ρ (and then by polar angles ϕ for identical ρ). A shortcut <code>pixels(polarimg)</code> is translated to <code>pixels(polarimg, 0, pi/2)</code>.</p>
<p>The <code>segments</code> function can further split these ring pixels in n segments (eg. for clumping calculation). It returns a vector with n elements, each again a vector with the segment pixels.</p>
<p>For the <em>gapfraction</em>, we suggest (see online documentation) to use the contact frequencies $K(\theta_V) = -\ln[T(\theta_v)] \cos\theta_V$ for LAI inversion calculations, with $T$ the gapfraction and $\theta_V$ the view angle. The input N determines the number of rings between view angles θ1 and θ2 for a polimg with a certain treshold. The function returns a vector with angle edges of the rings, the weighted average midpoint angle for each ring and the contact frequency for each ring.</p>
<pre><code>θedges, θmid, K = contactfreqs(polimg, θ1, θ2, N, thresh)
</code></pre>
<p>In case of problems or suggestion, don't hesitate to submit an issue through the issue tracker or code suggestions through a pull request.</p>
<h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Documentation</h2>
<p>View the full documentation on (<a href="https://etc-ua.github.io/LeafAreaIndex.jl" rel="nofollow">https://etc-ua.github.io/LeafAreaIndex.jl</a>).</p>
</article></div>