<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-minfinder" class="anchor" aria-hidden="true" href="#minfinder"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Minfinder</h1>
<p><a href="https://travis-ci.org/Ken-B/MinFinder.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/400d46f2b48541afe3e5f0552135b7b2ef62791d/68747470733a2f2f7472617669732d63692e6f72672f4b656e2d422f4d696e46696e6465722e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/Ken-B/MinFinder.jl.svg?branch=master" style="max-width:100%;"></a></p>
<p>The <a href="www.cs.uoi.gr/~lagaris/papers/MINF.pdf">MinFinder algorithm</a> solves those problems where you need to find all the minima for a differentiable function inside a bounded domain. It launches many local optimizations from a set of random starting points in the search domain, after some preselection of the points and until a stopping criteria is hit. The local searches use the <code>Fminbox</code> method from the <code>Optim.jl</code> package.</p>
<h2><a id="user-content-about" class="anchor" aria-hidden="true" href="#about"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>About</h2>
<p>This package originated from a <a href="https://github.com/JuliaOpt/Optim.jl/pull/73">pull request</a> for the <code>Optim.jl</code> package but now simply extends that package.</p>
<p>I have some ideas for some extra features, but do let me know in the issues if you have more. For example:</p>
<ul>
<li>use low-discrepancy samples for the starting points from the <a href="https://github.com/stevengj/Sobol.jl"><code>Sobol.jl</code></a> package</li>
<li>implement 2 more stopping rules from the MinFinder 2.0 paper, as well as the extra sample checking rule without derivatives.</li>
</ul>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<p>Have a good look at <a href="https://github.com/JuliaOpt/Optim.jl#box-minimization">the <code>Fminbox</code> section of Optim.jl</a>, because you need to pass your function in a Optim.DifferentiableFunction type.</p>
<p>As an example, consider the Six Hump Camel Back function with 6 minima inside [-5, 5]²:</p>
<pre><code>camel_f(x) = 4x[1]^2 - 2.1x[1]^4 + 1/3*x[1]^6 + x[1]*x[2] - 4x[2]^2 + 4x[2]^4

function camel_g!(x, g) #gradient evaluation to pre-allocated array
    g[1] = 8x[1] - 8.4x[1]^3 + 2x[1]^5 + x[2]
    g[2] = x[1] - 8x[2] + 16x[2]^3
    return nothing
end

function camel_fg!(x, g) #function call and gradient combined
    g[1] = 8x[1] - 8.4x[1]^3 + 2x[1]^5 + x[2]
    g[2] = x[1] - 8x[2] + 16x[2]^3
    return 4x[1]^2 - 2.1x[1]^4 + 1/3*x[1]^6 + x[1]*x[2] - 4x[2]^2 + 4x[2]^4
end

df = Optim.DifferentiableFunction(camel_f, camel_g!, camel_fg!)

result = optimize(df, [-5, -5], [5, 5]; show_trace=true)
</code></pre>
<p>The output is of type <code>FminfinderOptimizationResults</code> with following methods defined:</p>
<ul>
<li><code>Optim.minimizer</code>: vector of points (each again a vector) where function reaches a minimum</li>
<li><code>Optim.minimum</code>: vector of function values at those points</li>
<li><code>Optim.converged</code>: whether a local search has converged at least once</li>
<li><code>Optim.lower_bound</code>, <code>Optim.upper_bound</code>, <code>Optim.method</code>, <code>Optim.f_calls</code>, <code>Optim.g_calls</code> : <em>self explanatory</em></li>
</ul>
<p>Additional options are:</p>
<ul>
<li><code>Ninit</code>: initial number of sample points in the search space per iteration (default 20).</li>
<li><code>Nmax</code>: maximum number of sample points in the search space per iteration (default 100 as in the paper, but I usually find 250 more appropriate).</li>
<li><code>enrich</code>: multiplication of sample points N when more than half of sample points failed preselection criteria (default= 1.1).</li>
<li><code>exhaustive</code>: in (0,1). For small values p→0 the algorithm searches the area exhaustively, while for p→1 the algorithm terminates earlier, but perhaps prematurely (default value 0.5).</li>
<li><code>max_algo_steps</code>: maximum number of iterations, each with N points samples and local searches (default 10_000).</li>
<li><code>show_trace</code>: print iteration results (default = true)</li>
<li><code>dist_unique</code>: the results of a local search will be added to the <code>minima</code> list if its location differs less than this threshold from previously found minima. Increase when lots of returned minima correspond to the same physical point (default = <code>sqrt(local_tol)</code>).</li>
<li><code>polish</code>: boolean flag to indicate whether to perform an extra search at the very end for each minima found, to polish off the found minima with extra precision (default = true).</li>
<li><code>distpolish</code>: same as <code>distmin</code> for final polish phase (default <code>sqrt(polish_tol)</code> ).</li>
<li><code>local_xtol</code>: tolerance level used for the local searches, default eps(Type) (or <code>sqrt(eps(T)^(2/3))</code> when <code>polish=true</code>). Similar poslish_ftol and polish_gtol (default <code>eps(Type)^(2/3)</code>, or <code>sqrt(eps(T)^(2/3))</code> when <code>polish=true</code>)</li>
<li><code>polish_xtol</code>: tolerance level of final polish searches (default <code>eps(Type)^(2/3)</code>).</li>
</ul>
</article></div>