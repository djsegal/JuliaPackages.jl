<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-regularizedproblemsjl" class="anchor" aria-hidden="true" href="#regularizedproblemsjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>RegularizedProblems.jl</h1>
<p dir="auto"><a href="https://github.com/JuliaSmoothOptimizers/RegularizedProblems.jl/actions/workflows/ci.yml"><img src="https://github.com/JuliaSmoothOptimizers/RegularizedProblems.jl/actions/workflows/ci.yml/badge.svg" alt="CI" style="max-width: 100%;"></a>
<a href="https://JuliaSmoothOptimizers.github.io/RegularizedProblems.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/488b4d0ade5e1683e5e6fd4e9e5e032f66bb645872789d758251744fe48a896d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d3366353162352e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-latest-3f51b5.svg" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/JuliaSmoothOptimizers/RegularizedProblems.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/6977a11736d0bcde04c7e06f4b72249fb9eac0d3efb1f90a175058f4aea7b6cc/68747470733a2f2f636f6465636f762e696f2f67682f4a756c6961536d6f6f74684f7074696d697a6572732f526567756c6172697a656450726f626c656d732e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d664d6f504b7574394670" alt="codecov" data-canonical-src="https://codecov.io/gh/JuliaSmoothOptimizers/RegularizedProblems.jl/branch/main/graph/badge.svg?token=fMoPKut9Fp" style="max-width: 100%;"></a>
<a href="https://zenodo.org/badge/latestdoi/392158884" rel="nofollow"><img src="https://camo.githubusercontent.com/198e743e7e92506cf429d00306ef3638bd59f1861042b072deed4346f2cb06f0/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3339323135383838342e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/392158884.svg" style="max-width: 100%;"></a></p>
<h2 dir="auto"><a id="user-content-how-to-cite" class="anchor" aria-hidden="true" href="#how-to-cite"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How to cite</h2>
<p dir="auto">If you use RegularizedProblems.jl in your work, please cite using the format given in <a href="CITATION.bib">CITATION.bib</a>.</p>
<h2 dir="auto"><a id="user-content-synopsis" class="anchor" aria-hidden="true" href="#synopsis"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Synopsis</h2>
<p dir="auto"><code>RegularizedProblems</code> is a repository of optimization problems implemented in pure Julia.
Contrary to what the name suggests, the problems are <em>not</em> regularized but they <em>should be</em>.
However, the choice of regularizer is left to the user.</p>
<p dir="auto">The problems concerned by the package have the form</p>
<p align="center" dir="auto">
minimize f(x) + h(x)
</p>
<p dir="auto">where f: ℝⁿ → ℝ has Lipschitz-continuous gradient and h: ℝⁿ → ℝ is lower semi-continuous and proper.
The smooth term f describes the objective to minimize while the role of the regularizer h is to select
a solution with desirable properties: minimum norm, sparsity below a certain level, maximum sparsity, etc.</p>
<p dir="auto">This repository gives access to several f terms.
Regularizers h should be taken from <a href="https://github.com/JuliaFirstOrder/ProximalOperators.jl">ProximalOperators.jl</a>.</p>
<h2 dir="auto"><a id="user-content-how-to-install" class="anchor" aria-hidden="true" href="#how-to-install"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How to Install</h2>
<p dir="auto">Until this package is registered, use</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="pkg&gt; add https://github.com/optimizers/RegularizedProblems.jl"><pre>pkg<span class="pl-k">&gt;</span> add https<span class="pl-k">:</span><span class="pl-k">//</span>github<span class="pl-k">.</span>com<span class="pl-k">/</span>optimizers<span class="pl-k">/</span>RegularizedProblems<span class="pl-k">.</span>jl</pre></div>
<h2 dir="auto"><a id="user-content-what-is-implemented" class="anchor" aria-hidden="true" href="#what-is-implemented"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>What is Implemented?</h2>
<p dir="auto">Please refer to the documentation.</p>
<h2 dir="auto"><a id="user-content-related-software" class="anchor" aria-hidden="true" href="#related-software"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Related Software</h2>
<ul dir="auto">
<li><a href="https://github.com/rjbaraldi/ShiftedProximalOperators">ShiftedProximalOperators.jl</a></li>
<li><a href="https://github.com/UW-AMO/RegularizedOptimization.jl">RegularizedOptimization.jl</a></li>
</ul>
<h2 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<ul dir="auto">
<li>A. Y. Aravkin, R. Baraldi and D. Orban, <em>A Proximal Quasi-Newton Trust-Region Method for Nonsmooth Regularized Optimization</em>, SIAM Journal on Optimization, 32(2), pp.900–929, 2022. Technical report: <a href="https://arxiv.org/abs/2103.15993" rel="nofollow">https://arxiv.org/abs/2103.15993</a></li>
</ul>
<div class="highlight highlight-text-bibtex notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="@article{aravkin-baraldi-orban-2022,
  author = {Aravkin, Aleksandr Y. and Baraldi, Robert and Orban, Dominique},
  title = {A Proximal Quasi-{N}ewton Trust-Region Method for Nonsmooth Regularized Optimization},
  journal = {SIAM Journal on Optimization},
  volume = {32},
  number = {2},
  pages = {900--929},
  year = {2022},
  doi = {10.1137/21M1409536},
  abstract = { We develop a trust-region method for minimizing the sum of a smooth term (f) and a nonsmooth term (h), both of which can be nonconvex. Each iteration of our method minimizes a possibly nonconvex model of (f + h) in a trust region. The model coincides with (f + h) in value and subdifferential at the center. We establish global convergence to a first-order stationary point when (f) satisfies a smoothness condition that holds, in particular, when it has a Lipschitz-continuous gradient, and (h) is proper and lower semicontinuous. The model of (h) is required to be proper, lower semi-continuous and prox-bounded. Under these weak assumptions, we establish a worst-case (O(1/\epsilon^2)) iteration complexity bound that matches the best known complexity bound of standard trust-region methods for smooth optimization. We detail a special instance, named TR-PG, in which we use a limited-memory quasi-Newton model of (f) and compute a step with the proximal gradient method, resulting in a practical proximal quasi-Newton method. We establish similar convergence properties and complexity bound for a quadratic regularization variant, named R2, and provide an interpretation as a proximal gradient method with adaptive step size for nonconvex problems. R2 may also be used to compute steps inside the trust-region method, resulting in an implementation named TR-R2. We describe our Julia implementations and report numerical results on inverse problems from sparse optimization and signal processing. Both TR-PG and TR-R2 exhibit promising performance and compare favorably with two linesearch proximal quasi-Newton methods based on convex models. }
}"><pre><span class="pl-k">@article</span>{<span class="pl-en">aravkin-baraldi-orban-2022</span>,
  <span class="pl-s">author</span> = <span class="pl-s"><span class="pl-pds">{</span>Aravkin, Aleksandr Y. and Baraldi, Robert and Orban, Dominique<span class="pl-pds">}</span></span>,
  <span class="pl-s">title</span> = <span class="pl-s"><span class="pl-pds">{</span>A Proximal Quasi-{N}ewton Trust-Region Method for Nonsmooth Regularized Optimization<span class="pl-pds">}</span></span>,
  <span class="pl-s">journal</span> = <span class="pl-s"><span class="pl-pds">{</span>SIAM Journal on Optimization<span class="pl-pds">}</span></span>,
  <span class="pl-s">volume</span> = <span class="pl-s"><span class="pl-pds">{</span>32<span class="pl-pds">}</span></span>,
  <span class="pl-s">number</span> = <span class="pl-s"><span class="pl-pds">{</span>2<span class="pl-pds">}</span></span>,
  <span class="pl-s">pages</span> = <span class="pl-s"><span class="pl-pds">{</span>900--929<span class="pl-pds">}</span></span>,
  <span class="pl-s">year</span> = <span class="pl-s"><span class="pl-pds">{</span>2022<span class="pl-pds">}</span></span>,
  <span class="pl-s">doi</span> = <span class="pl-s"><span class="pl-pds">{</span>10.1137/21M1409536<span class="pl-pds">}</span></span>,
  abstract = { We develop a trust-region method for minimizing the sum of a smooth term (f) and a nonsmooth term (h), both of which can be nonconvex. Each iteration of our method minimizes a possibly nonconvex model of (f + h) in a trust region. The model coincides with (f + h) in value and subdifferential at the center. We establish global convergence to a first-order stationary point when (f) satisfies a smoothness condition that holds, in particular, when it has a Lipschitz-continuous gradient, and (h) is proper and lower semicontinuous. The model of (h) is required to be proper, lower semi-continuous and prox-bounded. Under these weak assumptions, we establish a worst-case (O(1/\epsilon^2)) iteration complexity bound that matches the best known complexity bound of standard trust-region methods for smooth optimization. We detail a special instance, named TR-PG, in which we use a limited-memory quasi-Newton model of (f) and compute a step with the proximal gradient method, resulting in a practical proximal quasi-Newton method. We establish similar convergence properties and complexity bound for a quadratic regularization variant, named R2, and provide an interpretation as a proximal gradient method with adaptive step size for nonconvex problems. R2 may also be used to compute steps inside the trust-region method, resulting in an implementation named TR-R2. We describe our Julia implementations and report numerical results on inverse problems from sparse optimization and signal processing. Both TR-PG and TR-R2 exhibit promising performance and compare favorably with two linesearch proximal quasi-Newton methods based on convex models. }
}</pre></div>
</article></div>