<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-proximalmethods" class="anchor" aria-hidden="true" href="#proximalmethods"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ProximalMethods</h1>
<p dir="auto">This is a package for non-smooth optimization algorithms based on proximal methods.</p>
<p dir="auto">Provides proximal operator evaluation routines and proximal optimization algorithms, such as (accelerated) proximal gradient methods and alternating direction method of multipliers (ADMM), for non-smooth/non-differentiable objective functions.</p>
<h1 dir="auto"><a id="user-content-proximal-operators" class="anchor" aria-hidden="true" href="#proximal-operators"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Proximal Operators</h1>
<p dir="auto">The following proximal operators are supported</p>
<ul dir="auto">
<li>
<code>soft_thresh(x, λ)</code>: proximal operator of <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$\ell_{1}$</math-renderer>-norm</li>
<li>
<code>block_soft_thresh(x, λ)</code>: proximal operator of <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$\ell_{2}$</math-renderer>-norm</li>
<li>
<code>shrinkage(x, λ)</code>: proximal operator of <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$\ell^{2}_{2}$</math-renderer>-norm (ridge)</li>
<li>
<code>shrinkage(x, λ, A, b)</code>: proximal operator of quadratic function <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$f(x) = c + b^{\prime}x + x^{\prime}Ax$</math-renderer>
</li>
<li>
<code>smooth(x, λ, f, ∇f!, y_prev)</code>: proximal operator of a general smooth objective function <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$f(x)$</math-renderer>
</li>
</ul>
<h1 dir="auto">
<a id="user-content-algorithms" class="anchor" aria-hidden="true" href="#algorithms"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Algorithms</h1>
<p dir="auto">Proximal gradient methods, w/ and w/o acceleration, can be used to optimize an objective function that can be split into two components, one of which is differentiable, i.e.</p>
<p dir="auto"><math-renderer class="js-display-math" style="display: block" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$$
\min f(x) + g(x)
$$</math-renderer></p>
<p dir="auto">where <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$f$</math-renderer> is differentiable and <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$g$</math-renderer> potentially non-smooth.</p>
<p dir="auto">Alternating direction method of multipliers (ADMM), also known as Douglas-Rachford splitting, can be used to optimize an objective function that can be split into two components, where both components can be non-smooth.</p>
<p dir="auto">Linearized ADMM can be used to solve problems of the form</p>
<p dir="auto"><math-renderer class="js-display-math" style="display: block" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$$
\min f(x) + g(Ax)
$$</math-renderer></p>
<p dir="auto">where <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$f$</math-renderer> and <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$g$</math-renderer> are potentially non-smooth. It does so by linearizing the implied augmented Lagrangian function obtained for the problem</p>
<p dir="auto"><math-renderer class="js-display-math" style="display: block" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$$
\min f(x) + g(z) \\
\text{s.t.} ; Ax - z = 0.
$$</math-renderer></p>
<h1 dir="auto">
<a id="user-content-acceleration" class="anchor" aria-hidden="true" href="#acceleration"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Acceleration</h1>
<p dir="auto">For the proximal gradient method there exist so-called accelerated versions, which implies the following update step at iteration <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$k$</math-renderer></p>
<p dir="auto"><math-renderer class="js-display-math" style="display: block" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$$
\begin{aligned}
y^{k+1} &amp; = x^{k} + \omega^{k}(x^{k} - x^{k-1}) \\
x^{k+1} &amp; = \text{prox}_{\lambda^{k} g}(y^{k+1} - \lambda^{k} \nabla f(y^{k+1}))
\end{aligned}
$$</math-renderer></p>
<p dir="auto">Two flavours of this acceleration are implemented</p>
<ul dir="auto">
<li>
<p dir="auto">Simple extrapolation, i.e. <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$\omega^{k} = \frac{k - 1}{k + 2}$</math-renderer> for every iteration <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$k$</math-renderer>.</p>
</li>
<li>
<p dir="auto">Nesterov momentum extrapolation, i.e. <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$\omega^{k} = \frac{\lambda^{k}\theta^{k-1}(1 - \theta^{k-1})}{\lambda^{k-1}\theta^{k} + \lambda^{k}(\theta^{k-1})^{2}}$</math-renderer> where <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="0575b986539c405ec7758a25ac3e9dd1">$\theta^{k}$</math-renderer> is the positive root of the quadratic equation</p>
<p dir="auto">$$
\frac{(\theta^{k})^{2}}{\lambda^{k}} = (1 - \theta^{k})\frac{(\theta^{k-1})^{2}}{\lambda^{k-1}} + m\theta^{k}
$$</p>
</li>
</ul>
<h1 dir="auto">
<a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Documentation</h1>
<p dir="auto"><a href="https://qntwrsm.github.io/ProximalMethods.jl/stable" rel="nofollow"><img src="https://img.shields.io/badge/docs-stable-blue.svg" alt="" style="max-width: 100%;"></a>
<a href="https://qntwrsm.github.io/ProximalMethods.jl/dev" rel="nofollow"><img src="https://img.shields.io/badge/docs-dev-blue.svg" alt="" style="max-width: 100%;"></a></p>
<h1 dir="auto">
<a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h1>
<p dir="auto">To install, in the Julia REPL:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Pkg; Pkg.add(&quot;ProximalMethods&quot;)"><pre><span class="pl-k">using</span> Pkg; Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>ProximalMethods<span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto"><a href="https://github.com/qntwrsm/ProximalMethods.jl/actions/workflows/CI.yml?query=branch%3Amain"><img src="https://github.com/qntwrsm/ProximalMethods.jl/actions/workflows/CI.yml/badge.svg?branch=main" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/qntwrsm/ProximalMethods.jl" rel="nofollow"><img src="https://codecov.io/gh/qntwrsm/ProximalMethods.jl/branch/main/graph/badge.svg" alt="Coverage" style="max-width: 100%;"></a></p>
</article></div>