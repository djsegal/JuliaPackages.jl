<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-discreet" class="anchor" aria-hidden="true" href="#discreet"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Discreet</h1>
<p><a href="https://travis-ci.org/cynddl/Discreet.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/36835df5ea2b76f0d3fc575c523e76732038bc9d/68747470733a2f2f7472617669732d63692e6f72672f63796e64646c2f44697363726565742e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/cynddl/Discreet.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/cynddl/Discreet.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/9363e41f3a116675d0a03e9297d295fae3755ff4/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f63796e64646c2f44697363726565742e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/cynddl/Discreet.jl/badge.svg?branch=master&amp;service=github" style="max-width:100%;"></a>
<a href="http://codecov.io/github/cynddl/Discreet.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/9b3ae91d5b91e29f9fc2d0646b5cb594c82f68e9/687474703a2f2f636f6465636f762e696f2f6769746875622f63796e64646c2f44697363726565742e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/cynddl/Discreet.jl/coverage.svg?branch=master" style="max-width:100%;"></a></p>
<p>Discreet is a small opinionated toolbox to estimate entropy and mutual information from discrete samples. It contains methods to adjust results and correct over- or under-estimations.</p>
<h2><a id="user-content-estimating-entropy" class="anchor" aria-hidden="true" href="#estimating-entropy"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Estimating entropy</h2>
<p>Discreet uses StatsBase's FrequencyWeights and ProbabilityWeights types.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> StatsBase<span class="pl-k">:</span> FrequencyWeights, ProbabilityWeights
<span class="pl-k">using</span> Discreet

dist <span class="pl-k">=</span> <span class="pl-c1">FrequencyWeights</span>([<span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>])
<span class="pl-c1">entropy</span>(dist)  <span class="pl-c"><span class="pl-c">#</span> Naive method: log(6) ≈ 1.792</span>

<span class="pl-c1">entropy</span>(dist; method<span class="pl-k">=</span><span class="pl-c1">:CS</span>)  <span class="pl-c"><span class="pl-c">#</span> Chao-Shen correction: ≈ 3.840</span>

<span class="pl-c1">entropy</span>(dist; method<span class="pl-k">=</span><span class="pl-c1">:Shrink</span>)  <span class="pl-c"><span class="pl-c">#</span> Shrinkage correction: ≈ 1.792</span>

dist <span class="pl-k">=</span> <span class="pl-c1">ProbabilityWeights</span>([<span class="pl-c1">.5</span>, <span class="pl-c1">.5</span>])
<span class="pl-c1">entropy</span>(dist)  <span class="pl-c"><span class="pl-c">#</span> log(2) ≈ 0.693</span></pre></div>
<p>Discreet can also estimate the entropy of a sample:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Discreet

data <span class="pl-k">=</span> [<span class="pl-s"><span class="pl-pds">"</span>tomato<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>apple<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>apple<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>banana<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>tomato<span class="pl-pds">"</span></span>]
<span class="pl-c1">estimate_entropy</span>(data)  <span class="pl-c"><span class="pl-c">#</span> == entropy(FrequencyWeights([2, 2, 1]))</span></pre></div>
<h2><a id="user-content-estimate-mutual-information" class="anchor" aria-hidden="true" href="#estimate-mutual-information"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Estimate mutual information</h2>
<p>Discrete provides similar routines to estimate mutual information.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> Discreet

labels_a <span class="pl-k">=</span> [<span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>]
labels_b <span class="pl-k">=</span> [<span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">1</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>]
<span class="pl-c1">mutual_information</span>(labels_a, labels_b)  <span class="pl-c"><span class="pl-c">#</span> Naive method: ≈ 0.410</span>

<span class="pl-c1">mutual_information</span>(labels_a, labels_b; method<span class="pl-k">=</span><span class="pl-c1">:CS</span>)  <span class="pl-c"><span class="pl-c">#</span> Chao-Shen correction: ≈ 0.148</span>

<span class="pl-c1">mutual_information</span>(labels_a, labels_b; normalize<span class="pl-k">=</span><span class="pl-c1">true</span>)  <span class="pl-c"><span class="pl-c">#</span> Normalized score (between 0 and 1): ≈ 0.382</span></pre></div>
</article></div>