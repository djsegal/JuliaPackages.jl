<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-discreet" class="anchor" aria-hidden="true" href="#discreet"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Discreet</h1>
<p><a href="https://travis-ci.org/cynddl/Discreet.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/e8f9a9b9a138b1e14225fbdd21094341503980fa2b87d65b55ebf02ab94fc69b/68747470733a2f2f7472617669732d63692e6f72672f63796e64646c2f44697363726565742e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/cynddl/Discreet.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/cynddl/Discreet.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/159e4a89cb57e4a00621b5dbad396eaa60c706a1d7a546392cfae7c3df13be7a/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f63796e64646c2f44697363726565742e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/cynddl/Discreet.jl/badge.svg?branch=master&amp;service=github" style="max-width:100%;"></a>
<a href="http://codecov.io/github/cynddl/Discreet.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/1aa2e8436d473556b0e4d047ffb29a7c5509422753e2d4efd30c359fb7897ffd/687474703a2f2f636f6465636f762e696f2f6769746875622f63796e64646c2f44697363726565742e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/cynddl/Discreet.jl/coverage.svg?branch=master" style="max-width:100%;"></a></p>
<p>Discreet is a small opinionated toolbox to estimate entropy and mutual information from discrete samples. It contains methods to adjust results and correct over- or under-estimations.</p>
<h2><a id="user-content-estimating-entropy" class="anchor" aria-hidden="true" href="#estimating-entropy"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Estimating entropy</h2>
<p>Discreet uses StatsBase's FrequencyWeights and ProbabilityWeights types.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using StatsBase: FrequencyWeights, ProbabilityWeights
using Discreet

dist = FrequencyWeights([1, 1, 1, 1, 1, 1])
entropy(dist)  # Naive method: log(6) ≈ 1.792

entropy(dist; method=:CS)  # Chao-Shen correction: ≈ 3.840

entropy(dist; method=:Shrink)  # Shrinkage correction: ≈ 1.792

dist = ProbabilityWeights([.5, .5])
entropy(dist)  # log(2) ≈ 0.693
"><pre><span class="pl-k">using</span> StatsBase<span class="pl-k">:</span> FrequencyWeights, ProbabilityWeights
<span class="pl-k">using</span> Discreet

dist <span class="pl-k">=</span> <span class="pl-c1">FrequencyWeights</span>([<span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>])
<span class="pl-c1">entropy</span>(dist)  <span class="pl-c"><span class="pl-c">#</span> Naive method: log(6) ≈ 1.792</span>

<span class="pl-c1">entropy</span>(dist; method<span class="pl-k">=</span><span class="pl-c1">:CS</span>)  <span class="pl-c"><span class="pl-c">#</span> Chao-Shen correction: ≈ 3.840</span>

<span class="pl-c1">entropy</span>(dist; method<span class="pl-k">=</span><span class="pl-c1">:Shrink</span>)  <span class="pl-c"><span class="pl-c">#</span> Shrinkage correction: ≈ 1.792</span>

dist <span class="pl-k">=</span> <span class="pl-c1">ProbabilityWeights</span>([<span class="pl-c1">.5</span>, <span class="pl-c1">.5</span>])
<span class="pl-c1">entropy</span>(dist)  <span class="pl-c"><span class="pl-c">#</span> log(2) ≈ 0.693</span></pre></div>
<p>Discreet can also estimate the entropy of a sample:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using Discreet

data = [&quot;tomato&quot;, &quot;apple&quot;, &quot;apple&quot;, &quot;banana&quot;, &quot;tomato&quot;]
estimate_entropy(data)  # == entropy(FrequencyWeights([2, 2, 1]))
"><pre><span class="pl-k">using</span> Discreet

data <span class="pl-k">=</span> [<span class="pl-s"><span class="pl-pds">"</span>tomato<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>apple<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>apple<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>banana<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>tomato<span class="pl-pds">"</span></span>]
<span class="pl-c1">estimate_entropy</span>(data)  <span class="pl-c"><span class="pl-c">#</span> == entropy(FrequencyWeights([2, 2, 1]))</span></pre></div>
<h2><a id="user-content-estimate-mutual-information" class="anchor" aria-hidden="true" href="#estimate-mutual-information"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Estimate mutual information</h2>
<p>Discrete provides similar routines to estimate mutual information.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using Discreet

labels_a = [1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]
labels_b = [1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 3, 1, 3, 3, 3, 2, 2]
mutual_information(labels_a, labels_b)  # Naive method: ≈ 0.410

mutual_information(labels_a, labels_b; method=:CS)  # Chao-Shen correction: ≈ 0.148

mutual_information(labels_a, labels_b; normalize=true)  # Normalized score (between 0 and 1): ≈ 0.382
"><pre><span class="pl-k">using</span> Discreet

labels_a <span class="pl-k">=</span> [<span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>]
labels_b <span class="pl-k">=</span> [<span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">1</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>]
<span class="pl-c1">mutual_information</span>(labels_a, labels_b)  <span class="pl-c"><span class="pl-c">#</span> Naive method: ≈ 0.410</span>

<span class="pl-c1">mutual_information</span>(labels_a, labels_b; method<span class="pl-k">=</span><span class="pl-c1">:CS</span>)  <span class="pl-c"><span class="pl-c">#</span> Chao-Shen correction: ≈ 0.148</span>

<span class="pl-c1">mutual_information</span>(labels_a, labels_b; normalize<span class="pl-k">=</span><span class="pl-c1">true</span>)  <span class="pl-c"><span class="pl-c">#</span> Normalized score (between 0 and 1): ≈ 0.382</span></pre></div>
</article></div>