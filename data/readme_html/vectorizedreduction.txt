<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-vectorizedreduction" class="anchor" aria-hidden="true" href="#vectorizedreduction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>VectorizedReduction</h1>
<h2 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using Pkg
Pkg.add(&quot;VectorizedReduction&quot;)"><pre><span class="pl-k">using</span> Pkg
Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>VectorizedReduction<span class="pl-pds">"</span></span>)</pre></div>
<h2 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h2>
<p dir="auto">This library provides "vectorized" (with/without multithreading) versions of the following functions</p>
<ol dir="auto">
<li><code>mapreduce</code> and common derived functions: <code>reduce</code>, <code>sum</code>, <code>prod</code>, <code>minimum</code>, <code>maximum</code>, <code>extrema</code></li>
<li><code>count</code>, <code>any</code>, <code>all</code></li>
<li><code>findmin</code>, <code>findmax</code>, <code>argmin</code>, <code>argmax</code></li>
<li><code>logsumexp</code>, <code>softmax</code>, <code>logsoftmax</code> ("safe" versions: avoid underflow/overflow)</li>
</ol>
<p dir="auto">The naming convention is as follows: a vectorized (without threading) version is prefixed by <code>v</code>, and a vectorized with threading version is prefixed by <code>vt</code>.
There is a single exception to this rule: vectorized (without threading) versions of the functions listed in 1. are prefixed by <code>vv</code> in order to avoid name collisions with LoopVectorization and VectorizedStatistics.</p>
<p dir="auto">This library also provides other, less common, reductions (all of which follow the naming convention above):</p>
<ol dir="auto">
<li><code>mapreducethen</code> : Apply function <code>f</code> to each element of <code>A</code>, reduce the result over the dimensions <code>dims</code> using the binary function <code>op</code>, then apply <code>g</code> to the result</li>
<li>distances: <code>manhattan</code>, <code>euclidean</code>, <code>chebyshe</code>, <code>minkowski</code></li>
<li>norms: <code>norm</code>, treating arbitrary slices via <code>dims</code> keyword</li>
<li>deviances: <code>counteq</code>, <code>countne</code>, <code>meanad</code>, <code>maxad</code>, <code>mse</code>, <code>rmse</code></li>
<li>means: <code>mean</code>, <code>geomean</code>, <code>harmmean</code></li>
<li>entropies: <code>crossentropy</code>, <code>shannonentropy</code>, <code>collisionentropy</code>, <code>minentropy</code>, <code>maxentropy</code>, <code>renyientropy</code></li>
<li>divergences: <code>kldivergence</code>, <code>gkldiv</code>, <code>renyidivergence</code></li>
</ol>
<h2 dir="auto"><a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Motivation</h2>
<p dir="auto">When writing numerical code, one may wish to perform a reduction, perhaps across multiple dimensions, as the most natural means of expressing the relevant mathematical operation.
For readers well-acquainted with LoopVectorization.jl, the thought immediately comes to mind: writing out the loops will inevitably be a large performance gain. Thus, in that neverending pursuit of fast code, we write the loops -- but this produces specific code, tailored to the dimensions of the problem.
Instead, we might have liked to write generic code, parameterizing our function with an index set of dimensions. This package attempts to resolve this perpetual dilemma using metaprogramming. The hope is that the next time one asks the question: is it worthwhile to write the loops (gain performance, lose genericity), or can I make do with the Base implementation? that one can confidently reach for one of the "vectorized" versions provided by this package.</p>
<p dir="auto">Now, before diving into other interesting topics, a few salient comments. Foremost, this package is not intended as a univeral replacement for Base implementations of the same functions. The scope of functions provided by this package is limited to numerical code, and subject to all restrictions imposed by LoopVectorization (the user is encouraged to familiarize themselves with said package).
Moreover, there exist limitations of <code>vfindmin</code> and friends which are not yet resolved (a workaround is provided, but not without a performance cost). That being said, the user may find useful the expanded capabilities of <code>vfindmin</code>/<code>vfindmax</code> which are not yet part of Base (an aspect the author hopes to rectify). The user is encouraged to read the additional commentary below, but it is not strictly necessary.</p>
<h2 dir="auto"><a id="user-content-commentary" class="anchor" aria-hidden="true" href="#commentary"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Commentary</h2>
<h3 dir="auto"><a id="user-content-why-provide-dims-directly-rather-than-as-kwargs-an-optional-performance-enhancement-for-small-arrays" class="anchor" aria-hidden="true" href="#why-provide-dims-directly-rather-than-as-kwargs-an-optional-performance-enhancement-for-small-arrays"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Why provide <code>dims</code> directly, rather than as kwargs? (an optional performance enhancement for small arrays)</h3>
<p dir="auto">To define a multi-dimensional mapreduce, one specifies a index set of dimensions, <code>dims</code> over which the reduction will occur. In Base, one passes <code>dims</code> using keyword arguments, e.g. <code>sum(A, dims=(2,4))</code>. However, this sometimes incurs an overhead of ~20ns. Admittedly, small, and in almost all cases negligible, but, if one wishes to ensure that such costs are avoided, the interface also supports direct calls which provide <code>init</code> and <code>dims</code> as positional arguments.</p>
<h3 dir="auto"><a id="user-content-when-to-consider-replacing-anyall-with-vectorized-versions" class="anchor" aria-hidden="true" href="#when-to-consider-replacing-anyall-with-vectorized-versions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>When to consider replacing any/all with vectorized versions</h3>
<p dir="auto">Assumptions: x is inherently unordered, such that the probablilty of a "success" is independent of the index (i.e. independent of a random permutation of the effective vector over which the reduction occurs).
This is a very reasonable assumption for certain types of data, e.g. Monte Carlo simulations. However, for cases in which there is some inherent order (e.g. a solution to an ODE, or even very simply, <code>cos.(-2π:0.1:2π)</code>), then the analysis below does not hold. If inherent order exists, then the probability of success depends on said ordering -- the caller must then exercise judgment based on where the first success might land (if at all); as this is inevitably problem-specific, I am unable to offer general advice.</p>
<p dir="auto">For inherently unordered data:
Define <code>p</code> as the probability of "success", i.e. the probability of <code>true</code> w.r.t. <code>any</code> and the probability of <code>false</code> w.r.t. <code>all</code>.
The cumulative probability of evaluating all elements, <code>Pr(x ≤ 0)</code> is</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="binomial(n, 0) * p^0 * (1 - p)^(n - 0) # (1 - p)^n"><pre><span class="pl-c1">binomial</span>(n, <span class="pl-c1">0</span>) <span class="pl-k">*</span> p<span class="pl-k">^</span><span class="pl-c1">0</span> <span class="pl-k">*</span> (<span class="pl-c1">1</span> <span class="pl-k">-</span> p)<span class="pl-k">^</span>(n <span class="pl-k">-</span> <span class="pl-c1">0</span>) <span class="pl-c"><span class="pl-c">#</span> (1 - p)^n</span></pre></div>
<p dir="auto">Define a linearized cost model, with <code>t</code> the time required to evaluate one element, and <code>n</code> the length of the vector. Denote <code>t₀</code> as the non-vectorized evaluation time per element, and <code>tᵥ</code> as the vectorized evaluation time per element. A crude estimate for the expected cost of the call is therefore</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="t₀ * n * (1 - p)^n"><pre>t₀ <span class="pl-k">*</span> n <span class="pl-k">*</span> (<span class="pl-c1">1</span> <span class="pl-k">-</span> p)<span class="pl-k">^</span>n</pre></div>
<p dir="auto">Thus, the point at which non-vectorized evaluation is optimal is</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="t₀ * (1 - p)^n &lt; tᵥ"><pre>t₀ <span class="pl-k">*</span> (<span class="pl-c1">1</span> <span class="pl-k">-</span> p)<span class="pl-k">^</span>n <span class="pl-k">&lt;</span> tᵥ</pre></div>
<p dir="auto">Or, rearranging: non-vectorized is optimal when <code>p &gt; 1 - (tᵥ/t₀)^(1/n)</code>. Intuitively, as <code>(tᵥ/t₀)</code> becomes smaller, larger <code>p</code> is needed to make the non-vectorized option optimal.
Holding <code>(tᵥ/t₀)</code> constant, increasing <code>n</code> results in a rapid decrease in the <code>p</code> required for the non-vectorized option to be optimal. Consider the following examples, denoting <code>r = (tᵥ/t₀)</code></p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; p(r, n) = 1 - r^(1/n)
p (generic function with 1 method)

julia&gt; p.(.1, 10 .^ (1:4))
4-element Vector{Float64}:
 0.2056717652757185
 0.02276277904418933
 0.0022999361774467264
 0.0002302320018434667

julia&gt; p.(.01, 10 .^ (1:4))
4-element Vector{Float64}:
 0.36904265551980675
 0.045007413978564004
 0.004594582648473011
 0.0004604109969121861"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-en">p</span>(r, n) <span class="pl-k">=</span> <span class="pl-c1">1</span> <span class="pl-k">-</span> r<span class="pl-k">^</span>(<span class="pl-c1">1</span><span class="pl-k">/</span>n)
p (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">p</span>.(.<span class="pl-c1">1</span>, <span class="pl-c1">10</span> <span class="pl-k">.^</span> (<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">4</span>))
<span class="pl-c1">4</span><span class="pl-k">-</span>element Vector{Float64}<span class="pl-k">:</span>
 <span class="pl-c1">0.2056717652757185</span>
 <span class="pl-c1">0.02276277904418933</span>
 <span class="pl-c1">0.0022999361774467264</span>
 <span class="pl-c1">0.0002302320018434667</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">p</span>.(.<span class="pl-c1">01</span>, <span class="pl-c1">10</span> <span class="pl-k">.^</span> (<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">4</span>))
<span class="pl-c1">4</span><span class="pl-k">-</span>element Vector{Float64}<span class="pl-k">:</span>
 <span class="pl-c1">0.36904265551980675</span>
 <span class="pl-c1">0.045007413978564004</span>
 <span class="pl-c1">0.004594582648473011</span>
 <span class="pl-c1">0.0004604109969121861</span></pre></div>
<p dir="auto">However, due to the current implementation details of Base <code>any</code>/<code>all</code>, early breakout occurs only when the reduction is being carried out across the entire array (i.e. does not occur when reducing over a subset of dimensions). Thus, the current advice is to use <code>vany</code>/<code>vall</code> unless one is reducing over the entire array, and even then, one should consider the <code>p</code> and <code>n</code> for one's problem.</p>
<h2 dir="auto"><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Examples</h2>
<h3 dir="auto"><a id="user-content-simple-examples" class="anchor" aria-hidden="true" href="#simple-examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Simple examples</h3>
<details>
 
<p dir="auto">
</p><p dir="auto">A very simple comparison.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; A = rand(5,5,5,5);

julia&gt; @benchmark mapreduce($abs2, $+, $A, dims=$(1,2,4))
BenchmarkTools.Trial: 10000 samples with 133 evaluations.
 Range (min … max):  661.038 ns … 139.234 μs  ┊ GC (min … max): 0.00% … 99.24%
 Time  (median):     746.880 ns               ┊ GC (median):    0.00%
 Time  (mean ± σ):   798.069 ns ±   1.957 μs  ┊ GC (mean ± σ):  3.46% ±  1.40%

 Memory estimate: 368 bytes, allocs estimate: 8.

julia&gt; @benchmark vvmapreduce($abs2, $+, $A, dims=$(1,2,4))
BenchmarkTools.Trial: 10000 samples with 788 evaluations.
 Range (min … max):  160.538 ns …  29.430 μs  ┊ GC (min … max):  0.00% … 99.11%
 Time  (median):     203.479 ns               ┊ GC (median):     0.00%
 Time  (mean ± σ):   212.916 ns ± 761.848 ns  ┊ GC (mean ± σ):  10.68% ±  2.97%

 Memory estimate: 240 bytes, allocs estimate: 6.

julia&gt; @benchmark extrema($A, dims=$(1,2))
BenchmarkTools.Trial: 10000 samples with 9 evaluations.
 Range (min … max):  2.813 μs …   5.827 μs  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     2.990 μs               ┊ GC (median):    0.00%
 Time  (mean ± σ):   3.039 μs ± 149.676 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%

 Memory estimate: 960 bytes, allocs estimate: 14.

julia&gt; @benchmark vvextrema($A, dims=$(1,2))
BenchmarkTools.Trial: 10000 samples with 202 evaluations.
 Range (min … max):  381.743 ns … 86.288 μs  ┊ GC (min … max):  0.00% … 99.05%
 Time  (median):     689.658 ns              ┊ GC (median):     0.00%
 Time  (mean ± σ):   712.113 ns ±  2.851 μs  ┊ GC (mean ± σ):  13.84% ±  3.43%

 Memory estimate: 1.19 KiB, allocs estimate: 8."><pre>julia<span class="pl-k">&gt;</span> A <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">mapreduce</span>(<span class="pl-k">$</span>abs2, <span class="pl-k">$</span><span class="pl-k">+</span>, <span class="pl-k">$</span>A, dims<span class="pl-k">=</span><span class="pl-k">$</span>(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">4</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">133</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">661.038</span> ns … <span class="pl-c1">139.234</span> μs  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">99.24</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">746.880</span> ns               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">798.069</span> ns ±   <span class="pl-c1">1.957</span> μs  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">3.46</span><span class="pl-k">%</span> ±  <span class="pl-c1">1.40</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">368</span> bytes, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">8.</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">vvmapreduce</span>(<span class="pl-k">$</span>abs2, <span class="pl-k">$</span><span class="pl-k">+</span>, <span class="pl-k">$</span>A, dims<span class="pl-k">=</span><span class="pl-k">$</span>(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">4</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">788</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">160.538</span> ns …  <span class="pl-c1">29.430</span> μs  ┊ GC (min … max)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">99.11</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">203.479</span> ns               ┊ GC (median)<span class="pl-k">:</span>     <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">212.916</span> ns ± <span class="pl-c1">761.848</span> ns  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">10.68</span><span class="pl-k">%</span> ±  <span class="pl-c1">2.97</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">240</span> bytes, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">6.</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">extrema</span>(<span class="pl-k">$</span>A, dims<span class="pl-k">=</span><span class="pl-k">$</span>(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">9</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">2.813</span> μs …   <span class="pl-c1">5.827</span> μs  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">2.990</span> μs               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">3.039</span> μs ± <span class="pl-c1">149.676</span> ns  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> ± <span class="pl-c1">0.00</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">960</span> bytes, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">14.</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">vvextrema</span>(<span class="pl-k">$</span>A, dims<span class="pl-k">=</span><span class="pl-k">$</span>(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">202</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">381.743</span> ns … <span class="pl-c1">86.288</span> μs  ┊ GC (min … max)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">99.05</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">689.658</span> ns              ┊ GC (median)<span class="pl-k">:</span>     <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">712.113</span> ns ±  <span class="pl-c1">2.851</span> μs  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">13.84</span><span class="pl-k">%</span> ±  <span class="pl-c1">3.43</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">1.19</span> KiB, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">8.</span></pre></div>
<p dir="auto"></p>
</details>
<h3 dir="auto"><a id="user-content-varargs-examples" class="anchor" aria-hidden="true" href="#varargs-examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Varargs examples</h3>
<details>
 
<p dir="auto">
</p><p dir="auto">These are somewhat standard fare, but can be quite convenient for expressing
certain Bayesian computations.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; A1, A2, A3, A4 = rand(5,5,5,5), rand(5,5,5,5), rand(5,5,5,5), rand(5,5,5,5);

julia&gt; @benchmark mapreduce($+, $+, $A1, $A2, $A3, $A4, dims=$(1,2,4))
BenchmarkTools.Trial: 10000 samples with 10 evaluations.
 Range (min … max):  1.597 μs …  1.181 ms  ┊ GC (min … max): 0.00% … 97.71%
 Time  (median):     1.867 μs              ┊ GC (median):    0.00%
 Time  (mean ± σ):   2.257 μs ± 14.216 μs  ┊ GC (mean ± σ):  8.56% ±  1.38%

 Memory estimate: 5.66 KiB, allocs estimate: 14.

julia&gt; @benchmark vvmapreduce($+, $+, $A1, $A2, $A3, $A4, dims=$(1,2,4))
BenchmarkTools.Trial: 10000 samples with 203 evaluations.
 Range (min … max):  384.768 ns … 150.041 μs  ┊ GC (min … max): 0.00% … 99.57%
 Time  (median):     437.601 ns               ┊ GC (median):    0.00%
 Time  (mean ± σ):   478.179 ns ±   2.117 μs  ┊ GC (mean ± σ):  7.50% ±  1.72%

 Memory estimate: 304 bytes, allocs estimate: 6.

# And for really strange stuff (e.g. posterior predictive transformations)
julia&gt; @benchmark vvmapreduce((x,y,z) -&gt; ifelse(x*y+z ≥ 1, 1, 0), +, $A1, $A2, $A3)
BenchmarkTools.Trial: 10000 samples with 198 evaluations.
 Range (min … max):  438.126 ns …  5.704 μs  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     439.995 ns              ┊ GC (median):    0.00%
 Time  (mean ± σ):   442.020 ns ± 63.038 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%

 Memory estimate: 0 bytes, allocs estimate: 0.

# using ifelse for just a boolean is quite slow, but the above is just for demonstration
julia&gt; @benchmark vvmapreduce((x,y,z) -&gt; ≥(x*y+z, 1), +, $A1, $A2, $A3)
BenchmarkTools.Trial: 10000 samples with 975 evaluations.
 Range (min … max):  70.558 ns …  2.085 μs  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     70.888 ns              ┊ GC (median):    0.00%
 Time  (mean ± σ):   71.425 ns ± 23.489 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%

 Memory estimate: 0 bytes, allocs estimate: 0.

# What I mean by posterior predictive transformation? Well, one might encounter
# this in Bayesian model checking, which provides a convenient example.
# If one wishes to compute the Pr = ∫∫𝕀(T(yʳᵉᵖ, θ) ≥ T(y, θ))p(yʳᵉᵖ|θ)p(θ|y)dyʳᵉᵖdθ
# Let's imagine that A1 represents T(yʳᵉᵖ, θ) and A2 represents T(y, θ)
# i.e. the test variable samples computed as a functional of the Markov chain (samples of θ)
# Then, Pr is computed as
vvmapreduce(≥, +, A1, A2) / length(A1)
# Or, if only the probability is of interest, and we do not wish to use the functionals
# for any other purpose, we could compute it as:
vvmapreduce((x, y) -&gt; ≥(f(x), f(y)), +, A1, A2) / length(A1)
# where `f` is the functional of interest, e.g.
vvmapreduce((x, y) -&gt; ≥(abs2(x), abs2(y)), +, A1, A2) / length(A1)

# One can also express commonly encountered reductions with ease;
# these will be fused once a post-reduction operator can be specified
# Mean squared error
vvmapreduce((x, y) -&gt; abs2(x - y), +, A1, A2, dims=(2,4)) ./ (size(A1, 2) * size(A1, 4))
# Euclidean distance
(√).(vvmapreduce((x, y) -&gt; abs2(x - y), +, A1, A2, dims=(2,4)))"><pre>julia<span class="pl-k">&gt;</span> A1, A2, A3, A4 <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">mapreduce</span>(<span class="pl-k">$</span><span class="pl-k">+</span>, <span class="pl-k">$</span><span class="pl-k">+</span>, <span class="pl-k">$</span>A1, <span class="pl-k">$</span>A2, <span class="pl-k">$</span>A3, <span class="pl-k">$</span>A4, dims<span class="pl-k">=</span><span class="pl-k">$</span>(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">4</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">10</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">1.597</span> μs …  <span class="pl-c1">1.181</span> ms  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">97.71</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">1.867</span> μs              ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">2.257</span> μs ± <span class="pl-c1">14.216</span> μs  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">8.56</span><span class="pl-k">%</span> ±  <span class="pl-c1">1.38</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">5.66</span> KiB, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">14.</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">vvmapreduce</span>(<span class="pl-k">$</span><span class="pl-k">+</span>, <span class="pl-k">$</span><span class="pl-k">+</span>, <span class="pl-k">$</span>A1, <span class="pl-k">$</span>A2, <span class="pl-k">$</span>A3, <span class="pl-k">$</span>A4, dims<span class="pl-k">=</span><span class="pl-k">$</span>(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">4</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">203</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">384.768</span> ns … <span class="pl-c1">150.041</span> μs  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">99.57</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">437.601</span> ns               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">478.179</span> ns ±   <span class="pl-c1">2.117</span> μs  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">7.50</span><span class="pl-k">%</span> ±  <span class="pl-c1">1.72</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">304</span> bytes, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">6.</span>

<span class="pl-c"><span class="pl-c">#</span> And for really strange stuff (e.g. posterior predictive transformations)</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">vvmapreduce</span>((x,y,z) <span class="pl-k">-&gt;</span> <span class="pl-c1">ifelse</span>(x<span class="pl-k">*</span>y<span class="pl-k">+</span>z <span class="pl-k">≥</span> <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">0</span>), <span class="pl-k">+</span>, <span class="pl-k">$</span>A1, <span class="pl-k">$</span>A2, <span class="pl-k">$</span>A3)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">198</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">438.126</span> ns …  <span class="pl-c1">5.704</span> μs  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">439.995</span> ns              ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">442.020</span> ns ± <span class="pl-c1">63.038</span> ns  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> ± <span class="pl-c1">0.00</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">0.</span>

<span class="pl-c"><span class="pl-c">#</span> using ifelse for just a boolean is quite slow, but the above is just for demonstration</span>
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">vvmapreduce</span>((x,y,z) <span class="pl-k">-&gt;</span> <span class="pl-k">≥</span>(x<span class="pl-k">*</span>y<span class="pl-k">+</span>z, <span class="pl-c1">1</span>), <span class="pl-k">+</span>, <span class="pl-k">$</span>A1, <span class="pl-k">$</span>A2, <span class="pl-k">$</span>A3)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">975</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">70.558</span> ns …  <span class="pl-c1">2.085</span> μs  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">70.888</span> ns              ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">71.425</span> ns ± <span class="pl-c1">23.489</span> ns  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> ± <span class="pl-c1">0.00</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">0.</span>

<span class="pl-c"><span class="pl-c">#</span> What I mean by posterior predictive transformation? Well, one might encounter</span>
<span class="pl-c"><span class="pl-c">#</span> this in Bayesian model checking, which provides a convenient example.</span>
<span class="pl-c"><span class="pl-c">#</span> If one wishes to compute the Pr = ∫∫𝕀(T(yʳᵉᵖ, θ) ≥ T(y, θ))p(yʳᵉᵖ|θ)p(θ|y)dyʳᵉᵖdθ</span>
<span class="pl-c"><span class="pl-c">#</span> Let's imagine that A1 represents T(yʳᵉᵖ, θ) and A2 represents T(y, θ)</span>
<span class="pl-c"><span class="pl-c">#</span> i.e. the test variable samples computed as a functional of the Markov chain (samples of θ)</span>
<span class="pl-c"><span class="pl-c">#</span> Then, Pr is computed as</span>
<span class="pl-c1">vvmapreduce</span>(<span class="pl-k">≥</span>, <span class="pl-k">+</span>, A1, A2) <span class="pl-k">/</span> <span class="pl-c1">length</span>(A1)
<span class="pl-c"><span class="pl-c">#</span> Or, if only the probability is of interest, and we do not wish to use the functionals</span>
<span class="pl-c"><span class="pl-c">#</span> for any other purpose, we could compute it as:</span>
<span class="pl-c1">vvmapreduce</span>((x, y) <span class="pl-k">-&gt;</span> <span class="pl-k">≥</span>(<span class="pl-c1">f</span>(x), <span class="pl-c1">f</span>(y)), <span class="pl-k">+</span>, A1, A2) <span class="pl-k">/</span> <span class="pl-c1">length</span>(A1)
<span class="pl-c"><span class="pl-c">#</span> where `f` is the functional of interest, e.g.</span>
<span class="pl-c1">vvmapreduce</span>((x, y) <span class="pl-k">-&gt;</span> <span class="pl-k">≥</span>(<span class="pl-c1">abs2</span>(x), <span class="pl-c1">abs2</span>(y)), <span class="pl-k">+</span>, A1, A2) <span class="pl-k">/</span> <span class="pl-c1">length</span>(A1)

<span class="pl-c"><span class="pl-c">#</span> One can also express commonly encountered reductions with ease;</span>
<span class="pl-c"><span class="pl-c">#</span> these will be fused once a post-reduction operator can be specified</span>
<span class="pl-c"><span class="pl-c">#</span> Mean squared error</span>
<span class="pl-c1">vvmapreduce</span>((x, y) <span class="pl-k">-&gt;</span> <span class="pl-c1">abs2</span>(x <span class="pl-k">-</span> y), <span class="pl-k">+</span>, A1, A2, dims<span class="pl-k">=</span>(<span class="pl-c1">2</span>,<span class="pl-c1">4</span>)) <span class="pl-k">./</span> (<span class="pl-c1">size</span>(A1, <span class="pl-c1">2</span>) <span class="pl-k">*</span> <span class="pl-c1">size</span>(A1, <span class="pl-c1">4</span>))
<span class="pl-c"><span class="pl-c">#</span> Euclidean distance</span>
(<span class="pl-k">√</span>)<span class="pl-k">.</span>(<span class="pl-c1">vvmapreduce</span>((x, y) <span class="pl-k">-&gt;</span> <span class="pl-c1">abs2</span>(x <span class="pl-k">-</span> y), <span class="pl-k">+</span>, A1, A2, dims<span class="pl-k">=</span>(<span class="pl-c1">2</span>,<span class="pl-c1">4</span>)))</pre></div>
<p dir="auto"></p>
</details>
<h3 dir="auto"><a id="user-content-findminfindmax-examples" class="anchor" aria-hidden="true" href="#findminfindmax-examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>findmin</code>/<code>findmax</code> examples</h3>
<details>
 
<p dir="auto">
</p><p dir="auto">Examples of extended syntax  using <code>vfindmin(f, A; dims)</code>, <code>vfindmin(f, A...; dims)</code>. In the former case, <code>f</code> : ℝ → ℝ; in the latter, <code>f</code> : ℝᴺ → ℝ. Also applies to  <code>vfindmax</code>, <code>vargmin</code>, <code>vargmax</code>.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# Easy to express without the extended syntax, but not efficient.
julia&gt; B1, B2, B3 = rand(5,5,5,5), rand(5,5,5,5), rand(5,5,5,5);

julia&gt; B′ = @. B1 + B2 + B3;

julia&gt; findmax(B′) == vfindmax(+, B1, B2, B3)
true

julia&gt; @benchmark findmin(@. $B1 + $B2 + $B3)
BenchmarkTools.Trial: 10000 samples with 8 evaluations.
 Range (min … max):  3.905 μs … 943.922 μs  ┊ GC (min … max): 0.00% … 94.06%
 Time  (median):     4.011 μs               ┊ GC (median):    0.00%
 Time  (mean ± σ):   4.128 μs ±   9.418 μs  ┊ GC (mean ± σ):  2.15% ±  0.94%

 Memory estimate: 5.11 KiB, allocs estimate: 2.

julia&gt; @benchmark vfindmin(+, $B1, $B2, $B3)
BenchmarkTools.Trial: 10000 samples with 943 evaluations.
 Range (min … max):  100.346 ns … 151.376 ns  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     100.821 ns               ┊ GC (median):    0.00%
 Time  (mean ± σ):   100.866 ns ±   0.651 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%

 Memory estimate: 0 bytes, allocs estimate: 0.

# A multidimensional example

julia&gt; @benchmark findmin((@. abs2($B1) * $B2 + $B3), dims=$(3,4))
BenchmarkTools.Trial: 10000 samples with 7 evaluations.
 Range (min … max):  4.026 μs …  1.132 ms  ┊ GC (min … max): 0.00% … 94.30%
 Time  (median):     4.311 μs              ┊ GC (median):    0.00%
 Time  (mean ± σ):   4.494 μs ± 11.335 μs  ┊ GC (mean ± σ):  2.37% ±  0.94%

 Memory estimate: 6.55 KiB, allocs estimate: 12.

julia&gt; @benchmark vfindmin((x, y, z) -&gt; abs2(x) * y + z, $B1, $B2, $B3, dims=$(3,4))
BenchmarkTools.Trial: 10000 samples with 173 evaluations.
 Range (min … max):  615.145 ns … 27.463 μs  ┊ GC (min … max):  0.00% … 95.61%
 Time  (median):     635.491 ns              ┊ GC (median):     0.00%
 Time  (mean ± σ):   850.233 ns ±  1.487 μs  ┊ GC (mean ± σ):  10.58% ±  5.89%

 Memory estimate: 1.62 KiB, allocs estimate: 9."><pre><span class="pl-c"><span class="pl-c">#</span> Easy to express without the extended syntax, but not efficient.</span>
julia<span class="pl-k">&gt;</span> B1, B2, B3 <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>), <span class="pl-c1">rand</span>(<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>,<span class="pl-c1">5</span>);

julia<span class="pl-k">&gt;</span> B′ <span class="pl-k">=</span> <span class="pl-c1">@.</span> B1 <span class="pl-k">+</span> B2 <span class="pl-k">+</span> B3;

julia<span class="pl-k">&gt;</span> <span class="pl-c1">findmax</span>(B′) <span class="pl-k">==</span> <span class="pl-c1">vfindmax</span>(<span class="pl-k">+</span>, B1, B2, B3)
<span class="pl-c1">true</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">findmin</span>(<span class="pl-c1">@.</span> <span class="pl-k">$</span>B1 <span class="pl-k">+</span> <span class="pl-k">$</span>B2 <span class="pl-k">+</span> <span class="pl-k">$</span>B3)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">8</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">3.905</span> μs … <span class="pl-c1">943.922</span> μs  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">94.06</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">4.011</span> μs               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">4.128</span> μs ±   <span class="pl-c1">9.418</span> μs  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">2.15</span><span class="pl-k">%</span> ±  <span class="pl-c1">0.94</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">5.11</span> KiB, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">2.</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">vfindmin</span>(<span class="pl-k">+</span>, <span class="pl-k">$</span>B1, <span class="pl-k">$</span>B2, <span class="pl-k">$</span>B3)
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">943</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">100.346</span> ns … <span class="pl-c1">151.376</span> ns  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">100.821</span> ns               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">100.866</span> ns ±   <span class="pl-c1">0.651</span> ns  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> ± <span class="pl-c1">0.00</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">0</span> bytes, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">0.</span>

<span class="pl-c"><span class="pl-c">#</span> A multidimensional example</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">findmin</span>((<span class="pl-c1">@.</span> <span class="pl-c1">abs2</span>(<span class="pl-k">$</span>B1) <span class="pl-k">*</span> <span class="pl-k">$</span>B2 <span class="pl-k">+</span> <span class="pl-k">$</span>B3), dims<span class="pl-k">=</span><span class="pl-k">$</span>(<span class="pl-c1">3</span>,<span class="pl-c1">4</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">7</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">4.026</span> μs …  <span class="pl-c1">1.132</span> ms  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">94.30</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">4.311</span> μs              ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">4.494</span> μs ± <span class="pl-c1">11.335</span> μs  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">2.37</span><span class="pl-k">%</span> ±  <span class="pl-c1">0.94</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">6.55</span> KiB, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">12.</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">vfindmin</span>((x, y, z) <span class="pl-k">-&gt;</span> <span class="pl-c1">abs2</span>(x) <span class="pl-k">*</span> y <span class="pl-k">+</span> z, <span class="pl-k">$</span>B1, <span class="pl-k">$</span>B2, <span class="pl-k">$</span>B3, dims<span class="pl-k">=</span><span class="pl-k">$</span>(<span class="pl-c1">3</span>,<span class="pl-c1">4</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">173</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">615.145</span> ns … <span class="pl-c1">27.463</span> μs  ┊ GC (min … max)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">95.61</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">635.491</span> ns              ┊ GC (median)<span class="pl-k">:</span>     <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">850.233</span> ns ±  <span class="pl-c1">1.487</span> μs  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">10.58</span><span class="pl-k">%</span> ±  <span class="pl-c1">5.89</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">1.62</span> KiB, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">9.</span></pre></div>
<p dir="auto"></p>
</details>
<h3 dir="auto"><a id="user-content-mapreducethen-examples" class="anchor" aria-hidden="true" href="#mapreducethen-examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><code>mapreducethen</code> examples</h3>
<details>
 
<p dir="auto">
</p><p dir="auto">Examples of seemingly strange but useful concept: <code>mapreduce(f, op, ...)</code>, then apply <code>g</code> to each element of the result. However, the post-transform <code>g</code> can be fused such that the output array is populated in a single pass, hence, <code>mapreducethen(f, op, g, ...)</code>. It happens that many familiar quantities follow this pattern, as shown below.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="# L₂ norm
julia&gt; A = rand(10,10,10,10);

julia&gt; @benchmark vmapreducethen(abs2, +, √, $A, dims=(2,4))
BenchmarkTools.Trial: 10000 samples with 10 evaluations.
 Range (min … max):  1.634 μs … 620.474 μs  ┊ GC (min … max): 0.00% … 99.00%
 Time  (median):     1.969 μs               ┊ GC (median):    0.00%
 Time  (mean ± σ):   2.040 μs ±   6.188 μs  ┊ GC (mean ± σ):  3.01% ±  0.99%

 Memory estimate: 960 bytes, allocs estimate: 3.

julia&gt; @benchmark .√mapreduce(abs2, +, $A, dims=(2,4))
BenchmarkTools.Trial: 10000 samples with 4 evaluations.
 Range (min … max):  7.462 μs …  13.938 μs  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     7.957 μs               ┊ GC (median):    0.00%
 Time  (mean ± σ):   8.017 μs ± 378.040 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%

 Memory estimate: 2.05 KiB, allocs estimate: 10.

# Euclidean distance
julia&gt; euclidean(x, y; dims=:) = .√mapreduce(abs2 ∘ -, +, x, y, dims=dims);

julia&gt; veuclidean(x, y; dims=:) = vmapreducethen((a, b) -&gt; abs2(a - b), +, √, x, y, dims=dims);

julia&gt; @benchmark veuclidean(A, B, dims=(1,3))
BenchmarkTools.Trial: 10000 samples with 8 evaluations.
 Range (min … max):  3.277 μs …   6.065 μs  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     3.576 μs               ┊ GC (median):    0.00%
 Time  (mean ± σ):   3.602 μs ± 202.787 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%

 Memory estimate: 992 bytes, allocs estimate: 4.

julia&gt; @benchmark euclidean(A, B, dims=(1,3))
BenchmarkTools.Trial: 10000 samples with 1 evaluation.
 Range (min … max):  11.103 μs …  2.024 ms  ┊ GC (min … max): 0.00% … 95.82%
 Time  (median):     13.781 μs              ┊ GC (median):    0.00%
 Time  (mean ± σ):   17.502 μs ± 58.495 μs  ┊ GC (mean ± σ):  9.72% ±  2.90%

 Memory estimate: 80.28 KiB, allocs estimate: 13."><pre><span class="pl-c"><span class="pl-c">#</span> L₂ norm</span>
julia<span class="pl-k">&gt;</span> A <span class="pl-k">=</span> <span class="pl-c1">rand</span>(<span class="pl-c1">10</span>,<span class="pl-c1">10</span>,<span class="pl-c1">10</span>,<span class="pl-c1">10</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">vmapreducethen</span>(abs2, <span class="pl-k">+</span>, <span class="pl-k">√</span>, <span class="pl-k">$</span>A, dims<span class="pl-k">=</span>(<span class="pl-c1">2</span>,<span class="pl-c1">4</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">10</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">1.634</span> μs … <span class="pl-c1">620.474</span> μs  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">99.00</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">1.969</span> μs               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">2.040</span> μs ±   <span class="pl-c1">6.188</span> μs  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">3.01</span><span class="pl-k">%</span> ±  <span class="pl-c1">0.99</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">960</span> bytes, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">3.</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> .<span class="pl-k">√</span><span class="pl-c1">mapreduce</span>(abs2, <span class="pl-k">+</span>, <span class="pl-k">$</span>A, dims<span class="pl-k">=</span>(<span class="pl-c1">2</span>,<span class="pl-c1">4</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">4</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">7.462</span> μs …  <span class="pl-c1">13.938</span> μs  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">7.957</span> μs               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">8.017</span> μs ± <span class="pl-c1">378.040</span> ns  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> ± <span class="pl-c1">0.00</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">2.05</span> KiB, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">10.</span>

<span class="pl-c"><span class="pl-c">#</span> Euclidean distance</span>
julia<span class="pl-k">&gt;</span> <span class="pl-en">euclidean</span>(x, y; dims<span class="pl-k">=</span>:) <span class="pl-k">=</span> .<span class="pl-k">√</span><span class="pl-c1">mapreduce</span>(abs2 <span class="pl-k">∘</span> <span class="pl-k">-</span>, <span class="pl-k">+</span>, x, y, dims<span class="pl-k">=</span>dims);

julia<span class="pl-k">&gt;</span> <span class="pl-en">veuclidean</span>(x, y; dims<span class="pl-k">=</span>:) <span class="pl-k">=</span> <span class="pl-c1">vmapreducethen</span>((a, b) <span class="pl-k">-&gt;</span> <span class="pl-c1">abs2</span>(a <span class="pl-k">-</span> b), <span class="pl-k">+</span>, <span class="pl-k">√</span>, x, y, dims<span class="pl-k">=</span>dims);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">veuclidean</span>(A, B, dims<span class="pl-k">=</span>(<span class="pl-c1">1</span>,<span class="pl-c1">3</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">8</span> evaluations.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">3.277</span> μs …   <span class="pl-c1">6.065</span> μs  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">3.576</span> μs               ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">3.602</span> μs ± <span class="pl-c1">202.787</span> ns  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">0.00</span><span class="pl-k">%</span> ± <span class="pl-c1">0.00</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">992</span> bytes, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">4.</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@benchmark</span> <span class="pl-c1">euclidean</span>(A, B, dims<span class="pl-k">=</span>(<span class="pl-c1">1</span>,<span class="pl-c1">3</span>))
BenchmarkTools<span class="pl-k">.</span>Trial<span class="pl-k">:</span> <span class="pl-c1">10000</span> samples with <span class="pl-c1">1</span> evaluation.
 Range (min … max)<span class="pl-k">:</span>  <span class="pl-c1">11.103</span> μs …  <span class="pl-c1">2.024</span> ms  ┊ GC (min … max)<span class="pl-k">:</span> <span class="pl-c1">0.00</span><span class="pl-k">%</span> … <span class="pl-c1">95.82</span><span class="pl-k">%</span>
 Time  (median)<span class="pl-k">:</span>     <span class="pl-c1">13.781</span> μs              ┊ GC (median)<span class="pl-k">:</span>    <span class="pl-c1">0.00</span><span class="pl-k">%</span>
 Time  (mean ± σ)<span class="pl-k">:</span>   <span class="pl-c1">17.502</span> μs ± <span class="pl-c1">58.495</span> μs  ┊ GC (mean ± σ)<span class="pl-k">:</span>  <span class="pl-c1">9.72</span><span class="pl-k">%</span> ±  <span class="pl-c1">2.90</span><span class="pl-k">%</span>

 Memory estimate<span class="pl-k">:</span> <span class="pl-c1">80.28</span> KiB, allocs estimate<span class="pl-k">:</span> <span class="pl-c1">13.</span></pre></div>
<p dir="auto"></p>
</details>
<h2 dir="auto"><a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Acknowledgments</h2>
<p dir="auto">The original motivation for this work was a vectorized &amp; multithreaded multi-dimensional findmin, taking a variable number of array arguments -- it's a long story, but the similarity between findmin and mapreduce motivated a broad approach. My initial attempt (visible in the /attic) did not deliver all the performance possible -- this was only apparent through comparison to C. Elrod's approach to multidimensional forms in VectorizedStatistics. Having fully appreciated the beauty of branching through @generated functions, I decided to take a tour of some low-hanging fruit -- this package is the result.</p>
<h2 dir="auto"><a id="user-content-future-work" class="anchor" aria-hidden="true" href="#future-work"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Future work</h2>
<ol dir="auto">
<li>✓ post-reduction operators</li>
<li>□ reductions over index subsets within a dimension.</li>
<li>□ actual documentation</li>
</ol>
<h2 dir="auto"><a id="user-content-elsewhere" class="anchor" aria-hidden="true" href="#elsewhere"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Elsewhere</h2>
<ul dir="auto">
<li><a href="https://github.com/chriselrod/LoopVectorization.jl">LoopVectorization.jl</a> back-end for this package.</li>
<li><a href="https://github.com/mcabbott/Tullio.jl">Tullio.jl</a> express any of the reductions using index notation</li>
</ul>
</article></div>