<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-neuralnetdiffeq" class="anchor" aria-hidden="true" href="#neuralnetdiffeq"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>NeuralNetDiffEq</h1>
<p><a href="https://gitter.im/JuliaDiffEq/Lobby?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge" rel="nofollow"><img src="https://camo.githubusercontent.com/063a520f1733d1b53d1e2fdb37b70a8016dd36f6/68747470733a2f2f6261646765732e6769747465722e696d2f4a756c69614469666645712f4c6f6262792e737667" alt="Join the chat at https://gitter.im/JuliaDiffEq/Lobby" data-canonical-src="https://badges.gitter.im/JuliaDiffEq/Lobby.svg" style="max-width:100%;"></a>
<a href="https://travis-ci.org/JuliaDiffEq/NeuralNetDiffEq.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/a77257401cb75961b89520843ea4ef12a676f807/68747470733a2f2f7472617669732d63692e6f72672f4a756c69614469666645712f4e657572616c4e65744469666645712e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/JuliaDiffEq/NeuralNetDiffEq.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://ci.appveyor.com/project/ChrisRackauckas/neuralnetdiffeq-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/cfee5e9f2852c746efab364fc4725331da3751a6/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f7630656f7033303162783130356176343f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/v0eop301bx105av4?svg=true" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/JuliaDiffEq/NeuralNetDiffEq.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/e4781c13792a6c301f7d5ed70ad2a28ed28d4faf/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c69614469666645712f4e657572616c4e65744469666645712e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/JuliaDiffEq/NeuralNetDiffEq.jl/badge.svg?branch=master&amp;service=github" style="max-width:100%;"></a>
<a href="http://codecov.io/github/JuliaDiffEq/NeuralNetDiffEq.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/190ef45a255480c58f6ab85a36c0abe475de5785/687474703a2f2f636f6465636f762e696f2f6769746875622f4a756c69614469666645712f4e657572616c4e65744469666645712e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/JuliaDiffEq/NeuralNetDiffEq.jl/coverage.svg?branch=master" style="max-width:100%;"></a></p>
<p>The repository is for the development of neural network solvers of differential equations.
It utilizes techniques like neural stochastic differential equations to make it
practical to solve high dimensional PDEs of the form:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1814174/63212617-48980480-c0d5-11e9-9fec-0776117464c7.PNG"><img src="https://user-images.githubusercontent.com/1814174/63212617-48980480-c0d5-11e9-9fec-0776117464c7.PNG" alt="" style="max-width:100%;"></a></p>
<p>Additionally it utilizes neural networks as universal function approximators to
solve ODEs. These are techniques of a field becoming known as Scientific Machine
Learning (Scientific ML), encapsulated in a maintained repository.</p>
<h1><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Examples</h1>
<h2><a id="user-content-solving-the-100-dimensional-black-scholes-barenblatt-equation" class="anchor" aria-hidden="true" href="#solving-the-100-dimensional-black-scholes-barenblatt-equation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Solving the 100 dimensional Black-Scholes-Barenblatt Equation</h2>
<p>In this example we will solve a Black-Scholes-Barenblatt equation of 100 dimensions.
The Black-Scholes-Barenblatt equation is a nonlinear extension to the Black-Scholes
equation which models uncertain volatility and interest rates derived from the
Black-Scholes equation. This model results in a nonlinear PDE whose dimension
is the number of assets in the portfolio. The PDE is of the form:</p>
<p><a target="_blank" rel="noopener noreferrer" href=""><img src="" alt="PDEFORM" style="max-width:100%;"></a></p>
<p>To solve it using the <code>TerminalPDEProblem</code>, we write:</p>
<div class="highlight highlight-source-julia"><pre>d <span class="pl-k">=</span> <span class="pl-c1">100</span> <span class="pl-c"><span class="pl-c">#</span> number of dimensions</span>
X0 <span class="pl-k">=</span> <span class="pl-c1">repeat</span>([<span class="pl-c1">1.0</span>f0, <span class="pl-c1">0.5</span>f0], <span class="pl-c1">div</span>(d,<span class="pl-c1">2</span>)) <span class="pl-c"><span class="pl-c">#</span> initial value of stochastic state</span>
tspan <span class="pl-k">=</span> (<span class="pl-c1">0.0</span>f0,<span class="pl-c1">1.0</span>f0)
r <span class="pl-k">=</span> <span class="pl-c1">0.05</span>f0
sigma <span class="pl-k">=</span> <span class="pl-c1">0.4</span>f0
<span class="pl-en">f</span>(X,u,σᵀ∇u,p,t) <span class="pl-k">=</span> r <span class="pl-k">*</span> (u <span class="pl-k">-</span> <span class="pl-c1">sum</span>(X<span class="pl-k">.*</span>σᵀ∇u))
<span class="pl-en">g</span>(X) <span class="pl-k">=</span> <span class="pl-c1">sum</span>(X<span class="pl-k">.^</span><span class="pl-c1">2</span>)
μ<span class="pl-en">_f</span>(X,p,t) <span class="pl-k">=</span> <span class="pl-c1">zero</span>(X) <span class="pl-c"><span class="pl-c">#</span>Vector d x 1</span>
σ<span class="pl-en">_f</span>(X,p,t) <span class="pl-k">=</span> <span class="pl-c1">Diagonal</span>(sigma<span class="pl-k">*</span>X<span class="pl-k">.</span>data) <span class="pl-c"><span class="pl-c">#</span>Matrix d x d</span>
prob <span class="pl-k">=</span> <span class="pl-c1">TerminalPDEProblem</span>(g, f, μ_f, σ_f, X0, tspan)</pre></div>
<p>As described in the API docs, we now need to define our <code>NNPDENS</code> algorithm
by giving it the Flux.jl chains we want it to use for the neural networks.
<code>u0</code> needs to be a <code>d</code> dimensional -&gt; 1 dimensional chain, while <code>σᵀ∇u</code>
needs to be <code>d+1</code> dimensional to <code>d</code> dimensions. Thus we define the following:</p>
<div class="highlight highlight-source-julia"><pre>hls  <span class="pl-k">=</span> <span class="pl-c1">10</span> <span class="pl-k">+</span> d <span class="pl-c"><span class="pl-c">#</span>hide layer size</span>
opt <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">ADAM</span>(<span class="pl-c1">0.001</span>)
u0 <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(d,hls,relu),
                <span class="pl-c1">Dense</span>(hls,hls,relu),
                <span class="pl-c1">Dense</span>(hls,<span class="pl-c1">1</span>))
σᵀ∇u <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(d<span class="pl-k">+</span><span class="pl-c1">1</span>,hls,relu),
                  <span class="pl-c1">Dense</span>(hls,hls,relu),
                  <span class="pl-c1">Dense</span>(hls,hls,relu),
                  <span class="pl-c1">Dense</span>(hls,d))
pdealg <span class="pl-k">=</span> <span class="pl-c1">NNPDENS</span>(u0, σᵀ∇u, opt<span class="pl-k">=</span>opt)</pre></div>
<p>And now we solve the PDE. Here we say we want to solve the underlying neural
SDE using the Euler-Maruyama SDE solver with our chosen <code>dt=0.2</code>, do at most
150 iterations of the optimizer, 100 SDE solves per loss evaluation (for averaging),
and stop if the loss ever goes below <code>1f-6</code>.</p>
<div class="highlight highlight-source-julia"><pre>ans <span class="pl-k">=</span> <span class="pl-c1">solve</span>(prob, pdealg, verbose<span class="pl-k">=</span><span class="pl-c1">true</span>, maxiters<span class="pl-k">=</span><span class="pl-c1">150</span>, trajectories<span class="pl-k">=</span><span class="pl-c1">100</span>,
                            alg<span class="pl-k">=</span><span class="pl-c1">EM</span>(), dt<span class="pl-k">=</span><span class="pl-c1">0.2</span>, pabstol <span class="pl-k">=</span> <span class="pl-c1">1</span>f<span class="pl-k">-</span><span class="pl-c1">6</span>)</pre></div>
<h2><a id="user-content-solving-a-100-dimensional-hamilton-jacobi-bellman-equation" class="anchor" aria-hidden="true" href="#solving-a-100-dimensional-hamilton-jacobi-bellman-equation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Solving a 100 dimensional Hamilton-Jacobi-Bellman Equation</h2>
<p>In this example we will solve a Hamilton-Jacobi-Bellman equation of 100 dimensions.
The Hamilton-Jacobi-Bellman equation is the solution to a stochastic optimal
control problem. Here, we choose to solve the classical Linear Quadratic Gaussian
(LQG) control problem of 100 dimensions, which is governed by the SDE
<code>dX_t = 2sqrt(λ)c_t dt + sqrt(2)dW_t</code> where <code>c_t</code> is a control process. The solution
to the optimal control is given by a PDE of the form:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1814174/63213366-b1817b80-c0d9-11e9-99b2-c8c08b86d2d5.PNG"><img src="https://user-images.githubusercontent.com/1814174/63213366-b1817b80-c0d9-11e9-99b2-c8c08b86d2d5.PNG" alt="HJB" style="max-width:100%;"></a></p>
<p>with terminating condition <code>g(X) = log(0.5f0 + 0.5f0*sum(X.^2))</code>. To solve it
using the <code>TerminalPDEProblem</code>, we write:</p>
<div class="highlight highlight-source-julia"><pre>d <span class="pl-k">=</span> <span class="pl-c1">100</span> <span class="pl-c"><span class="pl-c">#</span> number of dimensions</span>
X0 <span class="pl-k">=</span> <span class="pl-c1">fill</span>(<span class="pl-c1">0.0</span>f0,d) <span class="pl-c"><span class="pl-c">#</span> initial value of stochastic control process</span>
tspan <span class="pl-k">=</span> (<span class="pl-c1">0.0</span>f0, <span class="pl-c1">1.0</span>f0)
λ <span class="pl-k">=</span> <span class="pl-c1">1.0</span>f0

<span class="pl-en">g</span>(X) <span class="pl-k">=</span> <span class="pl-c1">log</span>(<span class="pl-c1">0.5</span>f0 <span class="pl-k">+</span> <span class="pl-c1">0.5</span>f0<span class="pl-k">*</span><span class="pl-c1">sum</span>(X<span class="pl-k">.^</span><span class="pl-c1">2</span>))
<span class="pl-en">f</span>(X,u,σᵀ∇u,p,t) <span class="pl-k">=</span> <span class="pl-k">-</span>λ<span class="pl-k">*</span><span class="pl-c1">sum</span>(σᵀ∇u<span class="pl-k">.^</span><span class="pl-c1">2</span>)
μ<span class="pl-en">_f</span>(X,p,t) <span class="pl-k">=</span> <span class="pl-c1">zero</span>(X)  <span class="pl-c"><span class="pl-c">#</span>Vector d x 1 λ</span>
σ<span class="pl-en">_f</span>(X,p,t) <span class="pl-k">=</span> <span class="pl-c1">Diagonal</span>(<span class="pl-c1">sqrt</span>(<span class="pl-c1">2.0</span>f0)<span class="pl-k">*</span><span class="pl-c1">ones</span>(Float32,d)) <span class="pl-c"><span class="pl-c">#</span>Matrix d x d</span>
prob <span class="pl-k">=</span> <span class="pl-c1">TerminalPDEProblem</span>(g, f, μ_f, σ_f, X0, tspan)</pre></div>
<p>As described in the API docs, we now need to define our <code>NNPDENS</code> algorithm
by giving it the Flux.jl chains we want it to use for the neural networks.
<code>u0</code> needs to be a <code>d</code> dimensional -&gt; 1 dimensional chain, while <code>σᵀ∇u</code>
needs to be <code>d+1</code> dimensional to <code>d</code> dimensions. Thus we define the following:</p>
<div class="highlight highlight-source-julia"><pre>hls <span class="pl-k">=</span> <span class="pl-c1">10</span> <span class="pl-k">+</span> d <span class="pl-c"><span class="pl-c">#</span>hidden layer size</span>
opt <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">ADAM</span>(<span class="pl-c1">0.01</span>)  <span class="pl-c"><span class="pl-c">#</span>optimizer</span>
<span class="pl-c"><span class="pl-c">#</span>sub-neural network approximating solutions at the desired point</span>
u0 <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(d,hls,relu),
                <span class="pl-c1">Dense</span>(hls,hls,relu),
                <span class="pl-c1">Dense</span>(hls,<span class="pl-c1">1</span>))
<span class="pl-c"><span class="pl-c">#</span> sub-neural network approximating the spatial gradients at time point</span>
σᵀ∇u <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(d<span class="pl-k">+</span><span class="pl-c1">1</span>,hls,relu),
                  <span class="pl-c1">Dense</span>(hls,hls,relu),
                  <span class="pl-c1">Dense</span>(hls,hls,relu),
                  <span class="pl-c1">Dense</span>(hls,d))
pdealg <span class="pl-k">=</span> <span class="pl-c1">NNPDENS</span>(u0, σᵀ∇u, opt<span class="pl-k">=</span>opt)</pre></div>
<p>And now we solve the PDE. Here we say we want to solve the underlying neural
SDE using the Euler-Maruyama SDE solver with our chosen <code>dt=0.2</code>, do at most
100 iterations of the optimizer, 100 SDE solves per loss evaluation (for averaging),
and stop if the loss ever goes below <code>1f-2</code>.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">@time</span> ans <span class="pl-k">=</span> <span class="pl-c1">solve</span>(prob, pdealg, verbose<span class="pl-k">=</span><span class="pl-c1">true</span>, maxiters<span class="pl-k">=</span><span class="pl-c1">100</span>, trajectories<span class="pl-k">=</span><span class="pl-c1">100</span>,
                            alg<span class="pl-k">=</span><span class="pl-c1">EM</span>(), dt<span class="pl-k">=</span><span class="pl-c1">0.2</span>, pabstol <span class="pl-k">=</span> <span class="pl-c1">1</span>f<span class="pl-k">-</span><span class="pl-c1">2</span>)
</pre></div>
<h1><a id="user-content-api-documentation" class="anchor" aria-hidden="true" href="#api-documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>API Documentation</h1>
<h2><a id="user-content-solving-high-dimensional-pdes-with-neural-networks" class="anchor" aria-hidden="true" href="#solving-high-dimensional-pdes-with-neural-networks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Solving High Dimensional PDEs with Neural Networks</h2>
<p>To solve high dimensional PDEs, first one should describe the PDE in terms of
the <code>TerminalPDEProblem</code> with constructor:</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">TerminalPDEProblem</span>(g,f,μ_f,σ_f,X0,tspan,p<span class="pl-k">=</span><span class="pl-c1">nothing</span>)</pre></div>
<p>which describes the semilinear parabolic PDE of the form:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1814174/63212617-48980480-c0d5-11e9-9fec-0776117464c7.PNG"><img src="https://user-images.githubusercontent.com/1814174/63212617-48980480-c0d5-11e9-9fec-0776117464c7.PNG" alt="" style="max-width:100%;"></a></p>
<p>with terminating condition <code>u(tspan[2],x) = g(x)</code>. These methods solve the PDE in
reverse, satisfying the terminal equation and giving a point estimate at
<code>u(tspan[1],X0)</code>. The dimensionality of the PDE is determined by the choice
of <code>X0</code>, which is the initial stochastic state.</p>
<p>To solve this PDE problem, there exists two algorithms:</p>
<ul>
<li><code>NNPDENS(u0,σᵀ∇u;opt=Flux.ADAM(0.1))</code>: Uses a neural stochastic differential
equation which is then solved by the methods available in DifferentialEquations.jl
The <code>alg</code> keyword is required for specifying the SDE solver algorithm that
will be used on the internal SDE. All of the other keyword arguments are passed
to the SDE solver.</li>
<li><code>NNPDEHan(u0,σᵀ∇u;opt=Flux.ADAM(0.1))</code>: Uses the stochastic RNN algorithm
<a href="https://www.pnas.org/content/115/34/8505" rel="nofollow">from Han</a>. Only applicable when
<code>μ_f</code> and <code>σ_f</code> result in a non-stiff SDE where low order non-adaptive time
stepping is applicable.</li>
</ul>
<p>Here, <code>u0</code> is a Flux.jl chain with <code>d</code> dimensional input and 1 dimensional output.
For <code>NNPDEHan</code>, <code>σᵀ∇u</code> is an array of <code>M</code> chains with <code>d</code> dimensional input and
<code>d</code> dimensional output, where <code>M</code> is the total number of timesteps. For <code>NNPDENS</code>
it is a <code>d+1</code> dimensional input (where the final value is time) and <code>d</code> dimensional
output. <code>opt</code> is a Flux.jl optimizer.</p>
<p>Each of these methods has a special keyword argument <code>pabstol</code> which specifies
an absolute tolerance on the PDE's solution, and will exit early if the loss
reaches this value. Its defualt value is <code>1f-6</code>.</p>
<h2><a id="user-content-solving-odes-with-neural-networks" class="anchor" aria-hidden="true" href="#solving-odes-with-neural-networks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Solving ODEs with Neural Networks</h2>
<p>For ODEs, <a href="http://docs.juliadiffeq.org/dev/solvers/ode_solve.html#NeuralNetDiffEq.jl-1" rel="nofollow">see the DifferentialEquations.jl documentation</a>
for the <code>nnode(chain,opt=ADAM(0.1))</code> algorithm, which takes in a Flux.jl chain
and optimizer to solve an ODE. This method is not particularly efficient, but
is parallel. It is based on the work of:</p>
<p><a href="https://arxiv.org/pdf/physics/9705023.pdf" rel="nofollow">Lagaris, Isaac E., Aristidis Likas, and Dimitrios I. Fotiadis. "Artificial neural networks for solving ordinary and partial differential equations." IEEE Transactions on Neural Networks 9, no. 5 (1998): 987-1000.</a></p>
<h2><a id="user-content-related-packages" class="anchor" aria-hidden="true" href="#related-packages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Related Packages</h2>
<ul>
<li><a href="https://github.com/MartinuzziFrancesco/ReservoirComputing.jl">ReservoirComputing.jl</a> has an implementation of the <a href="https://arxiv.org/pdf/1710.07313.pdf" rel="nofollow">Echo State Network method</a> for learning the attractor properties of a chaotic system.</li>
</ul>
</article></div>