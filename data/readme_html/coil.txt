<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-coiljl" class="anchor" aria-hidden="true" href="#coiljl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Coil.jl</h1>
<blockquote>
<p dir="auto">An experimental package to lower and execute Julia tensor operations to the IREE compiler stack using MLIR.</p>
</blockquote>
<p dir="auto">Coil exports only one function: <code>Coil.compile(f)</code> which returns a function which leverages <a href="https://mlir.llvm.org" rel="nofollow">MLIR</a> and the <a href="https://github.com/iree-org/iree">IREE</a> compiler stack to produce a (hopefully) faster version of <code>f</code>. Goals are the following:</p>
<ul dir="auto">
<li>Perform whole model analysis and optimizations to fuse and re-order operations across function calls.</li>
<li>Fold model hyperparameters by unrolling loops, control flow, etc...</li>
<li>Evaluate on different hardware accelerators using the <a href="https://github.com/iree-org/iree">IREE</a> runtime.</li>
</ul>
<blockquote>
<p dir="auto"><span class="color-fg-accent"><svg class="octicon octicon-info mr-2" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</span>
Note that Coil currently does not meet any of those goals and is also a way for me to learn about MLIR and IREE.</p>
</blockquote>
<h2 dir="auto"><a id="user-content-example-usage" class="anchor" aria-hidden="true" href="#example-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example usage</h2>
<p dir="auto"><code>Coil.compile</code> <em>should</em> return an equivalent and hopefully faster function. Note that like Julia, the function will compile when its first called.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Coil, Flux

julia&gt; dense = Dense(3, 6, relu)
Dense(3 =&gt; 6, relu)  # 24 parameters

julia&gt; compiled_dense = Coil.compile(dense)
#23 (generic function with 1 method)

julia&gt; x = randn(Float32,3,1);

julia&gt; compiled_dense(x)
2.7212882f0

julia&gt; compiled_dense(x)
2.7212882f0

julia&gt; dense(x)
2.7212882f0"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Coil, Flux

julia<span class="pl-k">&gt;</span> dense <span class="pl-k">=</span> <span class="pl-c1">Dense</span>(<span class="pl-c1">3</span>, <span class="pl-c1">6</span>, relu)
<span class="pl-c1">Dense</span>(<span class="pl-c1">3</span> <span class="pl-k">=&gt;</span> <span class="pl-c1">6</span>, relu)  <span class="pl-c"><span class="pl-c">#</span> 24 parameters</span>

julia<span class="pl-k">&gt;</span> compiled_dense <span class="pl-k">=</span> Coil<span class="pl-k">.</span><span class="pl-c1">compile</span>(dense)
<span class="pl-c"><span class="pl-c">#</span>23 (generic function with 1 method)</span>

julia<span class="pl-k">&gt;</span> x <span class="pl-k">=</span> <span class="pl-c1">randn</span>(Float32,<span class="pl-c1">3</span>,<span class="pl-c1">1</span>);

julia<span class="pl-k">&gt;</span> <span class="pl-c1">compiled_dense</span>(x)
<span class="pl-c1">2.7212882f0</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">compiled_dense</span>(x)
<span class="pl-c1">2.7212882f0</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">dense</span>(x)
<span class="pl-c1">2.7212882f0</span></pre></div>
<p dir="auto">Other niceties include the <code>@code_mlir</code> and <code>@code_linalg</code> macros.</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; using Coil

julia&gt; f(x) = sum(exp, x)
f (generic function with 1 method)

julia&gt; @code_mlir f(Float32[1., 2., 3.])
MModule:
module {
  func.func @f(%arg0: tensor&lt;3xf32&gt;) -&gt; f32 {
    %cst = arith.constant dense&lt;0.000000e+00&gt; : tensor&lt;f32&gt;
    %reduced = linalg.reduce ins(%arg0 : tensor&lt;3xf32&gt;) outs(%cst : tensor&lt;f32&gt;) dimensions = [0]
      (%in: f32, %init: f32) {
        %1 = math.exp %in : f32
        %2 = arith.addf %1, %init : f32
        linalg.yield %2 : f32
      }
    %c0 = arith.constant 0 : index
    %0 = mhlo.reshape %reduced : (tensor&lt;f32&gt;) -&gt; tensor&lt;1xf32&gt;
    %extracted = tensor.extract %0[%c0] : tensor&lt;1xf32&gt;
    return %extracted : f32
  }
}"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Coil

julia<span class="pl-k">&gt;</span> <span class="pl-en">f</span>(x) <span class="pl-k">=</span> <span class="pl-c1">sum</span>(exp, x)
f (generic <span class="pl-k">function</span> with <span class="pl-c1">1</span> method)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@code_mlir</span> <span class="pl-c1">f</span>(Float32[<span class="pl-c1">1.</span>, <span class="pl-c1">2.</span>, <span class="pl-c1">3.</span>])
MModule<span class="pl-k">:</span>
<span class="pl-k">module</span> {
  func<span class="pl-k">.</span>func <span class="pl-c1">@f</span>(<span class="pl-k">%</span>arg0<span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">3</span>xf32<span class="pl-k">&gt;</span>) <span class="pl-k">-&gt;</span> f32 {
    <span class="pl-k">%</span>cst <span class="pl-k">=</span> arith<span class="pl-k">.</span>constant dense<span class="pl-k">&lt;</span><span class="pl-c1">0.000000e+00</span><span class="pl-k">&gt;</span> <span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span>f32<span class="pl-k">&gt;</span>
    <span class="pl-k">%</span>reduced <span class="pl-k">=</span> linalg<span class="pl-k">.</span>reduce <span class="pl-c1">ins</span>(<span class="pl-k">%</span>arg0 <span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">3</span>xf32<span class="pl-k">&gt;</span>) <span class="pl-c1">outs</span>(<span class="pl-k">%</span>cst <span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span>f32<span class="pl-k">&gt;</span>) dimensions <span class="pl-k">=</span> [<span class="pl-c1">0</span>]
      (<span class="pl-k">%</span>in<span class="pl-k">:</span> f32, <span class="pl-k">%</span>init<span class="pl-k">:</span> f32) {
        <span class="pl-k">%</span><span class="pl-c1">1</span> <span class="pl-k">=</span> math<span class="pl-k">.</span>exp <span class="pl-k">%</span>in <span class="pl-k">:</span> f32
        <span class="pl-k">%</span><span class="pl-c1">2</span> <span class="pl-k">=</span> arith<span class="pl-k">.</span>addf <span class="pl-k">%</span><span class="pl-c1">1</span>, <span class="pl-k">%</span>init <span class="pl-k">:</span> f32
        linalg<span class="pl-k">.</span>yield <span class="pl-k">%</span><span class="pl-c1">2</span> <span class="pl-k">:</span> f32
      }
    <span class="pl-k">%</span>c0 <span class="pl-k">=</span> arith<span class="pl-k">.</span>constant <span class="pl-c1">0</span> <span class="pl-k">:</span> index
    <span class="pl-k">%</span><span class="pl-c1">0</span> <span class="pl-k">=</span> mhlo<span class="pl-k">.</span>reshape <span class="pl-k">%</span>reduced <span class="pl-k">:</span> (tensor<span class="pl-k">&lt;</span>f32<span class="pl-k">&gt;</span>) <span class="pl-k">-&gt;</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">1</span>xf32<span class="pl-k">&gt;</span>
    <span class="pl-k">%</span>extracted <span class="pl-k">=</span> tensor<span class="pl-k">.</span>extract <span class="pl-k">%</span><span class="pl-c1">0</span>[<span class="pl-k">%</span>c0] <span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">1</span>xf32<span class="pl-k">&gt;</span>
    <span class="pl-k">return</span> <span class="pl-k">%</span>extracted <span class="pl-k">:</span> f32
  }
}</pre></div>
<h2 dir="auto"><a id="user-content-tracing" class="anchor" aria-hidden="true" href="#tracing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Tracing</h2>
<p dir="auto">To trace functions, Coil leverages <a href="https://github.com/dfdx/Umlaut.jl">Umlaut.jl</a> which converts functions to linearized tapes. It then replaces lowerable calls from this tape to MLIR operations. Since not all Julia
calls can be replaced to MLIR operation (struct code, io, etc...), the transformation produce a new
tape where only tensor and arithmetic operations are lifted to MLIR dialects.</p>
<p dir="auto">Consider this input tape of a <code>Flux.Dense</code> layer with bias and a relu activation:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="julia&gt; import Coil.Tracing

julia&gt; dense = Dense(3, 6, relu)
Dense(3 =&gt; 6, relu)  # 24 parameters

julia&gt; x = randn(Float32,3,1);

julia&gt; _, tape = Tracing.trace(dense, x; ctx=Tracing.Context(dense));

julia&gt; tape
inp %1::Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}
  inp %2::Matrix{Float32}
  const %3 = fast_act::typeof(NNlib.fast_act)
  %4 = getproperty(%1, :σ)::typeof(relu) 
  const %5 = nothing::Nothing
  const %6 = +::typeof(+)
  %7 = getproperty(%1, :weight)::Matrix{Float32} 
  %8 = *(%7, %2)::Matrix{Float32} 
  %9 = getproperty(%1, :bias)::Vector{Float32} 
  %10 = broadcasted(%6, %8, %9)::Broadcasted{} 
  %11 = broadcasted(%4, %10)::Broadcasted{} 
  %12 = materialize(%11)::Matrix{Float32} 

julia&gt; Tracing.compile_tape(tape, x; verbose=true)
[...]
Tape{Coil.Tracing.Context}
  inp %1::Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}
  inp %2::Matrix{Float32}
  %3 = getproperty(%1, :weight)::Matrix{Float32} 
  %4 = getproperty(%1, :bias)::Vector{Float32} 
  %5 = Call(#= 3 =&gt; 1 =#)(%3, %2, %4)::Matrix{Float32} "><pre class="notranslate"><code>julia&gt; import Coil.Tracing

julia&gt; dense = Dense(3, 6, relu)
Dense(3 =&gt; 6, relu)  # 24 parameters

julia&gt; x = randn(Float32,3,1);

julia&gt; _, tape = Tracing.trace(dense, x; ctx=Tracing.Context(dense));

julia&gt; tape
inp %1::Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}
  inp %2::Matrix{Float32}
  const %3 = fast_act::typeof(NNlib.fast_act)
  %4 = getproperty(%1, :σ)::typeof(relu) 
  const %5 = nothing::Nothing
  const %6 = +::typeof(+)
  %7 = getproperty(%1, :weight)::Matrix{Float32} 
  %8 = *(%7, %2)::Matrix{Float32} 
  %9 = getproperty(%1, :bias)::Vector{Float32} 
  %10 = broadcasted(%6, %8, %9)::Broadcasted{} 
  %11 = broadcasted(%4, %10)::Broadcasted{} 
  %12 = materialize(%11)::Matrix{Float32} 

julia&gt; Tracing.compile_tape(tape, x; verbose=true)
[...]
Tape{Coil.Tracing.Context}
  inp %1::Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}
  inp %2::Matrix{Float32}
  %3 = getproperty(%1, :weight)::Matrix{Float32} 
  %4 = getproperty(%1, :bias)::Vector{Float32} 
  %5 = Call(#= 3 =&gt; 1 =#)(%3, %2, %4)::Matrix{Float32} 
</code></pre></div>
<p dir="auto">where the <code>Call</code> struct calls into the following generated MLIR function:</p>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="julia&gt; Coil.@code_mlir dense(x)
MModule:
module {
  func.func @Dense(%arg0: tensor&lt;6x3xf32&gt;, %arg1: tensor&lt;3x1xf32&gt;, %arg2: tensor&lt;6xf32&gt;) -&gt; tensor&lt;6x1xf32&gt; {
    %0 = &quot;mhlo.dot&quot;(%arg0, %arg1) : (tensor&lt;6x3xf32&gt;, tensor&lt;3x1xf32&gt;) -&gt; tensor&lt;6x1xf32&gt;
    %1 = &quot;mhlo.broadcast_in_dim&quot;(%arg2) {broadcast_dimensions = dense&lt;0&gt; : tensor&lt;1xi64&gt;} : (tensor&lt;6xf32&gt;) -&gt; tensor&lt;6x1xf32&gt;
    %2 = mhlo.add %0, %1 : tensor&lt;6x1xf32&gt;
    %3 = tensor.empty() : tensor&lt;6x1xf32&gt;
    %cst = arith.constant dense&lt;0.000000e+00&gt; : tensor&lt;6x1xf32&gt;
    %3 = arith.maxf %2, %cst : tensor&lt;6x1xf32&gt;
    return %3 : tensor&lt;6x1xf32&gt;
  }
}"><pre>julia<span class="pl-k">&gt;</span> Coil<span class="pl-k">.</span><span class="pl-c1">@code_mlir</span> <span class="pl-c1">dense</span>(x)
MModule<span class="pl-k">:</span>
<span class="pl-k">module</span> {
  func<span class="pl-k">.</span>func <span class="pl-c1">@Dense</span>(<span class="pl-k">%</span>arg0<span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>x3xf32<span class="pl-k">&gt;</span>, <span class="pl-k">%</span>arg1<span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">3</span>x1xf32<span class="pl-k">&gt;</span>, <span class="pl-k">%</span>arg2<span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>xf32<span class="pl-k">&gt;</span>) <span class="pl-k">-&gt;</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>x1xf32<span class="pl-k">&gt;</span> {
    <span class="pl-k">%</span><span class="pl-c1">0</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>mhlo.dot<span class="pl-pds">"</span></span>(<span class="pl-k">%</span>arg0, <span class="pl-k">%</span>arg1) <span class="pl-k">:</span> (tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>x3xf32<span class="pl-k">&gt;</span>, tensor<span class="pl-k">&lt;</span><span class="pl-c1">3</span>x1xf32<span class="pl-k">&gt;</span>) <span class="pl-k">-&gt;</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>x1xf32<span class="pl-k">&gt;</span>
    <span class="pl-k">%</span><span class="pl-c1">1</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>mhlo.broadcast_in_dim<span class="pl-pds">"</span></span>(<span class="pl-k">%</span>arg2) {broadcast_dimensions <span class="pl-k">=</span> dense<span class="pl-k">&lt;</span><span class="pl-c1">0</span><span class="pl-k">&gt;</span> <span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">1</span>xi64<span class="pl-k">&gt;</span>} <span class="pl-k">:</span> (tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>xf32<span class="pl-k">&gt;</span>) <span class="pl-k">-&gt;</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>x1xf32<span class="pl-k">&gt;</span>
    <span class="pl-k">%</span><span class="pl-c1">2</span> <span class="pl-k">=</span> mhlo<span class="pl-k">.</span>add <span class="pl-k">%</span><span class="pl-c1">0</span>, <span class="pl-k">%</span><span class="pl-c1">1</span> <span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>x1xf32<span class="pl-k">&gt;</span>
    <span class="pl-k">%</span><span class="pl-c1">3</span> <span class="pl-k">=</span> tensor<span class="pl-k">.</span><span class="pl-c1">empty</span>() <span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>x1xf32<span class="pl-k">&gt;</span>
    <span class="pl-k">%</span>cst <span class="pl-k">=</span> arith<span class="pl-k">.</span>constant dense<span class="pl-k">&lt;</span><span class="pl-c1">0.000000e+00</span><span class="pl-k">&gt;</span> <span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>x1xf32<span class="pl-k">&gt;</span>
    <span class="pl-k">%</span><span class="pl-c1">3</span> <span class="pl-k">=</span> arith<span class="pl-k">.</span>maxf <span class="pl-k">%</span><span class="pl-c1">2</span>, <span class="pl-k">%</span>cst <span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>x1xf32<span class="pl-k">&gt;</span>
    <span class="pl-k">return</span> <span class="pl-k">%</span><span class="pl-c1">3</span> <span class="pl-k">:</span> tensor<span class="pl-k">&lt;</span><span class="pl-c1">6</span>x1xf32<span class="pl-k">&gt;</span>
  }
}</pre></div>
<h3 dir="auto"><a id="user-content-control-flow" class="anchor" aria-hidden="true" href="#control-flow"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Control flow</h3>
<p dir="auto">Due to its use of <a href="https://github.com/dfdx/Umlaut.jl">Umlaut.jl</a>, all control flow from the input function is taken as is for the first given arguments. This means that loops and conditions are unrolled when applied to the linear tape.</p>
<h2 dir="auto"><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Building</h2>
<p dir="auto">To build <a href="https://github.com/iree-org/iree">IREE</a> to be used as a shared library callable from Julia, you need to use a <a href="https://github.com/Pangoraw/iree/tree/build_coil">custom fork</a>:</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Pangoraw/iree
cd iree
git checkout build_coil2
git submodule update --init
cmake -GNinja -B ../iree-build/ -S . \
    -DCMAKE_BUILD_TYPE=RelWithDebInfo \
    -DIREE_ENABLE_ASSERTIONS=ON \
    -DCMAKE_C_COMPILER=clang \
    -DCMAKE_CXX_COMPILER=clang++ \
    -DIREE_HAL_DRIVER_VULKAN=on \
    -DIREE_TARGET_BACKEND_VULKAN_SPIRV=on \
    -DIREE_ENABLE_LLD=ON
cmake --build ../iree-build --target iree_runtime_runtime_shared"><pre>git clone https://github.com/Pangoraw/iree
<span class="pl-c1">cd</span> iree
git checkout build_coil2
git submodule update --init
cmake -GNinja -B ../iree-build/ -S <span class="pl-c1">.</span> \
    -DCMAKE_BUILD_TYPE=RelWithDebInfo \
    -DIREE_ENABLE_ASSERTIONS=ON \
    -DCMAKE_C_COMPILER=clang \
    -DCMAKE_CXX_COMPILER=clang++ \
    -DIREE_HAL_DRIVER_VULKAN=on \
    -DIREE_TARGET_BACKEND_VULKAN_SPIRV=on \
    -DIREE_ENABLE_LLD=ON
cmake --build ../iree-build --target iree_runtime_runtime_shared</pre></div>
<p dir="auto">This will build the runtime library in the <code>iree-build/</code> folder. The runtime library (<code>lib_runtime_shared_shared</code>) contains the bytecode interpreter and hardware drivers to run IREE programs.</p>
<p dir="auto">The compiler library (<code>libIREECompiler</code>) containing MLIR and IREE specific passes is downloaded using artifacts from <a href="https://github.com/openxla/iree/releases">the official releases</a> (Linux x86_64 glibc only) when the package is instantiated.</p>
<p dir="auto">Later, these libraries will be provided as _jll packages built using <a href="https://binarybuilder.org" rel="nofollow">Binary Builder</a>.</p>
<h2 dir="auto"><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Dependencies</h2>
<p dir="auto">This package is tested only on the Julia 1.9 release, therefore a special version of <a href="https://github.com/JuliaCompilerPlugins/CompilerPluginTools.jl">CompilerPluginTools.jl</a> should be installed (see <a href="https://github.com/JuliaCompilerPlugins/CompilerPluginTools.jl/pull/9" data-hovercard-type="pull_request" data-hovercard-url="/JuliaCompilerPlugins/CompilerPluginTools.jl/pull/9/hovercard">CompilerPluginTools.jl#9</a>):</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="(Coil) pkg&gt; add https://github.com/JuliaCompilerPlugins/CompilerPluginTools.jl#roger/fix-1.9"><pre class="notranslate"><code>(Coil) pkg&gt; add https://github.com/JuliaCompilerPlugins/CompilerPluginTools.jl#roger/fix-1.9
</code></pre></div>
<h2 dir="auto"><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>References</h2>
<ul dir="auto">
<li><a href="https://github.com/FluxML/ONNX.jl">ONNX.jl</a> - Coil takes a very similar approach to ONNX.jl but lowers down to MLIR modules instead of ONNX operations.</li>
<li><a href="https://github.com/JuliaTPU/XLA.jl">XLA.jl</a> - XLA lowers from Julia IR down to XLA HLO and can execute to TPU. Interestingly, the tensor shape inference is embedded in Julia's type system whereas Coil uses the runtime values collected during tracing.</li>
</ul>
</article></div>