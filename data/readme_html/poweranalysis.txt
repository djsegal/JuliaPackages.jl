<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-poweranalysisjl" class="anchor" aria-hidden="true" href="#poweranalysisjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>PowerAnalysis.jl</h1>
<p>Tools for analyzing the power of proposed statistical designs.</p>
<h1><a id="user-content-core-concepts" class="anchor" aria-hidden="true" href="#core-concepts"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Core Concepts</h1>
<p>The PowerAnalysis package exports several core functions:</p>
<ul>
<li><code>power</code>: Compute the power of a design given a proposed sample size and
effect size</li>
<li><code>effect_size</code>: Compute the smallest measurable effect size given a proposed
sample size and the desired level of power</li>
<li><code>sample_size</code>: Compute the smallest sample size that can measure a given
effect size with the desired level of power</li>
<li><code>type_1</code>: How often do we falsely reject the null when it's true?</li>
<li><code>type_2</code>: How often do we fail to reject the null when it's false?</li>
<li><code>type_s</code>: How often do we reject the null when our estimate of δ has the
wrong sign?</li>
<li><code>type_m</code>: How often do we overestimate the magnitude of δ when we reject the
the null?</li>
<li><code>exaggeration_factor</code>: How much larger is our estimate of δ than the true
value when we reject the null?</li>
</ul>
<p>All of these functions assume that statistical designs are described in terms
of:</p>
<ul>
<li><code>ns</code>: The per-group sample size(s)</li>
<li><code>δ</code>: The difference in means between groups or the difference from zero</li>
<li><code>σs</code>: The per-group standard deviation(s)</li>
<li><code>p</code>: The desired power</li>
<li><code>α</code>: The significance level at which the null would be rejected</li>
</ul>
<h1><a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples</h1>
<p>We consider comparing two groups using a t-test that assumes that both groups
have the same variance. We consider using 100 samples per-group to test
a difference of 0.01 in means between groups, each of which have variance 1.
We also determine what effect size and sample size would be required to reach
power 0.8 when rejecting the null with a significance level of 0.05:</p>
<div class="snippet-clipboard-content position-relative" data-snippet-clipboard-copy-content="using PowerAnalysis, HypothesisTests

n = 100
δ = 0.01
σs = 1.0
p = 0.8
α = 0.05

power(EqualVarianceTTest, n, δ, σs, α)

effect_size(EqualVarianceTTest, n, p, α)

sample_size(EqualVarianceTTest, δ, σs, p, α)

type_1(EqualVarianceTTest, n, δ, σs, α)

type_2(EqualVarianceTTest, n, δ, σs, α)

type_s(EqualVarianceTTest, n, δ, σs, α)

type_m(EqualVarianceTTest, n, δ, σs, α)

exaggeration_factor(EqualVarianceTTest, n, δ, σs, α)
"><pre><code>using PowerAnalysis, HypothesisTests

n = 100
δ = 0.01
σs = 1.0
p = 0.8
α = 0.05

power(EqualVarianceTTest, n, δ, σs, α)

effect_size(EqualVarianceTTest, n, p, α)

sample_size(EqualVarianceTTest, δ, σs, p, α)

type_1(EqualVarianceTTest, n, δ, σs, α)

type_2(EqualVarianceTTest, n, δ, σs, α)

type_s(EqualVarianceTTest, n, δ, σs, α)

type_m(EqualVarianceTTest, n, δ, σs, α)

exaggeration_factor(EqualVarianceTTest, n, δ, σs, α)
</code></pre></div>
<p>As you can tell, attempting to measure an effect of size 0.01 is unwise.</p>
<h1><a id="user-content-caveats" class="anchor" aria-hidden="true" href="#caveats"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Caveats</h1>
<ul>
<li>All methods assume that δ is strictly positive</li>
<li>All methods assume that one-sided tests are "greater than null" tests</li>
</ul>
<h1><a id="user-content-bibliography" class="anchor" aria-hidden="true" href="#bibliography"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Bibliography</h1>
<ul>
<li>z-test calculations: "All of Statistics" by Larry Wasserman</li>
<li>t-test calculations: "Sample size and power calculations using the
noncentral t-distribution" by David A. Harrison and Anthony R. Brady</li>
<li>Type S error: "Beyond power calculations: Assessing Type S (sign) and Type M
(magnitude) errors" by Andrew Gelman and John Carlin</li>
<li>Type M error: "Beyond power calculations: Assessing Type S (sign) and Type M
(magnitude) errors" by Andrew Gelman and John Carlin</li>
<li>Exaggeration factor: "Beyond power calculations: Assessing Type S (sign) and
Type M (magnitude) errors" by Andrew Gelman and John Carlin</li>
</ul>
</article></div>