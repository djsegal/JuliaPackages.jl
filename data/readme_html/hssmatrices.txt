<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-hssmatricesjl" class="anchor" aria-hidden="true" href="#hssmatricesjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>HssMatrices.jl</h1>
<p><a href="https://github.com/bonevbs/HssMatrices.jl/actions"><img src="https://github.com/bonevbs/HssMatrices.jl/workflows/CI/badge.svg" alt="Build status (Github Actions)" style="max-width:100%;"></a>
<a href="http://codecov.io/github/bonevbs/HssMatrices.jl?branch=main" rel="nofollow"><img src="https://camo.githubusercontent.com/3aeabac1a6faa36ad71b2bce53f2f19b8ebda9372f4c3980d7a7dd2b319e4b29/687474703a2f2f636f6465636f762e696f2f6769746875622f626f6e657662732f4873734d617472696365732e6a6c2f636f7665726167652e7376673f6272616e63683d6d61696e" alt="codecov.io" data-canonical-src="http://codecov.io/github/bonevbs/HssMatrices.jl/coverage.svg?branch=main" style="max-width:100%;"></a>
<a href="https://doi.org/10.5281/zenodo.4696465" rel="nofollow"><img src="https://camo.githubusercontent.com/91abb19e5fe93d44c591dd73aa5459c18488cbab80698ea663c6ced0e3fd2acb/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e343639363436352e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.4696465.svg" style="max-width:100%;"></a></p>
<p><code>HssMatrices</code> is a Julia package for hierarchically semi-separable (HSS) matrices. These matrices are a type of hierarchically structured matrices, that arise in the context of solving PDEs numerically, among others. HssMatrices.jl is intendend to help users experiment with HSS matrices and related algorithms. HssMatrices.jl implements compression routines, HSS arithmetic, as well as helpful routines for clustering and visualization. These matrices have structures similar to the one in the illustration below.
<a target="_blank" rel="noopener noreferrer" href="./img/plotranks.svg"><img src="./img/plotranks.svg" alt="Plotranks" style="max-width:100%;"></a></p>
<h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Getting started</h2>
<p>Let us generate a simple Kernel matrix and convert it into HSS format:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using LinearAlgebra
using HssMatrices

K(x,y) = (x-y) != 0 ? 1/(x-y) : 1.
A = [ K(x,y) for x=-1:0.001:1, y=-1:0.001:1]
hssA = hss(A)
"><pre><span class="pl-k">using</span> LinearAlgebra
<span class="pl-k">using</span> HssMatrices

<span class="pl-en">K</span>(x,y) <span class="pl-k">=</span> (x<span class="pl-k">-</span>y) <span class="pl-k">!=</span> <span class="pl-c1">0</span> <span class="pl-k">?</span> <span class="pl-c1">1</span><span class="pl-k">/</span>(x<span class="pl-k">-</span>y) <span class="pl-k">:</span> <span class="pl-c1">1.</span>
A <span class="pl-k">=</span> [ <span class="pl-c1">K</span>(x,y) <span class="pl-k">for</span> x<span class="pl-k">=</span><span class="pl-k">-</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">0.001</span><span class="pl-k">:</span><span class="pl-c1">1</span>, y<span class="pl-k">=</span><span class="pl-k">-</span><span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">0.001</span><span class="pl-k">:</span><span class="pl-c1">1</span>]
hssA <span class="pl-k">=</span> <span class="pl-c1">hss</span>(A)</pre></div>
<p>This will automatically build a cluster tree and compress the matrix accordingly. <code>hss()</code> acts as a smart constructor, which will construct the matrix depending on the supplied matrix and parameters. We can either pass these parameters, for instance by doing:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="hssA = hss(A, leafsize=64, atol=1e-6, rtol=1e-6)
"><pre>hssA <span class="pl-k">=</span> <span class="pl-c1">hss</span>(A, leafsize<span class="pl-k">=</span><span class="pl-c1">64</span>, atol<span class="pl-k">=</span><span class="pl-c1">1e-6</span>, rtol<span class="pl-k">=</span><span class="pl-c1">1e-6</span>)</pre></div>
<p>It can be handy to set default values for those parameters once and forget about them later on. This can be achieved bt doing:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="HssMatrices.setopts!(leafsize=64)
"><pre>HssMatrices<span class="pl-k">.</span><span class="pl-c1">setopts!</span>(leafsize<span class="pl-k">=</span><span class="pl-c1">64</span>)</pre></div>
<h3><a id="user-content-compressionrecompression" class="anchor" aria-hidden="true" href="#compressionrecompression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Compression/Recompression</h3>
<p>But what if you want to choose the compression algorithm yourself? Instead of calling <code>hss</code>, HssMatrices provides access to deterministic and randomized HSS compression routines, as well as the recompression routine. In order to call these, we first have to specify a clustering of the degrees of freedom. We provide the function <code>bisection_cluster</code>, to form a cluster tree of the degrees of freedom. If we use <a href="https://github.com/JuliaCollections/AbstractTrees.jl">AbstractTrees.jl</a>, we can also print them with <code>print_tree</code>:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using AbstractTrees
cl = bisection_cluster(1:m, leafsize=32)
print_tree(cl)
"><pre><span class="pl-k">using</span> AbstractTrees
cl <span class="pl-k">=</span> <span class="pl-c1">bisection_cluster</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>m, leafsize<span class="pl-k">=</span><span class="pl-c1">32</span>)
<span class="pl-c1">print_tree</span>(cl)</pre></div>
<p>Once we have created row- and column-clusters, we can move on to compress our matrix. Direct compression can be achieved by calling <code>compress</code>:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="rcl = bisection_cluster(1:m)
rcl = bisection_cluster(1:n)
hssA = compress(A, rcl, ccl, atol=1e-9, rtol=1e-9)
"><pre>rcl <span class="pl-k">=</span> <span class="pl-c1">bisection_cluster</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>m)
rcl <span class="pl-k">=</span> <span class="pl-c1">bisection_cluster</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>n)
hssA <span class="pl-k">=</span> <span class="pl-c1">compress</span>(A, rcl, ccl, atol<span class="pl-k">=</span><span class="pl-c1">1e-9</span>, rtol<span class="pl-k">=</span><span class="pl-c1">1e-9</span>)</pre></div>
<p>The tolerances in HssMatrices are handled in a way that the algorithms stop once either the absolute norm is below <code>atol</code> or once the relative norm is below <code>rtol</code>. In order to enforce that only one of the two criteria is met, we can set the other criterion to 0.</p>
<p>Apart from the direct compression routine, HssMatrices also implements the randomized compression routine developed by Per-Gunnar Martinsson. We can call this routine by either calling <code>randcompress</code> or <code>randcompress_adaptive</code>. The latter starts with a rank estimate of <code>kest=10</code> and increases the estimated rank of the random sampling until the estimate of the norm is below the respective tolerance.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="hssB = randcompress(A, rcl, ccl, kest=10);
hssB = randcompress_adaptive(A, rcl, ccl);
"><pre>hssB <span class="pl-k">=</span> <span class="pl-c1">randcompress</span>(A, rcl, ccl, kest<span class="pl-k">=</span><span class="pl-c1">10</span>);
hssB <span class="pl-k">=</span> <span class="pl-c1">randcompress_adaptive</span>(A, rcl, ccl);</pre></div>
<p>It is often useful to be able to call this indirect compression matrix without explicitly constructing a matrix. To this end, HssMatrices implements the <code>LinearMap</code>, type which is derived from the <code>LinearOperator</code> type defined in LowRankApproximation.jl. This type contains two functions for multiplication with the matrix and it's routine respectively, as well as one function for accessing individual indices of the <code>LinearMap</code>.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="Id(i,j) = Matrix{Float64}(i.*ones(length(j))' .== ones(length(i)).*j')
IdOp = LinearMap{Float64}(n, n, (y,_,x) -&gt; x, (y,_,x) -&gt; x, (i,j) -&gt; Id(i,j))
hssI = randcompress(IdOp, ccl, ccl, 0)
"><pre><span class="pl-en">Id</span>(i,j) <span class="pl-k">=</span> <span class="pl-c1">Matrix</span><span class="pl-c1">{Float64}</span>(i<span class="pl-k">.*</span><span class="pl-c1">ones</span>(<span class="pl-c1">length</span>(j))<span class="pl-k">'</span> <span class="pl-k">.==</span> <span class="pl-c1">ones</span>(<span class="pl-c1">length</span>(i))<span class="pl-k">.*</span>j<span class="pl-k">'</span>)
IdOp <span class="pl-k">=</span> <span class="pl-c1">LinearMap</span><span class="pl-c1">{Float64}</span>(n, n, (y,_,x) <span class="pl-k">-&gt;</span> x, (y,_,x) <span class="pl-k">-&gt;</span> x, (i,j) <span class="pl-k">-&gt;</span> <span class="pl-c1">Id</span>(i,j))
hssI <span class="pl-k">=</span> <span class="pl-c1">randcompress</span>(IdOp, ccl, ccl, <span class="pl-c1">0</span>)</pre></div>
<p>Finally, basic arithmetic on hierarchical matrices often requires frequent recompression of the matrices in order to guarantee that the matrices remain efficient. This is implemented in src/compression.jl via the <code>recompress!</code> routine.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="hssA = recompress!(hssA, atol=1e-3, rtol=1e-3)
"><pre>hssA <span class="pl-k">=</span> <span class="pl-c1">recompress!</span>(hssA, atol<span class="pl-k">=</span><span class="pl-c1">1e-3</span>, rtol<span class="pl-k">=</span><span class="pl-c1">1e-3</span>)</pre></div>
<p>All compression is handled in the sense that individual HSS block rows and columns approximate the original matrix A such that the tolerance is below <code>atol</code> of <code>rtol</code> for this block.</p>
<p>It can also be useful to construct HSS matrices from specific datastructures. For instance, we can construct an HSS matrix from a low-rank matrix in the following fashion:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="U = randn(m, k); V = randn(n,k)
rcl = bisection_cluster(1:m, lsz)
ccl = bisection_cluster(1:n, lsz)
hssA = lowrank2hss(U, V, rcl, ccl)
"><pre>U <span class="pl-k">=</span> <span class="pl-c1">randn</span>(m, k); V <span class="pl-k">=</span> <span class="pl-c1">randn</span>(n,k)
rcl <span class="pl-k">=</span> <span class="pl-c1">bisection_cluster</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>m, lsz)
ccl <span class="pl-k">=</span> <span class="pl-c1">bisection_cluster</span>(<span class="pl-c1">1</span><span class="pl-k">:</span>n, lsz)
hssA <span class="pl-k">=</span> <span class="pl-c1">lowrank2hss</span>(U, V, rcl, ccl)</pre></div>
<h3><a id="user-content-efficient-hss-multiplication-and-division-inversion" class="anchor" aria-hidden="true" href="#efficient-hss-multiplication-and-division-inversion"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Efficient HSS multiplication and division (inversion)</h3>
<p>Of course we can now perform some arithmetic using HSS matrices. HssMatrices implements fast multiplication with dense and HSS matrices as well as fast solution of linear systems via the ULV factorization.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="hssA*x
hssA\x
"><pre>hssA<span class="pl-k">*</span>x
hssA<span class="pl-k">\</span>x</pre></div>
<p>These operations will automatically call the right routines for fast multiplication and fast matrix division. Moreover, we can also use HSS arithmetic to multiply Hss matrices with eachother and use left/right division on them:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="hssA+hssB
hssA-hssB
hssA*hssB
hssA\hssB
hssA/hssB
"><pre>hssA<span class="pl-k">+</span>hssB
hssA<span class="pl-k">-</span>hssB
hssA<span class="pl-k">*</span>hssB
hssA<span class="pl-k">\</span>hssB
hssA<span class="pl-k">/</span>hssB</pre></div>
<p>Do not forget to call recompression in order to keep the ranks low!</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="recompress!(hssA)
"><pre><span class="pl-c1">recompress!</span>(hssA)</pre></div>
<h3><a id="user-content-convenience-routines" class="anchor" aria-hidden="true" href="#convenience-routines"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Convenience routines</h3>
<p>We can also have a look at the generators and extract them via</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="U1, V2 = generators(hssA, (1,2))
"><pre>U1, V2 <span class="pl-k">=</span> <span class="pl-c1">generators</span>(hssA, (<span class="pl-c1">1</span>,<span class="pl-c1">2</span>))</pre></div>
<p>Another important information is the maximum off-diagonal rank. We can compute it using</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="hssrank(hssA)
"><pre><span class="pl-c1">hssrank</span>(hssA)</pre></div>
<p>Alternatively, we can visualize the clustering and the off-diagonal ranks by calling</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="plotranks(hssA)
"><pre><span class="pl-c1">plotranks</span>(hssA)</pre></div>
<p>This should generate an image similar to the one seen at the top of the page.</p>
<h2><a id="user-content-contribute" class="anchor" aria-hidden="true" href="#contribute"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contribute</h2>
<p>We would like to encourage users to share their problems, bugs and experiences so that we can keep improving the library.</p>
<h2><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Acknowledgements</h2>
<p>This library was inspired by the amazing package <a href="https://github.com/numpi/hm-toolbox">hm-toolbox</a> by Stefano Massei, Leonardo Robol and Daniel Kressner. If you are using Matlab, I highly recommend to try this package.</p>
<p>In numerous occasions, members of the Julia Slack channel have helped me with the challenges of writing my first library in Julia. I would like to acknowledge their support.</p>
</article></div>