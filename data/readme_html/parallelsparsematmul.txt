<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-parallelsparsematmul" class="anchor" aria-hidden="true" href="#parallelsparsematmul"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>ParallelSparseMatMul</h1>

<p dir="auto">A Julia library for parallel sparse matrix multiplication using shared memory.
This library implements SharedSparseMatrixCSC and SharedBilinearOperator types
to make it easy to multiply by sparse matrices in parallel on shared memory systems.</p>
<h1 dir="auto"><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h1>
<p dir="auto">To install, just open a Julia prompt and call</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="Pkg.clone(&quot;git@github.com:madeleineudell/ParallelSparseMatMul.jl.git&quot;)"><pre class="notranslate"><code>Pkg.clone("git@github.com:madeleineudell/ParallelSparseMatMul.jl.git")
</code></pre></div>
<h1 dir="auto"><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Usage</h1>
<p dir="auto">Before you begin, initialize all the processes you want to participate in multiplying by your matrix.
You'll suffer decreased performance if you add more processes
than you have hyperthreads on your shared-memory computer.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="addprocs(3)
using ParallelSparseMatMul"><pre class="notranslate"><code>addprocs(3)
using ParallelSparseMatMul
</code></pre></div>
<p dir="auto">Create a shared sparse matrix by sharing a sparse matrix.
For example, if <code>typeof(A) == SparseMatrixCSC</code>, then you can share it by calling</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="S = share(A)"><pre class="notranslate"><code>S = share(A)
</code></pre></div>
<p dir="auto">If you're just experimenting, you might try calling one of the matrix creation functions,
eg random uniform entries <code>shsprand</code>, random normal entries <code>shsprandn</code>,
or an identity matrix <code>shspeye</code>.
These are often faster than their serial counterparts, since
they parallelize the generation of random numbers.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="m,n,p = 100,30,.1 # generate an 100 x 30 matrix with 10% fill
S = shsprandn(m,n,p) # entries are normal random variables"><pre class="notranslate"><code>m,n,p = 100,30,.1 # generate an 100 x 30 matrix with 10% fill
S = shsprandn(m,n,p) # entries are normal random variables
</code></pre></div>
<p dir="auto">You can multiply by your matrix and its transpose.
Multiplication by shared arrays will be faster than multiplication by other kinds of vectors,
which have to be shared first.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="x = Base.shmem_randn(n) # create a shared memory array of length n
y = S*x
x = S'*y"><pre class="notranslate"><code>x = Base.shmem_randn(n) # create a shared memory array of length n
y = S*x
x = S'*y
</code></pre></div>
<p dir="auto">The matrices are stored in CSC format, which means that transpose multiplication <code>x = S'*y</code>
will be faster than multiplication <code>y = S*x</code>.
You can examine the entries of a shared sparse matrix by indexing into it,
eg <code>S[3,5]</code>.
Setting entries is not yet supported.
Instead, you can always convert your matrix to a local sparse matrix,
set entries, and re-share it.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="A = localize(S)
A[3,5] = 42
S = share(A)"><pre class="notranslate"><code>A = localize(S)
A[3,5] = 42
S = share(A)
</code></pre></div>
<p dir="auto">Shared bilinear operators implement fast multiplication by A and A'.
This feature is useful in iterative algorithms that require many multiplications
by a fixed matrix and its transpose.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="L = operator(A) # make A into a shared bilinear operator L
# multiplication by L' should be faster than multiplication by A'
y = L*x 
x = L'*y"><pre class="notranslate"><code>L = operator(A) # make A into a shared bilinear operator L
# multiplication by L' should be faster than multiplication by A'
y = L*x 
x = L'*y
</code></pre></div>
<p dir="auto">The command <code>L=operator(A)</code> forms and stores <code>A'</code>.
This allows multiplication by <code>A</code> to be as fast as multiplication by <code>A'</code>,
at the cost of doubling the storage requirements.</p>
</article></div>