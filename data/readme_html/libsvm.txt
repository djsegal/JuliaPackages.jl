<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-libsvmjl" class="anchor" aria-hidden="true" href="#libsvmjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LIBSVM.jl</h1>
<p><a href="https://github.com/JuliaML/LIBSVM.jl/actions?query=workflow%3ACI"><img src="https://github.com/JuliaML/LIBSVM.jl/workflows/CI/badge.svg?branch=master" alt="Build Status" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/JuliaML/LIBSVM.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/80d9e2d704597ee68cda3e74b899b1fef98f59bd21fe1494f89a1df600521f70/68747470733a2f2f636f6465636f762e696f2f67682f4a756c69614d4c2f4c494253564d2e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d6247777a7954744e506e" alt="codecov" data-canonical-src="https://codecov.io/gh/JuliaML/LIBSVM.jl/branch/master/graph/badge.svg?token=bGwzyTtNPn" style="max-width:100%;"></a></p>
<p>This is a Julia interface for <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/" rel="nofollow">LIBSVM</a>.</p>
<p><strong>Features:</strong></p>
<ul>
<li>Supports all LIBSVM models: classification C-SVC, nu-SVC, regression: epsilon-SVR, nu-SVR
and distribution estimation: one-class SVM</li>
<li>Model objects are represented by Julia type SVM which gives you easy
access to model features and can be saved e.g. as JLD file</li>
<li>Supports ScikitLearn.jl API</li>
</ul>
<h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage</h2>
<h3><a id="user-content-libsvm-api" class="anchor" aria-hidden="true" href="#libsvm-api"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LIBSVM API</h3>
<p>This provides a lower level API similar to LIBSVM C-interface. See <code>?svmtrain</code>
for options.</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using LIBSVM
using RDatasets
using Printf
using Statistics

# Load Fisher's classic iris data
iris = dataset(&quot;datasets&quot;, &quot;iris&quot;)

# First four dimension of input data is features
X = Matrix(iris[:, 1:4])'

# LIBSVM handles multi-class data automatically using a one-against-one strategy
y = iris.Species

# Split the dataset into training set and testing set
Xtrain = X[:, 1:2:end]
Xtest  = X[:, 2:2:end]
ytrain = y[1:2:end]
ytest  = y[2:2:end]

# Train SVM on half of the data using default parameters. See documentation
# of svmtrain for options
model = svmtrain(Xtrain, ytrain)

# Test model on the other half of the data.
ŷ, decision_values = svmpredict(model, Xtest);

# Compute accuracy
@printf &quot;Accuracy: %.2f%%\n&quot; mean(ŷ .== ytest) * 100
"><pre><span class="pl-k">using</span> LIBSVM
<span class="pl-k">using</span> RDatasets
<span class="pl-k">using</span> Printf
<span class="pl-k">using</span> Statistics

<span class="pl-c"><span class="pl-c">#</span> Load Fisher's classic iris data</span>
iris <span class="pl-k">=</span> <span class="pl-c1">dataset</span>(<span class="pl-s"><span class="pl-pds">"</span>datasets<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>iris<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">#</span> First four dimension of input data is features</span>
X <span class="pl-k">=</span> <span class="pl-c1">Matrix</span>(iris[:, <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">4</span>])<span class="pl-k">'</span>

<span class="pl-c"><span class="pl-c">#</span> LIBSVM handles multi-class data automatically using a one-against-one strategy</span>
y <span class="pl-k">=</span> iris<span class="pl-k">.</span>Species

<span class="pl-c"><span class="pl-c">#</span> Split the dataset into training set and testing set</span>
Xtrain <span class="pl-k">=</span> X[:, <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]
Xtest  <span class="pl-k">=</span> X[:, <span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]
ytrain <span class="pl-k">=</span> y[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]
ytest  <span class="pl-k">=</span> y[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]

<span class="pl-c"><span class="pl-c">#</span> Train SVM on half of the data using default parameters. See documentation</span>
<span class="pl-c"><span class="pl-c">#</span> of svmtrain for options</span>
model <span class="pl-k">=</span> <span class="pl-c1">svmtrain</span>(Xtrain, ytrain)

<span class="pl-c"><span class="pl-c">#</span> Test model on the other half of the data.</span>
ŷ, decision_values <span class="pl-k">=</span> <span class="pl-c1">svmpredict</span>(model, Xtest);

<span class="pl-c"><span class="pl-c">#</span> Compute accuracy</span>
<span class="pl-c1">@printf</span> <span class="pl-s"><span class="pl-pds">"</span>Accuracy: %.2f%%<span class="pl-cce">\n</span><span class="pl-pds">"</span></span> <span class="pl-c1">mean</span>(ŷ <span class="pl-k">.==</span> ytest) <span class="pl-k">*</span> <span class="pl-c1">100</span></pre></div>
<h3><a id="user-content-scikitlearn-api" class="anchor" aria-hidden="true" href="#scikitlearn-api"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ScikitLearn API</h3>
<p>You can alternatively use <code>ScikitLearn.jl</code> API with same options as <code>svmtrain</code>:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="using LIBSVM
using RDatasets

# Classification C-SVM
iris = dataset(&quot;datasets&quot;, &quot;iris&quot;)
X = Matrix(iris[:, 1:4])
y = iris.Species

Xtrain = X[1:2:end, :]
Xtest  = X[2:2:end, :]
ytrain = y[1:2:end]
ytest  = y[2:2:end]

model = fit!(SVC(), Xtrain, ytrain)
ŷ = predict(model, Xtest)
"><pre><span class="pl-k">using</span> LIBSVM
<span class="pl-k">using</span> RDatasets

<span class="pl-c"><span class="pl-c">#</span> Classification C-SVM</span>
iris <span class="pl-k">=</span> <span class="pl-c1">dataset</span>(<span class="pl-s"><span class="pl-pds">"</span>datasets<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>iris<span class="pl-pds">"</span></span>)
X <span class="pl-k">=</span> <span class="pl-c1">Matrix</span>(iris[:, <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">4</span>])
y <span class="pl-k">=</span> iris<span class="pl-k">.</span>Species

Xtrain <span class="pl-k">=</span> X[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>, :]
Xtest  <span class="pl-k">=</span> X[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>, :]
ytrain <span class="pl-k">=</span> y[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]
ytest  <span class="pl-k">=</span> y[<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>]

model <span class="pl-k">=</span> <span class="pl-c1">fit!</span>(<span class="pl-c1">SVC</span>(), Xtrain, ytrain)
ŷ <span class="pl-k">=</span> <span class="pl-c1">predict</span>(model, Xtest)</pre></div>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="# Epsilon-Regression

whiteside = RDatasets.dataset(&quot;MASS&quot;, &quot;whiteside&quot;)
X = Matrix(whiteside[:, 3:3])  # the `Gas` column
y = whiteside.Temp

model = fit!(EpsilonSVR(cost = 10., gamma = 1.), X, y)
ŷ = predict(model, X)
"><pre><span class="pl-c"><span class="pl-c">#</span> Epsilon-Regression</span>

whiteside <span class="pl-k">=</span> RDatasets<span class="pl-k">.</span><span class="pl-c1">dataset</span>(<span class="pl-s"><span class="pl-pds">"</span>MASS<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>whiteside<span class="pl-pds">"</span></span>)
X <span class="pl-k">=</span> <span class="pl-c1">Matrix</span>(whiteside[:, <span class="pl-c1">3</span><span class="pl-k">:</span><span class="pl-c1">3</span>])  <span class="pl-c"><span class="pl-c">#</span> the `Gas` column</span>
y <span class="pl-k">=</span> whiteside<span class="pl-k">.</span>Temp

model <span class="pl-k">=</span> <span class="pl-c1">fit!</span>(<span class="pl-c1">EpsilonSVR</span>(cost <span class="pl-k">=</span> <span class="pl-c1">10.</span>, gamma <span class="pl-k">=</span> <span class="pl-c1">1.</span>), X, y)
ŷ <span class="pl-k">=</span> <span class="pl-c1">predict</span>(model, X)</pre></div>
<h2><a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Credits</h2>
<p>The library is currently developed and maintained by Matti Pastell. It was originally
developed by Simon Kornblith.</p>
<p><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/" rel="nofollow">LIBSVM</a> by Chih-Chung Chang and Chih-Jen Lin</p>
</article></div>