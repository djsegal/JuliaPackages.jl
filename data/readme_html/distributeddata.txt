<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content--distributeddatajl" class="anchor" aria-hidden="true" href="#-distributeddatajl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a target="_blank" rel="noopener noreferrer" href="docs/src/assets/logo.svg"><img src="docs/src/assets/logo.svg" alt="DistributedData.jl logo" height="32px" style="max-width:100%;"></a> DistributedData.jl</h1>
<table>
<thead>
<tr>
<th align="center">Build status</th>
<th align="center">Documentation</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a target="_blank" rel="noopener noreferrer" href="https://github.com/LCSB-BioCore/DistributedData.jl/workflows/CI/badge.svg?branch=develop"><img src="https://github.com/LCSB-BioCore/DistributedData.jl/workflows/CI/badge.svg?branch=develop" alt="CI" style="max-width:100%;"></a></td>
<td align="center"><a href="https://lcsb-biocore.github.io/DistributedData.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/82c347c7b50bd81a04b5c6fbc99d91f2a1565fffa213c21f5ed152243e2fccf5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c7565" alt="doc" data-canonical-src="https://img.shields.io/badge/docs-stable-blue" style="max-width:100%;"></a> <a href="https://lcsb-biocore.github.io/DistributedData.jl/dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/9e50bd744da332d6eb4aeaf467eadf72db0d6507361d587a4ac2245dc540f934/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c7565" alt="doc" data-canonical-src="https://img.shields.io/badge/docs-dev-blue" style="max-width:100%;"></a></td>
</tr>
</tbody>
</table>
<p>Simple distributed data manipulation and processing routines for Julia.</p>
<h4><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Acknowledgements</h4>
<p>This was originally developed for
<a href="https://github.com/LCSB-BioCore/GigaSOM.jl"><code>GigaSOM.jl</code></a>;
<code>DistributedData.jl</code> package contains the separated-out lightweight
distributed-processing framework that was used in <code>GigaSOM.jl</code>.</p>
<p><code>DistributedData.jl</code> was developed at the
Luxembourg Centre for Systems Biomedicine of the University of Luxembourg (<a href="https://www.uni.lu/lcsb" rel="nofollow">uni.lu/lcsb</a>).
The development was supported by
European Union ELIXIR Staff Exchange programme 2020 (<a href="https://elixir-europe.org/" rel="nofollow">elixir-europe.org</a>), and
European Union's Horizon 2020 Programme under PerMedCoE project (<a href="https://www.permedcoe.eu/" rel="nofollow">permedcoe.eu</a>) agreement no. 951773.</p>
<p><a target="_blank" rel="noopener noreferrer" href="docs/src/assets/unilu.svg"><img src="docs/src/assets/unilu.svg" alt="Uni.lu logo" height="64px" style="max-width:100%;"></a>   <a target="_blank" rel="noopener noreferrer" href="docs/src/assets/lcsb.svg"><img src="docs/src/assets/lcsb.svg" alt="LCSB logo" height="64px" style="max-width:100%;"></a>   <a target="_blank" rel="noopener noreferrer" href="docs/src/assets/elixir.svg"><img src="docs/src/assets/elixir.svg" alt="ELIXIR logo" height="64px" style="max-width:100%;"></a>   <a target="_blank" rel="noopener noreferrer" href="docs/src/assets/permedcoe.svg"><img src="docs/src/assets/permedcoe.svg" alt="PerMedCoE logo" height="64px" style="max-width:100%;"></a></p>
<h2><a id="user-content-why" class="anchor" aria-hidden="true" href="#why"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Why?</h2>
<p><code>DistributedData.jl</code> provides a very simple, imperative and straightforward way
to move your data around a cluster of Julia processes created by the
<a href="https://docs.julialang.org/en/v1/stdlib/Distributed/" rel="nofollow"><code>Distributed</code></a> package,
and run computation on the distributed data pieces. The main aim of the package
is to avoid anything complicated-- the first version used in
<a href="https://github.com/LCSB-BioCore/GigaSOM.jl">GigaSOM</a> had just under 500 lines
of relatively straightforward code (including the doc-comments).</p>
<p>Compared to plain <code>Distributed</code> API, you get more straightforward data
manipulation primitives, some extra control over the precise place where code
is executed, and a few high-level functions. These include a distributed
version of <code>mapreduce</code>, simpler work-alike of the
<a href="https://github.com/JuliaParallel/DistributedArrays.jl">DistributedArrays</a>
functionality, and easy-to-use distributed dataset saving and loading.</p>
<p>Most importantly, the main motivation behind the package is that the
distributed processing should be simple and accessible.</p>
<h2><a id="user-content-brief-how-to" class="anchor" aria-hidden="true" href="#brief-how-to"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Brief how-to</h2>
<p>The package provides a few very basic primitives that lightly wrap the
<code>Distributed</code> package functions <code>remotecall</code> and <code>fetch</code>. The most basic one is
<code>save_at</code>, which takes a worker ID, variable name and variable content, and
saves the content to the variable on the selected worker. <code>get_from</code> works the
same way, but takes the data back from the worker.</p>
<p>You can thus send some random array to a few distributed workers:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; using Distributed, DistributedData

julia&gt; addprocs(2)
2-element Array{Int64,1}:
 2
 3

julia&gt; @everywhere using DistributedData

julia&gt; save_at(2, :x, randn(10,10))
Future(2, 1, 4, nothing)
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Distributed, DistributedData

julia<span class="pl-k">&gt;</span> <span class="pl-c1">addprocs</span>(<span class="pl-c1">2</span>)
<span class="pl-c1">2</span><span class="pl-k">-</span>element Array{Int64,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
 <span class="pl-c1">2</span>
 <span class="pl-c1">3</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">@everywhere</span> <span class="pl-k">using</span> DistributedData

julia<span class="pl-k">&gt;</span> <span class="pl-c1">save_at</span>(<span class="pl-c1">2</span>, <span class="pl-c1">:x</span>, <span class="pl-c1">randn</span>(<span class="pl-c1">10</span>,<span class="pl-c1">10</span>))
<span class="pl-c1">Future</span>(<span class="pl-c1">2</span>, <span class="pl-c1">1</span>, <span class="pl-c1">4</span>, <span class="pl-c1">nothing</span>)</pre></div>
<p>The <code>Future</code> returned from <code>save_at</code> is the normal Julia future from
<code>Distributed</code>, you can even <code>fetch</code> it to wait until the operation is really
done on the other side. Fetching the data is done the same way:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; get_from(2,:x)
Future(2, 1, 15, nothing)

julia&gt; get_val_from(2,:x) # auto-fetch()ing variant
10×10 Array{Float64,2}:
 -0.850788    0.946637     1.78006   … 
 -0.49596     0.497829    -2.03013
   …
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">get_from</span>(<span class="pl-c1">2</span>,<span class="pl-c1">:x</span>)
<span class="pl-c1">Future</span>(<span class="pl-c1">2</span>, <span class="pl-c1">1</span>, <span class="pl-c1">15</span>, <span class="pl-c1">nothing</span>)

julia<span class="pl-k">&gt;</span> <span class="pl-c1">get_val_from</span>(<span class="pl-c1">2</span>,<span class="pl-c1">:x</span>) <span class="pl-c"><span class="pl-c">#</span> auto-fetch()ing variant</span>
<span class="pl-c1">10</span><span class="pl-k">×</span><span class="pl-c1">10</span> Array{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-k">-</span><span class="pl-c1">0.850788</span>    <span class="pl-c1">0.946637</span>     <span class="pl-c1">1.78006</span>   … 
 <span class="pl-k">-</span><span class="pl-c1">0.49596</span>     <span class="pl-c1">0.497829</span>    <span class="pl-k">-</span><span class="pl-c1">2.03013</span>
   …</pre></div>
<p>All commands support full quoting, which allows you to easily distinguish
between code parts that are executed locally and remotely:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; save_at(3, :x, randn(1000,1000))     # generates a matrix locally and sends it to the remote worker

julia&gt; save_at(3, :x, :(randn(1000,1000)))  # generates a matrix right on the remote worker and saves it there

julia&gt; get_val_from(3, :x)                  # retrieves the generated matrix and fetches it
…

julia&gt; get_val_from(3, :(randn(1000,1000))) # generates the matrix on the worker and fetches the data
…
"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">save_at</span>(<span class="pl-c1">3</span>, <span class="pl-c1">:x</span>, <span class="pl-c1">randn</span>(<span class="pl-c1">1000</span>,<span class="pl-c1">1000</span>))     <span class="pl-c"><span class="pl-c">#</span> generates a matrix locally and sends it to the remote worker</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">save_at</span>(<span class="pl-c1">3</span>, <span class="pl-c1">:x</span>, :(<span class="pl-c1">randn</span>(<span class="pl-c1">1000</span>,<span class="pl-c1">1000</span>)))  <span class="pl-c"><span class="pl-c">#</span> generates a matrix right on the remote worker and saves it there</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">get_val_from</span>(<span class="pl-c1">3</span>, <span class="pl-c1">:x</span>)                  <span class="pl-c"><span class="pl-c">#</span> retrieves the generated matrix and fetches it</span>
…

julia<span class="pl-k">&gt;</span> <span class="pl-c1">get_val_from</span>(<span class="pl-c1">3</span>, :(<span class="pl-c1">randn</span>(<span class="pl-c1">1000</span>,<span class="pl-c1">1000</span>))) <span class="pl-c"><span class="pl-c">#</span> generates the matrix on the worker and fetches the data</span>
…</pre></div>
<p>Notably, this is different from the approach taken by <code>DistributedArrays</code> and
similar packages -- all data manipulation is explicit, and any data type is
supported as long as it can be moved among workers by the <code>Distributed</code>
package. This helps with various highly non-array-ish data, such as large text
corpora and graphs.</p>
<p>There are various goodies for easy work with matrix-style data, namely
scattering, gathering and running distributed algorithms:</p>
<div class="highlight highlight-source-julia position-relative" data-snippet-clipboard-copy-content="julia&gt; x = randn(1000,3)
1000×3 Array{Float64,2}:
 -0.992481   0.551064     1.67424
 -0.751304  -0.845055     0.105311
 -0.712687   0.165619    -0.469055
  ⋮

julia&gt; dataset = scatter_array(:myDataset, x, workers())  # sends slices of the array to workers
Dinfo(:myDataset, [2, 3])   # a helper for holding the variable name and the used workers together

julia&gt; get_val_from(3, :(size(myDataset)))
(500, 3)    # there's really only half of the data

julia&gt; dmapreduce(dataset, sum, +) # MapReduce-style sum of all data
-51.64369103751014

julia&gt; dstat(dataset, [1,2,3]) # get means and sdevs in individual columns
([-0.030724038974465212, 0.007300925745200863, -0.028220577808245786],
 [0.9917470012495775, 0.9975120525455358, 1.000243845434252])

julia&gt; dmedian(dataset, [1,2,3]) # distributed iterative median in columns
3-element Array{Float64,1}:
  0.004742259615849834
  0.039043266340824986
 -0.05367799062404967

julia&gt; dtransform(dataset, x -&gt; 2 .^ x) # exponentiate all data (medians should now be around 1)
Dinfo(:myDataset, [2, 3])

julia&gt; gather_array(dataset) # download the data from workers to a sing
1000×3 Array{Float64,2}:
 0.502613  1.46517   3.1915
 0.594066  0.55669   1.07573
 0.610183  1.12165   0.722438
  ⋮
"><pre>julia<span class="pl-k">&gt;</span> x <span class="pl-k">=</span> <span class="pl-c1">randn</span>(<span class="pl-c1">1000</span>,<span class="pl-c1">3</span>)
<span class="pl-c1">1000</span><span class="pl-k">×</span><span class="pl-c1">3</span> Array{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-k">-</span><span class="pl-c1">0.992481</span>   <span class="pl-c1">0.551064</span>     <span class="pl-c1">1.67424</span>
 <span class="pl-k">-</span><span class="pl-c1">0.751304</span>  <span class="pl-k">-</span><span class="pl-c1">0.845055</span>     <span class="pl-c1">0.105311</span>
 <span class="pl-k">-</span><span class="pl-c1">0.712687</span>   <span class="pl-c1">0.165619</span>    <span class="pl-k">-</span><span class="pl-c1">0.469055</span>
  ⋮

julia<span class="pl-k">&gt;</span> dataset <span class="pl-k">=</span> <span class="pl-c1">scatter_array</span>(<span class="pl-c1">:myDataset</span>, x, <span class="pl-c1">workers</span>())  <span class="pl-c"><span class="pl-c">#</span> sends slices of the array to workers</span>
<span class="pl-c1">Dinfo</span>(<span class="pl-c1">:myDataset</span>, [<span class="pl-c1">2</span>, <span class="pl-c1">3</span>])   <span class="pl-c"><span class="pl-c">#</span> a helper for holding the variable name and the used workers together</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">get_val_from</span>(<span class="pl-c1">3</span>, :(<span class="pl-c1">size</span>(myDataset)))
(<span class="pl-c1">500</span>, <span class="pl-c1">3</span>)    <span class="pl-c"><span class="pl-c">#</span> there's really only half of the data</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">dmapreduce</span>(dataset, sum, <span class="pl-k">+</span>) <span class="pl-c"><span class="pl-c">#</span> MapReduce-style sum of all data</span>
<span class="pl-k">-</span><span class="pl-c1">51.64369103751014</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">dstat</span>(dataset, [<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>]) <span class="pl-c"><span class="pl-c">#</span> get means and sdevs in individual columns</span>
([<span class="pl-k">-</span><span class="pl-c1">0.030724038974465212</span>, <span class="pl-c1">0.007300925745200863</span>, <span class="pl-k">-</span><span class="pl-c1">0.028220577808245786</span>],
 [<span class="pl-c1">0.9917470012495775</span>, <span class="pl-c1">0.9975120525455358</span>, <span class="pl-c1">1.000243845434252</span>])

julia<span class="pl-k">&gt;</span> <span class="pl-c1">dmedian</span>(dataset, [<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>]) <span class="pl-c"><span class="pl-c">#</span> distributed iterative median in columns</span>
<span class="pl-c1">3</span><span class="pl-k">-</span>element Array{Float64,<span class="pl-c1">1</span>}<span class="pl-k">:</span>
  <span class="pl-c1">0.004742259615849834</span>
  <span class="pl-c1">0.039043266340824986</span>
 <span class="pl-k">-</span><span class="pl-c1">0.05367799062404967</span>

julia<span class="pl-k">&gt;</span> <span class="pl-c1">dtransform</span>(dataset, x <span class="pl-k">-&gt;</span> <span class="pl-c1">2</span> <span class="pl-k">.^</span> x) <span class="pl-c"><span class="pl-c">#</span> exponentiate all data (medians should now be around 1)</span>
<span class="pl-c1">Dinfo</span>(<span class="pl-c1">:myDataset</span>, [<span class="pl-c1">2</span>, <span class="pl-c1">3</span>])

julia<span class="pl-k">&gt;</span> <span class="pl-c1">gather_array</span>(dataset) <span class="pl-c"><span class="pl-c">#</span> download the data from workers to a sing</span>
<span class="pl-c1">1000</span><span class="pl-k">×</span><span class="pl-c1">3</span> Array{Float64,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-c1">0.502613</span>  <span class="pl-c1">1.46517</span>   <span class="pl-c1">3.1915</span>
 <span class="pl-c1">0.594066</span>  <span class="pl-c1">0.55669</span>   <span class="pl-c1">1.07573</span>
 <span class="pl-c1">0.610183</span>  <span class="pl-c1">1.12165</span>   <span class="pl-c1">0.722438</span>
  ⋮</pre></div>
<h2><a id="user-content-using-distributeddatajl-in-hpc-environments" class="anchor" aria-hidden="true" href="#using-distributeddatajl-in-hpc-environments"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Using <code>DistributedData.jl</code> in HPC environments</h2>
<p>You can use
<a href="https://github.com/JuliaParallel/ClusterManagers.jl"><code>ClusterManagers</code></a>
package to add distributed workers from many different workload managers and
task scheduling environments, such as Slurm, PBS, LSF, and others.</p>
<p>See the documentation for an <a href="https://lcsb-biocore.github.io/DistributedData.jl/stable/slurm/" rel="nofollow">example of using Slurm to run
DistributedData</a>.</p>
</article></div>