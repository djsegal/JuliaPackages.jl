<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-project-ananke" class="anchor" aria-hidden="true" href="#project-ananke"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Project-Ananke</h1>
<p dir="auto">Project Anake is a on-onging CFD project, a highly efficient Magnetohydrodynamics (MHD) direct fluid GPU based code implemented on high level programming language julia. It is inspired by <a href="https://github.com/PrincetonUniversity/athena"><code>Athena++</code></a>/<a href="https://github.com/MHDFlows/MHDFlows.jl"><code>MHDFLows.jl</code></a>/<a href="https://github.com/FourierFlows/FourierFlows.jl"><code>FourierFlows.jl</code></a>. Its goals is to achieve a native GPU based, highly parallel, and efficient MHD simulation code using Finite Volume Method(FVM).</p>
<p dir="auto">At the end of this proejct, we aim to provide a prototype MHD code, which will support the following features:</p>
<ol dir="auto">
<li>1D/2D/3D uniform Grid simulation on cartesian coordinate system</li>
<li>Hydrodynamics/Magnetohydrodynamics Equation Solver</li>
<li>Support Isothermal/Adiabatic equation of state.</li>
</ol>
<h1 dir="auto"><a id="user-content-current-state-of-development" class="anchor" aria-hidden="true" href="#current-state-of-development"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Current State of development:</h1>
<p dir="auto">Version  : v.0.1.2<br>
Phase  I : Finished &amp; under testing<br>
Phase II : Under development of MPI boundary value exchange module</p>
<p dir="auto">To achieve those features, we split our development into three phases:</p>
<h2 dir="auto"><a id="user-content-i-simple-gpu-hd-simulation-with-hllchlle-solver-supporting--uniform-cartesian-coordinate" class="anchor" aria-hidden="true" href="#i-simple-gpu-hd-simulation-with-hllchlle-solver-supporting--uniform-cartesian-coordinate"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>I) Simple GPU HD simulation with HLLC/HLLE Solver supporting  uniform cartesian coordinate</h2>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="- Data structure &amp; Problem construction 
- Recontruction construction  (DC(1)/ PLM(2)/ PPM(3) )
- Solver Construction  ( HLLC for addiabatic/ HLLE for isothermal)
- Basic Integrator Construction  (second-order accurate van Leer predictor-corrector scheme)
- Boundary value problem constructor  (periodic/outflow/reflective)"><pre class="notranslate"><code>- Data structure &amp; Problem construction 
- Recontruction construction  (DC(1)/ PLM(2)/ PPM(3) )
- Solver Construction  ( HLLC for addiabatic/ HLLE for isothermal)
- Basic Integrator Construction  (second-order accurate van Leer predictor-corrector scheme)
- Boundary value problem constructor  (periodic/outflow/reflective)
</code></pre></div>
<h2 dir="auto"><a id="user-content-ii-mpi-implementation---curvilinear-coordinate-support" class="anchor" aria-hidden="true" href="#ii-mpi-implementation---curvilinear-coordinate-support"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>II) MPI implementation  &amp; Curvilinear coordinate Support</h2>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="- MPI Meshblock distribution
- MPI Boundary value exchange function
- Problem diagnotics for global statistics after each iteration (e.g. Total Energy)   
- Global FFT contructor  (with CuFFTMp)
- Support for cylindrical/ spherical coordinates (optional)"><pre class="notranslate"><code>- MPI Meshblock distribution
- MPI Boundary value exchange function
- Problem diagnotics for global statistics after each iteration (e.g. Total Energy)   
- Global FFT contructor  (with CuFFTMp)
- Support for cylindrical/ spherical coordinates (optional)
</code></pre></div>
<h2 dir="auto"><a id="user-content-iii-b-field-implementation" class="anchor" aria-hidden="true" href="#iii-b-field-implementation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>III) B-field implementation</h2>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="- Reconstruction method with B-field 
- HLLD Solvers  
- Div B Free algorthm (CT)"><pre class="notranslate"><code>- Reconstruction method with B-field 
- HLLD Solvers  
- Div B Free algorthm (CT)
</code></pre></div>
<h1 dir="auto"><a id="user-content-compatiblility-" class="anchor" aria-hidden="true" href="#compatiblility-"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Compatiblility :</h1>
<p dir="auto">Support Julia v1.8.3 with CUDA compatible GPU</p>
<h1 dir="auto"><a id="user-content-performance-evaluation" class="anchor" aria-hidden="true" href="#performance-evaluation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Performance Evaluation:</h1>
<p dir="auto">Ananke is still under development and lack of optimzation. User should expect the perforamnce could change from time to time. As for now, Ananke is mainly memory-bound. So the performance decline moderately from swtiching between <code>Float32/Float64</code> calulation. Nonetheless, as the current test is based on high-end gaming card with nerfed VRAM/<code>FP64 Core</code> configuration, one could expect better performance for <code>Float64</code> calculation for data center GPU.<br>
3090 24GB with 199 iterations after warm up process</p>
<table>
<thead>
<tr>
<th>Method (M Zones Update /s )</th>
<th><math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="359bad565e24fa45e75367af6331884e">$128^3$</math-renderer></th>
<th><math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="359bad565e24fa45e75367af6331884e">$256^3$</math-renderer></th>
<th><math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="359bad565e24fa45e75367af6331884e">$384^3$</math-renderer></th>
</tr>
</thead>
<tbody>
<tr>
<td>VL2 + PLM + HLLC(HD/Float32)</td>
<td>86.278</td>
<td>192.651</td>
<td>242.94</td>
</tr>
<tr>
<td>VL2 + PLM + HLLC(HD/Float64)</td>
<td>60.918</td>
<td>157.583</td>
<td>186.07</td>
</tr>
<tr>
<td>VL2 + PPM + HLLC(HD/Float32)</td>
<td>74.528</td>
<td>130.43</td>
<td>155.41</td>
</tr>
<tr>
<td>VL2 + PPM + HLLC(HD/Float64)</td>
<td>60.996</td>
<td>98.529</td>
<td>109.78</td>
</tr>
</tbody>
</table>
<p dir="auto">The performance comparsion to Athena++ (Table 3 in Stone et al. 2020)<br>
2× Skylake-SP Gold 614 (Total 40 Cores)</p>
<table>
<thead>
<tr>
<th>Method (M Zones Update /s )</th>
<th>about <math-renderer class="js-inline-math" style="display: inline" data-static-url="https://github.githubassets.com/static" data-run-id="359bad565e24fa45e75367af6331884e">$256^3$</math-renderer>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>VL2 + PLM + HLLC(HD/Float64)</td>
<td>84.769</td>
</tr>
<tr>
<td>VL2 + PPM + HLLC(HD/Float64)</td>
<td>49.759</td>
</tr>
</tbody>
</table>
<p dir="auto">For breakdown of the runtime (i.e. <code>VL2 + PPM + HLLC (HD/Float32)</code> in below), as expected, Ananke spend most of the time in recontruction state &amp; Flux construction step.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content=" ────────────────────────────────────────────────────────────────────────────────
                                        Time                    Allocations      
                               ───────────────────────   ────────────────────────
       Tot / % measured:            91.9s /  79.3%           91.7MiB /  93.8%    
 Section               ncalls     time    %tot     avg     alloc    %tot      avg
 ────────────────────────────────────────────────────────────────────────────────
 Time Stepper             199    71.0s   97.4%   357ms   77.2MiB   89.8%   397KiB
   Flux intregation       398    67.0s   92.0%   168ms   34.7MiB   40.3%  89.2KiB
     Reconstruct dir x    398    14.0s   19.3%  35.3ms   4.15MiB    4.8%  10.7KiB
     Reconstruct dir y    398    13.6s   18.6%  34.0ms   4.15MiB    4.8%  10.7KiB
     Reconstruct dir z    398    13.5s   18.6%  34.0ms   4.15MiB    4.8%  10.7KiB
     Solver dir y         398    7.57s   10.4%  19.0ms   3.57MiB    4.1%  9.18KiB
     Solver dir z         398    7.56s   10.4%  19.0ms   3.57MiB    4.1%  9.18KiB
     Solver dir x         398    7.54s   10.3%  18.9ms   3.58MiB    4.2%  9.20KiB
     Adding ∂F∂x          398    3.14s    4.3%  7.88ms   6.38MiB    7.4%  16.4KiB
   Cons to Prims          398    2.74s    3.8%  6.89ms   15.9MiB   18.5%  41.0KiB
   Boundary Exchange      398    1.18s    1.6%  2.96ms   26.5MiB   30.8%  68.1KiB
 CFL                      199    1.91s    2.6%  9.60ms   8.82MiB   10.2%  45.4KiB
 User defined function    199    182μs    0.0%   915ns     0.00B    0.0%    0.00B
 ────────────────────────────────────────────────────────────────────────────────"><pre class="notranslate"><code> ────────────────────────────────────────────────────────────────────────────────
                                        Time                    Allocations      
                               ───────────────────────   ────────────────────────
       Tot / % measured:            91.9s /  79.3%           91.7MiB /  93.8%    
 Section               ncalls     time    %tot     avg     alloc    %tot      avg
 ────────────────────────────────────────────────────────────────────────────────
 Time Stepper             199    71.0s   97.4%   357ms   77.2MiB   89.8%   397KiB
   Flux intregation       398    67.0s   92.0%   168ms   34.7MiB   40.3%  89.2KiB
     Reconstruct dir x    398    14.0s   19.3%  35.3ms   4.15MiB    4.8%  10.7KiB
     Reconstruct dir y    398    13.6s   18.6%  34.0ms   4.15MiB    4.8%  10.7KiB
     Reconstruct dir z    398    13.5s   18.6%  34.0ms   4.15MiB    4.8%  10.7KiB
     Solver dir y         398    7.57s   10.4%  19.0ms   3.57MiB    4.1%  9.18KiB
     Solver dir z         398    7.56s   10.4%  19.0ms   3.57MiB    4.1%  9.18KiB
     Solver dir x         398    7.54s   10.3%  18.9ms   3.58MiB    4.2%  9.20KiB
     Adding ∂F∂x          398    3.14s    4.3%  7.88ms   6.38MiB    7.4%  16.4KiB
   Cons to Prims          398    2.74s    3.8%  6.89ms   15.9MiB   18.5%  41.0KiB
   Boundary Exchange      398    1.18s    1.6%  2.96ms   26.5MiB   30.8%  68.1KiB
 CFL                      199    1.91s    2.6%  9.60ms   8.82MiB   10.2%  45.4KiB
 User defined function    199    182μs    0.0%   915ns     0.00B    0.0%    0.00B
 ────────────────────────────────────────────────────────────────────────────────
</code></pre></div>
<h1 dir="auto">
<a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example</h1>
<p dir="auto">The user interface of the Ananke is inherited from <a href="https://github.com/MHDFlows/MHDFlows.jl"><code>MHDFlows.jl</code></a> and they share most of the workflow.
<a href="https://github.com/MHDFlows/Ananke-Example">Few Examples </a>  were set to illustrate the workflow of performing 1D/2D/3D simulation and its visualization.</p>
</article></div>