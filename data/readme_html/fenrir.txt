<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><h1 dir="auto"><a id="user-content-fenrir-physics-enhanced-regression-for-ivps" class="anchor" aria-hidden="true" href="#fenrir-physics-enhanced-regression-for-ivps"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Fenrir: Physics-Enhanced Regression for IVPs</h1>
<p dir="auto"><a href="https://nathanaelbosch.github.io/Fenrir.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="Stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width: 100%;"></a>
<a href="https://nathanaelbosch.github.io/Fenrir.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="Dev" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width: 100%;"></a>
<a href="https://github.com/nathanaelbosch/Fenrir.jl/actions/workflows/CI.yml?query=branch%3Amain"><img src="https://github.com/nathanaelbosch/Fenrir.jl/actions/workflows/CI.yml/badge.svg?branch=main" alt="Build Status" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/nathanaelbosch/Fenrir.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/2bd7d80ba50c958e08064b60a7aedf23e5ee7a59279e93a6756c051bf51045ff/68747470733a2f2f636f6465636f762e696f2f67682f6e617468616e61656c626f7363682f46656e7269722e6a6c2f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/nathanaelbosch/Fenrir.jl/branch/main/graph/badge.svg" style="max-width: 100%;"></a></p>
<p dir="auto">This package exports a single function, <code>fenrir_nll</code>:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="    fenrir_nll(prob::ODEProblem, data::NamedTuple{(:t, :u)}, observation_noise_var::Real,
        diffusion_var::Union{Real,Vector{&lt;:Real}};
        adaptive=false, dt=false,  proj=I, order=3::Int, tstops=[])

Compute the &quot;Fenrir&quot; approximate negative log-likelihood (NLL) of the data."><pre class="notranslate"><code>    fenrir_nll(prob::ODEProblem, data::NamedTuple{(:t, :u)}, observation_noise_var::Real,
        diffusion_var::Union{Real,Vector{&lt;:Real}};
        adaptive=false, dt=false,  proj=I, order=3::Int, tstops=[])

Compute the "Fenrir" approximate negative log-likelihood (NLL) of the data.
</code></pre></div>
<p dir="auto">To see the full docstring, check out the
<a href="https://nathanaelbosch.github.io/Fenrir.jl/stable" rel="nofollow">documentation</a>.</p>
<h3 dir="auto"><a id="user-content-minimal-example-parameter-likelihood-on-fitzhugh-nagumo" class="anchor" aria-hidden="true" href="#minimal-example-parameter-likelihood-on-fitzhugh-nagumo"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Minimal example: Parameter likelihood on FitzHugh-Nagumo</h3>
<div class="highlight highlight-source-julia notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="using ProbNumDiffEq, Plots, LinearAlgebra, Fenrir

# Define problem:
function f(du, u, p, t)
    a, b, c = p
    du[1] = c*(u[1] - u[1]^3/3 + u[2])
    du[2] = -(1/c)*(u[1] -  a - b*u[2])
end
u0 = [-1.0, 1.0]
tspan = (0.0, 20.0)
p = (0.2, 0.2, 3.0)
prob = ODEProblem(f, u0, tspan, p)

# Generate data:
true_sol = solve(prob, EK1())
times = 1:0.1:20
odedata = [u + 0.1*randn(size(u)) for u in true_sol(times).u.μ]
scatter(times, ProbNumDiffEq.stack(odedata), markersize=2, markerstrokewidth=0.1,
        color=1, label=[&quot;Data&quot; &quot;&quot;])

# With the wrong parameters:
pwrong = (0.1, 0.1, 2.0)
solwrong = solve(remake(prob, p=pwrong), EK1(smooth=false), dense=false);
plot!(solwrong, color=2, label=[&quot;Wrong solution&quot; &quot;&quot;])

# Fenrir:
data = (t=times, u=odedata);
σ² = 1e-1
κ² = 1e30
nll, ts, states = fenrir_nll(remake(prob, p=pwrong), data, σ², κ²)

means = ProbNumDiffEq.stack([x.μ for x in states]);
stddevs = ProbNumDiffEq.stack([sqrt.(diag(x.Σ)) for x in states]);

plot!(ts, means, ribbon=2stddevs,
      marker=:o, markersize=1, markerstrokewidth=0.1,
      color=3, fillalpha=0.1, label=[&quot;Fenrir interpolation&quot; &quot;&quot;])

println(&quot;Negative log-likelihood: $nll&quot;)"><pre><span class="pl-k">using</span> ProbNumDiffEq, Plots, LinearAlgebra, Fenrir

<span class="pl-c"><span class="pl-c">#</span> Define problem:</span>
<span class="pl-k">function</span> <span class="pl-en">f</span>(du, u, p, t)
    a, b, c <span class="pl-k">=</span> p
    du[<span class="pl-c1">1</span>] <span class="pl-k">=</span> c<span class="pl-k">*</span>(u[<span class="pl-c1">1</span>] <span class="pl-k">-</span> u[<span class="pl-c1">1</span>]<span class="pl-k">^</span><span class="pl-c1">3</span><span class="pl-k">/</span><span class="pl-c1">3</span> <span class="pl-k">+</span> u[<span class="pl-c1">2</span>])
    du[<span class="pl-c1">2</span>] <span class="pl-k">=</span> <span class="pl-k">-</span>(<span class="pl-c1">1</span><span class="pl-k">/</span>c)<span class="pl-k">*</span>(u[<span class="pl-c1">1</span>] <span class="pl-k">-</span>  a <span class="pl-k">-</span> b<span class="pl-k">*</span>u[<span class="pl-c1">2</span>])
<span class="pl-k">end</span>
u0 <span class="pl-k">=</span> [<span class="pl-k">-</span><span class="pl-c1">1.0</span>, <span class="pl-c1">1.0</span>]
tspan <span class="pl-k">=</span> (<span class="pl-c1">0.0</span>, <span class="pl-c1">20.0</span>)
p <span class="pl-k">=</span> (<span class="pl-c1">0.2</span>, <span class="pl-c1">0.2</span>, <span class="pl-c1">3.0</span>)
prob <span class="pl-k">=</span> <span class="pl-c1">ODEProblem</span>(f, u0, tspan, p)

<span class="pl-c"><span class="pl-c">#</span> Generate data:</span>
true_sol <span class="pl-k">=</span> <span class="pl-c1">solve</span>(prob, <span class="pl-c1">EK1</span>())
times <span class="pl-k">=</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">0.1</span><span class="pl-k">:</span><span class="pl-c1">20</span>
odedata <span class="pl-k">=</span> [u <span class="pl-k">+</span> <span class="pl-c1">0.1</span><span class="pl-k">*</span><span class="pl-c1">randn</span>(<span class="pl-c1">size</span>(u)) <span class="pl-k">for</span> u <span class="pl-k">in</span> <span class="pl-c1">true_sol</span>(times)<span class="pl-k">.</span>u<span class="pl-k">.</span>μ]
<span class="pl-c1">scatter</span>(times, ProbNumDiffEq<span class="pl-k">.</span><span class="pl-c1">stack</span>(odedata), markersize<span class="pl-k">=</span><span class="pl-c1">2</span>, markerstrokewidth<span class="pl-k">=</span><span class="pl-c1">0.1</span>,
        color<span class="pl-k">=</span><span class="pl-c1">1</span>, label<span class="pl-k">=</span>[<span class="pl-s"><span class="pl-pds">"</span>Data<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>])

<span class="pl-c"><span class="pl-c">#</span> With the wrong parameters:</span>
pwrong <span class="pl-k">=</span> (<span class="pl-c1">0.1</span>, <span class="pl-c1">0.1</span>, <span class="pl-c1">2.0</span>)
solwrong <span class="pl-k">=</span> <span class="pl-c1">solve</span>(<span class="pl-c1">remake</span>(prob, p<span class="pl-k">=</span>pwrong), <span class="pl-c1">EK1</span>(smooth<span class="pl-k">=</span><span class="pl-c1">false</span>), dense<span class="pl-k">=</span><span class="pl-c1">false</span>);
<span class="pl-c1">plot!</span>(solwrong, color<span class="pl-k">=</span><span class="pl-c1">2</span>, label<span class="pl-k">=</span>[<span class="pl-s"><span class="pl-pds">"</span>Wrong solution<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>])

<span class="pl-c"><span class="pl-c">#</span> Fenrir:</span>
data <span class="pl-k">=</span> (t<span class="pl-k">=</span>times, u<span class="pl-k">=</span>odedata);
σ² <span class="pl-k">=</span> <span class="pl-c1">1e-1</span>
κ² <span class="pl-k">=</span> <span class="pl-c1">1e30</span>
nll, ts, states <span class="pl-k">=</span> <span class="pl-c1">fenrir_nll</span>(<span class="pl-c1">remake</span>(prob, p<span class="pl-k">=</span>pwrong), data, σ², κ²)

means <span class="pl-k">=</span> ProbNumDiffEq<span class="pl-k">.</span><span class="pl-c1">stack</span>([x<span class="pl-k">.</span>μ <span class="pl-k">for</span> x <span class="pl-k">in</span> states]);
stddevs <span class="pl-k">=</span> ProbNumDiffEq<span class="pl-k">.</span><span class="pl-c1">stack</span>([<span class="pl-c1">sqrt</span>.(<span class="pl-c1">diag</span>(x<span class="pl-k">.</span>Σ)) <span class="pl-k">for</span> x <span class="pl-k">in</span> states]);

<span class="pl-c1">plot!</span>(ts, means, ribbon<span class="pl-k">=</span><span class="pl-c1">2</span>stddevs,
      marker<span class="pl-k">=</span><span class="pl-c1">:o</span>, markersize<span class="pl-k">=</span><span class="pl-c1">1</span>, markerstrokewidth<span class="pl-k">=</span><span class="pl-c1">0.1</span>,
      color<span class="pl-k">=</span><span class="pl-c1">3</span>, fillalpha<span class="pl-k">=</span><span class="pl-c1">0.1</span>, label<span class="pl-k">=</span>[<span class="pl-s"><span class="pl-pds">"</span>Fenrir interpolation<span class="pl-pds">"</span></span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>])

<span class="pl-c1">println</span>(<span class="pl-s"><span class="pl-pds">"</span>Negative log-likelihood: <span class="pl-v">$nll</span><span class="pl-pds">"</span></span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="./docs/src/readmedemo.svg?raw=true"><img src="./docs/src/readmedemo.svg?raw=true" alt="README Demo" title="README Demo" style="max-width: 100%;"></a></p>
<p dir="auto">Prints: <code>Negative log-likelihood: 5849.3096741464615</code></p>
<p dir="auto">You can use this NLL it as any other NLL:
Optimize it to compute maximum-likelihood estimates or MAPs,
or plug it into MCMC to sample from the posterior.
In <a href="https://arxiv.org/abs/2202.01287" rel="nofollow">our paper</a> we compute MLEs by pairing Fenrir with <a href="http://optimization.sciml.ai/stable/" rel="nofollow">Optimization.jl</a> and <a href="https://juliadiff.org/ForwardDiff.jl/stable/" rel="nofollow">ForwardDiff.jl</a>.
Check out the <a href="https://nathanaelbosch.github.io/Fenrir.jl/stable/" rel="nofollow">documentation</a> for more details on how to do this.</p>
<h2 dir="auto"><a id="user-content-reference" class="anchor" aria-hidden="true" href="#reference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Reference</h2>
<p dir="auto">This method has been developed in the paper "Fenrir: Physics-Enhanced Regression for Initial Value Problems" by Tronarp et al, published at ICML 2022 (<a href="https://proceedings.mlr.press/v162/tronarp22a.html" rel="nofollow">link</a>).</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="
@InProceedings{pmlr-v162-tronarp22a,
  title = 	 {Fenrir: Physics-Enhanced Regression for Initial Value Problems},
  author =       {Tronarp, Filip and Bosch, Nathanael and Hennig, Philipp},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {21776--21794},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/tronarp22a/tronarp22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/tronarp22a.html}
}"><pre class="notranslate"><code>
@InProceedings{pmlr-v162-tronarp22a,
  title = 	 {Fenrir: Physics-Enhanced Regression for Initial Value Problems},
  author =       {Tronarp, Filip and Bosch, Nathanael and Hennig, Philipp},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {21776--21794},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/tronarp22a/tronarp22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/tronarp22a.html}
}
</code></pre></div>
</article></div>