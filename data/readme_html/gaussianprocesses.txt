<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-gaussianprocessesjl" class="anchor" aria-hidden="true" href="#gaussianprocessesjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>GaussianProcesses.jl</h1>
<p><a href="https://travis-ci.org/STOR-i/GaussianProcesses.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/0996a12957aeb5189337250380555e5baa9f8bb8/68747470733a2f2f7472617669732d63692e6f72672f53544f522d692f476175737369616e50726f6365737365732e6a6c2e706e67" alt="Build Status" data-canonical-src="https://travis-ci.org/STOR-i/GaussianProcesses.jl.png" style="max-width:100%;"></a>
<a href="https://ci.appveyor.com/project/STOR-i/gaussianprocesses-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/00645d5ef0dd95b88d82ac138dff2bb604751a9f/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f53544f522d692f476175737369616e50726f6365737365732e6a6c3f6272616e63683d6d6173746572267376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/STOR-i/GaussianProcesses.jl?branch=master&amp;svg=true" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/STOR-i/GaussianProcesses.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/0bfc71a7106459d8ad06eae8b5f9eaa4611708ba/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f53544f522d692f476175737369616e50726f6365737365732e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/STOR-i/GaussianProcesses.jl/badge.svg?branch=master" style="max-width:100%;"></a>
<a href="https://codecov.io/gh/STOR-i/GaussianProcesses.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/da6004566104b93c051dddccddf3bb8f43563ea6/68747470733a2f2f636f6465636f762e696f2f67682f53544f522d692f476175737369616e50726f6365737365732e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/STOR-i/GaussianProcesses.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></p>
<p><a href="http://STOR-i.github.io/GaussianProcesses.jl/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/f7b92a177c912c1cc007fc9b40f17ff3ee3bb414/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a></p>
<p>A Gaussian Processes package for Julia.</p>
<p>This package is still under development. If you have any suggestions to improve the package, or if you've noticed a bug, then please post an <a href="https://github.com/STOR-i/GaussianProcesses.jl/issues/new">issue</a> for us and we'll get to it as quickly as we can. Pull requests are also welcome.</p>
<h2><a id="user-content-citing-gaussianprocessesjl" class="anchor" aria-hidden="true" href="#citing-gaussianprocessesjl"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Citing GaussianProcesses.jl</h2>
<p>To cite GaussianProcesses.jl, please reference the <a href="https://arxiv.org/abs/1812.09064" rel="nofollow">arXiv paper</a>. Sample Bibtex is given below:</p>
<pre><code>@article{gaussianprocesses.jl,
  title={GaussianProcesses. jl: A Nonparametric Bayes package for the Julia Language},
  author={Fairbrother, Jamie and Nemeth, Christopher and Rischard, Maxime and Brea, Johanni and Pinder, Thomas},
  journal={arXiv preprint arXiv:1812.09064},
  year={2018}
}
</code></pre>
<h2><a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Introduction</h2>
<p>Gaussian processes are a family of stochastic processes which provide a flexible nonparametric tool for modelling data. A Gaussian Process places a prior over functions, and can be described as an infinite dimensional generalisation of a multivariate Normal distribution. Moreover, the joint distribution of any finite collection of points is a multivariate Normal. This process can be fully characterised by its mean and covariance functions, where the mean of any point in the process is described by the <em>mean function</em> and the covariance between any two observations is specified by the <em>kernel</em>. Given a set of observed real-valued points over a space, the Gaussian Process is used to make inference on the values at the remaining points in the space.</p>
<p>For an extensive review of Gaussian Processes there is an excellent book <a href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf" rel="nofollow">Gaussian Processes for Machine Learning</a> by Rasmussen and Williams, (2006)</p>
<h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<p>GaussianProcesses.jl requires Julia version 0.7 or above. To install GaussianProcesses.jl run the following command inside a Julia session:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Pkg
julia<span class="pl-k">&gt;</span> Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>GaussianProcesses<span class="pl-pds">"</span></span>)</pre></div>
<h2><a id="user-content-functionality" class="anchor" aria-hidden="true" href="#functionality"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Functionality</h2>
<p>The package allows the user to fit exact <strong>Gaussian process</strong> models when the observations are Gaussian distributed about the latent function. In the case where the <em>observations are non-Gaussian</em>, the posterior distribution of the latent function is intractable. The package allows for Monte Carlo sampling from the posterior.</p>
<p>The main function of the package is <code>GP</code>, which fits the Gaussian process</p>
<div class="highlight highlight-source-julia"><pre>gp <span class="pl-k">=</span> <span class="pl-c1">GP</span>(x, y, mean, kernel)
gp <span class="pl-k">=</span> <span class="pl-c1">GP</span>(x, y, mean, kernel, likelihood)</pre></div>
<p>for Gaussian and non-Gaussian data respectively.</p>
<p>The package has a number of <em>mean</em>, <em>kernel</em> and <em>likelihood</em> functions available. See the documentation for further details.</p>
<h3><a id="user-content-inference" class="anchor" aria-hidden="true" href="#inference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Inference</h3>
<p>The parameters of the model can be estimated by maximizing the log-likelihood (where the latent function is integrated out) using the <code>optimize!</code> function, or in the case of <em>non-Gaussian data</em>, an <code>mcmc</code> function is available, utilizing the Hamiltonian Monte Carlo sampler. In addition to a HMC sampler, it is possible to sample from the posterior using an elliptical slice sampler, provided that the data exhibits a Gaussian likelihood. Finally, for fast, yet approximate inference in the case of Poisson data, a variational approximation can be used to infer the model parameters and latent function values.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">optimize!</span>(gp)    <span class="pl-c"><span class="pl-c">#</span> Find parameters which maximize the log-likelihood</span>
<span class="pl-c1">mcmc</span>(gp)         <span class="pl-c"><span class="pl-c">#</span> Sample from the GP posterior</span>
<span class="pl-c1">ess</span>(gp)          <span class="pl-c"><span class="pl-c">#</span> Sample from the GP posterior using an elliptical slice sampler</span>
<span class="pl-c1">vi</span>(gp)           <span class="pl-c"><span class="pl-c">#</span> Create a variational approximation</span></pre></div>
<p>See the <a href="https://github.com/STOR-i/GaussianProcesses.jl/tree/master/notebooks">notebooks</a> for examples of the functions used in the package.</p>
<h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Documentation</h2>
<p>Documentation is accessible in the Julia REPL in help mode. Help mode can be started by typing '?' at the prompt.</p>
<pre><code>julia&gt; ?GP
search: GP GPE GPMC GPBase gperm log1p getpid getproperty MissingException

  GP(x, y, mean::Mean, kernel::Kernel[, logNoise::Float64=-2.0])

  Fit a Gaussian process that is defined by its mean, its kernel, and the
  logarithm logNoise of the standard deviation of its observation noise to a
  set of training points x and y.

  See also: GPE

  ────────────────────────────────────────────────────────────────────────────

  GP(x, y, mean::Mean, kernel::Kernel, lik::Likelihood)

  Fit a Gaussian process that is defined by its mean, its kernel, and its
  likelihood function lik to a set of training points x and y.

  See also: GPA
</code></pre>
<p>Alternatively, <a href="http://stor-i.github.io/GaussianProcesses.jl/latest/index.html" rel="nofollow">online documentation</a> and is under development</p>
<h2><a id="user-content-notebooks" class="anchor" aria-hidden="true" href="#notebooks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Notebooks</h2>
<p>Sample code is available from the <a href="https://github.com/STOR-i/GaussianProcesses.jl/tree/master/notebooks">notebooks</a></p>
<h2><a id="user-content-related-packages" class="anchor" aria-hidden="true" href="#related-packages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Related packages</h2>
<p><a href="https://github.com/juliohm/GeoStats.jl">GeoStats</a> - High-performance implementations of geostatistical algorithms for the Julia programming language. This package is in its initial development, and currently only contains Kriging estimation methods. More features will be added as the Julia type system matures.</p>
<h2><a id="user-content-scikitlearn" class="anchor" aria-hidden="true" href="#scikitlearn"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>ScikitLearn</h2>
<p>This package also supports the <a href="https://github.com/cstjean/ScikitLearn.jl">ScikitLearn</a> interface. ScikitLearn provides many tools for machine learning such as hyperparameter tuning and cross-validation. See <a href="https://github.com/cstjean/ScikitLearn.jl/blob/master/examples/Gaussian_Processes_Julia.ipynb">here</a> for an example of its usage with this package.</p>
</article></div>