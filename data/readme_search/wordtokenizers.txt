wordtokenizers basic tokenizers natural language processing installation standard julia package pkg add usage normal call tokenize str split string words sentences maybe configurable functions sentence splitters defined sensible defaults set override method calling tokenizer func splitter passing preferred function list elsewhere configuring throw overwritten warning trigger recompilation methods means using tokenization splitting via default changing change behavior feature corpusloaders author don allow user explicitly example setting tinysegmenter japanese text include trivial import print substring word basically assume poorman poormans deletes punctuation splits spaces worse space marginally improved version occurring outside penn robert macintyre original treebank contractions nltk similar improvements matches treebankwordtokenizer unicode handling changes commonly minus tokenizing step weird historical successive variations improving matching reversible rev detokenize punctuations special symbols generated tokens tokenized detokenizer toktok simple input line final period enhanced tested reasonably results english persian russian czech french german vietnamese tajik tweet casual solely designed tweets apart twitter specific emoticons web aspects support html entities closely tweettokenizer currently rule based spitter rulebased periods question marks exclamation followed white exceptions exported alias useful implemented atm range complex leatherback sea turtle largest measuring six seven feet length maturity five width weighing pounds species proportionally wide flatback found northerncoast australia element array northern coast experimental api trying added dispatches base foo tokenbuffer custom offer supporting utility lexers speed writing readable stream building span class read characters return true false indicate matched combined easily spacesornumber skips whitespace parses token simplest isdone character tokenise bar baz prewritten components src fast mixed create url phonenumbers tokeinze urls continue generic phonenumber detected phone tips lexer written care match boundserror errors edge common flush push buffer flushed separate pattern continuous idx hello hihello statistical sentencepiece unigram encoder processor implementation vocab file library containing log probability detail refer blog post note escapes meta symbol pretrained wordtokenizer provides albert subtypes pretrainedtokenizer tokenizerfiles clean xlarge xxlarge datadeps handle downloading issue models directly load providing path spm loading sentencepiecemodel dict shots dev silv doubtful pol chem disrespect love subword unfriendly friendly para level performance dynamic technical computing ulia indices usually deep learning index pad unk cls sep mask ids int contributing contributions form bug reports pull requests additional documentation encouraged github repository follow colprac guide collaborative practices contributor communications abide community standards software prevailing style code request issues getting responses days hesitate bump posting comment update status sometimes notifications lost feel free help discourse forum channel slack join raise