neuralprocesses framework composing neural processes built top flux juliacon link video process family code reproduce image experiments convolutional conditional gordon contents introduction predefined experimental setup train manual principles available models regression building blocks data generators training evaluation examples attentive package implementation details setting meta learning concerned map sets directly predictive distributions powerful class parametrisations based encoding eager started file contains immediately example julia project model convcnp matern loss loglik epochs usage num samples batch size starting epoch evaluate dir bson optional arguments set mixture noisy weakly periodic sawtooth append conv corconvcnp global mean sum introduce latent variable amortised observation noise het heterogeneous estimate defaults elbo type int default continue force importance weighting objective task interpolation range directory store specify save load help message exit consists encoder decoder takes produces abstract representation prediction target inputs functional representations coding objects common particular represented function tuple corresponds indices decoding collectively call transformations functions implemented transforms context express desire output maps indeed operation called complete hand partial encoders decoders coders composed simpler compositional coder design using chain parallel useful multiple encodings multi headed architecture split processed heads splitter head combined concatenation channel dimension materialise section readily extended additional designs likelihoods deterministic stochastic achieved appending likelihood deterministiclikelihood heterogeneousgaussianlikelihood run sampled resulting sample fed scenarios outputs desirable concatenate tensor prepending heterogenousgaussian means variances test exports constructors architectures literature name constructor reference cnp garnelo rosenbaum schwarz acnp kim mnih anp bruinsma convnp foong gaussian requeima download links pretrained instructions follows extract tar xzvf experiment lowers uppers predict randn float random results provides various compose easily construct block information obtained layernorm glue description sequence basic batchedmlp batched mlp batchedconv build cnn channels layer normalisation meanpooling pooling sumpooling advanced attention mechanism setconv convolution setconvpd kernel fixedgaussianlikelihood fixed variance amortisedgaussianlikelihood calculated input dependent functionalcoder space discretisation uniformdiscretisation discretise uniformly density inputscoder mlpcoder rho phi trained callables integer batches iterator generates tuples tensors rank feature third constructed datagenerator underlying stheno addition following bayesianconvnp prior weights experimentation functionality exported running forward calling convenience runs vector lower upper credible bounds amongst requires optimiser described optimisers found applications adam probably suffices evaluated eval losses biased log expected exact style alternative saving loading current five saved written determined keyword loaded path simplest cnps employ provide simple finite dimensional concatenated object achieve inputsencoder simply locations form deep network receives mlps construction pre post dim hidden embedding layers chained materialises concatenates passes standard deviation location combine summation multiplicative flows considered pass dimensionality plus twice require automatically splits treats half distribution predictions extend adding enables nps capture joint marginal allows producing coherent extending neuralprocceses extremely easy replace component adjust produce change replacing increase accordingly main required switch reuse previously defined note typical consider increasing repo include emphasise ease switching complicated demonstrate implement anps considering comes deploy aggregates separate iii represent transformer embeds applies dimensionalities desired div account final key difference terms encodes infinite handled neuralpeocesses expect indicates exactly instead unit span minimal maximal margin discretised length scale inter spacing reproducing hilbert rkhs ensures injective true receptive field currently port academic support tasks plan add images changes carefully tests components tested coverage near gpu performance crucial documentation improved automatic differentiation tracker compute gradients custom src util parameter handling functors handle parameters adheres abstractarray else scalars array wrap unwrap runtime acceleration cuda depthwise separable convolutions depthwiseconv loop fusion cause issues oftentimes computations unrolled