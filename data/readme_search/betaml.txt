beta machine learning toolkit simple repository algorithms started implementing julia language concepts taught mitx python linear models deep course note bear affiliation theoretical notes describing companion focus library skewed user friendliness computational efficiency code relatively easy read implementation core external libraries little bit numpy heavily optimised gpu supported excellent mature support huge datasets organise complex partially automated pipelines please consider packages section alternative simplicity functions pretty explicit names usual example dense layer denselayer rbf kernel radialkernel etc didn aim heavy optimisation able api application programming interface beginner friendly flexible contrary established methods provide reasonable defaults overridden neural network optimiser verbosity level loss function implement subtype abstract type algorithm optimisationalgorithm specify distance metric clustering kmedoids fast hard job multithreaded using matrix operations underlying reasonably exploratory tasks mid size analysis basically holds memory documentation refer package stable dev inline system press question mark special help prompt module name distinct extensively commented tutorial covers reference manual covering currently implemented following modules betaml perceptron based classifiers trees decision random forests networks kmean kmenoids expectation maximisation missing value imputation utils looking introductory book look quick syntax apress easily employing juliacall pyjulia respectively getting examples learn relation floral sepals petal measures columns specie column famous iris flower dataset supervised third unsupervised classification delimitedfiles readdlm joinpath dirname base test data csv skipstart xtrain xtest ytrain ytest partition dropdims dims myforest buildforest train predict trainaccuracy accuracy testaccuracy artificial multinomial categorisation load statsplots main ausiliary seed fix obtain reproducible results shuffle axes records aren default convert array float map dict setosa versicolor virginica target onehotencoder hot representation split training testing sets false ntrain ntest define model relu activation identity vectorfunctionlayer softmax add parameterless defined nodes mynn buildnetwork squaredcost logistic regression sepal build squared cost aka mse error crossentropy adam res scale epochs batchsize optalg sgd stochastic gradient descent instead scaling tol visualise testsize testchosen argmax groupedbar label est title true estimated categories correctly labelled plot ylabel xlabel legend avg epoch normalise dimensions ranges minvariance mincovariance minvarrange collect mincovarrange run gmm various sphout mixtures sphericalgaussian none diagout diagonalgaussian fullout fullgaussian bayesian information criterion aic available sphbic bic length diagbic fullbic compare sphacc ignorelabels diagacc fullacc markershape circle sph diag cov accuracies advanced techniques improve predictions provided opposite micro usage studied unit tests folder category toolkits scikitlearn automlpipeline mlj flux knet decisiontree gaussianmixtures impute todo short term utility hyper parameter tuning cross validation convolutional layers rnn reinforcement markov processes contribute contributions welcome particularly covered list didactic research documented highly reason fine verbose issue discuss ideas directly pull request required means customising writing subclassing abstractlayer sampler abstractdatasampler mixture component abstractmixture community integrate citations cite lobianco self contained journal source software article doi joss url publisher volume pages author antonello acknowledgements development bureau economie orique appliqu nancy french national agency laboratory excellence arbre investissements avenir program anr labx