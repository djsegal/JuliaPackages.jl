beta machine learning toolkit simple package including algorithms utilities implement workflows julia python language binding currently following models available betaml name mlj interface category perceptronclassifier linearperceptron supervised classifier kernelperceptronclassifier kernelperceptron pegasosclassifier pegasos decisiontreeestimator decisiontreeclassifier decisiontreeregressor regressor randomforestestimator randomforestclassifier randomforestregressor neuralnetworkestimator neuralnetworkregressor multitargetneuralnetworkregressor neuralnetworkclassifier gmmregressor gaussianmixtureregressor multitargetgaussianmixtureregressor kmeansclusterer kmeans unsupervised hard clusterer kmedoidsclusterer kmedoids gmmclusterer gaussianmixtureclusterer soft featurebasedimputer simpleimputer missing data imputer gmmimputer gaussianmixtureimputer rfimputer randomforestimputer universalimputer generalimputer minmaxscaler transformer standardscaler scaler pca dimensionality reduction onehotencoder ordinalencoder confusionmatrix predictions assessment theoretical notes describing companion repository implemented entirely hosted wrapper third party favorite option model try pull request share section contribute implementation issue thanks jit compiler indeed sweet spot easily write level running efficiently documentation please refer inline system press question mark special help prompt type module function distinct extensively commented tutorial covers library reference manual covering api looking introductory material look book quick syntax apress online course scientific programming employing juliacall pyjulia respectively relevant examples using artificial neural network multinomial categorisation example train networks predict specie column floral sepals petals measures columns famous iris flower dataset load modules delimitedfiles random pipe plots auxiliary seed fix obtain reproducible results readdlm joinpath dirname base test csv skipstart convert array float string encode categories levels separate aka hot encoding ohmod fit split training testing sets xtrain xtest ytrain ytest partition ntrain ntest size define denselayer relu activation identity default vectorfunctionlayer softmax add parameterless layer defined nodes mynn layers loss crossentropy descr logistic regression sepal batch epochs build cross entropy error swith auto tuning autotune true adam optimizer res scaled ground observations inverse note scaling reverse functions accuracy analyse performances print betamlmodel fitted confusion matrix scores actual rows predicted labels virginica versicolor setosa normalised report misclassification rate classes class precision recall specificity score count tpr tnr support avg weigthed info lossperepoch plot length ylabel xlabel legend title epoch heatmap cgrad white blue advanced techniques improve provided basic micro usage various studied unit tests folder limitations alternative packages focus skewed user friendliness computational efficiency code relatively easy read heavily optimised operate cpu fits memory suggest specialised list toolkits pipelines scikitlearn automlpipeline flux knet decision trees decisiontree clustering gaussianmixtures imputation impute todo short term autotuning bic aic silhouette method check cluster validity pam variants mid rnn convolutional speed reinforcement markov processes contributions welcome particularly covered consider didactic research documented reasonable defaults highly reason fine verbose names discuss ideas directly required means customising writing subclassing abstractlayer sampler abstractdatasampler mixture component abstractmixture community integrate citations cite lobianco self contained journal source software article doi joss url publisher volume pages author antonello acknowledgements development bureau economie orique appliqu nancy supported french national agency laboratory excellence arbre investissements avenir program anr labx