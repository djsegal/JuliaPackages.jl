parquet reader file dataset loaded using read function directory multiple files partition belonging path kwargs returns table contained tables compatible format options rows row range iterate default applicable reading single filter apply loading subset partitions provided parameter batchsize maximum batch count applied threads julia switched processes started column generator generate partitioned found parameters index length implementation determines values returned object converted forms dataframes dataframe via iterated iterator method lower level load metadata initially data chunks demand note parquetfiles provides support fileio package represents handle holds weakly referenced cache page references required closed anymore close closes releases makes cached internal structures available instance filename customer impala parquetfile version nrows created build fccbff examine schema ncols colnames element array string custkey name address nationkey phone acctbal mktsegment comment optional int byte double performs logical type conversions automatically arrays decimals fixed datetime depends populated correctly detect care map types argument value names tuple return converter functon supported implementations included mapping dict interpret based following methods timestamp offset dates timestamps converts strings represented vector uint decimal precision scale float true len integer depending variants custom caller batchedcolumnscursor create cursor batches iteration named nested schemas reusebuffer boolean indicate reuse buffers refer buffer setting reduces pressure help significantly processing example typemap batched columns cols batchvals propertynames union missing recordcursor records parallel mode remote cursors retrieve record collect isa namedtuple ivhziaperb writer write accessible contains bool categoricalarray furthermore date tbl rand randstring boolm false stringm abc def ghi tempname