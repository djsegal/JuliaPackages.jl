protograd experimental julia package gradient based model optimization including course deep learning aims simple composable flexible progress playground ideas don expect feature completeness stability builds top mature popular libraries zygote automatic differentiation nnlib providing common operators check examples folder construct train models following readme feeling philosophy begins naturally using callable objects type extends abstract overly example defines linear version struct linearmodel attributes interpreted parameters optimized gradients respect assumed numerical arrays abstractarray abstractfloat functions tuple types note means hyper paramenters stored hyperparameters implicit structure layers units otherwise value defined vector space free randn scaled sum dot syntax assignment loop fusion products linearalgebra objective training usually amounts optimizing function principle custom mean squared error yhat size data artificially generated according random noisy original define returns stochastic approximations implemented iterating batches coupling loss follows statsbase batch forever idx sample replace false return supervisedobjective evaluating yield time computation computing easy grad val evaluated contains importantly object added subtracted fitting algorithms relatively plain descent constant stepsize fit copy verify compared implements form iterators iterations optimizer gradientdescent iterator looped elements inspected decide stop sake compactness output iteration solution