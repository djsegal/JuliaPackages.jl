protograd experimental julia package gradient based model optimization including course deep learning aims simple composable flexible progress playground ideas don expect feature completeness stability builds top mature popular libraries zygote automatic differentiation nnlib providing common operators check examples folder construct train models following readme feeling philosophy begins naturally using callable objects type extends abstract overly example defines linear version struct linearmodel attributes interpreted parameters optimized gradients respect assumed numerical arrays abstractarray abstractfloat functions tuple types note means hyper paramenters stored hyperparameters implicit structure layers units otherwise value defined vector space free randn scaled sum main dot syntax assignment loop fusion products linearalgebra objective training usually amounts optimizing function principle custom mean squared error yhat size generic method data artificially generated according random noisy original define returns loss stochastic approximations implemented iterating batches coupling follows statsbase batch forever idx sample replace false return supervisedobjective typeof base generator iterators repeated var matrix float evaluating yield println time computation computing easy grad val evaluated contains importantly object added subtracted fitting algorithms relatively plain descent constant stepsize fit copy warning soft scope ambiguous global variable name exists treated local disambiguate suppress assign existing string verify compared implements form iterations optimizer gradientdescent gradientdescentiterable iterator looped elements inspected decide stop sake compactness output iteration solution page literate