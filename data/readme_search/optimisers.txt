optimisers defines standard gradient based optimisation rules tools applying deeply nested models future training flux neural networks lux separately array else understood functors installation add usage core idea optimiser momentum explicitly handled initialised setup step update returns model trainable parameters adjusted adam grad zygote loss layers containing similarly tree using explicit style shown implicit params function destructure collects vector build similar documentation explains detail describes optimization define ones