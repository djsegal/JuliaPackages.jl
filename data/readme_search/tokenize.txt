tokenize julia package serves similar purpose api module python string buffer containing code perform lexical analysis return stream tokens goals fast currently lexes source files million round trippable original recoverable exactly error throwing instead errors token returned tokenization function main entrypoint generating takes creates iterator sequentially argument iobuffer iostream collect keyword whitespace identifier lparen rparen endmarker represented starts contains type exported startpos tuple int row column start endpos startbyte byte offset endbyte untokenize representation exactkind exact difference returns operators keywords unique tok rightwards double arrow seen kinds file