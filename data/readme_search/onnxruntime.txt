onnxruntime provides inofficial julia bindings exposes low level interface mirrors official api contributions welcome usage follows import path testdatapath increment onnx toy model load inference input dict randn float string matrix entry output gpu simply pkg add cuda execution provider offical example looks using capi getapi env createenv name myenv createsessionoptions session createsession mem createcpumemoryinfo array tensor createtensorwithdataasortvalue vec size run options createrunoptions names inputs outputs gettensormutabledata alternatives python via pycall onnxnaivenasflux