autograd automatic differentiation package julia started port popular python forms foundation knet deep learning framework differentiate regular code includes loops conditionals helper functions closures etc keeping track primitive operations using execution trace compute gradients reverse mode backpropagation efficiently handle array inputs scalar outputs derivatives installation install pkg add start interface param user declares parameters wrapped struct value original sum abs act values outside diff represents grad contains params pre supported following example linear regression callable objects defines model initialize object randn sgd training loop data loss axpy examples directory extending function primitives zerograd macros log macro marks method expression gradient wrt argument expressions refer parameter return variable optionally indicated list declaration multiple existent zero specified omitting default broadcasting version defined don note supports dispatch methods supporting types float bigfloat independently specific rules generic debugging profiling view contents computational graph differentiating gcnode node lost rand displaying causes pretty printing broadcast collect creates dump maxdepth allowing look individual nodes result parents children outgrad cdr func type typeof args tuple kwargs base iterators pairs union namedtuple itr profile timeroutputs set environment env timer true rebuild build evaluating checked compile time run performance reasons detailed timing information slows forget delete symbol indicates spent forward pass backward record outgrads internal reset allocations tot measured mib section ncalls avg alloc kib structure core implements main functionality acts documentation source support define test getindex iterate cat common structures including arrays tuples dictionaries numerical files math current status future coverage unit testing spotty adding tests cover improved overwriting setindex efficiency reducing runtime compilation memoization static computation acknowledgments references written deniz yuret initially ported thank author dougal maclaurin baydin review tutorial phd thesis design principles juliadiff fluxml alternative tools contributors carlo lucibello ekin aky rek emre yolcu jarrett revels mike innes ozan arkan rene donner suggested citation inproceedings mlsys title beginning lines booktitle machine systems workshop nips