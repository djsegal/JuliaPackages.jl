invertiblenetworks documentation build status building blocks invertible neural networks julia programming language memory efficient hand derived gradients jacobians log flux integration support zygote chainrules gpu includes various examples normalizing flows variational inference uncertainty quantification installation dev papers following publications preconditioned training inverse paper presentation code fastapproximateinference parameterizing deep application reservoir characterization generalized minkowski sets regularization setintersectionprojection convolutions using householder transformations example residual block coupling layer dinh hyperbolic lensink putzky welling recursive hint kruse activation normalization kingma dhariwal functions sigmoid relu leaky galu objective misfit mean squared error likelihood dimensionality manipulation squeeze unsqueeze column patch checkerboard split cat wavelet transform recurrent machines generic generative models maximum via change variable formula glow flow source supported cuarray move input network batchsize image randn float actnorm logdet true test invertibility forward acknowledgments package nnlib wavelets references yann dauphin angela fan michael auli david grangier modeling gated convolutional proceedings international conference machine learning laurent jascha sohl dickstein samy bengio density estimation real nvp representations diederik prafulla information processing systems keegan eldad haber bas peters arxiv computer vision pattern recognition patrick max invert learn advances jakob gianluca detommaso robert scheichl ullrich hierarchical transport bayesian statistics authors philipp witte microsoft corporation pwitte com gabrio rizzuti utrecht university mathias louboutin georgia institute technology ali siahkoohi