namedplus package exists experiment arrays provided nameddims fairly minimal focused providing type performance defines lots useful functions defined packages loaded convenient add names exports named nameless pirate base rand int keywords ones zeros fill parent adds refines existing ellipsisnotation skip read generator variables rename renames transpose controlled split reshape size join copy adjacent dropdims defaults kills permutes hack code propagate namedint etc sqrt comprehensions via sizes using einsum tensorcast dont array undef cast automatic dimensions align sum prod lazy generalised permutedims auto permuted broadcasting manually fix reduce including matrix multiplication mul contract batchmul shared index typed tab tensoroperations indices leaving infix version odot tensor inputs arranged strided omeinsum const batch zygote gradient bits moved axiskeys plots custom ranges scatter ans yaxis log labels axes series try hard zero cost exploit constant propagation true particluar faster aligned nearly free compared pytorch tensors refine except instead unflatten exactly flatten dims consecutive mine required allows target subset superset neither input support torch matmul handles batched