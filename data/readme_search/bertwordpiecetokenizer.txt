bertwordpiecetokenizer load bert wordpiece tokenizer installation julia using pkg add usage initialize import bwp local file init path vocab txt lowercase true false http url cache vocabulary tokenize initializing text encode tokens apples token ids segment truncation specify max length strategy enable post pre benchmark timeit uncased loops loop pure python keras tokenizers lower mean std dev runs rust binding encoding num attributes type offsets attention mask special overflowing