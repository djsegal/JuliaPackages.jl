stackednets provides simple interface deep stacks neural network units trained using gradient descent defined error measures consist layers stacked top layer output feed stack activation functions currently supported include exponential linear rectified sigmoid softmax softplus tanh activations able compute diagonal jacobian terms computes differentials unit respect inputs incorporates values backpropagation algorithm means model depends input question squared cross entropy designed relatively easy write add source code time pass custom call level support dropout visible hidden training added future ability save load models main priority develop flexible clean api specify train prediction hopefully reasonably performant cpu based framework calls blas routines adding gpu compatibility target development specifying constructed list specifies stackednet example feeding define follows note object corresponds defaults type specified typically desirable alternatively complicated following constructing lists float parameters outputs sub class julia floatingpoint primary imagine keyword function errors stochastic minibatches randomly sampled set replacement classifying mnist digits check script multinomial logistic classifier complex feedforward trains classify handwritten digit classes data