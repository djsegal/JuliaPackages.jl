mljflux interface flux deep learning models mlj machine framework branch julia cpu gpu coverage master dev makes apply meta algorithms provided sample performance evaluation hyper parameter optimization classes supervised providing guiding vision package evaluating optimizing basic convenient users familiar workflow goal restrictions class medium term example online enforcement adversarial networks currently scope idea model builder hyperparameter object encoding instructions creating neural network data eventually classification simple default define builders results require familiarity api defining chain future provide larger assortment canned pull requests introducing ones welcome installation using pkg activate environment shared true add rdatasets demo following introductory standardization input features notebook script implementing stopping snapshots iteratedmodel wrapper mnist dataset loading instantiating import iris datasets unpack species colname rng neuralnetworkclassifier load clf short hidden dropout nnlib finaliser softmax optimiser adam iddict loss crossentropy epochs batch size lambda alpha changes trigger retraining false incremental training random seed mach fit cross entropy predict mean increasing rate adding iterations eta verbosity info updating accessing fitted params dense float evolution range lower upper scale log curve resampling holdout fraction train measure plots plot values measurements xlab name xscale ylab mutable struct storing hyperparameters algorithm indicated particular store learned parameters warning meaning objects call chains restrict sense provides types targets scientific type table refer information passed described prediction scitype neuralnetworkregressor deterministic continuous columns abstractvector multitargetneuralnetworkregressor probabilistic finite imageclassifier image output tabular abstractmatrix abstractfloat xmat forced replacing furthermore wrapping subsequent unwrapping hood compile includes support sparse matrix implementation optimized time caution coercing common formats warm restart machines cache enabling demonstrated changed ignored comparison allows dynamically modify rates associated feature criteria defined earlystopping examples handled controlling arbitrary iterative specify acceleration cudalibs copied onto cached conclusion available built box linear builds connected layer inputs outputs activation function defaulting relu nodes specified applied final layers geometric relate share regressors classifiers mse regularization strength mix fitting scratch whenever additional operation unnormalized obtain probabilities summing return vector length definition method mynetwork int build note depend concrete means sub typing signatures channels instance subject conditions array integer returned functions internally conform supply classifier constructors expanded version six alternating convolution max pool generic color gray helper flatten abstractarray reshape myconvbuilder filter mod error odd padding preserve div compute dims maxpool half conv pad check images labels grayimage count target element fix coerce multiclass accuracy set evaluate mode misclassification measurement fold