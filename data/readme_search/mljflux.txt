mljflux interface flux deep learning models mlj machine framework branch julia cpu gpu coverage master dev makes apply meta algorithms provided sample performance evaluation hyper parameter optimization iteration control classes supervised providing guiding vision package evaluating optimizing basic convenient users familiar workflow goal restrictions class medium term example online enforcement adversarial networks currently scope limited training data fits memory idea model builder hyperparameter object encoding instructions creating neural network eventually classification simple default define builders results require familiarity api defining chain future provide larger assortment canned pull requests introducing ones welcome installation using pkg activate environment shared true add rdatasets demo plots following introductory standardization input features notebook script implementing stopping snapshots iteratedmodel wrapper mnist dataset loading instantiating import iris datasets unpack species colname rng neuralnetworkclassifier load clf short hidden dropout nnlib finaliser softmax optimiser adam iddict loss crossentropy epochs batch size lambda alpha changes trigger retraining false incremental random seed mach fit cross entropy predict mean increasing rate adding iterations eta verbosity info updating trained times caches args source table abstractvector continuous multiclass accessing fitted params dense float evolution range lower upper scale log curve resampling holdout fraction train measure plot values measurements xlab name xscale ylab mutable struct storing hyperparameters algorithm indicated particular store learned parameters warning meaning objects call chains restrict sense provides types targets scientific type channels refer information passed described prediction scitype neuralnetworkregressor deterministic columns multitargetneuralnetworkregressor probabilistic finite imageclassifier image output tabular abstractmatrix abstractfloat xmat forced replacing furthermore wrapping subsequent unwrapping hood compile includes support sparse matrix implementation optimized time caution coercing common formats warm restart machines cache enabling demonstrated changed ignored comparison allows dynamically modify rates associated feature criteria defined earlystopping examples handled controlling arbitrary iterative specify acceleration cudalibs copied onto cached conclusion available generators reproducibility purposes weight initialization abstractrng integer mersennetwister reset cold mechanism layers manually global isa additionally cuda built box query doc strings advanced options details description linear relu vanilla activation function sigmoid connected layer mlp multi perceptron share regressors classifiers mse regularization strength mix generator intitialization fitting scratch whenever additional operation applied unnormalized final obtain probabilities outputs summing return vector length nodes definition method mybuilder int build init glorot uniform note depend concrete means sub typing signatures instance subject conditions array returned alternatively net automatically create valid expression symbols appear literally interpretations explained tanh functions specified internally conform supply classifier constructors expanded version builds six alternating convolution max pool generic color gray mldatasets helper flatten abstractarray reshape myconvbuilder filter mod error odd padding preserve div front conv pad maxpool outputsize check xraw yraw traindata unknown count inputs element grayimage coerce target accuracy set evaluate mode misclassification measurement fold section mainly developers assumes subtypes mljfluxprobabilistic mljfluxdeterministic instead methods mljmodelinterface update fallbacks level shape fitresult code implement