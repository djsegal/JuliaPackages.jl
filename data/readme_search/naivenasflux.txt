naivenasflux naivenaslib enable mutation operations arbitrary flux computation graphs designed neural architecture search nas mind purpose changes model desired following supported change input output size layers parameter pruning including methods rank neurons add remove inputs note functionality check naivegaflux simple proof concept basic usage verbose examples quick rundown common type channels image invertex inputvertex fluxconv mutable conv pad batchnorm nout relu explore graph test outputs nin layertype isa fluxbatchnorm naming vertices idea debugging logging purposes namedconv name concatenate activations conc concat residualconv elementwise addition operation metadata evaluation compgraph evaluated function ones float copied graphcopy copy mutate layer insert kernel supply padding weights kernelsizealigned apply mutations parameters changed lazy default created btw course unaffected built policies cool stuff example trained xor boilerplate create training using import train mse random seed niters layerfun activationcontribution wrap compute metric trains mdense outsize act dense fluxdense sigmoid original params opt adam loss data truth table iter try prune hidden nprune randomly selected pruned rand org valuable according neuron value free lunch please calculated actually atol toy efficiently fit losses logitbinarycrossentropy glorot uniform statistics mconv init mavgpool meanpool height width nconv invariantvertex flatten identity return agg mean ish class matrices true bool vcat hcat joke generates false negatives generate batch catbatch tuple cat dims batchsize mapfoldl startloss didn scratch disclaimer experiment intended library meant evidence method option hyperparameters tuned strongly favor avoid sporadic failures idmapping initialized mapping basically potential guaranteed relies existing provide gradient diversity deepcopy contributing contributions welcome file issue creating